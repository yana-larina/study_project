{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nc3PWKvGUSiA",
    "outputId": "a8aea6b9-aa04-41d2-d46a-6331e985c69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.29.3.tar.gz (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 1.9 MB/s \n",
      "\u001b[?25hCollecting scikit-learn==0.24.2\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.5)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.3)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 64.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
      "Collecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
      "\u001b[K     |████████████████████████████████| 263 kB 71.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
      "Collecting syntok==1.3.3\n",
      "  Downloading syntok-1.3.3-py3-none-any.whl (22 kB)\n",
      "Collecting seqeval==0.0.19\n",
      "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
      "Collecting transformers==4.10.3\n",
      "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 59.4 MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 61.6 MB/s \n",
      "\u001b[?25hCollecting keras_bert>=0.86.0\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[K     |████████████████████████████████| 468 kB 51.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->ktrain) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->ktrain) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->ktrain) (1.21.5)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.8.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from syntok==1.3.3->ktrain) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 52.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.3->ktrain) (4.63.0)\n",
      "Collecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 71.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.3->ktrain) (4.11.3)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 49.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.3->ktrain) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.3->ktrain) (3.10.0.2)\n",
      "Collecting keras-transformer==0.40.0\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "Collecting keras-pos-embd==0.13.0\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "Collecting keras-multi-head==0.29.0\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "Collecting keras-layer-normalization==0.16.0\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "Collecting keras-position-wise-feed-forward==0.8.0\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "Collecting keras-embed-sim==0.10.0\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "Collecting keras-self-attention==0.51.0\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.3->ktrain) (3.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.3->ktrain) (7.1.2)\n",
      "Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ktrain: filename=ktrain-0.29.3-py3-none-any.whl size=25295410 sha256=f101eecd93ac0cc4aae72d66b0a162e74a148cf40b7dd641482f1937b708d794\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/d5/2a/1a1826e16685841c68a43c31c8a892452b105f9467f64e49e6\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9931 sha256=256b3880fcc529e30d86675d6b9c67318da681440d54b72365f2169214583da0\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=6131c1fd0c1d62c2ed5f47ca437dd91c5af566ed204c330b6ed792ab7d2fd199\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/e8/45/842b3a39831261aef9154b907eacbc4ac99499a99ae829b06f\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=5ac697ae3159759f855e888e97040077ea8afaa6e1b30b7d62effa69483c31ca\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/68/26/692ed21edd832833c3b0a0e21615bcacd99ca458b3f9ed571f\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=4ca33539f8433d7e58b336f6f85a73156820f2d6a80c14778004a14ce7c18ee8\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/67/b5/d847588d075895281e1cf5590f819bd4cf076a554872268bd5\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=cc2f36eca06417e9a0ab5f9998c56b977a7ceb6e14a306ed853a93ea3cd346a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/5d/1c/2e619f594f69fbcf8bc20943b27d414871c409be053994813e\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=ed0a39ccb82b9cd2bab65ca43a6127097f3203886f9a531cb12bebd4bea5afd6\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=f5c6aa7afab738b265fef2fbbf96f23ffabc010bf462ddef9b7199e663ced838\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/c1/a0/dc44fcf68c857b7ff6be9a97e675e5adf51022eff1169b042f\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=d56cde656058411c1cadef12ab9b09d4bb5f640a83ca6405475671da8d37f660\n",
      "  Stored in directory: /root/.cache/pip/wheels/c2/75/6f/d42f6e051506f442daeba53ff1e2d21a5f20ef8c411610f2bb\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=aeb0766d0d2df8a6bec2a9c09439d2b7743e5d4836f7638aebd08a14205a0fe5\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=12e0011781b0598d82ef317a4d3ceb359e0d36fffc269c4f7f06ffe24403558a\n",
      "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect\n",
      "Installing collected packages: keras-self-attention, pyyaml, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, sacremoses, keras-transformer, huggingface-hub, whoosh, transformers, syntok, seqeval, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
      "Successfully installed cchardet-2.1.7 huggingface-hub-0.4.0 keras-bert-0.89.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 ktrain-0.29.3 langdetect-1.0.9 pyyaml-6.0 sacremoses-0.0.49 scikit-learn-0.24.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.3 tokenizers-0.10.3 transformers-4.10.3 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4CF7d1HUncO"
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "from ktrain import tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-oI-OZlUqkC"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# plt\n",
    "import matplotlib.pyplot as plt\n",
    "#увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "#графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNe7tO-OUvm6"
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "BATCH_SIZE  = 8\n",
    "EPOCH       = 1\n",
    "VAL_SPLIT   = 0.3\n",
    "LR = 2e-5\n",
    "\n",
    "# TOKENIZER\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_WORDS = 1000\n",
    "# Max number of words in each complaint.\n",
    "MAXLEN    = 500#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ1UNZBgUvp_"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 800)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9RlFQu6AUvs2",
    "outputId": "eababda3-549b-461a-b92e-ed398bab1622"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-da1a76fd-1221-4155-8c97-2d795e536d2c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>claps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>23</td>\n",
       "      <td>https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Understanding Variational Autoencoders (VAEs) | by Joseph Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 24, 2019\\nThis post was co-written with Baptiste Rocca.\\nIn the last few years, deep learning based generative models have gained more and more interest due to (and implying) some amazing improvements in the field. Relying on huge amount of data, well-designed networks architectures and smart training techniques, deep generative models have shown an incredible ability to produce highly realistic pieces of content of various kind, such as images, texts and sounds. Among these deep generative models, two major families stand out and deserve a special attention: Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs).\\nIn a previous post, published in January of this year, we discussed in depth Generative Adversarial Networks (GANs) and showed,...</td>\n",
       "      <td>8300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guido Vivaldi</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/using-mixed-effects-models-for-linear-regression-7b7941d249b?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Using Mixed-Effects Models For Linear Regression | by Guido Vivaldi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 17, 2019\\nMixed-effects regression models are a powerful tool for linear regression models when your data contains global and group-level trends. This article walks through an example using fictitious data relating exercise to mood to introduce this concept. R has had an undeserved rough time in the news lately, so this post will use R as a small condolence to the language, though a robust framework exist in Python as well.\\nMixed-effect models are common in political polling analysis where national-level characteristics are assumed to occur at a state-level while state-level sample sizes may be too small to drive those characteristics on their own. They are also common in scientific experiments where a given effect is assumed to be present among all study ind...</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jerry Chen</td>\n",
       "      <td>11</td>\n",
       "      <td>https://news.greylock.com/the-new-moats-53f61aeac2d9?source=tag_archive---------9-----------------------</td>\n",
       "      <td>The New Moats. Why Systems of IntelligenceTM are the... | by Jerry Chen | Greylock Perspectives</td>\n",
       "      <td>Greylock Perspectives\\nApr 24, 2017\\nTo build a sustainable and profitable business, you need strong defensive moats around your company. This rings especially true today as we undergo one of the largest platform shifts in a generation as applications move to the cloud, are consumed on iPhones, Echoes, and Teslas, are built on open source, and are fueled by AI and data. These dramatic shifts are rendering some existing moats useless and leaving CEOs feeling like it’s almost impossible to build a defensible business.\\nIn this post, I’ll review some of the traditional economic moats that technology companies typically leverage and how they are being disrupted. I believe that startups today need to build systems of intelligenceTM — AI powered applications — “the new moats.”\\nBusinesses ca...</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sambasivarao. K</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Region of Interest Pooling. A Technique which allowed a new... | by Sambasivarao. K | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 22, 2019\\nThe major hurdle for going from image classification to object detection is fixed size input requirement to the network because of existing fully connected layers. In object detection, each proposal will be of a different shape. So there is a need for converting all the proposals to fixed shape as required by fully connected layers. ROI Pooling is exactly doing this.\\nRegion of Interest (ROI) pooling is used for utilising single feature map for all the proposals generated by RPN in a single pass. ROI pooling solves the problem of fixed image size requirement for object detection network.\\nROI pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of...</td>\n",
       "      <td>334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ryan Sander</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/modern-gaussian-process-regression-9c5196ca87ab?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Modern Gaussian Process Regression | by Ryan Sander | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 24, 2021\\nEver wonder how you can create non-parametric supervised learning models with unlimited expressive power? Look no further than Gaussian Process Regression (GPR), an algorithm that learns to make predictions almost entirely from the data itself (with a little help from hyperparameters). Combining this algorithm with recent advances in computing, such as automatic differentiation, allows for applying GPRs to solve a variety of supervised machine learning problems in near-real-time.\\nIn this article, we’ll discuss:\\nThis is the second article in my GPR series. For a rigorous, Ab initio introduction to Gaussian Process Regression, please check out my previous article here.\\nBefore we dive into how we can implement and use GPR, let’s quickly review the me...</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>3751</td>\n",
       "      <td>Nerves Foundation</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/nerves-foundation/nerves-gold-month-of-exchanges-listed-on-at-least-an-exchange-every-week-6463ca9f32b0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Nerves: “Gold Month of Exchanges” — listed on at least an exchange every week | by Nerves Foundation | Nerves Foundation | Medium</td>\n",
       "      <td>Nerves Foundation\\nSep 21, 2018\\nDear Nervesians,\\nToday is probably a special day for the developers and investors of Nerves as we are bringing to you a great news, a very special announcement: NER will be listed at least one exchange with large traders and big volume each week in the next whole month (up to at least 4 exchanges within next month). The first one in the series will list NER next week and we will make announcement on this exchange as soon as possible.\\nThe development team is doing everything possible to bring NER to a higher level, we have proceeded all the necessary steps to develop NER in the short, medium and long term. Your support and enthusiasm is our greatest motivation\\nWish the community of Nerves will grow stronger and stronger. A lot of great news is ahead i...</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>3752</td>\n",
       "      <td>Alexandre Xavier</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/neuronio/an-introduction-to-convlstm-55c9025563a7?source=tag_archive---------3-----------------------</td>\n",
       "      <td>An introduction to ConvLSTM. Nowadays it is quite common to find... | by Alexandre Xavier | Neuronio | Medium</td>\n",
       "      <td>Neuronio\\nMar 25, 2019\\nNote: a Portuguese version of this article is available here\\nNowadays it is quite common to find data in the form of a sequence of images. The most typical example is video at social networks such as YouTube, Facebook or Instagram. Other examples are:\\nThis article will introduce how to use sequences of images as input to a neural network model in a classification problem using ConvLSTM and Keras.\\nData collected over successive periods of time are characterised as a Time Series. In such cases, an interesting approach is to use a model based on LSTM (Long Short Term Memory), a Recurrent Neural Network architecture. In this kind of architecture, the model passes the previous hidden state to the next step of the sequence. Therefore holding information on previous...</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>3753</td>\n",
       "      <td>Luís Gonçalves</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/luisfredgs/automatic-text-summarization-made-simple-with-python-f9c3c645e34a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Automatic Text Summarization Made Simple | luisfredgs</td>\n",
       "      <td>luisfredgs\\nApr 19, 2020\\nSummarization condenses a longer document into a short version while retaining core information. When this is done through a computer, we call it Automatic Text Summarization. This process can be seen as a form of compression, and it inevitably suffers from information loss, but it is essential to tackle the information overload due to abundance of textual material available on the internet, which...\\n144 \\n144 \\n1\\nThis blog is about Machine Learning, Deep Learning, Data Mining, Statistics, Programming Languages, and related areas.\\n312 Followers\\nMachine Learning Researcher and PhD candidate in Computer Science at Universidade Federal de Pernambuco, Brazil.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>3754</td>\n",
       "      <td>Syed Sadat Nazrul</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multinomial-naive-bayes-classifier-for-text-analysis-python-8dd6825ece67?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Multinomial Naive Bayes Classifier for Text Analysis (Python) | by Syed Sadat Nazrul | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 9, 2018\\nOne of the most popular applications of machine learning is the analysis of categorical data, specifically text data. Issue is that, there are a ton of tutorials out there for numeric data but very little for texts. Considering how most of my past blogs on Machine Learning were based on Scikit-Learn, I decided to have some fun with this one by implementing the whole thing on my own.\\nIn this blog, I will cover how you can implement a Multinomial Naive Bayes Classifier for the 20 Newsgroups dataset. The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a me...</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>3755</td>\n",
       "      <td>Neha Tripathi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@nehatripathii/dropping-out-is-not-sexy-802b3852b16?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Dropping Out Is Not Sexy!. Hey, | by Neha Tripathi | Medium</td>\n",
       "      <td>Jun 27, 2021\\nHey,\\nI am Neha, I dropped out of the MPhil program in 2019 and this is my story of constant struggle since then.\\nI completed my MA in Psycho-Social Clinical Studies back in 2018 and I wanted to learn more.\\nMy imagination of the next step was always interdisciplinary. A little bit of economics, political science, and of course- psychology.\\nAlso, in early 2018 I felt the need to take a break to figure out certain things about myself.\\nTherefore, further education and break were conflicting ideas in my head which bothered me for the longest time.\\nUnfortunately, I ignored the conflict and went ahead with the higher education journey.\\nOnce you become a Delhi person, imagining a life without the city becomes difficult. At least, for me, the Delhi times were extremely impo...</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3756 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da1a76fd-1221-4155-8c97-2d795e536d2c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-da1a76fd-1221-4155-8c97-2d795e536d2c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-da1a76fd-1221-4155-8c97-2d795e536d2c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        id             author  reading_time  \\\n",
       "0        0       Joseph Rocca            23   \n",
       "1        1      Guido Vivaldi             6   \n",
       "2        2         Jerry Chen            11   \n",
       "3        3    Sambasivarao. K             4   \n",
       "4        4        Ryan Sander            10   \n",
       "...    ...                ...           ...   \n",
       "3751  3751  Nerves Foundation             1   \n",
       "3752  3752   Alexandre Xavier             6   \n",
       "3753  3753   Luís Gonçalves             4   \n",
       "3754  3754  Syed Sadat Nazrul             7   \n",
       "3755  3755      Neha Tripathi             4   \n",
       "\n",
       "                                                                                                                                                                                link  \\\n",
       "0                                        https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73?source=tag_archive---------4-----------------------   \n",
       "1                                    https://towardsdatascience.com/using-mixed-effects-models-for-linear-regression-7b7941d249b?source=tag_archive---------9-----------------------   \n",
       "2                                                                           https://news.greylock.com/the-new-moats-53f61aeac2d9?source=tag_archive---------9-----------------------   \n",
       "3                                                         https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af?source=tag_archive---------0-----------------------   \n",
       "4                                                 https://towardsdatascience.com/modern-gaussian-process-regression-9c5196ca87ab?source=tag_archive---------7-----------------------   \n",
       "...                                                                                                                                                                              ...   \n",
       "3751  https://medium.com/nerves-foundation/nerves-gold-month-of-exchanges-listed-on-at-least-an-exchange-every-week-6463ca9f32b0?source=tag_archive---------8-----------------------   \n",
       "3752                                                        https://medium.com/neuronio/an-introduction-to-convlstm-55c9025563a7?source=tag_archive---------3-----------------------   \n",
       "3753                             https://medium.com/luisfredgs/automatic-text-summarization-made-simple-with-python-f9c3c645e34a?source=tag_archive---------2-----------------------   \n",
       "3754                     https://towardsdatascience.com/multinomial-naive-bayes-classifier-for-text-analysis-python-8dd6825ece67?source=tag_archive---------4-----------------------   \n",
       "3755                                                      https://medium.com/@nehatripathii/dropping-out-is-not-sexy-802b3852b16?source=tag_archive---------3-----------------------   \n",
       "\n",
       "                                                                                                                                  title  \\\n",
       "0                                                Understanding Variational Autoencoders (VAEs) | by Joseph Rocca | Towards Data Science   \n",
       "1                                            Using Mixed-Effects Models For Linear Regression | by Guido Vivaldi | Towards Data Science   \n",
       "2                                       The New Moats. Why Systems of IntelligenceTM are the... | by Jerry Chen | Greylock Perspectives   \n",
       "3                            Region of Interest Pooling. A Technique which allowed a new... | by Sambasivarao. K | Towards Data Science   \n",
       "4                                                            Modern Gaussian Process Regression | by Ryan Sander | Towards Data Science   \n",
       "...                                                                                                                                 ...   \n",
       "3751  Nerves: “Gold Month of Exchanges” — listed on at least an exchange every week | by Nerves Foundation | Nerves Foundation | Medium   \n",
       "3752                      An introduction to ConvLSTM. Nowadays it is quite common to find... | by Alexandre Xavier | Neuronio | Medium   \n",
       "3753                                                                              Automatic Text Summarization Made Simple | luisfredgs   \n",
       "3754                        Multinomial Naive Bayes Classifier for Text Analysis (Python) | by Syed Sadat Nazrul | Towards Data Science   \n",
       "3755                                                                        Dropping Out Is Not Sexy!. Hey, | by Neha Tripathi | Medium   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0     Towards Data Science\\nSep 24, 2019\\nThis post was co-written with Baptiste Rocca.\\nIn the last few years, deep learning based generative models have gained more and more interest due to (and implying) some amazing improvements in the field. Relying on huge amount of data, well-designed networks architectures and smart training techniques, deep generative models have shown an incredible ability to produce highly realistic pieces of content of various kind, such as images, texts and sounds. Among these deep generative models, two major families stand out and deserve a special attention: Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs).\\nIn a previous post, published in January of this year, we discussed in depth Generative Adversarial Networks (GANs) and showed,...   \n",
       "1     Towards Data Science\\nMay 17, 2019\\nMixed-effects regression models are a powerful tool for linear regression models when your data contains global and group-level trends. This article walks through an example using fictitious data relating exercise to mood to introduce this concept. R has had an undeserved rough time in the news lately, so this post will use R as a small condolence to the language, though a robust framework exist in Python as well.\\nMixed-effect models are common in political polling analysis where national-level characteristics are assumed to occur at a state-level while state-level sample sizes may be too small to drive those characteristics on their own. They are also common in scientific experiments where a given effect is assumed to be present among all study ind...   \n",
       "2     Greylock Perspectives\\nApr 24, 2017\\nTo build a sustainable and profitable business, you need strong defensive moats around your company. This rings especially true today as we undergo one of the largest platform shifts in a generation as applications move to the cloud, are consumed on iPhones, Echoes, and Teslas, are built on open source, and are fueled by AI and data. These dramatic shifts are rendering some existing moats useless and leaving CEOs feeling like it’s almost impossible to build a defensible business.\\nIn this post, I’ll review some of the traditional economic moats that technology companies typically leverage and how they are being disrupted. I believe that startups today need to build systems of intelligenceTM — AI powered applications — “the new moats.”\\nBusinesses ca...   \n",
       "3     Towards Data Science\\nApr 22, 2019\\nThe major hurdle for going from image classification to object detection is fixed size input requirement to the network because of existing fully connected layers. In object detection, each proposal will be of a different shape. So there is a need for converting all the proposals to fixed shape as required by fully connected layers. ROI Pooling is exactly doing this.\\nRegion of Interest (ROI) pooling is used for utilising single feature map for all the proposals generated by RPN in a single pass. ROI pooling solves the problem of fixed image size requirement for object detection network.\\nROI pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of...   \n",
       "4     Towards Data Science\\nMar 24, 2021\\nEver wonder how you can create non-parametric supervised learning models with unlimited expressive power? Look no further than Gaussian Process Regression (GPR), an algorithm that learns to make predictions almost entirely from the data itself (with a little help from hyperparameters). Combining this algorithm with recent advances in computing, such as automatic differentiation, allows for applying GPRs to solve a variety of supervised machine learning problems in near-real-time.\\nIn this article, we’ll discuss:\\nThis is the second article in my GPR series. For a rigorous, Ab initio introduction to Gaussian Process Regression, please check out my previous article here.\\nBefore we dive into how we can implement and use GPR, let’s quickly review the me...   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "3751  Nerves Foundation\\nSep 21, 2018\\nDear Nervesians,\\nToday is probably a special day for the developers and investors of Nerves as we are bringing to you a great news, a very special announcement: NER will be listed at least one exchange with large traders and big volume each week in the next whole month (up to at least 4 exchanges within next month). The first one in the series will list NER next week and we will make announcement on this exchange as soon as possible.\\nThe development team is doing everything possible to bring NER to a higher level, we have proceeded all the necessary steps to develop NER in the short, medium and long term. Your support and enthusiasm is our greatest motivation\\nWish the community of Nerves will grow stronger and stronger. A lot of great news is ahead i...   \n",
       "3752  Neuronio\\nMar 25, 2019\\nNote: a Portuguese version of this article is available here\\nNowadays it is quite common to find data in the form of a sequence of images. The most typical example is video at social networks such as YouTube, Facebook or Instagram. Other examples are:\\nThis article will introduce how to use sequences of images as input to a neural network model in a classification problem using ConvLSTM and Keras.\\nData collected over successive periods of time are characterised as a Time Series. In such cases, an interesting approach is to use a model based on LSTM (Long Short Term Memory), a Recurrent Neural Network architecture. In this kind of architecture, the model passes the previous hidden state to the next step of the sequence. Therefore holding information on previous...   \n",
       "3753                                   luisfredgs\\nApr 19, 2020\\nSummarization condenses a longer document into a short version while retaining core information. When this is done through a computer, we call it Automatic Text Summarization. This process can be seen as a form of compression, and it inevitably suffers from information loss, but it is essential to tackle the information overload due to abundance of textual material available on the internet, which...\\n144 \\n144 \\n1\\nThis blog is about Machine Learning, Deep Learning, Data Mining, Statistics, Programming Languages, and related areas.\\n312 Followers\\nMachine Learning Researcher and PhD candidate in Computer Science at Universidade Federal de Pernambuco, Brazil.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "3754  Towards Data Science\\nApr 9, 2018\\nOne of the most popular applications of machine learning is the analysis of categorical data, specifically text data. Issue is that, there are a ton of tutorials out there for numeric data but very little for texts. Considering how most of my past blogs on Machine Learning were based on Scikit-Learn, I decided to have some fun with this one by implementing the whole thing on my own.\\nIn this blog, I will cover how you can implement a Multinomial Naive Bayes Classifier for the 20 Newsgroups dataset. The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a me...   \n",
       "3755  Jun 27, 2021\\nHey,\\nI am Neha, I dropped out of the MPhil program in 2019 and this is my story of constant struggle since then.\\nI completed my MA in Psycho-Social Clinical Studies back in 2018 and I wanted to learn more.\\nMy imagination of the next step was always interdisciplinary. A little bit of economics, political science, and of course- psychology.\\nAlso, in early 2018 I felt the need to take a break to figure out certain things about myself.\\nTherefore, further education and break were conflicting ideas in my head which bothered me for the longest time.\\nUnfortunately, I ignored the conflict and went ahead with the higher education journey.\\nOnce you become a Delhi person, imagining a life without the city becomes difficult. At least, for me, the Delhi times were extremely impo...   \n",
       "\n",
       "       claps  \n",
       "0     8300.0  \n",
       "1      336.0  \n",
       "2     3500.0  \n",
       "3      334.0  \n",
       "4      128.0  \n",
       "...      ...  \n",
       "3751   169.0  \n",
       "3752   768.0  \n",
       "3753   144.0  \n",
       "3754   523.0  \n",
       "3755    62.0  \n",
       "\n",
       "[3756 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/kaggle/articles/articles_train.csv').drop_duplicates().dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42CGFGutUAnB",
    "outputId": "dfeae1b5-3e2d-412c-9390-386c0d06a8ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train: 3394 rows x 5 columns\n",
      "['claps']\n",
      "    claps\n",
      "0  8300.0\n",
      "2  3500.0\n",
      "3   334.0\n",
      "4   128.0\n",
      "5  2300.0\n",
      "processing test: 362 rows x 5 columns\n",
      "['claps']\n",
      "     claps\n",
      "1    336.0\n",
      "11    55.0\n",
      "33     0.0\n",
      "34  1000.0\n",
      "43   632.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ktrain/utils.py:612: UserWarning: Task is being treated as REGRESSION because either class_names argument was not supplied or is_regression=True. If this is incorrect, change accordingly.\n",
      "  'either class_names argument was not supplied or is_regression=True. ' + \\\n"
     ]
    }
   ],
   "source": [
    "trn, val, preproc = tabular.tabular_from_df(data[['author','reading_time','title','text','claps']], is_regression=True,\n",
    "                                             label_columns='claps', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GK0H_tXUAsK",
    "outputId": "069a0ba6-f671-4059-e3b8-4135002bcfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = tabular.tabular_regression_model('mlp', trn)\n",
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihrjOg6SUAux",
    "outputId": "0c4b68ee-c40b-4604-e7be-372f7fb61807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 0.03...\n",
      "Epoch 1/15\n",
      "425/425 [==============================] - 17s 21ms/step - loss: 21808726.0000 - mae: 1517.9561 - val_loss: 18530172.0000 - val_mae: 1305.2335\n",
      "Epoch 2/15\n",
      "425/425 [==============================] - 7s 16ms/step - loss: 18190378.0000 - mae: 1386.3844 - val_loss: 13591858.0000 - val_mae: 991.2791\n",
      "Epoch 3/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 15402510.0000 - mae: 1212.4176 - val_loss: 8099903.0000 - val_mae: 869.2274\n",
      "Epoch 4/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 12372488.0000 - mae: 1080.4542 - val_loss: 8081481.0000 - val_mae: 872.1168\n",
      "Epoch 5/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 8460878.0000 - mae: 919.4960 - val_loss: 6247198.5000 - val_mae: 791.8099\n",
      "Epoch 6/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 10410556.0000 - mae: 950.3327 - val_loss: 6473057.0000 - val_mae: 814.6786\n",
      "Epoch 7/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 8737158.0000 - mae: 885.5300 - val_loss: 3155008.2500 - val_mae: 654.7162\n",
      "Epoch 8/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 9220247.0000 - mae: 906.9780 - val_loss: 3021836.7500 - val_mae: 652.3462\n",
      "Epoch 9/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 5641775.0000 - mae: 827.3931 - val_loss: 3439140.7500 - val_mae: 726.3530\n",
      "Epoch 10/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 12128299.0000 - mae: 900.5352 - val_loss: 6295217.0000 - val_mae: 786.7527\n",
      "Epoch 11/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 7905140.0000 - mae: 903.8506 - val_loss: 9640529.0000 - val_mae: 821.5460\n",
      "Epoch 12/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 9325451.0000 - mae: 879.1575 - val_loss: 3801122.0000 - val_mae: 706.8232\n",
      "Epoch 13/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 7223454.0000 - mae: 845.1210 - val_loss: 3323595.0000 - val_mae: 699.5427\n",
      "Epoch 14/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 7536191.5000 - mae: 802.2094 - val_loss: 2516873.2500 - val_mae: 646.2809\n",
      "Epoch 15/15\n",
      "425/425 [==============================] - 4s 10ms/step - loss: 7282238.5000 - mae: 811.4489 - val_loss: 3832493.5000 - val_mae: 689.0587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa772fcded0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(0.03, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAmmiBR-VQ6S"
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gKNzKHIyY6Wv",
    "outputId": "ca85ab02-3849-4652-99f2-11451111476f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4c2fd3ba-33b1-4e1e-8c46-ae5e9256a332\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3756</td>\n",
       "      <td>Rohit Thakur</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/step-by-step-r-cnn-implementation-from-scratch-in-python-e97101ccde55?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Step-by-Step R-CNN Implementation From Scratch In Python | by Rohit Thakur | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 18, 2019\\nClassification and object detection are the main parts of computer vision. Classification is finding what is in an image and object detection and localisation is finding where is that object in that image. Detection is a more complex problem to solve as we need to find the coordinates of the object in an image.\\nTo Solve this problem R-CNN was introduced by Ross Girshick, Jeff Donahue, Trevor Darrell and Jitendra Malik in 2014. R-CNN stands for Regions with CNN. In R-CNN instead of running classification on huge number of regions we pass the image through selective search and select first 2000 region proposal from the result and run classification on that. In this way instead of classifying huge number of regions we need to just classify first 2000 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3757</td>\n",
       "      <td>Giuliano Giacaglia</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/transformers-141e32e69591?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How Transformers Work. Transformers are a type of neural... | by Giuliano Giacaglia | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 11, 2019\\nIf you liked this post and want to learn how machine learning algorithms work, how did they arise, and where are they going, I recommend the following:\\nwww.holloway.com\\nTransformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in their language models, and also used recently by DeepMind for AlphaStar — their program to defeat a top professional Starcraft player.\\nTransformers were developed to solve the problem of sequence transduction, or neural machine translation. That means any task that transforms an input sequence to an output sequence. This includes speech recognition, text-to-speech transformation, etc..\\nFor models to perform sequence transduction, it is necessary to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3758</td>\n",
       "      <td>Darshan Adakane</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3759</td>\n",
       "      <td>Sachin Palewar</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@palewar/amazons-artificial-artificial-intelligence-a5d89253184e?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Amazon’s Artificial Artificial Intelligence | by Sachin Palewar | Medium</td>\n",
       "      <td>Nov 21, 2005\\nToday, we build complex software applications based on the things computers do well, such as storing and retrieving large amounts of information or rapidly performing calculations. However, humans still significantly outperform the most powerful computers at completing such simple tasks as identifying objects in photographs — something children can do even before they learn to speak.When we think of interfaces between human beings and computers, we usually assume that the human being is the one requesting that a task be completed, and the computer is completing the task and providing the results. What if this process were reversed and a computer program could ask a human being to perform a task and return the results? What if it could coordinate many human beings to perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3760</td>\n",
       "      <td>SDGCounting</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/sdg-counting/this-week-in-the-sdgs-february-17-2017-d88bc4d62dac?source=tag_archive---------0-----------------------</td>\n",
       "      <td>This week in the #SDGs- February 17, 2017 | by SDGCounting | SDG Counting | Medium</td>\n",
       "      <td>SDG Counting\\nFeb 17, 2017\\n1 . IISD provided context to news that the report of the 48th Statistical Commission (coming up March 7th-10th in New York) intends to include a draft resolution on the global indicator framework for the UN Economic and Social Council (ECOSOC) and the UN General Assembly to adopt. Last year, through the 47th Statistical Commission, the global indicator framework was agreed upon as a starting point and “taken note of by ECOSOC” in June 2016. A formal adoption would mean that methodology standards for indicator review and revision would be followed, as well as coming closer to the acceptance of all 230 indicators by all member states.\\nsdg.iisd.org\\n2. The Global Festival of Ideas for Sustainable Development is less than two weeks away, and a detailed agenda o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3761</td>\n",
       "      <td>Tam Pham</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@mrtampham/my-unconventional-year-after-dropping-out-of-college-befb536852dc?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Views From A College Dropout’s Unconventional Life — Year 2 | by Tam Pham | Medium</td>\n",
       "      <td>Jan 4, 2016\\nIf you asked me where I would be right now a year ago, my prediction wouldn’t even come close.\\nI had the opportunity to apprentice under radio show host and business coach, Margaret Jackson. On top of business skills, the biggest lesson she taught me was about legacy.\\nWhat legacy do I want to leave behind in the world?\\nMargaret told me to highlight my top 3 items on my bucket list. I wrote crazy goals like\\nMargaret looked at the rest of my (extensive) bucket list and started laughing to herself.\\n“Tam, you know there are people in organizations devoting their lives to ONE of these goals. How the hell in the world are you going to accomplish everything?”\\nMaintaining focus was the next crucial lesson. Mozart was known for music. Michael Jordan was known for basketball. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3762</td>\n",
       "      <td>Virginia Peón</td>\n",
       "      <td>1</td>\n",
       "      <td>https://lab.elconfidencial.com/introducci%C3%B3n-a-machine-learning-e3caed58e37a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Introducción a Machine Learning. Machine Learning, Big Data, Deep... | by Virginia Peón | ECLaboratorio</td>\n",
       "      <td>ECLaboratorio\\nDec 5, 2016\\nMachine Learning, Big Data, Deep Learning, ... ¿por qué cada día se oyen mas estos términos? y de hecho ¿qué significan? Acompáñame a descubrirlo de forma sencilla y con muchos ejemplos en el siguiente vídeo:\\n... Y la presentación llena de enlaces que te pueden ayudar a profundizar más:\\n5 \\n5 \\nTrabajamos con equipos autónomos y autosuficientes enfocados a la creación de productos útiles, sencillos y que consigan mayor satisfacción del cliente\\n28 Followers\\nData scientist\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3763</td>\n",
       "      <td>The Awl</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/the-awl/when-exactly-did-it-get-cool-to-be-a-geek-44d360e98ba5?source=tag_archive---------0-----------------------</td>\n",
       "      <td>When Exactly Did It Get Cool To Be A Geek? | by The Awl | The Awl | Medium</td>\n",
       "      <td>The Awl\\nFeb 22, 2012\\nby Jane Hu\\nIn the final episode of “Freaks and Geeks,” the Freaks group leader Daniel Desario accepts an invitation to play Dungeons &amp; Dragons with the notoriously geeky A/V club. Surprised by Daniel’s warm receptivity to the game, the Geeks wonders what this means for their future status. As Bill puts it: “Does him wanting to play with us again mean he’s turning into a geek or we’re turning into cool guys?” Sam answers, “I’m going to go for us becoming cool guys.” It’s a nice ambiguous note on which to end the show.\\nOutside the universe of “Freaks and Geeks,” a similar drift has occurred. Geekiness has accrued cachet, and geeks are becoming the cool guys. In an interview about the comedy web series “Geek Therapy,” actress America Young observed: “We started ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3764</td>\n",
       "      <td>Ekta Sharma</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------7-----------------------</td>\n",
       "      <td>K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3765</td>\n",
       "      <td>Igor de Sousa</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@igordesousa/lou-reed-entre-transformer-e-berlin-o-mito-3c5ff2c36f59?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Lou Reed: Entre “Transformer” e “Berlin” o mito. | by Igor de Sousa | Medium</td>\n",
       "      <td>Nov 12, 2015\\nas mentiras e conturbações feitas a vida do “monstro” e “mito” Lou Reed atráves de biográfias e material descártavel são absurdamentes grandes, mas de certa forma provacadas pelo mesmo, uma figura icônica e contráditoria.\\nantes da fama Lou já era conturbado, mas a primeira aparição do Velvet em uma zine desmistifica algumas das alegações tardias do cantor e guitarrista. Lou Reed cita os beatles como criativos e absolutamente magníficos, assim como os Stones. ele cita Creedence como legais a primeira ouvida mas depois absolutamente tedioso e desgastante era 1972 e Lou estava no caminho de albúns como “Transformer” que absorvia toda a atmosfera Glam da época com uma pegada Rock and Roll, e ao mesmo tempo definia uma época, a ambiguidade sexual em sua capa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3766</td>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Machine Learning is Fun!. The world’s easiest introduction to... | by Adam Geitgey | Medium</td>\n",
       "      <td>May 5, 2014\\nUpdate: This article is part of a series. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, Part 6, Part 7 and Part 8! You can also read this article in 日本語, Português, Português (alternate), Türkçe, Français, 한국어 , العَرَبِيَّة‎‎, Español (México), Español (España), Polski, Italiano, 普通话, Русский, 한국어 , Tiếng Việt or فارسی.\\nGiant update: I’ve written a new book based on these articles! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. Check it out now!\\nHave you heard people talking about machine learning but only have a fuzzy idea of what that means? Are you tired of nodding your way through conversations with co-workers? Let’s change that!\\nThis guide is f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3767</td>\n",
       "      <td>Viraf</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Master the COCO Dataset for Semantic Image Segmentation — Part 1 of 2 | by Viraf | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 3, 2020\\nCOCO (Common Objects in Context), being one of the most popular image datasets out there, with applications like object detection, segmentation, and captioning - it is quite surprising how few comprehensive but simple, end-to-end tutorials exist. When I first started out with this dataset, I was quite lost and intimidated. I had to plough my way through so many scattered, inadequate resources on the web, multiple vague tutorials, and some experimentation to finally see light at the end of this tunnel. When I was done, I knew I had to document this journey, from start to finish. And so I did. With the hope that someday, someone out there would find these of value and not have to go through all the trouble I faced.\\nHere’s presenting you a two part seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3768</td>\n",
       "      <td>Pankaj Kishore</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/it-support-ticket-classification-and-deployment-using-machine-learning-and-aws-lambda-8ef8b82643b6?source=tag_archive---------2-----------------------</td>\n",
       "      <td>IT Support Ticket Classification and Deployment using Machine Learning and AWS Lambda | by Pankaj Kishore | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 15, 2019\\nProject Description and initial assumptions:\\nAs a part of our final project for Cognitive computing, we decided to address a real life business challenge for which we chose IT Service Management. Of all the business cases, we were interested with four user cases that might befitting for our project.\\n1. In Helpdesk, almost 30–40% of incident tickets are not routed to the right team and the tickets keep roaming around and around and by the time it reaches the right team, the issue might have widespread and reached the top management inviting a lot of trouble.\\n2. Let’s say that users are having some trouble with printers. User calls help desk, he creates a ticket with IT Support, and they realize that they need to update a configuration in user’s sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3769</td>\n",
       "      <td>Ruben Winastwan</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Text Classification with BERT in PyTorch | by Ruben Winastwan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 10, 2021\\nBack in 2018, Google developed a powerful Transformer-based machine learning model for NLP applications that outperforms previous language models in different benchmark datasets. And this model is called BERT.\\nIn this post, we’re going to use a pre-trained BERT model from Hugging Face for a text classification task. As you might already know, the main goal of the model in a text classification task is to categorize a text into one of the predefined labels or tags.\\nSpecifically, soon we’re going to use the pre-trained BERT model to classify whether the text of a news article can be categorized as sport, politics, business, entertainment, or tech category.\\nBut before we dive into the implementation, let’s talk about the concept behind BERT briefly.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3770</td>\n",
       "      <td>Ronak Nathani</td>\n",
       "      <td>9</td>\n",
       "      <td>https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Anatomy of an Elasticsearch Cluster: Part I | by Ronak Nathani | Insight</td>\n",
       "      <td>Insight\\nJun 30, 2016\\nWant to learn Elasticsearch and other big data tools from top data engineers in Silicon Valley or New York? The Insight Data Engineering Fellows Program is a free 7-week professional training program where you can build cutting edge big data platforms and transition to a career in data engineering at top teams like Facebook, Uber, Slack and Squarespace.\\nLearn more about the program and apply today.\\nThis post is part of a series covering the underlying architecture and prototyping examples with a popular distributed search engine, Elasticsearch. In this post, we’ll be discussing the underlying storage model and how CRUD (create, read, update and delete) operations work in Elasticsearch.\\nElasticsearch is a very popular distributed search engine used at many comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3771</td>\n",
       "      <td>George Seif</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3772</td>\n",
       "      <td>Record Evolution</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/iot-and-cloud/iot-learning-algorithms-and-predictive-maintenance-3-few-shot-learning-95154b606197?source=tag_archive---------6-----------------------</td>\n",
       "      <td>IoT Learning Algorithms and Predictive Maintenance — Part III: Few-shot Learning | by Record Evolution | IoT &amp; Data Science | Medium</td>\n",
       "      <td>IoT &amp; Data Science\\nFeb 15, 2019\\nThe article tackles smart data processing of the Internet of Things (IoT) in a predictive maintenance context and relates this to recent developments in semi-supervised learning. While written with an eye towards a non-expert audience, the article references recent scientific publications. We leave it to the curious and technically oriented reader to expand their knowledge on the ideas we have sketched out (see References). We aim to be informative and open minds to stimulating discussions on IoT and data analytics.\\nWe cover the topic of IoT Learning Algorithms and Predictive Maintenance in a series of three articles. In PART I, we present a simple case study in detail and discuss some learning algorithms related to it. In PART II, we focus on IoT dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3773</td>\n",
       "      <td>Lachlan Miller</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Machine Learning week 1: Cost Function, Gradient Descent and Univariate Linear Regression | by Lachlan Miller | Medium</td>\n",
       "      <td>Jan 10, 2018\\nI have started doing Andrew Ng’s popular machine learning course on Coursera. The first week covers a lot, at least for someone who hasn’t touched much calculus for a few years\\nThese three topics were a lot to take in. I’ll talk about each in detail, and how they all fit together, with some python code to demonstrate.\\nEdit May 4th: I published a follow up focusing on how the Cost Function works here, including an intuition, how to calculate it by hand and two different Python implementations. I can do gradient descent and then bring them together for linear regression soon.\\nFirst, the goal of most machine learning algorithms is to construct a model: a hypothesis that can be used to estimate Y based on X. The hypothesis, or model, maps inputs to outputs. So, for example...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3774</td>\n",
       "      <td>Julia Powles</td>\n",
       "      <td>8</td>\n",
       "      <td>https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------7-----------------------</td>\n",
       "      <td>DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero</td>\n",
       "      <td>OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law &amp; Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3775</td>\n",
       "      <td>Pulkit Sharma</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/analytics-vidhya/computer-vision-tutorial-implementing-mask-r-cnn-for-image-segmentation-with-python-code-fe34da5b99cd?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Computer Vision Tutorial: Implementing Mask R-CNN for Image Segmentation (with Python Code) | by Pulkit Sharma | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJul 22, 2019\\nI am fascinated by self-driving cars. The sheer complexity and mix of different computer vision techniques that go into building a self-driving car system is a dream for a data scientist like me.\\nSo, I set about trying to understand the computer vision technique behind how a self-driving car potentially detects objects. A simple object detection framework might not work because it simply detects an object and draws a fixed shape around it.\\nThat’s a risky proposition in a real-world scenario. Imagine if there’s a sharp turn in the road ahead and our system draws a rectangular box around the road. The car might not be able to understand whether to turn or go straight. That’s a potential disaster!\\nInstead, we need a technique that can detect the exact sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3776</td>\n",
       "      <td>Ryan Kwok</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3777</td>\n",
       "      <td>Hongri Jia</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/henry-jia/how-to-score-your-credit-1c08dd73e2ed?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Credit Scoring with Machine Learning | by Hongri Jia | Passion for Data Science | Medium</td>\n",
       "      <td>Passion for Data Science\\nApr 1, 2018\\nThe credit score is a numeric expression measuring people’s creditworthiness. The banking usually utilizes it as a method to support the decision-making about credit applications. In this blog, I will talk about how to develop a standard scorecard with Python (Pandas, Sklearn), which is the most popular and simplest form for credit scoring, to measure the creditworthiness of the customers.\\nNowadays, creditworthiness is very important for everyone since it is regarded as an indicator for how dependable an individual is. In various situations, service suppliers need to evaluate customers’ credit history first, and then decide whether they will provide the service or not. However, it is time-consuming to check the entire personal portfolios and gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3778</td>\n",
       "      <td>Justin Davies</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@justindavies/from-gensim-models-doc2vec-import-labeledsentence-9b631f9f567f?source=tag_archive---------5-----------------------</td>\n",
       "      <td>If you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works... | by Justin Davies | Medium</td>\n",
       "      <td>Jun 6, 2016\\nIf you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works rather well for my use case.\\nfrom gensim.models.doc2vec import LabeledSentence\\nfrom os import listdir\\nfrom os.path import isfile, join\\nimport gensim\\nimport DocIterator as DocIt\\ndocLabels = []\\ndocLabels = [f for f in listdir(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu”) if f.endswith(‘.txt’)]\\ndata = []\\nfor doc in docLabels:\\nwith open(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu/” + doc, ‘r’) as f:\\ndata.append(f.read())\\nit = DocIt.DocIterator(data, docLabels)\\nmodel = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=3,alpha=0.04, min_alpha=0.005) # use fixed learning rate\\nmodel.build_vocab(it)\\nfor epoch in range(100):\\nprint(“Epoch “ + str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3779</td>\n",
       "      <td>Johannes Schmidt</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Creating and training a U-Net model with PyTorch for 2D &amp; 3D semantic segmentation: Model building [2/4] | by Johannes Schmidt | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 2, 2020\\nIn the previous chapter we built a dataloader that picks up our images and performs some transformations and augmentations so that they can be fed in batches to a neural network like the U-Net. In this part, we focus on building a U-Net from scratch with the PyTorch library. The goal is to implement the U-Net in such a way, that important model configurations such as the activation function or the depth can be passed as arguments when creating the model.\\nThe U-Net is a convolutional neural network architecture that is designed for fast and precise segmentation of images. It has performed extremely well in several challenges and to this day, it is one of the most popular end-to-end architectures in the field of semantic segmentation.\\nWe can split the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3780</td>\n",
       "      <td>Harsh Pokharna</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8?source=tag_archive---------9-----------------------</td>\n",
       "      <td>The best explanation of Convolutional Neural Networks on the Internet! | by Harsh Pokharna | TechnologyMadeEasy | Medium</td>\n",
       "      <td>TechnologyMadeEasy\\nJul 28, 2016\\nCNNs have wide applications in image and video recognition, recommender systems and natural language processing. In this article, the example that I will take is related to Computer Vision. However, the basic concept remains the same and can be applied to any other use-case!\\nFor a quick recap of Neural Networks, here’s a very clearly explained article series.\\nCNNs, like neural networks, are made up of neurons with learnable weights and biases. Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output. The whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs. Pretty straightforward, right?\\nSo, how are Convol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3781</td>\n",
       "      <td>Debmalya Biswas</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/@debmalyabiswas/i-had-an-opportunity-to-attend-the-oreilly-ai-london-conference-oct-9-11-2018-bf304ad69fd8?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Key takeaways — O’reilly AI London Conference, Oct 9–11, 2018 | by Debmalya Biswas | Medium</td>\n",
       "      <td>Nov 18, 2018\\nKey takeaways — O’reilly AI London Conference, Oct 9–11, 2018\\nI had an opportunity to attend the O’reilly AI London Conference, Oct 9–11, 2018. Given our short attention span these days, let me try a more clickbait style approach for the takeaways :)\\nKey takeaways\\n1. AI Gurus are the new rock stars and there was never a better time to be in this field. There continues to be tremendous interest in Enterprise AI. This was the first...\\n1 \\n1 \\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Patents https://www.linkedinin/debmalya-biswas-397526\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n125 Followers\\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3782</td>\n",
       "      <td>Javaid Nabi</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Machine Learning — Word Embedding &amp; Sentiment Classification using Keras | by Javaid Nabi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 4, 2018\\nIn the previous post, we discussed various steps of text processing involved in Nature Language Processing (NLP) and also implemented a basic Sentiment Analyzer using some of the classical ML techniques.\\nDeep learning has demonstrated superior performance on a wide variety of tasks including NLP, Computer Vision, and Games. To explore further, we will discuss and use some of the advanced NLP techniques, based on Deep Learning, to create an improved Sentiment Classifier.\\nSentiment classification is the task of looking at a piece of text and telling if someone likes or dislikes the thing they’re talking about.\\nThe input X is a piece of text and the output Y is the sentiment which we want to predict, such as the star rating of a movie review.\\nIf we c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3783</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Computer Vision: Instance Segmentation with Mask R-CNN | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nThis is the fourth part in the series on Computer vision journey. In this article we will explore Mask R-CNN to understand how instance segmentation works with Mask R-CNN and then predict the segmentation for an image with Mask R-CNN using Keras\\nPart 1- CNN, R-CNN, Fast R-CNN, Faster R-CNN\\nPart 2 — Understanding YOLO, YOLOv2, YOLO v3\\nPart 3- Object Detection with YOLOv3 using Keras\\nWhat is instance segmentation and how is different from semantic segmentation?\\nSemantic Segmentation detects all the objects present in an image at the pixel level. Outputs regions with different classes or objects\\nSemantic segmentation groups pixels in a semantically meaningful way. Pixels belonging to a person, road, building, fence, bicycle, cars or trees are grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3784</td>\n",
       "      <td>Hrishikesh Huilgolkar</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@hrishikeshio/traveling-santa-problem-an-incompetent-algorists-attempt-49ad9d26b26?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Traveling santa Problem — An incompetent algorist’s attempt | by Hrishikesh Huilgolkar | Medium</td>\n",
       "      <td>Jan 19, 2013\\nKaggle announced the Traveling santa problem in the christmas season. I joined in excitedly.. but soon realized this is not an easy problem. Solving this problem would require expertise on data structures and some good familiarity with TSP problems and its many heuristic algorithms. I had neither.. I had to find a way to deal with this problem. I compenseted my lack of algorithmic expertise with common sense, logic and intuition. I finished 65th out of 356 total competitors.\\nI did some research on packaged TSP solvers and top TSP algorithms. I found concorde but I could not get it to work on my ubuntu machine. So I settled with LKH which uses Lin-Kernighan heuristic for solving TSP and related problems. I wrote scripts for file conversions and for running LKH.\\nLKH easil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3785</td>\n",
       "      <td>Jan Schultink</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/slidemagic/data-without-context-is-meaningless-and-boring-c4a9944959a8?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Data without context is meaningless (and boring) | by Jan Schultink | SlideMagic | Medium</td>\n",
       "      <td>SlideMagic\\nSep 1, 2011\\nThe quarter is done, and here comes the day-long sales results presentation. Excel is pasted into PowerPoint, creating huge decks through which senior management has to sit through. Sales organizes by channel: small restaurants sales, growth; large restaurants sales, growth, supermarkets sales, growth. Marketing presents by brands: brand 1 sales, growth, brand 2 sales, growth.If you are a marketing manager, looking at the Q3 sales and growth figures of a particular brand is really interesting. All the numbers of the previous quarters are more or less in your head. For the production manager though, going through these pages is mental torture, as she does not have the historical context readily available. (Read more about the Curse of Knowledge here)The solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3786</td>\n",
       "      <td>Siladittya Manna</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538?source=tag_archive---------4-----------------------</td>\n",
       "      <td>K-Fold Cross Validation for Deep Learning Models using Keras | by Siladittya Manna | The Owl | Medium</td>\n",
       "      <td>The Owl\\nMar 20, 2020\\nwith a little help from sklearn\\nMachine Learning models often fails to generalize well on data it has not been trained on. Sometimes, it fails miserably, sometimes it gives somewhat better than miserable performance. To be sure that the model can perform well on unseen data, we use a re-sampling technique, called Cross-Validation.\\nWe often follow a simple approach of splitting the data into 3 parts, namely, Train, Validation and Test sets. But this technique does not generally work well for cases when we don’t have a large datasets. When we have limited data, dividing the dataset into Train and Validation sets may casue some data points with useful information to be excluded from the training procedure, and the model fails to learn the data distrubution properl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3787</td>\n",
       "      <td>Knoyd</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@Knoyd/gotta-catch-them-all-but-which-one-first-7d808378de72?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Gotta catch them all, but which one first? | by Knoyd | Medium</td>\n",
       "      <td>Aug 8, 2016\\nFor this blog post, we decided to jump on the PokémonGO hype and add a bit of science into the craze. Our goal is to give you the optimal portfolio of Pokémon to train, so you can be as effective as possible against a wide variety of opponents. As each Pokémon has its strengths and weaknesses, we created clusters of Pokémon with similar characteristics and looked at the few selected ones allowing the player to compete against as many different enemies as possible.\\nWe used the Pokémon API fan service available on the internet to find all the information about the little creatures.\\nThe data we used consists of:\\nThe data is available for 811 Pokémon. Although we have done the analysis for all the Pokémon, in this post, we focus only on the first 150 Pokémon as thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3788</td>\n",
       "      <td>Ryan Burke</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/glove-elmo-bert-9dbbc9226934?source=tag_archive---------6-----------------------</td>\n",
       "      <td>GloVe, ELMo &amp; BERT. A guide to state-of-the-art text... | by Ryan Burke | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 16, 2021\\nOne of the most challenging tasks for machine learning models is finding the best way to to generate numeric representations for words so the model can use that information in its calculations.\\nIn computer vision tasks, the red channel in a color (RGB) image will always refer to the red channel, and the green channel to the green channel. Text, however, is heavily based on context, such that the same word can take on multiple meanings depending on its use. Pandas, for example, can refer to cute and fuzzy bears or a Python data analysis library.\\nThis is further complicated when considering sentences and paragraphs. Consider the following:\\nPandas are cute and fuzzy. They don’t use Pandas data analysis library because they are bears.\\nNow I realize t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3789</td>\n",
       "      <td>Jeremie Harris</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/ai-safety-and-the-scaling-hypothesis-76bfee57f924?source=tag_archive---------8-----------------------</td>\n",
       "      <td>AI Safety and the Scaling Hypothesis | by Jeremie Harris | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 2, 2021\\nEditor’s note: This episode is part of our podcast series on emerging problems in data science and machine learning, hosted by Jeremie Harris. Apart from hosting the podcast, Jeremie helps run a data science mentorship startup called SharpestMinds.\\nWhen OpenAI announced the release of their GPT-3 API last year, the tech world was shocked. Here was a language model, trained only to perform a simple autocomplete task, which turned out to be capable of language translation, coding, essay writing, question answering and many other tasks that previously would each have required purpose-built systems.\\nWhat accounted for GPT-3’s ability to solve these problems? How did it beat state-of-the-art AIs that were purpose-built to solve tasks it was never explici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3790</td>\n",
       "      <td>Pavel Shestakov</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@am1goo/%D0%BF%D0%BE%D0%B4%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D0%B5-%D0%BA%D0%B0%D0%BC%D0%BD%D0%B8-unet-%D0%B2-unity-5-8e78a0e673b8?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Подводные камни UNet в Unity 5. или то, что не описано в документации | by Pavel Shestakov | Medium</td>\n",
       "      <td>Oct 17, 2016\\nИтак, вы решили подключить свой локальный пул геймобъектов, прочли документацию на сайте, нашли необходимые методы и решили , что сейчас все заработает. Возможно в вашем случае это действительно будет так, если вы до этого не регистрировали ни одного префаба для спаунинга по сети.\\nДело в том, что в Unity при спауне геймобъекта приватным методом ClientScene.OnObjectSpawn сначала проверяется наличие объекта в списке зарегистрированных (через инспектор компоненты NetworkManager или напрямую через добавление геймобъектов в словарь NetworkManager.spawnPrefabs), и только если необходимый геймобъект не найден, то идет в работу словарь хендлеров (делегатов SpawnDelegate) для спауна, в который и записывается ваш делегат с помощью методов ClientScene.RegisterSpawnHandl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3791</td>\n",
       "      <td>Saidakbar P</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@saidakbarp/real-time-face-recognition-tflite-3fb818ac039a?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Real-time face recognition: training and deploying on Android using Tensorflow lite — transfer learning | by Saidakbar P | Medium</td>\n",
       "      <td>Feb 25, 2019\\nFor the last couple of weeks, I have been experimenting with mobilenet models for object detection on Android devices. Since I took a Deep learning course in the past semester, I knew that those mobilenet models could be trained for detecting other objects as well. Moreover, available guides such as this object detection tutorial and this Android deployment tutorial rely on the older version of the Tensorflow framework — Tensorflow Mobile, which is being deprecated as of February 2019. Instead, Tensorflow Lite will be the main framework for mobile devices in the future and Lite version has moved from the contribution stage to the core of Tensorflow.\\nAdditionally, there are recent articles that manually annotate images for training purposes. However, we will implement ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3792</td>\n",
       "      <td>Prince Yadav</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/decision-tree-in-machine-learning-e380942a4c96?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Decision Tree in Machine Learning | by Prince Yadav | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2018\\nA decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules. Below diagram illustrate the basic flow of decision tree for decision making with labels (Rain(Yes), No Rain(No)).\\nDecision tree is one of the predictive modelling approaches used in statistics, data mining and machine learning.\\nDecision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3793</td>\n",
       "      <td>Julia Powles</td>\n",
       "      <td>8</td>\n",
       "      <td>https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------1-----------------------</td>\n",
       "      <td>DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero</td>\n",
       "      <td>OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law &amp; Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3794</td>\n",
       "      <td>Gabriel Pierobon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/dbscan-clustering-for-data-shapes-k-means-cant-handle-well-in-python-6be89af4e6ea?source=tag_archive---------0-----------------------</td>\n",
       "      <td>DBSCAN clustering for data shapes k-means can’t handle well (in Python) | by Gabriel Pierobon | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 30, 2018\\nIn this post I’d like to take some content from Introduction to Machine Learning with Python by Andreas C. Müller &amp; Sarah Guido and briefly expand on one of the examples provided to showcase some of the strengths of DBSCAN clustering when k-means clustering doesn’t seem to handle the data shape well. I’m going to go right to the point, so I encourage you to read the full content of Chapter 3, starting on page 168 if you would like to expand on this topic. I’ll be quoting the book when describing the working of the algorithm.\\nThis is how k-means work in a visual representation:\\nOne issue with k-means clustering is that it assumes that all directions are equally important for each cluster. This is usually not a big problem, unless we come across wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3795</td>\n",
       "      <td>Anas Al-Masri</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/how-does-back-propagation-in-artificial-neural-networks-work-c7cad873ea7?source=tag_archive---------4-----------------------</td>\n",
       "      <td>How Does Back-Propagation in Artificial Neural Networks Work? | by Anas Al-Masri | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 29, 2019\\nEver since the world of Machine Learning was introduced to non-linear functions that work recursively (i.e. Artificial Neural Networks), the applications of which boomed noticeably. In this context, proper training of a Neural Network is the most important aspect of making a reliable model. This training is usually associated with the term “Back-propagation”, which is highly vague to most people getting into Deep Learning. Heck, most people in the industry don’t even know how it works — they just know it does!\\nBack-propagation is the essence of neural net training. It is the practice of fine-tuning the weights of a neural net based on the error rate (i.e. loss) obtained in the previous epoch (i.e. iteration). Proper tuning of the weights ensures low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3796</td>\n",
       "      <td>Matt Kiser</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/emergent-future/teslas-big-plans-deepmind-pays-for-itself-internet-drones-and-moore-s-law-54e6bd8e2750?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Tesla’s Big Plans, DeepMind Pays For Itself, Internet Drones, and Moore’s Law | by Matt Kiser | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nJul 27, 2016\\nIssue 17 This week we review Elon Musk’s big plans for Tesla, how Google uses DeepMind to save millions of dollars, why Zuckerberg is building a fleet of internet drones, and check in on Moore’s Law death watch. Plus, projects to try at home, and our top reads from the past week.\\nNot a subscriber? Join the Emergent // Future newsletter here.\\nYou might have heard: Elon Musk outlined his masterplan for Tesla in blog post. For the past 10-years, Tesla’s vision had been to do:\\nNow, Musk is doubling-down on solar power, Tesla trucks, self-driving cars, and car-sharing — he wants your car to make you money when you aren’t using it. The company has already started developing electric and autonomous trucks and buses.\\ntl;dr “We’re not an electric car compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3797</td>\n",
       "      <td>Pedro Marcelino</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Transfer learning from pre-trained models | by Pedro Marcelino | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 23, 2018\\nThis article teaches you how to use transfer learning to solve image classification problems. A practical example using Keras and its pre-trained models is given for demonstration purposes.\\nDeep learning is fast becoming a key instrument in artificial intelligence applications (LeCun et al. 2015). For example, in areas such as computer vision, natural language processing, and speech recognition, deep learning has been producing remarkable results. Therefore, there is a growing interest in deep learning.\\nOne of the problems where deep learning excels is image classification (Rawat &amp; Wang 2017). The goal in image classification is to classify a specific picture according to a set of possible categories. A classic example of image classification is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3798</td>\n",
       "      <td>michaelulin</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@michaelulin/serving-pytorch-models-on-aws-lambda-with-caffe2-onnx-7b096806cfac?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Serving PyTorch Models on AWS Lambda with Caffe2 &amp; ONNX | by michaelulin | Medium</td>\n",
       "      <td>Oct 8, 2017\\nCode available here: https://github.com/michaelulin/pytorch-caffe2-aws-lambda\\nHaving worked with PyTorch, I love the flexibility and ease of development of the framework versus other platforms. As PyTorch is still early in its development, I was unable to find good resources on serving trained PyTorch models, so I’ve written up a method here that utilizes ONNX, Caffe2 and AWS Lambda to serve predictions from a trained PyTorch model. I hope that you find it to be useful.\\nHow to effectively deploy a trained PyTorch model\\nUsing ONNX, Facebook and Microsoft’s recently released platform for Neural Network interoperability, we can convert a model trained in PyTorch to Caffe2 and then serve predictions with that model from AWS Lambda.\\nONNX enables models trained in PyTorch to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3799</td>\n",
       "      <td>Chi-Lan Yang | 楊期蘭</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/%E4%BA%BA%E6%A9%9F%E5%85%B1%E7%94%9F%E4%BD%A0%E6%88%91%E5%AE%83/explainable-ai-for-intelligent-systems-part2-be9296529582?source=tag_archive---------5-----------------------</td>\n",
       "      <td>[談理解] 電競賽評也能告訴我們如何設計智慧系統的解釋機制?. 「蟲苔已經撲到人家的臉上了!」... | by Chi-Lan Yang | 楊期蘭 | 人機共生你我它 | Medium</td>\n",
       "      <td>人機共生你我它\\nDec 20, 2018\\n「蟲苔已經撲到人家的臉上了!」 「快要滿人口啦!應該要開戰了喔,因為其實人口滿,你剛剛把人家斷炊,這邊是一個很好的時機點可以來壓制」\\n電競賽評每天在做的事就是分析許多專業玩家打game的過程,帶著觀眾理解這些專業玩家每一步背後的策略,仔細想想,這些賽評帶領觀眾理解專業玩家的方式,是不是也跟使用者透過一個解釋機制來理解黑盒子般的智慧系統類似?電競賽評是專家行為的詮釋者,從他們身上,能帶給我們什麼智慧代理系統設計的啟發?\\n來自美國Oregon State University的研究團隊發現了這個關聯,透過分析賽評們對於電競的即時評論,試圖了解:當解釋機制(賽評)在說明智慧系統運作(專業玩家動作)時,需要哪些線索來搞懂智慧系統的行為、對使用者說明時需要包含哪些資訊、以及要怎麼說出這些難懂的資訊才能幫助使用者搞懂智慧系統這個黑盒子。\\n在眾多線索中,哪些資訊才是賽評需要的呢?研究者分析賽評切換的畫面,發現遊戲賽評會不斷的蒐集玩家當下的表現、所處的環境、產能狀況或統計資料(例:擊殺比例)以及賽評不斷切換視角(例:畫面轉到不同地點、切換成不同玩家的視角)來幫助自己解釋這些玩家為什麼在此時此刻會做出特定的行為。透過分析賽評如何理解專業玩家,我們可以知道當設計解釋機制的時候,需要想辦法讓使用者需要知道系統已做、能做哪些事,就如同賽評會說出「蟲苔已經撲到人家的臉上了」或告訴觀眾「滿人口應該就可以開戰了」,藉由這些資訊來讓觀眾理解玩家做出特定行為的意圖。\\n除此之外,智慧系統的解釋機制也需要告訴使用者現在系統已經看到、聽到或取得哪些資訊,以自駕車來說,在操作面板上對駕駛顯示目前系統偵測到周圍環境哪些資訊、已經分別執行過哪些步驟,幫助駕駛理解系統做決策的過程;或是讓使用者知道智慧系統做了哪些事、能做哪些事,例如透過系統協助保安人員判斷某位...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3800</td>\n",
       "      <td>Manjeet Singh</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/data-science-group-iitr/artistic-style-transfer-with-convolutional-neural-network-7ce2476039fd?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Artistic Style Transfer with Convolutional Neural Network | by Manjeet Singh | Data Science Group, IITR | Medium</td>\n",
       "      <td>Data Science Group, IITR\\nSep 4, 2017\\nWe all have used apps like Prisma and Lucid, but ever wondered how these things works? Like we give a photo from our camera roll and select a design to mix both the images and we get a new image which has the content of our input image and style of the design image. In the world of deep learning this is called style transfer.\\nStyle transfer is the technique of recomposing images in the style of other images. It all started when Gatys et al. published an awesome paper on how it was actually possible to transfer artistic style from one painting to another picture using convolutional neural networks..\\nHere are some examples :\\n“Neural networks are everywhere. I do not expect that they will take away the bread of artists and designers, but it took m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3801</td>\n",
       "      <td>Elior Cohen</td>\n",
       "      <td>9</td>\n",
       "      <td>https://blog.mlreview.com/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07?source=tag_archive---------5-----------------------</td>\n",
       "      <td>How to predict Quora Question Pairs using Siamese Manhattan LSTM | by Elior Cohen | ML Review</td>\n",
       "      <td>ML Review\\nJun 7, 2017\\nThe article is about Manhattan LSTM (MaLSTM) — a Siamese deep network and its appliance to Kaggle’s Quora Pairs competition.I will do my best to explain the network and go through the Keras code (if you are only here for the code, scroll down :)Full code on Github\\nIn the past few years, deep learning is all the fuss in the tech industry.To keep up on things I like to get my hands dirty implementing interesting network architectures I come across in article readings.\\nFew months ago I came across a very nice article called Siamese Recurrent Architectures for Learning Sentence Similarity.It offers a pretty straightforward approach to the common problem of sentence similarity.Named MaLSTM (“Ma” for Manhattan distance), its architecture is depicted in figure 1 (dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3802</td>\n",
       "      <td>Sambit Mahapatra</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Use-cases of Google’s Universal Sentence Encoder in Production | by Sambit Mahapatra | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 24, 2019\\nBefore building any Deep Learning model in Natural Language Processing (NLP), text embedding plays a major role. The text embedding converts text (words or sentences) into a numerical vector.\\nWhy do we convert texts into vectors?\\nA vector is an array of numbers of a particular dimension. A vector of size 5×1 contain 5 numbers and we can think of it as a point in 5D space. If there are two vectors each of dimension 5, they can be thought of two points in a 5D space. Thus we can calculate how close or distant those two vectors are, depending on the distance measure between them.\\nHence, lots of efforts in machine learning research are bring put to converting data into a vector as once data is converted into a vector, we can say two data points are si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3803</td>\n",
       "      <td>Ceshine Lee</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Understanding Bidirectional RNN in PyTorch | by Ceshine Lee | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2017\\nBidirectional recurrent neural networks(RNN) are really just putting two independent RNNs together. The input sequence is fed in normal time order for one network, and in reverse time order for another. The outputs of the two networks are usually concatenated at each time step, though there are other options, e.g. summation.\\nThis structure allows the networks to have both backward and forward information about the sequence at every time step. The concept seems easy enough. But when it comes to actually implementing a neural network which utilizes bidirectional structure, confusion arises...\\nThe first confusion is about the way to forward the outputs of a bidirectional RNN to a dense neural network. For normal RNNs we could just forward the outputs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3804</td>\n",
       "      <td>Daniel Voshart</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@voshart/appearance-of-the-principate-pt-ii-3df539f18fe5?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Appearance of The Principate [Pt. II] | by Daniel Voshart | Medium</td>\n",
       "      <td>Jul 24, 2020\\nUsing the neural-net tool Artbreeder, Photoshop and historical references, I have created photoreal depictions of Roman Emperors. Scroll down to see each emperor.\\nON CREATIVE COMMONS &amp; COPYRIGHT: Faces can be shared non-watermarked at 200 pixels max height OR 512 pixels with the digital mosaic watermark with Attribution-NonCommercial-ShareAlike. Please link back to this page. Continuation of this project depends on prints, licensing and commissions.\\n*CONCISE UPDATE (July 31st) replacing a July 27th CLARIFICATION: ‘TheApricity’, a tertiary source, has been removed entirely. I knew it to be unreliable prior to starting this project but kept here for posterity and debate. It is now clear to me they have distorted primary and secondary sources to push a pernicious white sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3805</td>\n",
       "      <td>Chandra Churh Chatterjee</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3806</td>\n",
       "      <td>Gustavo Chávez</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/understanding-logistic-regression-step-by-step-704a78be7e0a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Understanding Logistic Regression step by step | by Gustavo Chávez | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 21, 2019\\nLogistic Regression is a popular statistical model used for binary classification, that is for predictions of the type this or that, yes or no, A or B, etc. Logistic regression can, however, be used for multiclass classification, but here we will focus on its simplest application.\\nAs an example, consider the task of predicting someone’s gender (Male/Female) based on their Weight and Height.\\nFor this, we will train a machine learning model from a data set of 10,000 samples of people’s weight and height. The data set is taken from the Conway &amp; Myles Machine Learning for Hackers book, Chapter 2, and can it can be directly downloaded here.\\nThis is a preview of what the data looks like:\\nEach sample contains three columns: Height, Weight, and Male.\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3807</td>\n",
       "      <td>Apdullah Yayik</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@apdullahyayik/mask-rcnn-object-recognition-and-segmentation-with-colab-application-cd0b5e490130?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Object Detection &amp; Segmentation with Python | by Apdullah Yayik | Medium</td>\n",
       "      <td>Aug 27, 2019\\nIt was announced by FAIR (facebook artificial intelligence research) last year that the Mask RCNN structure using the resnet50 infrastructure was successfully implemented on MS COCO and Balloon datasets and valuable resuts were obtained (see dedicated github page). In addition, the trained weights were also released for researchers and practitionars to make transfer learning to solve different problems with reasonable cost(see matterport github page).\\nIn my another article I have explaineed how to make transfer learning with such released MS COCO weights to deletect an locate weapons (see article here)\\nAt the end of this reading this article, you will see succesful object recognition and segmentation in video and images taken randomly from the outerside of the world.\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3808</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3809</td>\n",
       "      <td>Erik Hallström</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767?source=tag_archive---------1-----------------------</td>\n",
       "      <td>How to build a Recurrent Neural Network in TensorFlow (1/7) | by Erik Hallström | Medium</td>\n",
       "      <td>Nov 10, 2016\\nDear reader,\\nThis article has been republished at Educaora and has also been open sourced. Unfortunately TensorFlow 2.0 changed the API so it is broken for later versions. Any help to make the tutorials up to date are greatly appreciated. I also recommend you looking into PyTorch.\\nIn this tutorial I’ll explain how to build a simple working Recurrent Neural Network in TensorFlow. This is the first in a series of seven parts where various aspects and techniques of building Recurrent Neural Networks in TensorFlow are covered. A short introduction to TensorFlow is available here. For now, let’s get started with the RNN!\\nIt is short for “Recurrent Neural Network”, and is basically a neural network that can be used when your data is treated as a sequence, where the particula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3810</td>\n",
       "      <td>Veysel Kocaman</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Text Classification in Spark NLP with Bert and Universal Sentence Encoders | by Veysel Kocaman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 12, 2020\\nNatural language processing (NLP) is a key component in many data science systems that must understand or reason about a text. Common use cases include text classification, question answering, paraphrasing or summarising, sentiment analysis, natural language BI, language modeling, and disambiguation.\\nNLP is essential in a growing number of AI applications. Extracting accurate information from free text is a must if you are building a chatbot, searching through a patent database, matching patients to clinical trials, grading customer service or sales calls, extracting facts from financial reports or solving for any of these 44 use cases across 17 industries.\\nText classification is one of the main tasks in modern NLP and it is the task of assigning a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3811</td>\n",
       "      <td>Marcio Geovani Jasinski</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@marciogj/dbscan-on-trajectories-determining-eps-and-minpts-ba3aa7c4ed7c?source=tag_archive---------2-----------------------</td>\n",
       "      <td>DBScan on trajectories — Determining Eps and MinPts | by Marcio Geovani Jasinski | Medium</td>\n",
       "      <td>Jun 11, 2017\\nIn the last post I’ve applied DBScan to remove noises from a trajectory. However, to achieve an acceptable result from original trajectory I tried several parameters before end up witth:\\nUsually data analysis cannot afford such strategy since it would take too long to clean up big amount of data if every trajectory demands a human evaluation. The good news is that this process can be automated. Actually, the original DBScan paper from Ester et al. brings a section about determining the parameters Eps and MinPts using a heuristic approach.\\nThe basic idea is process data evaluating the k-th nearest neighbor of each point and sort them descending. Usually the result will point out a threshold value where clusters will appear on the right side of the chart while noises will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3812</td>\n",
       "      <td>Vicente Luego</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@vicenteluego/tiktoks-new-feature-anime-filter-got-million-posts-in-3-days-c18a866e842e?source=tag_archive---------7-----------------------</td>\n",
       "      <td>TikTok’s new feature — anime filter got million posts in 3 days | by Vicente Luego | Medium</td>\n",
       "      <td>Jun 28, 2020\\nTikTok is an application which has been used for talking materials between teens and startups for years now. Most of time we only see how it creates from a new emerging industry instead of investigating what makes the customer retention high as 39%.\\nTikTok’s Chinese version, Douyin, published a new filter in its app this week. Within 3 days, they gathered millions of posts which used this filter. The filter names as “Anime Change”. The main character is to change the video into animation.\\nIt’s not a new one to be honest, many applications have launched a similar filter before, such as B612. But the difference here is to change a video and to make the result acceptable.\\nThe technology used behind is one called Generative Adversarial Networks, AKA GAN. GAN is used for ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3813</td>\n",
       "      <td>LucianoSphere</td>\n",
       "      <td>22</td>\n",
       "      <td>https://towardsdatascience.com/alphafold-based-databases-and-fully-fledged-easy-to-use-alphafold-interfaces-poised-to-baf865c6d75e?source=tag_archive---------2-----------------------</td>\n",
       "      <td>AlphaFold-based databases and fully-fledged, easy-to-use, online AlphaFold interfaces poised to revolutionize biology | by LucianoSphere | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 26, 2021\\nNot only computational but also experimental biology. Thoughts on the future of data science niches in biology.\\nIn a recent story I covered the release of the academic paper describing AlphaFold’s version 2 and its source code, and I showed you how scientists around the world were starting to apply the program to their favorite proteins through Google Colab notebooks, for free and without any hardware needs. These notebooks are rapidly evolving to enable more features, allowing anybody to model not only isolated proteins but also complexes of multiple proteins, and including known structures of related proteins and multiple sequence alignments to improve the program’s results. Moreover, Deepmind and the European Bioinformatics Institute started to u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3814</td>\n",
       "      <td>Jean-Marc Beaujour</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@jmlbeaujour/real-time-matting-of-webcam-video-on-the-browser-part-1-2c71a330ed08?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Background Removal in Real-Time Video Chats using TensorflowJS, Part 1 | by Jean-Marc Beaujour | Medium</td>\n",
       "      <td>Jun 27, 2018\\nAn app that removes and replaces in real-time the background in webcam video streams, and all from within the browser! No need for a green screen or a uniform background. This project was made during my 4 weeks at the AI Program of Insight Data Science (Palo Alto).\\nTry it here!\\nThere is a trend in AI to move from Centralized Cloud Computing to Edge Computing [1], in particular for real time services application for which Centralized Cloud Computing suffers from higher latency. Furthermore, Edge Computing AI might provide solutions for privacy conscientious consumers [2]. One tool that is likely to help this trend is TensorflowJS (TFJS), in brief Tensorflow in Javascript wrapper. TFJS enables to create AI apps, which training and prediction can be conducted on the client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3815</td>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Chatbots were the next big thing: what happened? | by Justin Lee | The Startup | Medium</td>\n",
       "      <td>The Startup\\nJun 5, 2018\\nOh, how the headlines blared:\\n“...the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nMessaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!\\nPlus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3816</td>\n",
       "      <td>Yash Patel</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/reinforcement-learning-w-keras-openai-actor-critic-models-f084612cfd69?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Reinforcement Learning w/ Keras + OpenAI: Actor-Critic Models | by Yash Patel | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2017\\nQuick Recap\\nLast time in our Keras/OpenAI tutorial, we discussed a very fundamental algorithm in reinforcement learning: the DQN. The Deep Q-Network is actually a fairly new advent that arrived on the seen only a couple years back, so it is quite incredible if you were able to understand and implement this algorithm having just gotten a start in the field. As with the original post, let’s take a quick moment to appreciate how incredible results we achieved are: in a continuous output space scenario and starting with absolutely no knowledge on what “winning” entails, we were able to explore our environment and “complete” the trials.\\nPut yourself in the situation of this simulation. This would essentially be like asking you to play a game, without a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3817</td>\n",
       "      <td>Victor Roman</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Machine Learning Project: Predicting Boston House Prices With Regression | by Victor Roman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 20, 2019\\nIn this project, we will develop and evaluate the performance and the predictive power of a model trained and tested on data collected from houses in Boston’s suburbs.\\nOnce we get a good fit, we will use this model to predict the monetary value of a house located at the Boston’s area.\\nA model like this would be very valuable for a real state agent who could make use of the information provided in a dayly basis.\\nYou can find the complete project, documentation and dataset on my GitHub page:\\nhttps://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/tree/master/projects/boston_housing\\nThe dataset used in this project comes from the UCI Machine Learning Repository. This data was collected in 1978 and each of the 506 entries represent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3818</td>\n",
       "      <td>Kaustubh Mhaisekar</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af?source=tag_archive---------0-----------------------</td>\n",
       "      <td>AdaBelief Optimizer: fast as Adam, generalizes as well as SGD | by Kaustubh Mhaisekar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 19, 2020\\nAll types of neural networks and many machine learning algorithms optimize their loss functions using gradient-based optimization algorithms. There are several such optimization algorithms, or optimizers, that exist and are used to train models - RMSprop, Stochastic Gradient Descent(SGD), Adaptive Moment Estimation(Adam) and so many more.\\nThere are two primary metrics to look at while determining the efficacy of an optimizer:\\nAdaptive algorithms like Adam have a good convergence speed, while algorithms like SGD generalize better.\\nBut recently researchers from Yale introduced a novel AdaBelief optimizer (AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients) that combines many benefits of existing optimization methods:\\nWe pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3819</td>\n",
       "      <td>James Briggs</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/how-to-train-a-bert-model-from-scratch-72cfce554fc6?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Train New BERT Model on Any Language | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 6, 2021\\nMany of my articles have been focused on BERT — the model that came and dominated the world of natural language processing (NLP) and marked a new age for language models.\\nFor those of you that may not have used transformers models (eg what BERT is) before, the process looks a little like this:\\nNow, this is a great approach, but if we only ever do this, we lack the understanding behind creating our own transformers models.\\nAnd, if we cannot create our own transformer models — we must rely on there being a pre-trained model that fits our problem, this is not always the case:\\nSo in this article, we will explore the steps we must take to build our own transformer model — specifically a further developed version of BERT, called RoBERTa.\\nThere are a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3820</td>\n",
       "      <td>Maneesha Rajaratne</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/credit-card-fraud-detection-using-autoencoders-in-h2o-399cbb7ae4f1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Credit Card Fraud Detection using Autoencoders in H2O | by Maneesha Rajaratne | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 17, 2018\\nFrauds in the finance field are very rare to be identified. Because of that, it can do a severe damage to the financial field. It is estimated that fraud costs at least $80 billion a year across all lines of insurance. If there is a small possibility of detecting fraudulent activities, that can do a major impact on annual losses. That is why financial companies invest in machine learning as a preemptive approach to tackling fraud.\\nThe benefits of using a machine learning approach are that,\\nThe best way to detect frauds is anomaly detection.\\nAnomaly detection is a technique to identify unusual patterns that do not conform to the expected behaviors, called outliers. It has many applications in business from fraud detection in credit card transaction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3821</td>\n",
       "      <td>Essam Wisam</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/backpropagation-the-natural-proof-946c5abf63b1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Backpropagation: The Simple Proof | by Essam Wisam | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 21, 2021\\nWhat sets artificial neural networks apart from other machine learning algorithms is how they can efficiently deal with big data and how they assume very little about your dataset.\\nYour neural network doesn’t care if your classification data isn’t linearly separable via a kernel or if the trend followed by your regression data is a roller coaster. As long that your dataset is some continuous mapping from one finite space (x) to another (y) then you can approximate that mapping to any degree of accuracy depending on your architecture. This follows from them being universal approximators as proven by the Universal Approximation Theory. The point is that back, when neural networks first showed up in the 40s, there was no fast way to make use of this as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3822</td>\n",
       "      <td>John Olafenwa</td>\n",
       "      <td>12</td>\n",
       "      <td>https://heartbeat.comet.ml/basics-of-image-classification-with-pytorch-2f8973c51864?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Basics of Image Classification with PyTorch | by John Olafenwa | Heartbeat</td>\n",
       "      <td>Heartbeat\\nMay 17, 2018\\nMany deep learning frameworks have been released over the past few years. Among them, PyTorch from Facebook AI Research is very unique and has gained widespread adoption because of its elegance, flexibility, speed, and simplicity. Most deep learning frameworks have either been too specific to application development without sufficient support for research, or too specific for research without sufficient support for application development.\\nHowever, PyTorch blurs the line between the two by providing an API that’s very friendly to application developers while at the same time providing functionalities to easily define custom layers and fully control the training process, including gradient propagation. This makes it a great fit for both developers and researche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3823</td>\n",
       "      <td>Arsh Chowdhry</td>\n",
       "      <td>8</td>\n",
       "      <td>https://blog.clairvoyantsoft.com/music-genre-classification-using-cnn-ef9461553726?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Music Genre Classification Using CNN | by Arsh Chowdhry | Clairvoyant Blog</td>\n",
       "      <td>Clairvoyant Blog\\nMay 7, 2021\\n“If Music is a Place — then Jazz is the City, Folk is the Wilderness, Rock is the Road, Classical is a Temple.” — Vera Nazarin\\nWe’ve all used some music streaming app to listen to music. But what is the app's logic for creating a personalized playlist for us?\\nOne general example of logic is by having a Music Genre Classification System.\\nMusic genre classification forms a basic step for building a strong recommendation system.\\nThe idea behind this project is to see how to handle sound files in python, compute sound and audio features from them, run Machine Learning Algorithms on them, and see the results.\\nIn a more systematic way, the main aim is to create a machine learning model, which classifies music samples into different genres. It aims to predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3824</td>\n",
       "      <td>Kaushal Trivedi</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Multi-label Text Classification using BERT – The Mighty Transformer | by Kaushal Trivedi | HuggingFace | Medium</td>\n",
       "      <td>HuggingFace\\nJan 27, 2019\\nThe past year has ushered in an exciting age for Natural Language Processing using deep neural networks. Research in the field of using pre-trained models have resulted in massive leap in state-of-the-art results for many of the NLP tasks, such as text classification, natural language inference and question-answering.\\n3.3K \\n3.3K \\n30\\nStories @ Hugging Face\\n1K Followers\\nChief Architect &amp; Technologist, AI &amp; Machine Learning, Co-founder at utterworks\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3825</td>\n",
       "      <td>commander</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@mst3c/google-deepmind-style-datacenter-optimization-ai-model-on-the-cheap-75f054330d27?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Google DeepMind-style datacenter optimization AI model (on the cheap) | by commander | Medium</td>\n",
       "      <td>Aug 17, 2016\\nThere was news recently in bloomberg about how google was able to cut electricity usage in its datacenter by using an AI scheme made by DeepMind (of AlphaGo fame). Earlier this week, i decided to make a quick-and-dirty implemetation in python and share it here for anyone interested in a practical example of what exactly they did. First lets take a quick look at why one would want to make such a thing...\\nDatacenters (and indeed any other large scale structures that use a lot of energy) need to be carefully optimized for efficiency as even a 10% - 15% saving on the electricity bill can add up to millions of dollars a year. The biggest challenge here is that even though there are certain simple steps that anyone can take to reduce energy use (don’t use a very low server roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3826</td>\n",
       "      <td>Acuity Derivatives</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/acuity-derivatives/the-volcker-metric-known-as-inventory-aging-and-thoughts-of-whisky-a6011bf720d4?source=tag_archive---------1-----------------------</td>\n",
       "      <td>The Volcker metric known as inventory aging... and thoughts of Whisky | by Acuity Derivatives | Acuity Derivatives | Medium</td>\n",
       "      <td>Acuity Derivatives\\nAug 1, 2014\\nInventory Aging is a rather innocuous looking member of the band of (now) seven metrics that, under the Volcker rule, banking entities with significant trading assets and liabilities are required to calculate daily and report monthly.\\nAs written, the metric description seems straightforward enough:\\nInventory Aging generally describes a schedule of the trading desk’s aggregate assets and liabilities and the amount of time that those assets and liabilities have been held. [It] should measure the age profile of the trading desk’s assets and liabilities and must include two schedules, an asset- aging schedule and a liability-aging schedule.\\nThe graphic below broadly outlines the processes of asset/liability tagging, matching, sorting and netting of trade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3827</td>\n",
       "      <td>Jehill Parikh</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/prior-over-functions-gaussian-process-1c58e8c40272?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Prior over functions: Gaussian process | by Jehill Parikh | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 7, 2019\\nIn this post we discuss working of Gaussian process. Gaussian process fall under kernel methods, and are model free. Gaussian process are specially useful for low data regimen to “learn” complex functions. We shall review a very practical real world application (not related to deep learning or neural networks). The discussion follows from the talks of subject matter experts Prof Neil Lawrence and Prof Richard Tuner.\\nBackground reading:\\nMultivariate gaussian distribution: A Gaussian distribution can be specified using a mean (u), variance (σ2) and probability distribution function (PDF) as shown below\\nIf we have more than one independent gaussian distribution we can combine them. The combined PDF is also Gaussian i.e. a multivariate Gaussian. E.g. o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3828</td>\n",
       "      <td>Wolf Garbe</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium</td>\n",
       "      <td>Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is &lt;=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3829</td>\n",
       "      <td>Amanda Iglesias Moreno</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Simple and multiple linear regression with Python | by Amanda Iglesias Moreno | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 27, 2019\\nLinear regression is an approach to model the relationship between a single dependent variable (target variable) and one (simple regression) or more (multiple regression) independent variables. The linear regression model assumes a linear relationship between the input and output variables. If this relationship is present, we can estimate the coefficients required by the model to make predictions on new data.\\nIn this article, you will learn how to visualize and implement the linear regression algorithm from scratch in Python using multiple libraries such as Pandas, Numpy, Scikit-Learn, and Scipy. Additionally, we will measure the direction and strength of the linear relationship between two variables using the Pearson correlation coefficient as well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3830</td>\n",
       "      <td>Paul Ellis</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/swlh/ner-spacy-and-lasagne-51b56fdad57e?source=tag_archive---------6-----------------------</td>\n",
       "      <td>NER, SpaCy and Lasagne. One of the great things about NER is... | by Paul Ellis | The Startup | Medium</td>\n",
       "      <td>The Startup\\nFeb 2, 2021\\nOne of the great things about NER is trying to find those critters! I recently completed a project where one of the pre-requisites was to identify a location from large text fields containing randomly entered data.\\nOf course if there’s no control during the input of data then chaos reigns but we are where we are and if someone wants to put their homemade recipe for lasagne in an address field then hey it’s going to get messy but we’ll keep the lecture notes on data entry for another time and place.\\n34 \\n34 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n15 Followers\\nRandom ramblings from a sedate stroller.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3831</td>\n",
       "      <td>Olga Chernytska</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Word2vec with PyTorch: Implementing the Original Paper | by Olga Chernytska | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 29, 2021\\nWord Embeddings is the most fundamental concept in Deep Natural Language Processing. And word2vec is one of the earliest algorithms used to train word embeddings.\\nIn this post, I want to go deeper into the first paper on word2vec — Efficient Estimation of Word Representations in Vector Space (2013), which as of now has 24k citations, and this number is still growing.\\nOur plan is the following:\\nI am attaching my Github project with word2vec training. We will go through it in this post.\\nToday we are reviewing only the first paper on word2vec. However, there are several later papers, describing the evolution of word2vec:\\nI believe, if you understand the first paper, you’ll easily catch the ideas described in later papers. So let’s go!\\nDisclosure. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3832</td>\n",
       "      <td>Praveenkumar</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/a-short-introduction-of-stylegan-898fe781937?source=tag_archive---------5-----------------------</td>\n",
       "      <td>A short introduction to StyleGAN. Generative models(GAN) have always been... | by Praveenkumar | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 1, 2021\\nGenerative models(GAN) have always been the niche and hard-to-master domain of the Deep learning space. Control over distinct features of output image has been a challenging research topic. StyleGAN is an approach that addresses this aspect. It distances itself from the conventional architectures of GAN and introduces a novel approach to generate high-resolution synthetic images along with a fair control over the distinct features...\\n5 \\n5 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n10 Followers\\nAI Enthusiast; M.Sc., University of Stuttgart, Mercedes-Benz AG\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3833</td>\n",
       "      <td>Chijioke Nwagwu</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@wyhzest/css-box-model-and-positioning-9f0263d60759?source=tag_archive---------9-----------------------</td>\n",
       "      <td>CSS Box Model and Positioning. VGG Virtual Internship Assignment. | by Chijioke Nwagwu | Medium</td>\n",
       "      <td>Jan 21, 2020\\nCSS Box Model and Positioning\\nVGG Virtual Internship Assignment.\\nThe CSS box model is crucial and fundamental to understand as far as layout and positioning are concerned in styling of a web page. This is so because every element in HTML generate a box around it and these boxes have properties that can be illustrated using what is popularly know as the CSS Box Model. You can view the box model from the developer tool by simply right clicking on an element on the web page then click on “inspect”.\\nOnce you are in the developer tools menu, ensure the “Elements” tab and “Styles” tab are selected (might be slightly different for other browsers). Then scroll down, you will see the box model for the element you are inspecting as shown below.\\nFrom the image above, we can see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3834</td>\n",
       "      <td>Shivam Duseja</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/text-summarization-using-deep-neural-networks-e7ee7521d804?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Text Summarization Using Deep Neural Networks | by Shivam Duseja | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 28, 2020\\nThe amount of textual data being produced every day is increasing rapidly both in terms of complexity as well as volume. Social Media, News articles, emails, text messages (the list goes on..), generate massive information and it becomes cumbersome to go through lengthy text materials (and boring too!). Thankfully with the advancements in Deep Learning, we can build models to shorten long pieces of text and produce a crisp and coherent summary to save time and understand the key points effectively.\\nWe can broadly classify text summarization into two types:\\n1. Extractive Summarization: This technique involves the extraction of important words/phrases from the input sentence. The underlying idea is to create a summary by selecting the most important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3835</td>\n",
       "      <td>Jonny Brooks-Bartlett</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Probability concepts explained: Maximum likelihood estimation | by Jonny Brooks-Bartlett | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 3, 2018\\nIn this post I’ll explain what the maximum likelihood method for parameter estimation is and go through a simple example to demonstrate the method. Some of the content requires knowledge of fundamental probability concepts such as the definition of joint probability and independence of events. I’ve written a blog post with these prerequisites so feel free to read this if you think you need a refresher.\\nOften in machine learning we use a model to describe the process that results in the data that are observed. For example, we may use a random forest model to classify whether customers may cancel a subscription from a service (known as churn modelling) or we may use a linear model to predict the revenue that will be generated for a company depending on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3836</td>\n",
       "      <td>Rishit Dagli</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Build K-Means from scratch in Python | by Rishit Dagli | Medium</td>\n",
       "      <td>Oct 29, 2019\\nK-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity. The results of the K-means clustering algorithm are:\\nRather than defining groups before looking at the data, clustering allows you to find and analyze the groups that have formed organically. The “Choosing K” section below describes how the number of groups can be determined.\\nThis story covers:\\nThe algorithm can be used to confirm business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3837</td>\n",
       "      <td>Sanne de Roever</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/using-resnet-for-time-series-data-4ced1f5395e3?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Using ResNet for ECG time-series data | by Sanne de Roever | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 29, 2020\\nRecurrent neural networks like plain RNN or more advanced models like LSTM and GRU used to be the goto models for deep-learning practitioners venturing into the time series domain. NLP, providing an abundance of sequence data, provided a willing subject. But transformer architectures like BERT and GPT have definitely taken over in the domain. Apart from these transformer architectures, CNN’s have also made a come-back or advance in the time-series domain. Are CNN’s good at modelling time-series?\\nHow good are CNN’s at modelling time-series?\\nTo answer this question tthis post replicates an article called “ECG Heartbeat Classification: A Deep Transferable Representation” [1] that applies ResNet, a CNN based architecture, to electrocardiogram (ECG) dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3838</td>\n",
       "      <td>Kirill Bondarenko</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@bond-kirill-alexandrovich/understanding-unet-27de538e08d8?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Understanding UNET. How to understand U-Net in the most... | by Kirill Bondarenko | Medium</td>\n",
       "      <td>Jul 2, 2019\\nHow to understand U-Net in the most simple way.\\nHello everyone!\\nIn this article I want to explain in simple way the one of the most popular models structures to solve image segmentation task — UNET.\\nIf you haven’t heard about it and haven’t seen its architecture, it’s not a problem, because in this article I will start with a simple structure and at the end will be traditional UNET. Let’s start.\\nUNET model was created for medicine purpose to find tumors in lungs or brain, but nowadays it has got much wider usage field.\\nFor example your task is to find rectangles on images, no matter what color or shape they are.\\nWe have a red one and yellow one rectangles on a green background. This is an input for UNET model.\\nWe need to define positive regions on the image where we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3839</td>\n",
       "      <td>Goibibo Tech</td>\n",
       "      <td>1</td>\n",
       "      <td>https://tech.goibibo.com/presenting-goibibo-insights-6b2ea7b3abc4?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Presenting Goibibo Insights. Its now been quite some time for... | by Goibibo Tech | Backstage</td>\n",
       "      <td>Backstage\\nDec 9, 2012\\nIts now been quite some time for Goibibo in business, which means that there is a huge amount of data that we have generated over this period. As a part of converting this data to information, we present to you our new initiative — Goibibo Insights.\\nAs the name suggests,Insights aims to give you interesting trends across the travel industry as seen by the large data we crunch at Goibibo. We believe this will further assist you in fine-tuning your travel plans. After all, this is your data — we have simply organised it and given it back.\\nRead on for the first series of insights with the info-graphics.\\nInsights are publicly shared on our Group portal (IbiboGroup) and also with the press.\\nOriginally published at goibibo.github.io on December 9, 2012.\\nBehind th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3840</td>\n",
       "      <td>Shi Yan</td>\n",
       "      <td>7</td>\n",
       "      <td>https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Understanding LSTM and its diagrams | by Shi Yan | ML Review</td>\n",
       "      <td>ML Review\\nMar 13, 2016\\nI just want to reiterate what’s said here:\\ncolah.github.io\\nI’m not better at explaining LSTM, I want to write this down as a way to remember it myself. I think the above blog post written by Christopher Olah is the best LSTM material you would find. Please visit the original link if you want to learn LSTM. (But I did create some nice diagrams.)\\nAlthough we don’t know how brain functions yet, we have the feeling that it must have a logic unit and a memory unit. We make decisions by reasoning and by experience. So do computers, we have the logic units, CPUs and GPUs and we also have memories.\\nBut when you look at a neural network, it functions like a black box. You feed in some inputs from one side, you receive some outputs from the other side. The decision i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3841</td>\n",
       "      <td>Pavan Gurram</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@gurrampavan6/fast-and-faster-region-based-convolutional-network-6a391a5a247a?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Fast and Faster Region-based Convolutional Network | by Pavan Gurram | Medium</td>\n",
       "      <td>Nov 27, 2019\\nObject detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.\\nThis post contains the details of Fast R-CNN and Faster R-CNN, which are the incremental improvements of R-CNN( aka “slow R-CNN”).\\nFast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks.\\nThe main contribution of Fast-R-CNN is the RoI pooling followed by a two-headed fully connected network.\\nAn input image is passed through CNN(set of convolutional and maxpooling layers)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3842</td>\n",
       "      <td>Synced</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf?source=tag_archive---------4-----------------------</td>\n",
       "      <td>GAN 2.0: NVIDIA’s Hyperrealistic Face Generator | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nDec 14, 2018\\nLook at the two pictures below. Can you tell which is a photograph and which was generated by AI?\\nThe truth is... wait for for it... both images are AI-generated fakes, products of American GPU producer NVIDIA’s new...\\n632 \\n632 \\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology &amp; Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3843</td>\n",
       "      <td>Rajneesh Jha</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/automated-feature-engineering-tools-44d00be56e3a?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Automated Feature Engineering Tools | by Rajneesh Jha | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 22, 2020\\nFeature Engineering is a technique to convert raw data columns to something meaningful which can help in predicting the outcomes in a machine learning task. Feature Engineering can be a very tedious and often the most time taking in machine learning life cycle.\\nBut to our rescue comes some of the cool tools which automates the whole feature engineering process and creates a large pool of features in a very short span for both classification and regression tasks.\\nWe have found following tools which automates the whole feature engineering process and creates large number of features for both relation and non-relational data. While some of them only performs feature engineering, we have some tools which also perform feature selection. Many a times these t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3844</td>\n",
       "      <td>Dimitris Panagopoulos</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Clustering documents with Python. A simple example with Wikipedia... | by Dimitris Panagopoulos | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 5, 2020\\nNatural Language Processing has made huge advancements in the last years. Currently, various implementations of neural networks are cutting edge and it seems that everybody talks about them. But, sometimes a simpler solution might be preferable. After all, one should try to walk before running. In this short article, I am going to demonstrate a simple method for clustering documents with Python. All code is available at GitHub (please note that it might be better to view the code in nbviewer).\\nWe are going to cluster Wikipedia articles using k-means algorithm. The steps for doing that are the following:\\n2. represent each article as a vector,\\n3. perform k-means clustering,\\n4. evaluate the result.\\nUsing the wikipedia package it is very easy to down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3845</td>\n",
       "      <td>Mo Hajr</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@mohamedhajr/ophow-i-got-my-first-android-job-without-a-degree-and-experience-98c70b931a9d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>How I got my first android job without a degree or experience | by Mo Hajr | Medium</td>\n",
       "      <td>Oct 7, 2016\\nIt’s a great time to work as an android developer, as Millions of android devices activated every day a huge demand for android developers is required.\\nBegging as an android developer can be extremely challenging too, so in this post, I will try to elaborate all the basic requirements and skills anyone needs to land a job as an android developer without the need of a degree or experience.\\nSo below is a list of all generalized requirements based on my little experience as an android developer and my researching for junior-level positions , the requirements will always vary from company to another and you will hardly find any two job descriptions exactly the same but these requirements will be good to start with.\\nYou might consider that this a lot of things but you can bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3846</td>\n",
       "      <td>Javaid Nabi</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-basics-part-1-a36d38c7916?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Machine Learning —Fundamentals. Basic theory underlying the field of... | by Javaid Nabi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 15, 2018\\nThis article introduces the basics of machine learning theory, laying down the common concepts and techniques involved. This post is intended for the people starting with machine learning, making it easy to follow the core concepts and get comfortable with machine learning basics.\\nIn 1959, Arthur Samuel, a computer scientist who pioneered the study of artificial intelligence, described machine learning as “the study that gives computers the ability to learn without being explicitly programmed.”\\nAlan Turing’s seminal paper (Turing, 1950) introduced a benchmark standard for demonstrating machine intelligence, such that a machine has to be intelligent and responsive in a manner that cannot be differentiated from that of a human being.\\nMachine Learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3847</td>\n",
       "      <td>SAGAR SHARMA</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Activation Functions in Neural Networks | by SAGAR SHARMA | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 6, 2017\\nIt’s just a thing function that you use to get the output of node. It is also known as Transfer Function.\\nIt is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\\nThe Activation Functions can be basically divided into 2 types-\\nFYI: The Cheat sheet is given below.\\nAs you can see the function is a line or linear. Therefore, the output of the functions will not be confined between any range.\\nEquation : f(x) = x\\nRange : (-infinity to infinity)\\nIt doesn’t help with the complexity or various parameters of usual data that is fed to the neural networks.\\nThe Nonlinear Activation Functions are the most used activation functions. Nonlinearity helps t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3848</td>\n",
       "      <td>Moses Olafenwa</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Train Object Detection AI with 6 lines of code | by Moses Olafenwa | DeepQuestAI | Medium</td>\n",
       "      <td>DeepQuestAI\\nAug 1, 2019\\nStep-by-step tutorial on training object detection models on your custom dataset\\nObject detection is one of the most profound aspects of computer vision as it allows you to locate, identify, count and track any object-of-interest in images and videos. Object detection is used extensively in many interesting areas of work and study such as:\\nA number of pre-collected object detection datasets such as Pascal VOC, Microsoft’s COCO, Google’s Open Images are readily available along with their pre-trained models for detection and identifying only a fix set of items.\\nHowever, the challenge with using these public datasets and pre-trained models is that they do not provide a convenient way for you to easily train new object detection models to detect and identify yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3849</td>\n",
       "      <td>Vincenzo Santopietro</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/intel-student-ambassadors/diving-into-abstractive-text-summarization-part-1-e8570d370021?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Diving into Abstractive Text Summarization — Part 1 | by Vincenzo Santopietro | Intel Student Ambassadors | Medium</td>\n",
       "      <td>Intel Student Ambassadors\\nFeb 14, 2019\\nText summarization is nowadays one of the most studied research topics in natural language processing (NLP) and has its applications in almost all domains of the internet, for example, e-shops, search engines and news websites that use summaries to give readers an overview of what a particular article might talk about.\\nText Summarization is a task to generate a shorter and concise version of a text while preserving the meaning of the original text.[1]\\nText summarization algorithms can be classified into two main categories:\\nExtractive text summarization algorithms are capable of extracting key sentences from a text without modifying any word [2][3]. Abstractive summarization, instead, involves a complex process understanding the language, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3850</td>\n",
       "      <td>Connor Shorten</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction to ResNets. This Article is Based on Deep Residual... | by Connor Shorten | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 24, 2019\\nThis Article is Based on Deep Residual Learning for Image Recognition from He et al. [2] (Microsoft Research): https://arxiv.org/pdf/1512.03385.pdf\\nIn 2012, Krizhevsky et al. [1] rolled out the red carpet for the Deep Convolutional Neural Network. This was the first time this architecture was more successful that traditional, hand-crafted feature learning on the ImageNet. Their DCNN, named AlexNet, contained 8 neural network layers, 5 convolutional and 3 fully-connected. This laid the foundational for the traditional CNN, a convolutional layer followed by an activation function followed by a max pooling operation, (sometimes the pooling operation is omitted to preserve the spatial resolution of the image).\\nMuch of the success of Deep Neural Network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3851</td>\n",
       "      <td>Akash Panchal</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3?source=tag_archive---------3-----------------------</td>\n",
       "      <td>NLP — Text Summarization using NLTK: TF-IDF Algorithm | by Akash Panchal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 10, 2019\\nIn the Article Text summarization in 5 steps using NLTK, we saw how we summarize the text using Word Frequency Algorithm.\\nBonus: See in Action with Streamlit App\\nNow, we’ll summarize the text using Tf-IDF Algorithm.\\nNote that, we’re implementing the actual algorithm here, not using any library to do the most of the tasks, we’re highly relying on the Math only.\\nIn a simple language, TF-IDF can be defined as follows:\\nA High weight in TF-IDF is reached by a high term frequency(in the given document) and a low document frequency of the term in the whole collection of documents.\\nTF-IDF algorithm is made of 2 algorithms multiplied together.\\nTerm frequency (TF) is how often a word appears in a document, divided by how many words there are.\\nTF(t) = (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3852</td>\n",
       "      <td>Vincenzo Lavorini</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/gaussian-mixture-model-clusterization-how-to-select-the-number-of-components-clusters-553bef45f6e4?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Gaussian Mixture Model clustering: how to select the number of components (clusters) | by Vincenzo Lavorini | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 21, 2018\\nIf you landed on this post, you probably already know what a Gaussian Mixture Model is, so I will avoid the general description of the this technique.\\nBut if you are not aware of the details, you can just see the GMM as a k-means which is able to form stretched clusters, like the ones you can see in Figure 2.\\nAll the code used for this post is in this notebook. In the same repository you can find the data to fully replicate the results you see plotted.\\nNow: suppose you are in the situation depicted in Figure 1, you want to discern how many clusters we have (or, if you prefer, how many gaussians components generated the data), and you don’t have information about the “ground truth”. A real case, where data do not have the nicety of behaving good as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3853</td>\n",
       "      <td>Supriya Secherla</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/understanding-optimization-algorithms-in-machine-learning-edfdb4df766b?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Understanding Optimization Algorithms in Machine Learning | by Supriya Secherla | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 18, 2021\\nMathematics behind two important optimization techniques in machine learning\\nOptimization is the process where we train the model iteratively that results in a maximum and minimum function evaluation. It is one of the most important phenomena in Machine Learning to get better results.\\nWhy do we optimize our machine learning models? We compare the results in every iteration by changing the hyperparameters in each step until we reach the optimum results. We create an accurate model with less error rate. There are different ways using which we can optimize a model. In this article, let’s discuss two important Optimization algorithms: Gradient Descent and Stochastic Gradient Descent Algorithms; how they are used in Machine Learning Models, and the math...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3854</td>\n",
       "      <td>Hucker Marius</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=tag_archive---------4-----------------------</td>\n",
       "      <td>HRNet Explained: Human Pose Estimation, Semantic Segmentation and Object Detection | by Hucker Marius | Oct, 2021 | Towards Data Science | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 6, 2021\\nOutline of HRNet explained:\\nIf you know already the basics (CNN + Areas of Application), skip down to section 3 or section 4.\\nHRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.\\nBut first, let’s understand what the fields mean and what kind of algorithm hides behind HRNet.\\nSemantic Segmentation is used to categorize structures of an image into certain classes. This is done by labeling each pixel with a certain class [3]. In the example below all pixels representing the cyclist are a class person and all pixels representing the bicycle are class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3855</td>\n",
       "      <td>Craig Villamor</td>\n",
       "      <td>1</td>\n",
       "      <td>https://cvil.ly/no-home-for-ipad-on-apple-com-88074e5ad99f?source=tag_archive---------4-----------------------</td>\n",
       "      <td>No home for iPad on Apple.com | by Craig Villamor | cvil.ly</td>\n",
       "      <td>cvil.ly\\nFeb 24, 2010\\nHave you noticed that there’s no spot in the Apple.com navigation for the iPad? I tried navigating to iPhone, iPod+iTunes and Mac and could not find iPad in any of those locations. I wonder when they plan to address this?\\n[caption id=”” align=”aligncenter” width=”576\" caption=”No home for iPad in Apple.com IA”]\\n[/caption]\\nUpdate: Now there is a home for iPad! Note that they also separated iPod &amp; iTunes.\\n[caption id=”” align=”aligncenter” width=”604\" caption=”Now there is a home for iPad on Aplle.com”]\\n[/caption]\\ndesign | technology | product\\n1.3K Followers\\nProduct leader, designer, tech and gadget nerd. Pragmatic optimist.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3856</td>\n",
       "      <td>Pranay Dugar</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Attention — Seq2Seq Models. Sequence-to-sequence (abrv. Seq2Seq)... | by Pranay Dugar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 13, 2019\\nSequence-to-sequence (abrv. Seq2Seq) models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning. Google Translate started using such a model in production in late 2016. These models are explained in the two pioneering papers (Sutskever et al., 2014, Cho et al., 2014).\\nA Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.\\nIn the case of Neural Machine Translation, the input is a series of words, and the output is the translated series of words.\\nNow let's work on reducing the blackness of our black box. The model is composed of an encoder and a decoder. The encoder captures the context of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3857</td>\n",
       "      <td>Arthur Juliani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3858</td>\n",
       "      <td>Dario Radečić</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/read-text-from-image-with-one-line-of-python-code-c22ede074cac?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Read Text from Image with One Line of Python Code | by Dario Radečić | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 28, 2019\\nDealing with images is not a trivial task. To you, as a human, it’s easy to look at something and immediately know what is it you’re looking at. But computers don’t work that way.\\nTasks that are too hard for you, like complex arithmetics, and math in general, is something that a computer chews without breaking a sweat. But here the exact opposite applies — tasks that are trivial to you, like recognizing is it cat or dog in an image are really hard for a computer. In a way, we are a perfect match. For now at least.\\nWhile image classification and tasks that involve some level of computer vision might require a good bit of code and a solid understanding, reading text from a somewhat well-formatted image turns out to be a one-liner in Python —and can b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3859</td>\n",
       "      <td>André Ferreira</td>\n",
       "      <td>24</td>\n",
       "      <td>https://towardsdatascience.com/interpreting-recurrent-neural-networks-on-multivariate-time-series-ebec0edb8f5a?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Interpreting recurrent neural networks on multivariate time series | by André Ferreira | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nIn this article, we’ll explore a state-of-the-art method of machine learning interpretability and adapt it to multivariate time series data, a use case which it wasn’t previously prepared to work on. You’ll find explanations to core concepts, on what they are and how they work, followed by examples. We’ll also address the main ideas behind the proposed solution, as well as a suggested visualization of instance importance.\\nIt’s not just hype anymore, machine learning is becoming an important part of our lives. Sure, there aren’t any sentient machines nor Scarlett Johansson ear lovers (shoutout to Her) out there, but the evolution of these algorithms is undeniable. They can ride cars, assist in medical prognosis, predict stock, play videogames at a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3860</td>\n",
       "      <td>Kate Marie Lewis</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/how-i-went-from-zero-coding-skills-to-data-scientist-in-6-months-c2207b65f2f3?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How I went from zero coding skills to data scientist in 6 months | by Kate Marie Lewis | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 24, 2020\\nI had just walked away from 8 years of study and hard work with no plan. You might be wondering why someone would do that. My boss was crushing my spirit and knew that I needed to make a change.\\nMy boyfriend suggested becoming a data scientist. I said ‘you're crazy!’ I didn’t know the first thing about programming. Surely he was overestimating what I was capable of. Imposter syndrome strikes again.\\nAbout two weeks later my friend Anna suggested the exact same thing, I thought about it some more and began to entertain the idea. Why not? I decided to become a beginner again and reinvent myself as a data scientist.\\nI wanted to learn at my own pace so I decided to take online courses. I figured that with a PhD in Neuroscience I probably had enough for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3861</td>\n",
       "      <td>Taras Bakusevych</td>\n",
       "      <td>7</td>\n",
       "      <td>https://uxdesign.cc/20-ideas-for-better-data-visualization-73f7e3c2782d?source=tag_archive---------3-----------------------</td>\n",
       "      <td>20 ideas for better data visualization | by Taras Bakusevych | UX Collective</td>\n",
       "      <td>UX Collective\\nAug 17, 2021\\nApplications we design are becoming increasingly data-driven. The need for quality data visualization is high as ever. Confusing and misleading graphics are all around us, but we can change this by following these simple rules.\\nChoosing the wrong chart type, or defaulting to the most common type of data visualization could confuse users or lead to data misinterpretation. The same data set can be represented in many ways, depending on what users would like to see. Always start with a review of your data set and user interview.\\nYou can learn more on how to pick the right representation for your data, and how to design effective dashboards in my article about Dashboard design.\\nWhen using horizontal bars, plot negatives values on the left side and positive o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3862</td>\n",
       "      <td>Joshua Holmes</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@JoshDHolmes/blog-9-information-architecture-3bc96dabdc0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Blog 9- Information Architecture. 1. What is the purpose of metadata... | by Joshua Holmes | Medium</td>\n",
       "      <td>Oct 18, 2015\\n1. What is the purpose of metadata? What are the categories of metadata?\\nMetadata provides definitions about the data they are attached to. It can include descriptive information about the context, quality, condition and characteristics.\\nMetadata is broken into three categories; structural (describes information about the document), descriptive (enables the document to be identified) and administrative (identifies the relationship of the document to the business context).\\n2. What is a controlled vocabulary? How is a controlled vocabulary beneficial to a web site and/or organisation?\\nA controlled vocabulary is a list of equivalent terms in the form of a synonym ring or a list of preferred terms in the form of an authority file.\\nThis is beneficial as it helps categoris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3863</td>\n",
       "      <td>Roan Gylberth</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/konvergen/understanding-dropout-ddb60c9f98aa?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Understanding Dropout. One particular layers that are useful... | by Roan Gylberth | Konvergen.AI | Medium</td>\n",
       "      <td>Konvergen.AI\\nJul 21, 2019\\nOne particular layer that is useful, yet mysterious when training neural networks is Dropout. Dropout is created as a regularization technique, that we can use to reduce the model capacity so that our model can achieve lower generalization error. The intuition is easy, we didn’t use all neurons but only turn on some neuron in each training iteration with probability p. But how does dropout works, and is it the same as the implementation?\\n105 \\n105 \\n2\\nThe sharing platform of Konvergen.ai. Visit our homepage at https://konvergen.ai\\n171 Followers\\nCofounder of Konvergen.AI\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3864</td>\n",
       "      <td>TokenGo Platform_RU</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@RU_TokenGo/tokengo-%D0%B7%D0%B0%D0%BF%D1%83%D1%81%D0%BA%D0%B0%D0%B5%D1%82-ico-15ed47e79fb7?source=tag_archive---------3-----------------------</td>\n",
       "      <td>TokenGo запускает ICO!. Приветствую вас, друзья! TokenGo... | by TokenGo Platform_RU | Medium</td>\n",
       "      <td>Feb 26, 2018\\nПриветствую вас, друзья! TokenGo запускает ICO!\\nМы долго шли к этому дню, к этому волнующему событию. До момента запуска ICO платформы TokenGo остались считанные часы.\\nВ первую очередь я хочу сказать спасибо всем тем, кто сегодня с нами! С кем-то мы знакомы уже несколько месяцев, успели пообщаться, обсудить будущее и подружиться, кто-то присоединяется только сейчас, изучает White Paper, читает темы на форумах, задает вопросы в Telegram-чате. И это очень здорово, что наше сообщество постоянно растет, укрепляется, и каждый участник вносит свой вклад в строительство экосистемы TokenGo. Отдельно хочу поздравить инвесторов, записавшихся в White List. Уверен, что полученный вами уникальный бонус вас обязательно порадует!\\nА в TokenGo все продолжает идти по плану. Совсем ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3865</td>\n",
       "      <td>karthic Rao</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@hackintoshrao/tips-to-avoid-the-pitfall-of-over-fitting-in-linear-regression-468e590c4f92?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Tips to avoid the pitfall of over fitting in Linear Regression | by karthic Rao | Medium</td>\n",
       "      <td>Jan 10, 2016\\nTips to avoid the pitfall of over fitting in Linear Regression\\n8. The choice of the model has to be based on the observation from training error and test error . Also its tricky to make choice of right features to come to make build the model for your predictions.\\n1 \\n1 \\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n743 Followers\\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3866</td>\n",
       "      <td>Pallawi</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/@pallawi-ds/step-by-step-understand-the-architecture-of-region-proposal-network-r-cnn-695a14a060a7?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Step by step -Understand the architecture of Region proposal network (R-CNN) | by Pallawi | Medium</td>\n",
       "      <td>Sep 5, 2020\\nThis blog is written to explain the evolution of object detection models in simple words and self-explanatory diagrams. This blog can be helpful to every individual who is entering into the field of computer vision and data science or has taken up a project which requires solving an object detection problem.\\nWe all must have heard about Faster R-CNN and there are high chances that you found this blog when you searched for the keyword “Faster R-CNN” as it has been among the state of arts used in many fields since January 2016.\\nA strong object detection architecture like Faster RCNN is built upon the successful research like R-CNN and Fast R-CNN. To honestly enjoy working, troubleshooting and pursuing the dream of creating your own model which can one day be called a state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3867</td>\n",
       "      <td>Unchainet</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@unchainet/invest-in-unchainet-heterogeneous-cloud-computing-infrastructure-b61dd2ba36e0?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Invest in Unchainet |Heterogeneous Cloud Computing Infrastructure | by Unchainet | Medium</td>\n",
       "      <td>Aug 28, 2018\\nUnchainet is aiming to provide a decentralized cloud platform connecting providers with spare computing resources and clients who need them. Research shows 30% of servers in private data centers consume energy but are not being used. We are working to provide easy-to-install software for companies with private data centers, hosting companies and individuals so they can easily connect to the Unchainet network and start earning money on a transparent and efficient marketplace. Unchainet clients will include existing partners and all other cloud users. Our platform’s important differentiation from competing decentralized cloud platforms is familiar open source technology and bridging interfaces which completely removes friction associated with staff training and allows easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3868</td>\n",
       "      <td>Justin</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/teklit/coding-is-a-trap-get-out-14a6beb28c8?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Coding is a Trap. Get Out. | TekLit</td>\n",
       "      <td>TekLit\\nJul 10, 2021\\nThe looming threat to the average programmer.\\nLet’s face it. Unless you are talented enough for Google to hire you, you are probably limited to developing APIs, websites, or customizing an ERP-like business system.\\nIf toiling day after day, adding mundane features to boring systems isn’t enough for you, you have the added task of keeping up with the frameworks and tools that will evolve with...\\n8.8K \\n8.8K \\n295\\nWe’re software developers, for better or for worse. Friendlier than your average StackOverflow moderator, but we probably won’t fix your code.\\n1.9K Followers\\nSoftware Developer | Writer for TekLit\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3869</td>\n",
       "      <td>Daniel Emaasit</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/emaasit/in-case-you-missed-it-my-webinar-on-model-based-machine-learning-1ca6bef79ae?source=tag_archive---------1-----------------------</td>\n",
       "      <td>In case you missed it: My Webinar on Model-Based Machine Learning | by Daniel Emaasit | emaasit | Medium</td>\n",
       "      <td>emaasit\\nAug 3, 2016\\nIn case you missed my free webinar on “Model-Based Machine Learning”, here is the recording.\\nApologies for the poor quality of the video. Domino Data Lab’s webinar platform suffered a service degradation while recording the event. The webinar slides may be found below.\\n[slideshare id=64647075&amp;doc=3rdpresentationpaperreview-160803065711]\\nIf you have any questions, please do not hesitate to contact me. Finally, I would like to thank Daniel Enthoven and Daniel Chalef from Domino Data Lab for setting up this webinar.\\nEmaasit’s personal blog about R, Bayesian Machine Learning, Big Data, Bayesian Nonparametrics, &amp; Probabilistic Programming\\n252 Followers\\nFounder at @SparkIQ_Labs, PhD Student in Urban Mobility, Bayesian Machine Learning Research Scientist, Organizer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3870</td>\n",
       "      <td>RomRoc</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/hackernoon/instance-segmentation-in-google-colab-with-custom-dataset-b3099ac23f35?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Instance Segmentation in Google Colab with Custom Dataset | by RomRoc | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nSep 18, 2018\\nThis article proposes an easy and free solution to train a Tensorflow model for instance segmentation in Google Colab notebook, with a custom dataset.\\nPrevious article was about Object Detection in Google Colab with Custom Dataset, where I trained a model to infer bounding box of my dog in pictures. The protagonist of my article is again my dog: in this case we take a step forward, we identify not only the bounding box, we make even pixel wise classification.\\nCompared to previous article, we hold the same characteristics:\\nThese features allow anybody following this tutorial to create an instance segmentation model, and test it in Google Colab or export the model to run in a local machine.\\nSource code of this article, including the sample dataset, is av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3871</td>\n",
       "      <td>Javed Shaikh</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK. | by Javed Shaikh | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 23, 2017\\nLatest Update:I have uploaded the complete code (Python and Jupyter notebook) on GitHub: https://github.com/javedsha/text-classification\\nDocument/Text classification is one of the important and typical task in supervised machine learning (ML). Assigning categories to documents, which can be a web page, library book, media articles, gallery etc. has many applications like e.g. spam filtering, email routing, sentiment analysis etc. In this article, I would like to demonstrate how we can do text classification using python, scikit-learn and little bit of NLTK.\\nDisclaimer: I am new to machine learning and also to blogging (First). So, if there are any mistakes, please do let me know. All feedback appreciated.\\nLet’s divide the classification problem in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3872</td>\n",
       "      <td>Bruce Yang</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Deep Reinforcement Learning for Automated Stock Trading | by Bruce Yang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 25, 2020\\nNote from Towards Data Science’s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author’s contribution. You should not rely on an author’s works without seeking professional advice. See our Reader Terms for details.\\nThis blog is based on our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, presented at ICAIF 2020: ACM International Conference on AI in Finance.\\nOur codes are available on Github.\\ngithub.com\\nOur paper is available on SSRN.\\npapers.ssrn.com\\nIf you want to cite our paper, the reference format is as follows:\\nHongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3873</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/the-official-unofficial-firefox-blog/the-first-inaugural-firefox-census-results-a1a05327ed7f?source=tag_archive---------2-----------------------</td>\n",
       "      <td>The First Inaugural Firefox Census Results | by Firefox | The Official Unofficial Firefox Blog | Medium</td>\n",
       "      <td>The Official Unofficial Firefox Blog\\nNov 10, 2016\\nWe did a bit of informal censusing last month to get to know our users in the best way possible: anonymously and collectively. You might have seen the survey, which we shared through email, our about:home page, and social media. You might have also noticed it came from our Bureau of Censusing (not an official team here), Department of Whimsy (also not an official department, but you better believe we’re doing some introspection now as to why not). It was totally voluntary and, like everything we do, about openness and transparency.\\nSo in that spirit, let’s look at the results! You can find the full report here, if you’re into that sort of thing. There were 44 questions and a ton of interesting ways to slice the data, so for the sake ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3874</td>\n",
       "      <td>Ketan Doshi</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Audio Deep Learning Made Simple: Automatic Speech Recognition (ASR), How it Works | by Ketan Doshi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 25, 2021\\nOver the last few years, Voice Assistants have become ubiquitous with the popularity of Google Home, Amazon Echo, Siri, Cortana, and others. These are the most well-known examples of Automatic Speech Recognition (ASR). This class of applications starts with a clip of spoken audio in some language and extracts the words that were spoken, as text. For this reason, they are also known as Speech-to-Text algorithms.\\nOf course, applications like Siri and the others mentioned above, go further. Not only do they extract the text but they also interpret and understand the semantic meaning of what was spoken, so that they can respond with answers, or take actions based on the user's commands.\\nIn this article, I will focus on the core capability of Speech-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3875</td>\n",
       "      <td>Chunguang (Wayne) Zhang</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/eagleview-super-high-resolution-image-segmentation-with-deeplabv3-mask-rcnn-using-keras-arcgis-9be08caac42c?source=tag_archive---------5-----------------------</td>\n",
       "      <td>EagleView high-resolution image semantic segmentation with Mask-RCNN/DeepLabV3+ using Keras and ArcGIS Pro | by Chunguang (Wayne) Zhang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 10, 2019\\nComputer vision in Machine Learning provides enormous opportunities for GIS. Its tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions.[1][2][3][4] In the last several years, computer vision is increasingly shifting from traditional statistical methods to the state-of-art deep learning neural network techniques.\\nIn this blog, I will share several empirical practices using Keras and ESRI ArcGIS Pro tools with deep learning and transfer learning techniques to build a building footprint image segmentation network model from a super-high-resolution 3-inch of EagleView (Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3876</td>\n",
       "      <td>Uday Paila</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@udaybhaskarpaila/everything-you-need-to-know-about-logistic-regression-18e740be87a0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Everything You Need to Know about Logistic Regression | by Uday Paila | Medium</td>\n",
       "      <td>Feb 6, 2020\\nIn this article, I will discuss all cases of Logistic Regression that are useful while applying.\\nLet’s take x as an input feature vector, and y is a class (-1 or +1), then the probability of class given input vector represented by the below formula.\\nand log loss is\\nLoss with regularization for optimization is\\nN is the number of data points we have, C is hyperparameter to control regularization. Above I added l2 regularization notation. x_i is the data points features and y_i(+1 or -1) is the label we have for x_i. This formulation works only for Binary classification.\\nAlso, we can represent the Loss function as below, and that works for multiclass formulation as well.\\nLet’s take we have K classes and N number of data points. Now the Log loss function is represented a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3877</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Gradient descent algorithms and adaptive learning rate adjustment methods | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 14, 2017\\nHere is a quick concise summary for reference. For more detailed explanation please read: http://ruder.io/optimizing-gradient-descent/\\nVanilla gradient descent, aka batch gradient descent, computes the gradient of the cost function w.r.t. to the parameters θ for the entire training dataset.\\nStochastic gradient descent (SGD) in contrast performs a parameter update for each training example x(i) and label y(i)\\nMini-batch gradient descent finally takes the best of both worlds and performs an update for every mini-batch of n training examples.\\nVanilla mini-batch gradient descent, however, does not guarantee good convergence, but offers a few challenges that need to be addressed:\\nSGD has trouble navigating ravines, i.e. areas where the surface curves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3878</td>\n",
       "      <td>Charlie Kufs</td>\n",
       "      <td>6</td>\n",
       "      <td>https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English</td>\n",
       "      <td>Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3879</td>\n",
       "      <td>Tara Mullin</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd?source=tag_archive---------1-----------------------</td>\n",
       "      <td>DBSCAN Parameter Estimation Using Python | by Tara Mullin | Medium</td>\n",
       "      <td>Jul 10, 2020\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is an unsupervised machine learning technique used to identify clusters of varying shape in a data set (Ester et al. 1996). Another post I wrote goes into what DBSCAN is and when to use it. You can find it here. This post will focus on estimating DBSCAN’s two parameters:\\nThere is no automatic way to determine the MinPts value for DBSCAN. Ultimately, the MinPts value should be set using domain knowledge and familiarity with the data set. From some research I’ve done, here are a few rules of thumb for selecting the MinPts value:\\nAfter you select your MinPts value, you can move on to determining ε. One technique to automatically determine the optimal ε value is described in this paper. This technique calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3880</td>\n",
       "      <td>Amirhossein Heydarian</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/u-net-for-semantic-segmentation-on-unbalanced-aerial-imagery-3474fa1d3e56?source=tag_archive---------4-----------------------</td>\n",
       "      <td>U-Net for Semantic Segmentation on Unbalanced Aerial Imagery | by Amirhossein Heydarian | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 3, 2021\\nIn this article, we review the problem of semantic segmentation on unbalanced binary masks. Focal loss and mIoU are introduced as loss functions to tune the network parameters. Finally, we train the U-Net implemented in PyTorch to perform semantic segmentation on aerial images. The training codes and PyTorch implementations are available through Github.\\nThe dataset used here is “Semantic segmentation of aerial imagery” which contains 72 satellite images of Dubai, the UAE, and is segmented into 6 classes. The classes include water, land, road, building, vegetation, and unlabeled.\\nU-Net is a convolutional neural network that originally was presented for biomedical image segmentation at the Computer Science Department of the University of Freiburg. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3881</td>\n",
       "      <td>Learner Subodh</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/analytics-vidhya/dimensionality-reduction-by-stochastic-gradient-descent-f617ebde3c1b?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Dimensionality Reduction by Stochastic Gradient Descent | by Learner Subodh | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 27, 2020\\nThis post demonstrates the use of Stochastic Gradient Descent for Dimensionality Reduction.\\nWhat is Dimensionality Reduction?\\nDimensionality reduction is the process of reducing a potentially large set of features F to a smaller set of features F’ to be considered in a given machine learning or statistics problem.\\nIn an unsupervised setting, dimensionality reduction is often used for exploratory data analysis, for example to visualize the distribution of high dimensional data in human-digestible two or three dimensions. In a supervised setting, the main use is to reduce the number of parameters a learning machine has to determine. In other words: The goal of dimensionality reduction is to overcome the curse of dimensionality.\\nA straightforward approa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3882</td>\n",
       "      <td>Walid Amamou</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647?source=tag_archive---------7-----------------------</td>\n",
       "      <td>How to Fine-Tune BERT Transformer with spaCy 3 | by Walid Amamou | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 28, 2021\\nSince the seminal paper “Attention is all you need” of Vaswani et al, Transformer models have become by far the state of the art in NLP technology. With applications ranging from NER, Text Classification, Question Answering or text generation, the applications of this amazing technology are limitless.\\nMore specifically, BERT — which stands for Bidirectional Encoder Representations from Transformers— leverages the transformer architecture in a novel way. For example, BERT analyses both sides of the sentence with a randomly masked word to make a prediction. In addition to predicting the masked token, BERT predicts the sequence of the sentences by adding a classification token [CLS] at the beginning of the first sentence and tries to predict if the sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3883</td>\n",
       "      <td>Arthur Juliani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3884</td>\n",
       "      <td>Becky Zhu</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/unpackai/sgd-mnist-putting-it-all-together-2b09d21c9e9a?source=tag_archive---------8-----------------------</td>\n",
       "      <td>SGD: MNIST — Putting it all together | by Becky Zhu | unpackAI | Medium</td>\n",
       "      <td>unpackAI\\nJun 6, 2021\\nThere are 7 steps to train/get a model in deep learning like this chart:\\nWe now put it with the SGD together and look at them step by step:\\nStep 1: Initialize\\nIn this step, we initialize our parameters with random values and tell PyTorch that we want to track their gradients:\\nWe will do the following things in this step:\\nStep 2: Predict\\nIn this step,we will calculate the predictions to see how close our predictions to our targets. The code will like this\\npreds = f(time, params)\\nStep 3: Calculate the Loss\\nIn this step, can change the weight by a little in the direction of the slope, calculate the loss and adjustment again, and repeat this a few times. We will get to the lowest point on the curve. We can use “mse”or “l1”to calculate.\\n“mse”stands for *mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3885</td>\n",
       "      <td>Utkarsh Ankit</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f?source=tag_archive---------9-----------------------</td>\n",
       "      <td>What is Transformer Network | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 24, 2020\\nThe Transformer Neural Network is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease. It was proposed in the paper “Attention Is All You Need” 2017 [1]. It is the current state-of-the-art technique in the field of NLP.\\nBefore directly jumping to Transformer, I will take some time to explain the reason why we use it and from where it comes into the picture. (If you want to skip this part then directly go to the Transformer topic, but I suggest you read it sequentially for better understanding).\\nSo, the story starts with RNN (Recurrent Neural Networks).\\nWhat is RNN? How is it different from simple ANN? What is the major difference?\\nRNNs are the Feed Forward Neural Networks that are ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3886</td>\n",
       "      <td>Venkatesh Tata</td>\n",
       "      <td>10</td>\n",
       "      <td>https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Simple Image Classification using Convolutional Neural Network — Deep Learning in python. | by Venkatesh Tata | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nDec 13, 2017\\nIn this article we will be solving an image classification problem, where our goal will be to tell which class the input image belongs to. The way we are going to achieve it is by training an artificial neural network on few thousand images of cats and dogs and make the NN(Neural Network) learn to predict which class the image belongs to, next time it sees an image having a cat or dog in it.\\nThe key thing to understand while following this article is that the model we are building now can be trained on any type of class you want, i am using cat and dog only as a simple example for making you understand how convolutional neural networks work. For example, if there are any doctors reading this, after completing this article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3887</td>\n",
       "      <td>Sarthak Jain</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/nanonets/how-to-easily-detect-objects-with-deep-learning-on-raspberrypi-225f29635c74?source=tag_archive---------2-----------------------</td>\n",
       "      <td>How to easily Detect Objects with Deep Learning on Raspberry Pi | by Sarthak Jain | NanoNets | Medium</td>\n",
       "      <td>NanoNets\\nMar 20, 2018\\nDisclaimer: I’m building nanonets.com to help build ML with less data and no hardware\\nIf you’re impatient scroll to the bottom of the post for the Github Repos\\nThe raspberry pi is a neat piece of hardware that has captured the hearts of a generation with ~15M devices sold, with hackers building even cooler projects on it. Given the popularity of Deep Learning and the Raspberry Pi Camera we thought it would be nice if we could detect any object using Deep Learning on the Pi.\\nNow you will be able to detect a photobomber in your selfie, someone entering Harambe’s cage, where someone kept the Sriracha or an Amazon delivery guy entering your house.\\n20M years of evolution have made human vision fairly evolved. The human brain has 30% of it’s Neurons work on proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3888</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/an-intuitive-explanation-of-beam-search-9b1d744e7a0f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>An intuitive explanation of Beam Search | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 2, 2020\\nIn this article, we will learn:\\nmedium.com\\ntowardsdatascience.com\\nIn this article, you will get a detailed explanation of how neural machine translation developed using sequence to sequence algorithm to find the most relevant words in sentences for a target language.\\nWhat is Beam search?\\nTo understand the Beam search, we will use the neural machine translation use case of sequence to sequence.\\nThe sequence to sequence model uses an encoder and decoder framework with Long Short Term Memory(LSTM) or Gated Recurrent Unit(GRU) as the basic blocks.\\nEncoder maps a source sequence encodes the source information and passes it to the decoder. The decoder takes the encoded data from the encoder as an input along with the start-of-string &lt;START&gt; token as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3889</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/the-games-that-ai-won-ff8fd4a71efc?source=tag_archive---------6-----------------------</td>\n",
       "      <td>The Games That AI Won. And The Progress They Represent | by Brandon Walker | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 15, 2020\\nSome tasks that AI does are actually not impressive. Think about your camera recognizing and auto-focusing on faces in pictures. That technology has been around since 2001, and it doesn’t tend to excite people. Why not? Well, because you can do that too, you can focus your eyes on someone’s face very easily. In fact, it’s so easy you don’t even know how you do it. If AI can do it too, then who cares how it works? Though we may not explicitly understand how this AI works, its underlying mechanisms don’t do anything we can’t. At least, this is what I think most people are thinking.\\nGames are just the opposite. Rather than games being an innate ability we have (like focusing your vision), you have an understanding of how and why you make decisions with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3890</td>\n",
       "      <td>bitsofinfo</td>\n",
       "      <td>16</td>\n",
       "      <td>https://medium.com/@bitsofinfo/clustering-liferay-globally-across-data-centers-gslb-with-jgroups-and-relay2-7786b8dbbb96?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Clustering Liferay globally across data centers (GSLB) with JGroups and RELAY2 | by bitsofinfo | Medium</td>\n",
       "      <td>May 21, 2014\\nRecently I’ve have been looking into options to solve the problem of GSLB’ing (global server load balancing) a Liferay Portal instance.\\nThis article is a work in progress... and a long one. Jan Eerdekens states it correctly in his article, “Configuring a Liferay cluster is part experience and part black magic” .... however doing it across data-centers however is like wielding black magic across N black holes....\\nFootnotes for this article are here: https://bitsofinfo.wordpress.com/2014/05/21/liferay-clustering-internals/\\nThe objective is a typical one.\\nHopefully this article will help others out there, point them in a new direction and give them some ideas on how to put something like this together.\\nI’d like to note that this is not necessarily the ideal way to do th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3891</td>\n",
       "      <td>Andreas Yonathan</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@andreasyonathan/kuliah-itu-gak-penting-292defe6d476?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Kuliah Itu Gak Penting. “Buat apa kuliah kalo kalah sukses atau... | by Andreas Yonathan | Medium</td>\n",
       "      <td>May 2, 2017\\n“Buat apa kuliah kalo kalah sukses atau gaji aja kalah gede dari lulusan SMA/SMK?”\\nSerius, pasti banyak orang yang pernah terlintas pikiran brilian seperti diatas. Bahkan bisa jadi kamu yang membaca ini adalah satunya bukan? Tenang saja, kamu tidak sendirian karena saya juga pernah berpikir seperti itu kok hehehe :D\\nYa, tidak bisa dipungkiri karena kita sering melihat contoh orang-orang terkenal yang sukses padahal mereka OD (baca: Out Dewe, kalau DO kan Drop Out, jelek kesannya ditendang, sementara OD gak perlu nunggu ditendang udah keluar-keluar sendiri hehehe :p) atau bahkan sekolah pun gak tamat. Contohnya Brad Pitt, Oprah Winfrey, Lady Gaga, John Lennon, Eminem. Nama-nama itu pasti sudah tidak asing lagi kan?\\nMungkin ada yang berpikir orang yang OD maupun DO tidak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3892</td>\n",
       "      <td>Rostyslav Neskorozhenyi</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/word-embeddings-in-2020-review-with-code-examples-11eb39a1ee6d?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Word embeddings in 2020. Review with code examples | by Rostyslav Neskorozhenyi  | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 24, 2020\\nIn this article we will study word embeddings — digital representation of words suitable for processing by machine learning algorithms.\\nOriginally I created this article as a general overview and compilation of current approaches to word embedding in 2020, which our AI Labs team could use from time to time as a quick refresher. I hope that my article will be useful to a wider circle of data scientists and developers. Each word embedding method in the article has a (very) short description, links for further study, and code examples in Python. All code is packed as Google Colab Notebook. So let’s begin.\\nAccording to Wikipedia, Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3893</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/autoencoders-introduction-and-implementation-3f40483b0a85?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Autoencoders — Introduction and Implementation in TF. | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 26, 2017\\nAutoencoders (AE) are a family of neural networks for which the input is the same as the output (they implement a identity function). They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.\\nA really popular use for autoencoders is to apply them to images. The trick is to replace fully connected layers by convolutional layers. These, along with pooling layers, convert the input from wide and thin (let’s say 100 x 100 px with 3 channels — RGB) to narrow and thick. This helps the network extract visual features from the images, and therefore obtain a much more accurate latent space representation. The reconstruction process uses upsampling and convolutions.\\nThe resulting netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3894</td>\n",
       "      <td>Anne Bonner</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Getting Started With Google Colab | by Anne Bonner | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 1, 2019\\nYou know it’s out there. You know there’s free GPU somewhere, hanging like a fat, juicy, ripe blackberry on a branch just slightly out of reach.\\nBeautiful lightning-fast speed waiting just for you.\\nWondering how on earth to get it to work? You’re in the right place!\\nFor anyone who doesn’t already know, Google has done the coolest thing ever by providing a free cloud service based on Jupyter Notebooks that supports free GPU. Not only is this a great tool for improving your coding skills, but it also allows absolutely anyone to develop deep learning applications using popular libraries such as PyTorch, TensorFlow, Keras, and OpenCV.\\nColab provides GPU and it’s totally free. Seriously!\\nThere are, of course, limits. (Nitty gritty details are availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3895</td>\n",
       "      <td>Diego Lopez Yse</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Your Guide to Natural Language Processing (NLP) | by Diego Lopez Yse | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 15, 2019\\nEverything we express (either verbally or in written) carries huge amounts of information. The topic we choose, our tone, our selection of words, everything adds some type of information that can be interpreted and value extracted from it. In theory, we can understand and even predict human behaviour using that information.\\nBut there is a problem: one person may generate hundreds or thousands of words in a declaration, each sentence with its corresponding complexity. If you want to scale and analyze several hundreds, thousands or millions of people or declarations in a given geography, then the situation is unmanageable.\\nData generated from conversations, declarations or even tweets are examples of unstructured data. Unstructured data doesn’t fit n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3896</td>\n",
       "      <td>Jessica Dafflon</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/pixelcnns-blind-spot-84e19a3797b9?source=tag_archive---------6-----------------------</td>\n",
       "      <td>PixelCNN’s Blind Spot. Limitations of the PixelCNN and how to... | by Jessica Dafflon | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 8, 2021\\nWritten by Walter Hugo Lopez Pinaya, Pedro F. da Costa, and Jessica Dafflon\\nHi everybody! Today, we will continue the series about autoregressive models and we will focus on one of the biggest limitations of PixelCNNs (i.e., blind spots) and how to improve to fix it.\\nSummary\\nFor each topic, the code is availiable in this repository.\\nIn the previous two posts, we introduced generative models, the concept behind PixelCNNs, and looked at how a coloured PixelCNN works. Recall that PixelCNNs are a type of generative models that learn the probability distribution of pixels, that means that the intensity of future pixels will be determined by previous pixels. In this blogpost series we implemented two PixelCNNs and noticed that the performance was not st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3897</td>\n",
       "      <td>Matthew Stewart, PhD Researcher</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Simple Introduction to Convolutional Neural Networks | by Matthew Stewart, PhD Researcher | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 26, 2019\\nIn this article, I will explain the concept of convolution neural networks (CNN’s) using many swan pictures and will make the case of using CNN’s over regular multilayer perceptron neural networks for processing images.\\nImage Analysis\\nLet us assume that we want to create a neural network model that is capable of recognizing swans in images. The swan has certain characteristics that can be used to help determine whether a swan is present or not, such as its long neck, its white color, etc.\\nFor some images, it may be more difficult to determine whether a swan is present, consider the following image.\\nThe features are still present in the above image, but it is more difficult for us to pick out these characteristic features. Let us consider some mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3898</td>\n",
       "      <td>Md Sohel Mahmood</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/practical-implementation-of-outlier-detection-in-python-90680453b3ce?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Practical implementation of outlier detection in python | by Md Sohel Mahmood | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 26, 2020\\nOutliers, one of the buzzwords in the manufacturing industry, has driven engineers and scientists to develop newer algorithms as well as robust techniques for continuous quality improvement. If the data include even if one outlier, it has the potential to dramatically skew the calculated parameters. Therefore, it is of utmost importance to analyze the data without those deviant points. It is also important to understand which of the data points are considered as outliers. Extreme data points do not always necessarily mean those are outliers.\\nIn this article, I will discuss the algorithm and the python implementation for three different outlier detection techniques. Those are Interquartile (IQR) method, Hampel method and DBSCAN clustering method.\\nIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3899</td>\n",
       "      <td>Vladimir Shapiro</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/sap-design/explaining-system-intelligence-68f8fcc07a64?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Explaining system intelligence. Empower your users, but don’t overwhelm... | by Vladimir Shapiro | SAP Design | Medium</td>\n",
       "      <td>SAP Design\\nApr 11, 2018\\nThis blog belongs to the SAP Design series about intelligent system design. You might also be interested in our previous post, 5 Challenges to Your Machine Learning Project.\\nOne of the guiding design principles for intelligent systems is to empower end users. If we want people to trust machines, we must share information about the underlying models and the reasoning behind the results of algorithms. This is even more vital for business applications, when users are held accountable for every decision they make.\\nIt’s widely accepted that intelligent systems must come with a certain level of transparency. There’s even a new term for it: explainable AI. But, that’s just the beginning. As designers, we need to ask ourselves how explainable AI is tied to user inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3900</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Topic Modeling and Latent Dirichlet Allocation (LDA) in Python | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 31, 2018\\nTopic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.\\nHere we are going to apply LDA to a set of documents and split them into topics. Let’s get started!\\nThe data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from Kaggle.\\nTake a peek of the data.\\n1048575\\nWe will perform the following steps:\\nLoading gensim and nltk libraries\\n[nltk_data] Downloading package wordnet to[nltk_data]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3901</td>\n",
       "      <td>Neeraj Varshney</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/analytics-vidhya/step-by-step-implementation-of-conditional-generative-adversarial-networks-54e4b47497d6?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Step by Step Implementation of Conditional Generative Adversarial Networks | by Neeraj Varshney | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJun 7, 2020\\nGenerative Adversarial Networks (GANs) have had a lot of success since they were introduced in 2014 by Ian Goodfellow. For somebody starting out in Machine Learning, the intricate Mathematics and the complex-looking architecture of GANs seems daunting. So, let’s demystify GANs/C-GANs and implement a simple application with PyTorch. This article is self-contained and is targeted for beginner to intermediate level Machine Learning enthusiasts.\\n159 \\n159 \\n2\\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n105 Followers\\nPh.D. student in Natural Language Processing (https://nrjvarshney.github.io)\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3902</td>\n",
       "      <td>Aakanksha NS</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/multiclass-text-classification-using-lstm-in-pytorch-eac56baed8df?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Multiclass Text Classification using LSTM in Pytorch | by Aakanksha NS | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 7, 2020\\nHuman language is filled with ambiguity, many-a-times the same phrase can have multiple interpretations based on the context and can even appear confusing to humans. Such challenges make natural language processing an interesting but hard problem to solve. However, we’ve seen a lot of advancement in NLP in the past couple of years and it’s quite fascinating to explore the various techniques being used. This article aims to cover one such technique in deep learning using Pytorch: Long Short Term Memory (LSTM) models.\\nHere’s a link to the notebook consisting of all the code I’ve used for this article: https://jovian.ml/aakanksha-ns/lstm-multiclass-text-classification\\nIf you’re new to NLP or need an in-depth read on preprocessing and word embeddings, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3903</td>\n",
       "      <td>Animesh Agarwal</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Linear Regression using Python. Linear Regression is usually the first... | by Animesh Agarwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 5, 2018\\nLinear Regression is usually the first machine learning algorithm that every data scientist comes across. It is a simple model but everyone needs to master it as it lays the foundation for other machine learning algorithms.\\nWhere can Linear Regression be used? It is a very powerful technique and can be used to understand the factors that influence profitability. It can be used to forecast sales in the coming months by analyzing the sales data for previous months. It can also be used to gain various insights about customer behaviour. By the end of the blog we will build a model which looks like the below picture i.e, determine a line which best fits the data.\\nThis is the first blog of the machine learning series that I am going to cover. One can get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3904</td>\n",
       "      <td>Vindula Jayawardana</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/autoencoders-bits-and-bytes-of-deep-learning-eaba376f23ad?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Autoencoders — Bits and Bytes of Deep Learning | by Vindula Jayawardana | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 4, 2017\\nOne way to think of what deep learning does is as “A to B mappings,” says Andrew Ng, chief scientist at Baidu Research. “You can input an audio clip and output the transcript. That’s speech recognition.” As long as you have data to train the software, the possibilities are endless, he maintains. “You can input email, and the output could be: Is this spam or not?” Input loan applications, he says, and the output might be the likelihood a customer will repay it. Input usage patterns on a fleet of cars and the output could advise where to send a car next.\\nRather making the facts complicated by having complex definitions, think of deep learning as a subset of a subset. Artificial Intelligence encircles a wide range of technologies and techniques that ena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3905</td>\n",
       "      <td>Dhruv Parthasarathy</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@dhruvp/how-to-write-a-neural-network-to-play-pong-from-scratch-956b57d4f6e0?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Write an AI to win at Pong from scratch with Reinforcement Learning | by Dhruv Parthasarathy | Medium</td>\n",
       "      <td>Sep 25, 2016\\nThere’s a huge difference between reading about Reinforcement Learning and actually implementing it.\\nIn this post, you’ll implement a Neural Network for Reinforcement Learning and see it learn more and more as it finally becomes good enough to beat the computer in Pong! You can play around with other such Atari games at the OpenAI Gym.\\nBy the end of this post, you’ll be able to do the following:\\nThe code and the idea are all tightly based on Andrej Karpathy’s blog post. The code in me_pong.py is intended to be a simpler to follow version of pong.py which was written by Dr. Karpathy.\\nTo follow along, you’ll need to know the following:\\nIf you want a deeper dive into the material at hand, read the blog post on which all of this is based. This post is meant to be a simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3906</td>\n",
       "      <td>Sebastian Theiler</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Basics of Using Pre-trained GloVe Vectors in Python | by Sebastian Theiler | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nSep 7, 2019\\nThis article will cover: * Downloading and loading the pre-trained vectors * Finding similar vectors to a given vector * “Math with words” * Visualizing the vectors\\nFurther reading resources, including the original GloVe paper, are available at the end.\\nGlobal Vectors for Word Representation, or GloVe, is an “unsupervised learning algorithm for obtaining vector representations for words.” Simply put, GloVe allows us to take a corpus of text, and intuitively transform each word in that corpus into a position in a high-dimensional space. This means that similar words will be placed together.\\nIf you would like a detailed explanation of how GloVe works, linked articles are available at the end.\\nHead over to https://nlp.stanford.edu/projects/glove/.Then un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3907</td>\n",
       "      <td>Himanshu Chandra</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Pipelines &amp; Custom Transformers in scikit-learn: The step-by-step guide (with Python code) | by Himanshu Chandra | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 6, 2020\\nThis article will cover:\\nThere’s a video walkthrough of the code at the end for those who prefer the format. I personally like written tutorials, but I’ve had requests for video versions too in the past, so there it is.\\nSince you are here, there’s a very good chance you already know Pipelines make your life easy by pre-processing the data. I heard that too and tried to implement one in my code.\\nA shout-out to the few great tutorials I could find on the topic! I recommend you certainly browse through them, before or after the current article :\\ni. https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65ii. https://machinelearningmastery.com/how-to-transform-target-variables-for-regression-with-scikit-learniii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3908</td>\n",
       "      <td>William Scott</td>\n",
       "      <td>19</td>\n",
       "      <td>https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089?source=tag_archive---------2-----------------------</td>\n",
       "      <td>TF-IDF from scratch in python on a real-world dataset. | by William Scott | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 15, 2019\\nTF-IDF stands for “Term Frequency — Inverse Document Frequency”. This is a technique to quantify words in a set of documents. We generally compute a score for each word to signify its importance in the document and corpus. This method is a widely used technique in Information Retrieval and Text Mining.\\nIf I give you a sentence for example “This building is so tall”. It's easy for us to understand the sentence as we know the semantics of the words and the sentence. But how can any program (eg: python) interpret this sentence? It is easier for any programming language to understand textual data in the form of numerical value. So, for this reason, we need to vectorize all of the text so that it is better represented.\\nBy vectorizing the documents we ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3909</td>\n",
       "      <td>Kevin Luxem</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/deep-latent-variable-models-unravel-hidden-structures-a5df0fd32ae2?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Deep Latent Variable Models: Unravel Hidden Structures | by Kevin Luxem | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nUnderstanding the underlying structure of real-world data is one of the most compelling quests in machine learning. But with the advent of deep generative models researcher and practitioners have a powerful method to unravel it.\\nReal-world data is often complex and high-dimensional. Traditional approaches of data analysis are in most cases ineffective and can only model a very simple data distribution. Nowadays, we can use machine learning models to directly learn the structure of our data. The most common approach in machine learning is supervised learning, where we ask the model to learn a mapping from an input to an output variable, e.g. an image x to a label y. However, labelled data is expensive and prone to errors or biases by the human annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3910</td>\n",
       "      <td>Sourav kumar</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Sentence correction using Deep learning techniques | by Sourav kumar | Medium</td>\n",
       "      <td>Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3911</td>\n",
       "      <td>Elif Meşeci</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@elifmeseci/r-cnn-ailesi-part-ii-76cce9e4a9d6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>R — CNN Ailesi Part II: Faster R-CNN &amp; Mask R-CNN | by Elif Meşeci | Medium</td>\n",
       "      <td>Aug 19, 2021\\nMerhaba, R-CNN Ailesi: Part I’ de CNN , R- CNN ve Fast R-CNN’den bahsetmiştim. Bu yazıda ise Faster R-CNN ile Mask R-CNN’in gelişimini, avantajlarını ve dezavantajlarını inceleyeceğiz.\\nBir önceki yazımda bahsettiğim R-CNN ve Fast R-CNN, bölge tekliflerini bulmak için seçici arama kullanır. Seçici arama, ağın performansını etkileyen yavaş ve zaman alıcı bir işlemdir. Bunun üzerine Shaoqing Ren ve ark. seçici arama algoritmasını ortadan kaldıran ve ağın bölge tekliflerini öğrenmesini sağlayan bir nesne algılama algoritması geliştirdi. Faster R-CNN’de bölge tekliflerini belirlemek için özellik haritası üzerinde Seçici Arama algoritması kullanmak yerine Bölge Teklif Ağı (RPN — Region Proposal Network) kullanılır.\\nFaster R-CNN’de izlenen adımlar:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3912</td>\n",
       "      <td>M Bharathwaj</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/clustering-techniques-hierarchical-and-non-hierarchical-b520b5d6a022?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Clustering Techniques. Clustering falls under the unsupervised... | by M Bharathwaj | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 22, 2020\\nClustering falls under the unsupervised learning technique. In this technique, the data is not labelled and there is no defined dependant variable. This type of learning is usually done to identify patterns in the data and/or to group similar data.\\nIn this post, a detailed explanation on the type of clustering techniques and a code walk-through is provided.\\nClustering is a method of grouping of similar objects. The objective of clustering is to create homogeneous groups out of heterogeneous observations. The assumption is that the data comes from multiple population, for example, there could be people from different walks of life requesting loan from a bank for different purposes. If the person is a student, he/she could ask for an education loan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3913</td>\n",
       "      <td>Sairaj Neelam</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/analytics-vidhya/introduction-to-object-detection-with-rcnn-family-models-310558ce2033?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction to Object Detection with RCNN Family Models | by Sairaj Neelam | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 28, 2021\\nIn this post, you will discover a gentle introduction to the problem of object detection and state-of-the-art deep learning models designed to address it.\\nAfter reading this post, you will know:\\nLet’s get started.\\nThis article is divided into three parts; they are:\\n· Input: An image with a single object, such as a photograph.\\n· Output: A class label (e.g. one or more integers that are mapped to class labels).\\n2. Object Localization: Locate the objects in an image and output their location with a bounding box.\\n· Input: An image with one or more objects, such as a photograph.\\n· Output: One or more bounding boxes (e.g. defined by a point, width, and height).\\n3. Object Detection: Locate the objects with a bounding box and types or classes of the loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3914</td>\n",
       "      <td>Rowel Atienza</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537?source=tag_archive---------0-----------------------</td>\n",
       "      <td>LSTM by Example using Tensorflow. In Deep Learning, Recurrent Neural... | by Rowel Atienza | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 17, 2017\\nIn Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class of RNN that has found practical applications is Long Short-Term Memory (LSTM) because it is robust against the problems of long-term dependency. There is no shortage of articles and references explaining LSTM. Two recommended references are:\\nChapter 10 of Deep Learning Book by Goodfellow et. al.\\nUnderstanding LSTM Networks by Chris Olah\\nThere is also no shortage of good libraries to build machine learning applications based on LSTM. In GitHub, Google’s Tensorflow has now over 50,000 stars at the time of this writing suggesting a strong popularity among machine learning practitioners.\\nWhat seems to be lacking is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3915</td>\n",
       "      <td>Michael Phi</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Illustrated Guide to LSTM’s and GRU’s: A step by step explanation | by Michael Phi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 24, 2018\\nHi and welcome to an Illustrated Guide to Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU). I’m Michael, and I’m a Machine Learning Engineer in the AI voice assistant space.\\nIn this post, we’ll start with the intuition behind LSTM ’s and GRU’s. Then I’ll explain the internal mechanisms that allow LSTM’s and GRU’s to perform so well. If you want to understand what’s happening under the hood for these two networks, then this post is for you.\\nYou can also watch the video version of this post on youtube if you prefer.\\nRecurrent Neural Networks suffer from short-term memory. If a sequence is long enough, they’ll have a hard time carrying information from earlier time steps to later ones. So if you are trying to process a paragraph of text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3916</td>\n",
       "      <td>IPG Media Lab</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/ipg-media-lab/amazon-adds-photographic-product-search-to-ios-app-3c023e5d71ed?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Amazon Adds Photographic Product Search To iOS App | by IPG Media Lab | IPG Media Lab | Medium</td>\n",
       "      <td>IPG Media Lab\\nFeb 7, 2014\\nAmazon is raising the stakes of showrooming for retailers once again, folding its “Flow” technology, previously found in a standalone app released by its subsidiary, A9, into its main shopping app for iOS. “Flow” is visual product search, allowing users to photograph an object and see details about it on Amazon, which is even simpler than the previous norm of barcode recognition. Amazon’s competitive pricing is its main advantage in comparison to retailers, and by more effectively using other retailers as showrooms for the products it sells, it has the potential to further extend its dominance in more consumer categories.\\nThe media futures agency of IPG Mediabrands\\n1.99K Followers\\nKeeping brands ahead of the digital curve. An @IPGMediabrands company.\\nHel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3917</td>\n",
       "      <td>Gabe Flomo</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How to cluster images based on visual similarity | by Gabe Flomo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 29, 2020\\nIn this tutorial, I'm going to walk you through using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.\\nThe pre-trained model that will be used in this tutorial is the VGG16 convolutional neural network (CNN), which is considered to be state of the art for image recognition tasks. We are going to be using this model as a feature extractor only, meaning that we will remove the final (prediction) layer so that we can obtain a feature vector.\\nThis implementation will use the flowers dataset from Kaggle which you can download here. The dataset contains 210 images of 10 different species of flowers that will be downloaded as png files.\\nBefore we get started, we need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3918</td>\n",
       "      <td>Sumit Saha</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53?source=tag_archive---------2-----------------------</td>\n",
       "      <td>A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way | by Sumit Saha | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 15, 2018\\nArtificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.\\nThe agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image &amp; Video recognition, Image Analysis &amp; Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>3919</td>\n",
       "      <td>Diganta Kalita</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Solving the FrozenLake environment from OpenAI gym using Value Iteration | by Diganta Kalita | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nNov 28, 2019\\nSo I was trying to learn about Reinforcement Learning, and then I came across this thing called ‘Value Iteration’. I really couldn’t wrap my head around Value Iteration. It was very difficult for me to understand how it worked and how it could help an agent to find the optimal policy. Then I got an idea.\\nWhat better way to understand “Value Iteration” than to use it to solve some game or environment. Thus I began my journey to find some game easy enough problem to solve. And then I stumbled upon this fairy from OpenAI.\\nLet me explain the game/environment first.\\nThere are 64 states in the game. The agent starts from S (S for Start) and our goal is to get to G (G for Goal). So just go. Nope. Its a slippery surface. The F’s and the H’s in between are pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>3920</td>\n",
       "      <td>Lihi Gur Arie, PhD</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/neural-networks-backpropagation-by-dr-lihi-gur-arie-27be67d8fdce?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Neural Networks Backpropagation Made Easy | by Lihi Gur Arie, PhD | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 8, 2021\\nUnderstanding the mathematic operands behind Neural Networks (NNs) is highly important for the data scientist capabilities, in designing an efficient deep model. In this article, the high-level calculus of a fully connected NN will be demonstrated, with focus on the backward propagation step. The article is oriented to people with basic knowledge of NNs, that seek to dive deeper into the NNs structure.\\nThe objective of the training process is to find the weights (W) and biases (b) that minimize the error. It is done by the gradient descent algorithm. To begin with, the weights are randomly initialized, and an iterative process of a subtle weights change is performed until convergence.\\nEach iteration begins with a forward pass, that outputs the curre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3921</td>\n",
       "      <td>Isaac Godfried</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/icml-2018-advances-in-transfer-multitask-and-semi-supervised-learning-2a15ef7208ec?source=tag_archive---------1-----------------------</td>\n",
       "      <td>ICML 2018: Advances in transfer, multitask, and semi-supervised learning | by Isaac Godfried | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 8, 2018\\nThe International Conference on Machine Learning took place last July in Stockholm. Altogether it showcased many interesting trends and directions in machine learning. Since, ICML was such a huge conference I will focus my attention on a few (of the many) interesting strands going on at the conference.\\nSpecifically, this year’s ICML split the oral talks into several different “tracks/sessions.” I was happy to see three of theses sessions focused on “transfer and multitask learning” as this has long been an area of interest of mine. Additionally, a large number of posters dealt with theses concepts as well as several orals from other tracks.\\nLack of large amounts of clean labeled data remains a barrier to the potential impact of deep learning. For ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>3922</td>\n",
       "      <td>Oleg Polosin</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/run-stylegan2-ada-on-an-aws-spot-instance-in-no-time-d2022fc1e119?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Run StyleGAN2 ADA on an AWS Spot Instance in No Time | by Oleg Polosin | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 1, 2020\\nRecently NVIDIA published a paper called “Training Generative Adversarial Networks with Limited Data” and released the code. They proposed an adaptive discriminator augmentation (ADA) mechanism that stabilizes StyleGAN2 training and achieves significantly better results on small datasets.\\nIn this post, we’ll show how to quickly run this code on an AWS Spot instance.\\n“A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly.”\\n— Spot Instances, AWS Documentation\\nTo launch a Spot instance and run a Docker container with the environment, we will be using Spotty. Spotty is an open-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3923</td>\n",
       "      <td>Luís Roque</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/generating-text-with-recurrent-neural-networks-based-on-the-work-of-f-pessoa-1e804d88692d?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Generating text with Recurrent Neural Networks based on the work of F. Pessoa | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 19, 2021\\nSequences of discrete tokens can be found in many applications, namely words in a text, notes in a musical composition, pixels in an image, actions in a reinforcement learning agent, etc [1]. These sequences often show a strong correlation between consecutive or nearby tokens. The correlations on words in a sentence or characters in words express the underlying semantics and language characteristics. The next token in the sequence x_n can be modeled as:\\nwhere x_i represents the ith token in the sequence. In Natural Language Processing (NLP), these are defined as language models. Usually, each token stands for a separate word or n-gram. The output generated is a probability distribution from which we can sample to generate the next token in the seque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3924</td>\n",
       "      <td>Adam Pickard</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@adampickard_44261/advancements-in-machine-learning-assisted-ideation-5c42cdf69c37?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Advancements in Machine Learning Assisted Ideation. | by Adam Pickard | Medium</td>\n",
       "      <td>Jun 23, 2020\\nThe most common debate around Artificial Intelligence and Machine Learning is “Will AI Take Your Job — or Make It Better?.” If most people had a choice, they would probably choose the latter. With any of these new technologies, it can be challenging to distinguish the hype from the headline. On one end, you have big tech companies and startups promising to fix problems ranging from detecting cancer to...\\n140 \\n140 \\n1\\nArt Director adampickard.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n13 Followers\\nArt Director adampickard.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3925</td>\n",
       "      <td>Jongdae Lim</td>\n",
       "      <td>24</td>\n",
       "      <td>https://medium.com/@jongdae.lim/%EA%B8%B0%EA%B3%84-%ED%95%99%EC%8A%B5-machine-learning-%EC%9D%80-%EC%A6%90%EA%B2%81%EB%8B%A4-part-5-83b7a44b797a?source=tag_archive---------8-----------------------</td>\n",
       "      <td>기계 학습(Machine Learning, 머신 러닝)은 즐겁다! Part 5 | by Jongdae Lim | Medium</td>\n",
       "      <td>Feb 24, 2017\\n딥러닝(Deep Learning)과 시퀀스(Sequence)의 마법을 사용한 언어 번역(Language Translation)\\n우리는 모두 마법처럼 100 가지 다른 언어를 즉시 번역 할 수 있는 웹 사이트 인 구글 번역(Google Translate)을 알고 있고 사랑합니다. 심지어 휴대 전화나 스마트 워치에서도 사용할 수 있습니다:\\n구글 번역에 사용된 기술을 기계 번역(Machine Translation)이라고 합니다. 다른 방법으로는 절대 불가능했던 전세계 사람들의 의사 소통을 가능하게 함으로써 세상을 변화시켰습니다.\\n그런데, 사실 고등학생들이... 음... 지난 15 년간 스페인어 숙제를 하기위해 구글 번역의 도움을 받아 왔다는 것을 모두 알고 있습니다. 그렇다면 이건 오래된 뉴스가 아닌가요?\\n지난 2 년 동안, 딥러닝(deep learning)은 기계 번역에 대하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3926</td>\n",
       "      <td>Daniel Godoy</td>\n",
       "      <td>21</td>\n",
       "      <td>https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Understanding PyTorch with an example: a step-by-step tutorial | by Daniel Godoy | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 7, 2019\\nUpdate (May 18th, 2021): Today I’ve finished my book: Deep Learning with PyTorch Step-by-Step: A Beginner’s Guide.\\nUpdate (February 23rd, 2022): The paperback edition is available now (in three volumes). For more details, please check pytorchstepbystep.com.\\nPyTorch is the fastest growing Deep Learning framework and it is also used by Fast.ai in its MOOC, Deep Learning for Coders and its library.\\nPyTorch is also very pythonic, meaning, it feels more natural to use it if you already are a Python developer.\\nBesides, using PyTorch may even improve your health, according to Andrej Karpathy :-)\\nThere are many many PyTorch tutorials around and its documentation is quite complete and extensive. So, why should you keep reading this step-by-step tutorial?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3927</td>\n",
       "      <td>Debarko De 🦁</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/hackernoon/rnn-or-recurrent-neural-network-for-noobs-a9afbb00e860?source=tag_archive---------6-----------------------</td>\n",
       "      <td>RNN or Recurrent Neural Network for Noobs | by Debarko De 🦁 | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nJun 19, 2018\\nWhat is a Recurrent Neural Network or RNN, how it works, where it can be used? This article tries to answer the above questions. It also shows a demo implementation of a RNN used for a specific purpose, but you would be able to generalise it for your needs.\\nKnowhow. Python, CNN knowledge is required. CNN is required to compare why and where RNN performs better than CNN? No need to understand the math. If you want to check then go back to my earlier article to check what is a CNN.\\nWe will begin with the word use of the word “Recurrent”. Why is it called Recurrent? In english the word recurrent means:\\noccurring often or repeatedly\\nIn the case of this type of Neural Network it’s called Recurrent since it does the same operation over and over on sets of se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3928</td>\n",
       "      <td>Ayushi choudhary</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@2809ayushic/optimizers-in-deep-learning-31db684c73cf?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Optimizers in Deep Learning. What is Optimizers? | by Ayushi choudhary | Medium</td>\n",
       "      <td>Apr 5, 2021\\nWhat is Optimizers?\\nOptimizers are algorithms used to reduce the loss function and update the weights in backpropagation.\\nHere is the formula used by all the optimizers for updating the weights with a certain value of the learning rate.\\nThis is the most common optimizer used in neural networks. The weights are updated when the whole dataset gradient is calculated, If there is a huge amount of data weights updation takes more time and required huge amount of RAM size memory which will slow down the process and computationally expensive.\\nThere is also a saddle point problem. This is a point where the gradient is zero but is not an optimal point.\\nIn some cases, problems like Vanishing Gradient or Exploding Gradient may also occur due to incorrect parameter initialization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3929</td>\n",
       "      <td>Samuele Mazzanti</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/isolation-forest-the-anomaly-detection-algorithm-any-data-scientist-should-know-1a99622eec2d?source=tag_archive---------1-----------------------</td>\n",
       "      <td>“Isolation Forest”: The Anomaly Detection Algorithm Any Data Scientist Should Know | by Samuele Mazzanti | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 4, 2021\\n“Isolation Forest” is a brilliant algorithm for anomaly detection born in 2009 (here is the original paper). It has since become very popular: it is also implemented in Scikit-learn (see the documentation).\\nIn this article, we will appreciate the beauty in the intuition behind this algorithm and understand how exactly it works under the hood, with the aid of some examples.\\nAnomaly (or outlier) detection is the task of identifying data points that are “very strange” compared to the majority of observations.\\nThis is useful in a range of applications, from fault detection to discovery of financial frauds, from finding health issues to identifying unsatisfied customers. Moreover, it can also be beneficial for machine learning pipelines, since it has be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3930</td>\n",
       "      <td>Mukul Malik</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/hackernoon/word2vec-part-1-fe2ec6514d70?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Word2Vec (Part 1). Word2Vec; the Steroids for Natural... | by Mukul Malik | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nOct 15, 2016\\nWord2Vec; the Steroids for Natural Language Processing\\nLet’s start with the Basics.\\nQ) What are word vectors?\\nAns) Representation of words with numbers.\\nQ) Why Word Vectors?\\nAns) I’ll sum it up with three main reasons:\\n1. Computer cannot do computations on strings.\\n2. Strings don’t hold much explicit information themselves.\\n3. Words Vectors are usually dense vector representations.\\nQ) So what is Explicit information?\\nAns) Yes, the word itself doesn’t say much about what it represents in real life. Example:\\nThe string “cat” just tells us it has three alphabets “c”, ”a” and “t”.\\nIt has no information about the animal it represents or the count or the context in which it is being used.\\nQ) Dense Vector Representation?\\nAns) Short answer (for now),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3931</td>\n",
       "      <td>Dr. Varshita Sher</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/keywords-to-know-before-you-start-reading-papers-on-gans-8a08a665b40c?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Keywords to know before you start reading papers on GANs | by Dr. Varshita Sher | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 22, 2021\\nThere is no denying the fact that GANs are awesome! If you don’t know what they are, check out this article where I explain GANs from scratch to a 5-year old and how to implement GANs in Pytorch! In a nutshell, GANs belong to a category of generative models that let us generate incredibly realistic synthetic data, with the same qualities as that of the underlying training data. That means if you feed the model images of a few bedroom decors, after few hours of training it can generate never-seen-before brand-new ideas for your interior design.\\nOver the past few weeks, I have probably read a dozen papers on GANs (and its variants) and tinkered around with their code on custom images (courtesy open-source Github repos). While most of these papers are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3932</td>\n",
       "      <td>Rob Parkin</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@robparkin_38642/bayesian-variational-autoencoder-4bb698c84644?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Bayesian Variational Autoencoders | by Rob Parkin | Medium</td>\n",
       "      <td>Oct 5, 2017\\nThe main motivation for this post was that I wanted to get more experience with Bayesian types of Variational Autoencoders (VAEs) using Tensorflow.\\nAutoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we’ll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed...\\n248 \\n248 \\n1\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3933</td>\n",
       "      <td>Steven Shen</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/cubo-ai/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540?source=tag_archive---------5-----------------------</td>\n",
       "      <td>關於影像辨識,所有你應該知道的深度學習模型. Computer vision object detection... | by Steven Shen | Cubo AI | Medium</td>\n",
       "      <td>Cubo AI\\nFeb 4, 2018\\nComputer vision object detection models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO\\n這篇是簡介一些用來辨識影像中物體的 AI 模型。\\n在前面有提到,透過 CNN 模型,你可以輸入一張圖片,得到該圖片屬於哪種類別的結果,這過程我們把他稱作分類 (Classification)。\\n但在真實世界的應用情境通常要從一張圖片中辨識所有出現的物體, 並且標示出位置來 (標出位置稱之為 Object Localization)。你一定在網路上看過類似底下的影片,這段影片可以看出中國閉路攝影機(CCTV)發展的概況,不只是可以框出影像中每個物件,辨別物件種類,偵測出移動物體的動量,甚至是人臉辨識,實現楚門世界的惡夢。要做到這就需要靠深度學習中的 Object Detection 演算法,這也是最近幾年來深度學習最蓬勃發展的一塊領域。\\n基本的想法是,既然 CNN 對於物體的分類又快又好,那我們可不可以拿 CNN 來掃描並辨識圖片中的任何物體? 答案當然是 — 可以。\\n最簡單的作法就是用 Sliding Windows 的概念,也就是用一個固定大小的框框,逐一的掃過整張圖片,每次框出來的圖像丟到 CNN 中去判斷類別。由於物體的大小是不可預知的,所以還要用不同大小的框框去偵測。但是 Sliding Window 是非常暴力的作法,對單一影像我們需要掃描非常多次,每掃一次都需要算一次 CNN,這將會耗費大量的運算資源,而且速度慢,根本無法拿來應用!\\n所以後來就有人提出了 R-CNN (Regions with CNN)\\n與其用 Sliding Window 的方式掃過一輪,R-CNN 的作法是預先篩選出約 2000 個可能的區域,再將...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3934</td>\n",
       "      <td>Robbie Tilton</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@robbietilton/emotional-computing-with-ai-3513884055fa?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Emotional Computing. Investigating the human to computer... | by Robbie Tilton | Medium</td>\n",
       "      <td>Apr 26, 2012\\nInvestigating the human to computer relationship through reverse engineering the Turing test\\nHumans are getting closer to creating a computer with the ability to feel and think. Although the processes of the human brain are at large unknown, computer scientists have been working to simulate the human capacity to feel and understand emotions. This paper explores what it means to live in an age where computers can have emotional depth and what this means for the future of human to computer interactions. In an experiment between a human and a human disguised as a computer, the Turing test is reverse engineered in order to understand the role computers will play as they become more adept to the processes of the human mind. Implications for this study are discussed and the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3935</td>\n",
       "      <td>Kyle Huang</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@huangkaikai/computational-creativity-generative-creature-design-for-concept-art-c4a1180ae0e6?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Computational creativity: generative creature design for concept art | by Kyle Huang | Medium</td>\n",
       "      <td>Oct 9, 2020\\nAbstract\\nWith the ever-powerful deep learning algorithm, computer graphics have been pushed to a new level. The generative adversarial network (GAN) can now generate almost any type of photo-realistic images with the proper size of datasets. However, most of the GAN use cases have been limited to the pursue of lifelike graphics. In this article, I prose a new framework “MonsterGAN,” combining machine learning, design, and psychology. MonsterGAN is a prototype of a generative design system (DRCI), which reduces the cognitive burden of creation and makes creativity scalable, for concept artists.\\nWhat happens if computer vision passes the Turing test? Where and how can we use it? As a designer, I’m fascinated by these questions because we designers are the graphic wizards w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3936</td>\n",
       "      <td>James Lee</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/nurture-ai/learning-artistic-styles-from-images-a07037fa46e3?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Learning Artistic Styles from Images | by James Lee | Nurture.AI | Medium</td>\n",
       "      <td>Nurture.AI\\nFeb 2, 2018\\nIt’s currently an arms race in the tech scene right now with Deep Learning and Artificial Intelligence already the next industry-grade buzzword. Everyone’s looking to make the next big commercial success with a successful and innovative application of Artificial Intelligence.\\nOne such breakthrough is the use of deep learning neural networks to mathematically separate the content and style of images. What naturally entails is the idea of taking the content of one image and the style of another, and merging them both into one image. This idea was successfully implemented in 2015 by Gatys. et al in their paper “A Neural Algorithm of Artistic Style”.\\nSince then, there have been many insights and improvements of the base idea. Modern iterations of the algorithm ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>3937</td>\n",
       "      <td>Korbinian Koch</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/a-friendly-introduction-to-text-clustering-fa996bcefd04?source=tag_archive---------6-----------------------</td>\n",
       "      <td>A Friendly Introduction to Text Clustering | by Korbinian Koch | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 26, 2020\\nThe topics covered in this article include k-means, brown clustering, tf-idf, topic models and latent Dirichlet allocation (also known as LDA).\\nClustering is one of the biggest topics in data science, so big that you will easily find tons of books discussing every last bit of it. The subtopic of text clustering is no exception. This article can therefore not deliver an exhaustive overview, but it covers the main aspects. This being said, let us start by getting on common ground what clustering is and what it isn’t.\\nYou just scrolled by clusters!\\nIn fact, clusters are nothing more than groups that contain similar objects. Clustering is the process used for separating the objects into these groups.\\nObjects inside of a cluster should be as similar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3938</td>\n",
       "      <td>Shay Geller</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Normalization vs Standardization — Quantitative analysis | by Shay Geller | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 4, 2019\\nEvery ML practitioner knows that feature scaling is an important issue (read more here).\\nThe two most discussed scaling methods are Normalization and Standardization. Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\\nIn this blog, I conducted a few experiments and hope to answer questions like:\\nI’ll analyze the empirical results of applying different scaling methods on features in multiple experiments settings.\\nFirst, I was trying to understand what is the difference between Normalization and Standardization.So, I encountered this excellent blog by Sebastian Raschka that supplies a mathematical background that sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3939</td>\n",
       "      <td>jiawei hu</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/an-overview-for-text-representations-in-nlp-311253730af1?source=tag_archive---------6-----------------------</td>\n",
       "      <td>An Overview for Text Representations in NLP | by jiawei hu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 4, 2020\\nWriting is always a good choice when it comes to clarifying one’s understandings of a given topic. By putting thoughts on papers, ideas will be clarified and confusions exposed. Though it might not be the most comfortable thing to do it’s indeed an efficient way to learn and improve.\\nIf you ever find yourself having a hard time explaining something to a friend, something you’ve been studying for a while but somehow still didn’t manage to portray the subject clearly and intuitively, you should try writing it down.\\nIn this article, I attempt to summarize some of the ideas for text representations in NLP, aiming to build a foundation for future complex concepts to come and hoping to contribute my granito de arena to your learning as well.\\nThe above di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>3940</td>\n",
       "      <td>Vivek Yadav</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@vivek-yadav/why-is-gradient-descent-robust-to-non-linearly-separable-data-a50c543e8f4a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Why is gradient descent robust to non-linearly separable data? | by Vivek Yadav | Medium</td>\n",
       "      <td>Nov 8, 2016\\nClarification: Gradient descent by itself is NOT robust to non-linearly separable data. However, when used with appropriate nonlinear activation functions it is.\\nThe reason is due to the kernel trick. In kernel trick, we apply a nonlinear transform on the data, so the resulting data set is linearly separable. This is illustrated below. Consider task of classifying blue and red points, they are not linearly separable. But what if we transform this data by adding a third variable (z = x2+y2), wecan draw a plane between blue and red points, and separate the two set of points. This is precisely what neural networks also do.\\nNeural networks’ learning can be viewed as a 2 part process where they learn some nonlinear transform of the data, and how to separate data based on this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>3941</td>\n",
       "      <td>SYED JUNAID IQBAL</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/edureka/k-means-clustering-1db7b018a0a2?source=tag_archive---------0-----------------------</td>\n",
       "      <td>K-means Clustering Algorithm | Edureka</td>\n",
       "      <td>Edureka\\nFeb 10, 2017\\nThe majority of retail business holders find it hard to recognize customer needs. The reason why Data-driven companies such as Netflix, Walmart, Target, etc. are doing so well is that they have an army of Certified Data Analysts that grow their business by using the right tools to create personalized marketing strategies. We do understand that not all customers are alike and have the same taste. So, this leads to the challenge of marketing the right product to the right customer. An offer or product which might entice a particular customer segment may not be very helpful to other segments. So, you can apply the k-means clustering algorithm to segment your entire customer audience into groups with similar traits and preferences based on various metrics (such as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3942</td>\n",
       "      <td>Snehal Reddy Koukuntla</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/meta-learning-ai-generalised-1007b9695fe1?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Meta Learning — AI Generalised.. AI learning to learn, to help with... | by Snehal Reddy Koukuntla | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 8, 2019\\nDeep Learning has shown immense success in various fields and is continuing to spread its wings. But one of the major issues with training any traditional neural network model is the requirement of colossal amounts of data, and using this data to perform many iterative updates across many labeled examples.\\nLet’s take a look at a classic example of cats vs dogs classification. Although over the last two decades, we have made our models better and better to increase the accuracy, but the fundamental problem mentioned above still persists. We still need loads of labelled dogs and cats to get a decent accuracy.\\nHow do humans classify them with much lesser examples. Lets say all of a sudden you are shown two new animals, which are as visually distinguish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3943</td>\n",
       "      <td>Aerin Kim</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/gamma-function-intuition-derivation-and-examples-5e5f72517dee?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Gamma Function — Intuition, Derivation, and Examples | by Aerin Kim | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 23, 2019\\nWhy should I care?\\nMany probability distributions are defined by using the gamma function — such as Gamma distribution, Beta distribution, Dirichlet distribution, Chi-squared distribution, and Student’s t-distribution, etc.For data scientists, machine learning engineers, researchers, the Gamma function is probably one of the most widely used functions because it is employed in many distributions. These distributions are then used for Bayesian inference, stochastic processes (such as queueing models), generative statistical models (such as Latent Dirichlet Allocation), and variational inference. Therefore, if you understand the Gamma function well, you will have a better understanding of a lot of applications in which it appears!\\nBecause we want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3944</td>\n",
       "      <td>Suhyun Kim</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-guide-to-convolutional-neural-networks-cnns-14649dbddce8?source=tag_archive---------4-----------------------</td>\n",
       "      <td>A Beginner’s Guide to Convolutional Neural Networks (CNNs) | by Suhyun Kim | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 15, 2019\\nA convolution is how the input is modified by a filter. In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge. Each time a match is found, it is mapped out onto an output image.\\nFor example, there is a picture of Eileen Collins and the matrix above the red arrow is used as a convolution to detect dark edges. As a result, we see an image where only dark edges are emphasized.\\nNote that an image is 2 dimensional with width and height. If the image is colored, it is considered to have one more dimension for RGB color. Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>3945</td>\n",
       "      <td>Aneesha Bakharia</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@aneesha/using-affinity-propagation-to-find-the-number-of-clusters-in-a-dataset-52f5dd3b0760?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Using Affinity Propagation to Find the Number of Clusters in a Dataset | by Aneesha Bakharia | Medium</td>\n",
       "      <td>Jan 11, 2016\\nClustering and dimension reduction algorithms help you to explore a dataset. Clustering and dimension reduction are unsupervised learning algorithms i.e., they don’t need labelled data to build a model. k-means is a popular clustering algorithm — you specify the the number of clusters (k) and it then finds the best cluster for each data instance. Choosing a good initial value for the number of clusters (k) can be problematic as k can be anything between 1 and the number of data instances. Finding the number of clusters is an active research field and techniques do exist (such as the Silhouette coefficient) but have varying success as the dimensionality of the data increases. I’m not going to go into any of these other techniques to find k in this blog post. Instead I’m go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3946</td>\n",
       "      <td>Matt.0</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92?source=tag_archive---------6-----------------------</td>\n",
       "      <td>10 Tips for Choosing the Optimal Number of Clusters | by Matt.0 | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 27, 2019\\nClustering is one of the most common unsupervised machine learning problems. Similarity between observations is defined using some inter-observation distance measures or correlation-based distance measures.\\nThere are 5 classes of clustering methods:\\n+ Hierarchical Clustering+ Partitioning Methods (k-means, PAM, CLARA)+ Density-Based Clustering+ Model-based Clustering+ Fuzzy Clustering\\nMy desire to write this post came mainly from reading about the clustree package, the dendextend documentation, and the Practical Guide to Cluster Analysis in R book written by Alboukadel Kassambara author of the factoextra package.\\nI will be using a lesser known data set from the cluster package: all.mammals.milk.1956, one which I haven’t looked at before.\\nThis sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3947</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 7, 2019\\nThis post was co-written with Baptiste Rocca.\\nYann LeCun described it as “the most interesting idea in the last 10 years in Machine Learning”. Of course, such a compliment coming from such a prominent researcher in the deep learning area is always a great advertisement for the subject we are talking about! And, indeed, Generative Adversarial Networks (GANs for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article Generative Adversarial Nets.\\nSo what are Generative Adversarial Networks ? What makes them so “interesting” ? In this post, we will see that adversarial training is an enlightening idea, beautiful by its simplicity, that represents a real conceptual progress for Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3948</td>\n",
       "      <td>Insight</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.insightdatascience.com/data-visualization-in-python-advanced-functionality-in-seaborn-20d217f1a9a6?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Data Visualization in Python: Advanced Functionality in Seaborn | by Insight | Insight</td>\n",
       "      <td>Insight\\nNov 13, 2015\\nSlater Stich is an Insight alum and was previously a Staff Data Scientist at Square. He is currently a Vice President at Valor Equity Partners.\\nSeaborn is a Python data visualization library with an emphasis on statistical plots. The library is an excellent resource for common regression and distribution plots, but where Seaborn really shines is in its ability to visualize many different features at once.\\nIn this post, we’ll cover three of Seaborn’s most useful functions: factorplot, pairplot, and jointgrid. Going a step further, we'll show how we can get even more mileage out of these functions by stepping up to their even-more-powerful forms: FacetGrid, PairGrid, and JointGrid.\\nTo showcase Seaborn, we’ll use the UCI “Auto MPG” data set. We did a bit of prepr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3949</td>\n",
       "      <td>Kaustubh N</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/somx-labs/lets-talk-clustering-unsupervised-learning-1c89bc27e908?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Let’s talk Clustering (Unsupervised Learning) | by Kaustubh N | SomX Labs | Medium</td>\n",
       "      <td>SomX Labs\\nSep 2, 2016\\nSimple Definition:\\nA collection of similar objects to each other.\\nSlightly Complex Definition:\\nA connected component of a level set of the probability density function of underlying (and unknown) distribution from which our data samples are drawn.\\nYou are posed with a problem to solve, what you have is a large amount of data represented in lot of dimensions. The data can not be read or understood by looking at it raw by a human.\\nEven before you start defining your problem (hypothesis), you need to understand the data, perform an EDA on it. There are multiple ways to do it.\\nA. Perform Clustering\\nPerfect! Clustering is a good way of identifying interesting parts of data by grouping it.\\nClustering is a process of grouping a sample of data into smaller simil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3950</td>\n",
       "      <td>Thomas Smith</td>\n",
       "      <td>9</td>\n",
       "      <td>https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------5-----------------------</td>\n",
       "      <td>I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero</td>\n",
       "      <td>OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder &amp; CEO of Gado Images. I write, speak &amp; consult about tech, food, privacy, AI &amp; photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3951</td>\n",
       "      <td>Ravi Prakash pandey</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@ravipandey71998/image-classifier-using-vgg-19-deep-learning-model-in-google-colab-notebook-dishes-detection-34861168e055?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Image Classifier using VGG-19 Deep learning model in Google Colab Notebook. Dishes Detection | by Ravi Prakash pandey | Medium</td>\n",
       "      <td>Aug 23, 2020\\nA simple Image classifier model to demonstrate the usage of VGG-19Deep Learning Model to predict input image. This model is developed in python programming and executed on a Colab notebook. At the end of this article you will learn how to develop a simple image classifier application that uses Pytorch Python based Deep Learning library to predict an image.\\nAt the end of this article you will learn:\\nVGG-19 is a variant of VGG model which in short consists of 19 layers (16 convolution layers, 3 Fully connected layer, 5 MaxPool layers and 1 SoftMax layer). There are other variants of VGG like VGG11, VGG16 and others.\\nAlexNet came out in 2012 and it improved on the traditional Convolutional neural networks, So we can understand VGG as a successor of the AlexNet.\\nVGG means...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3952</td>\n",
       "      <td>Aleksi Pietikäinen</td>\n",
       "      <td>14</td>\n",
       "      <td>https://medium.com/@aleksipietikinen/an-analysis-on-how-deepminds-starcraft-2-ai-s-superhuman-speed-could-be-a-band-aid-fix-for-the-1702fb8344d6?source=tag_archive---------2-----------------------</td>\n",
       "      <td>An Analysis On How Deepmind’s Starcraft 2 AI’s Superhuman Speed is Probably a Band-Aid Fix For The Limitations of Imitation Learning | by Aleksi Pietikäinen | Medium</td>\n",
       "      <td>Jan 27, 2019\\nAs all you have probably heard by now, an AI called AlphaStar developed by Google Deepmind has recently beaten human professionals in the real-time strategy game Starcraft 2. This is an unprecedented feat in the field of AI. However, I do have some constructive criticism about the way they did it.\\nI will try to make a convincing argument for the following:\\nFirst of all, I want to clarify that I am a layman. I’ve been following AI development and the Starcraft 2 scene for years but I do not claim to be an expert in either topic. If you notice any misconceptions in what I’m about to write please do point them out. I’m only a fanboy and all of this is incredibly fascinating to me. This essay will contain a lot of speculation and I admit that I can’t prove all of my core cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3953</td>\n",
       "      <td>Darshan Adakane</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3954</td>\n",
       "      <td>Anish Shrestha</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Generating Modern Art using\\nGenerative Adversarial Network(GAN) on Spell | by Anish Shrestha | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2019\\nYou need to have a good understanding of:\\nAnd some basic knowledge of:\\nImage data used in this project has been collected from WikiArts.org.\\nIn this tutorial, we are going to look at the step by step process to create a Generative Adversarial Network to generate Modern Art and write a code for that using Python and Keras together.\\nAfter that, for training the model, we are going to use a powerful GPU Instance of Spell platform. Everything will be explained along the way and links will be provided for further readings.\\nLet’s get started!\\nBefore getting started, let’s look at our image dataset.\\nWikiArt has a huge collection of modern art with various different styles. For our particular project, we are going to use images of Cubism Style.\\nYou c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3955</td>\n",
       "      <td>Synced</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129?source=tag_archive---------0-----------------------</td>\n",
       "      <td>A Brief Overview of Attention Mechanism | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nSep 25, 2017\\nAttention is simply a vector, often the outputs of dense layer using softmax function.\\nBefore Attention mechanism, translation relies on reading a complete sentence and compress all information into a fixed-length vector, as you can image, a sentence with hundreds of words represented by several words will surely lead to information loss, inadequate translation, etc.\\nHowever, attention partially fixes this problem. It allows machine translator to look over all the information the original sentence holds, then generate the proper word according to current word it works on and the context. It can even allow translator to zoom in or out (focus on local or global features).\\nAttention is not mysterious or complex. It is just an interface formulated by paramete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3956</td>\n",
       "      <td>Bhuvana Kundumani</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/ner-tensorflow-2-2-0-9f10dcf5a0a?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Named Entity Recognition (NER) for CoNLL dataset with Tensorflow 2.2.0 | by Bhuvana Kundumani | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 22, 2020\\nThis blog details the steps for Named Entity Recognition (NER) tagging of sentences (CoNLL-2003 dataset ) using Tensorflow2.2.0\\nCoNLL-2003 dataset includes 1,393 English and 909 German news articles. We will be looking at the English data. The CoNLL-2003 data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3957</td>\n",
       "      <td>Sourav kumar</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Sentence correction using Deep learning techniques | by Sourav kumar | Medium</td>\n",
       "      <td>Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>3958</td>\n",
       "      <td>Wamika Jha</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/implementation-of-principal-component-analysis-pca-in-k-means-clustering-b4bc0aa79cb6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Implementation of Principal Component Analysis(PCA) in K Means Clustering | by Wamika Jha | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 19, 2021\\nPrerequisites\\nThis article assumes that you are familiar with the basic theory behind PCA, K Means Algorithm and know Python programming language.\\nK Means clustering is one of the simplest yet efficient unsupervised algorithms. First let us have a brief description of what this algorithm does.\\nK Means Algorithm Suppose we have a dataset with two features x1 and x2. This is unlabelled data and our objective is to find K number of groups or “clusters” which are similar to each other. Suppose our training set looks like this :-\\nWe can clearly see there are two clusters, let us name them cluster 0 and cluster 1. Each cluster is associated with a centroid which is unique to each cluster. This algorithm iterates until the centroids do not change its positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3959</td>\n",
       "      <td>Maria Neumayer</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/a-problem-like-maria/ai-class-com-a-classroom-with-160-000-students-9c16f6e31390?source=tag_archive---------4-----------------------</td>\n",
       "      <td>AI-Class.com — A classroom with 160,000 students | by Maria Neumayer | A problem like Maria | Medium</td>\n",
       "      <td>A problem like Maria\\nOct 23, 2011\\nAI Class is a great experiment by two professors at the Stanford University: Sebastian Thrun and Peter Norvig. The course is being held as an actual course at Stanford University plus an online course for about 160,000 enrolled students. People in the advanced track have to do homework and write exams, people in the basic track just have to watch the lectures. Currently I’m in the advanced track, although I might switch to the basic track due to time problems (having a full time job + working on a private application + a University course is a bit too much). At the end of the course you’ll get a certificate, sadly not from Stanford but still. Pretty cool having done a course at Stanford... kind of.\\nI think it’s a great experience to attend a course ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>3960</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Multi-Class Text Classification with LSTM | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 10, 2019\\nAutomatic text classification or document classification can be done in many different ways in machine learning as we have seen before.\\nThis article aims to provide an example of how a Recurrent Neural Network (RNN) using the Long Short Term Memory (LSTM) architecture can be implemented using Keras. We will use the same data source as we did Multi-Class Text Classification with Scikit-Lean, the Consumer Complaints data set that originated from data.gov.\\nWe will use a smaller data set, you can also find the data on Kaggle. In the task, given a consumer complaint narrative, the model attempts to predict which product the complaint is about. This is a multi-class text classification problem. Let’s roll!\\nAfter first glance of the labels, we realized t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>3961</td>\n",
       "      <td>Mark Garvey</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/polynomial-regression-gradient-descent-from-scratch-279db2936fe9?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Polynomial Regression — Gradient Descent from Scratch | by Mark Garvey | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 18, 2021\\nGradient descent is an important algorithm to understand, as it underpins many of the more advanced algorithms used in Machine Learning and Deep Learning. Getting to grips with the inner workings of gradient descent will therefore be of great benefit to anyone who plans on exploring ML algorithms further.\\nThe best way to learn is by doing, so in this article I will be walking through the steps of how the gradient descent process works, without using ML libraries such as scikit-learn for example. In day-to-day work, it is of course quicker and neater to make use of such libraries, but regarding the learning process I have found the exercise of implementing by hand to be invaluable for this particular algorithm.\\nThe goal of gradient descent is to min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3962</td>\n",
       "      <td>Synced</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/syncedreview/from-faces-to-kitties-to-apartments-gan-fakes-the-world-ae04e5cbddf6?source=tag_archive---------6-----------------------</td>\n",
       "      <td>From Faces to Kitties to Apartments: GAN Fakes the World | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nFeb 27, 2019\\nWith just a mouse click, you can delight in mega-litters of adorable kitties, admire countless fresh anime characters, or stare into the twinkling eyes of all sorts of beautiful people. The only catch is that they’re all fake. As Synced previously reported, these hyperrealistic images now flooding the Internet come from US chip giant NVIDIA’s StyleGAN, a generative adversarial network based face generator that performs so well that most people can’t distinguish its creations from photos of real people.\\nSoon after StyleGAN was open-sourced earlier this month, Uber software engineer Philip Wang used the tool to create “This Person Does Not Exist,” a website which generates a new hyperrealistic fake human face every time it’s refreshed. The site quickly went v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>3963</td>\n",
       "      <td>Gorkem Polat</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/swlh/deep-learning-architectures-that-you-can-use-with-a-very-few-data-8e5b4fa1d5da?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Deep Learning Architectures That You Can Use with a Few Data | by Gorkem Polat | The Startup | Medium</td>\n",
       "      <td>The Startup\\nJun 26, 2020\\nConventional CNNs (AlexNet, VGG, GoogLeNet, ResNet, DenseNet ...) have good performances when there are many samples for each class in the dataset. Unfortunately, they generally do not work well when you have a small dataset. However, there are many real-life scenarios where it is challenging to gather data for your classes. For example, in face identification systems, there are...\\n373 \\n373 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n77 Followers\\nDeep learning researcher. PhD candidate at @METU. https://www.linkedin.com/in/gorkempolat/\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>3964</td>\n",
       "      <td>Taras Bakusevych</td>\n",
       "      <td>10</td>\n",
       "      <td>https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c?source=tag_archive---------1-----------------------</td>\n",
       "      <td>10 rules for better dashboard design | by Taras Bakusevych | UX Planet</td>\n",
       "      <td>UX Planet\\nJul 17, 2018\\nDashboard design is a frequent request these days. Businesses dream about a simple view that presents all information, shows trends and risky areas, updates users on what happened — a view that will guide them into a bright financial future.\\nFor me, a dashboard — is an at a glance preview of the most crucial information for the user at the moment he is looking at it, and an easy way to navigate directly to various areas of the application that require users attention. The term “dashboard” is a metaphor for a car dashboard, sometimes also called the cockpit area, usually near the front of an aircraft or spacecraft, from which a pilot controls the aircraft.\\nWorking on enterprise projects for years, I have designed countless dashboards. And every new one is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>3965</td>\n",
       "      <td>RAVI SHEKHAR TIWARI</td>\n",
       "      <td>9</td>\n",
       "      <td>https://becominghuman.ai/transfer-learning-part-4-0-vgg-16-and-vgg-19-d7f0045032de?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Transfer Learning — Part — 4.0!! VGG-16 and VGG-19 | by RAVI SHEKHAR TIWARI | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nOct 1, 2021\\nIn Part 3 of the Transfer Learning series we have discussed the datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch. In this, article we will discuss theoretically about the VGG-16 and VGG-19 and in article 4.2 and 4.3 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:\\nbecominghuman.ai\\nFor the repository and document please follow below two mentioned links:\\nKeras:\\nkeras.io\\nPyTorch:\\npytorch.org\\nAlexNet came out in 2012 and it improved on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3966</td>\n",
       "      <td>Synced</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/syncedreview/google-deepmind-releases-structure-predictions-for-coronavirus-linked-proteins-7dfb2fad05b6?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Google DeepMind Releases Structure Predictions for Coronavirus Linked Proteins | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nMar 5, 2020\\nThis is an updated version.\\nIn a bid to help the global research community better understand the coronavirus, DeepMind today released the structure predictions for six proteins associated with SARS-CoV-2, the virus that causes COVID-19, using the most up-to-date version of their AlphaFold system.\\nAs the world struggles with the COVID-19 outbreak, one research team after another in the global scientific community has stepped up to offer expertise, tools and possible solutions. In the early stages of the outbreak front-line labs open-sourced genomes of the virus which enabled other researchers to rapidly develop tests around the pathogen. Other labs modelled the coronavirus infection peak or produced molecular structures to develop drug compounds and treatmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3967</td>\n",
       "      <td>Ayush Pant</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Workflow of a Machine Learning project | by Ayush Pant | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 11, 2019\\nIn this blog, we will discuss the workflow of a Machine learning project this includes all the steps required to build the proper machine learning project from scratch.\\nWe will also go over data pre-processing, data cleaning, feature exploration and feature engineering and show the impact that it has on Machine Learning Model Performance. We will also cover a couple of the pre-modelling steps that can help to improve the model performance.\\nPython Libraries that would be need to achieve the task: 1. Numpy 2. Pandas 3. Sci-kit Learn 4. Matplotlib\\nWe can define the machine learning workflow in 3 stages.\\nOkay but first let’s start from the basics\\nThe machine learning model is nothing but a piece of code; an engineer or data scientist makes it smart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3968</td>\n",
       "      <td>TokenGo Platform_RU</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------9-----------------------</td>\n",
       "      <td>ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium</td>\n",
       "      <td>May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3969</td>\n",
       "      <td>Boaz Shmueli</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Multi-Class Metrics Made Simple, Part II: the F1-score | by Boaz Shmueli | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 3, 2019\\nIn Part I of Multi-Class Metrics Made Simple, I explained precision and recall, and how to calculate them for a multi-class classifier. In this post I’ll explain another popular performance measure, the F1-score, or rather F1-scores, as there are at least 3 variants. I’ll explain why F1-scores are used, and how to calculate them in a multi-class setting.\\nBut first, a BIG FAT WARNING: F1-scores are widely used as a metric, but are often the wrong way to compare classifiers. You will often spot them in academic papers where researchers use a higher F1-score as “proof” that their model is better than a model with a lower score. However, a higher F1-score does not necessarily mean a better classifier. Use with care, and take F1 scores with a grain of sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3970</td>\n",
       "      <td>Thiago Julio, MD</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/sa%C3%BAde-digital/rsna-2013-top-5-tend%C3%AAncias-em-ti-528f595225b7?source=tag_archive---------8-----------------------</td>\n",
       "      <td>RSNA 2013 — Top 5 Tendências em TI | by Thiago Julio, MD | Saúde Digital | Medium</td>\n",
       "      <td>Saúde Digital\\nJan 10, 2014\\nMuitas novidades foram apresentadas durante o congresso em Chicago. Muita inovação entre as aulas e sessões. Apresentações científicas com novas aplicações de conhecidas tecnologias e alguns novos protótipos. Diante de tanto conteúdo, seis dias passam rápido para quem gosta de tecnologia. Tentei elencar as cinco coisas mais bacanas que vi em termos de inovação e TI:\\n1. PACS 3.0\\nTermo repetido em inúmeras palestras. Ficou nítido que estamos diante de uma nova geração de PACS. Ferramentas de manipulação de imagens e workflow (manejo de worklists, aplicativos de laudo automatizados e reconhecimento de voz) já são considerados standart, e anualmente melhorados. As próximas versões de PACS, algumas já lançadas durante a feira, deverã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3971</td>\n",
       "      <td>Netflix Technology Blog</td>\n",
       "      <td>5</td>\n",
       "      <td>https://netflixtechblog.com/extracting-image-metadata-at-scale-c89c60a2b9d2?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Extracting image metadata at scale | by Netflix Technology Blog | Netflix TechBlog</td>\n",
       "      <td>Netflix TechBlog\\nMar 21, 2016\\nWe have a collection of nearly two million images that play very prominent roles in helping members pick what to watch. This blog describes how we use computer vision algorithms to address the challenges of focal point, text placement and image clustering at a large scale.\\nAll images have a region that is the most interesting (e.g. a character’s face, sharpest region, etc.) part of the image. In order to effectively render an image on a variety of canvases like a phone screen or TV, it is often required to display only the interesting region of the image and dynamically crop the rest of an image depending on the available real-estate and desired user experience. The goal of the focal point algorithm is to use a series of signals to identify the most int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>3972</td>\n",
       "      <td>Victor Zhou</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Machine Learning for Beginners: An Introduction to Neural Networks | by Victor Zhou | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 5, 2019\\nHere’s something that might surprise you: neural networks aren’t that complicated! The term “neural network” gets used as a buzzword a lot, but in reality they’re often much simpler than people imagine.\\nThis post is intended for complete beginners and assumes ZERO prior knowledge of machine learning. We’ll understand how neural networks work while implementing one from scratch in Python.\\nLet’s get started!\\nNote: I recommend reading this post on victorzhou.com — much of the formatting in this post looks better there.\\nFirst, we have to talk about neurons, the basic unit of a neural network. A neuron takes inputs, does some math with them, and produces one output. Here’s what a 2-input neuron looks like:\\n3 things are happening here. First, each inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>3973</td>\n",
       "      <td>Bernardo Caldas</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/using-maskrcnn-to-predict-tropical-fruits-in-custom-dataset-4f079d05fbe1?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Using MaskRCNN to predict tropical fruits in custom dataset | by Bernardo Caldas | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJan 26, 2020\\nApplication to predict fruits using Mask_RCNN on custom dataset, this is a easy tutorial to how create a object detection application for a custom dataset, as a sample we are using a dataset of tropical fruits in this case only ( Oranges and Pineapple).\\nsource code in github : https://github.com/bernardcaldas/object-detection-custom-maskrcnn\\nin recent years we can see a lot applications in our life including, autonomous cars, facial detections app, education, military, finance etc.\\nInstance segmentation it's a task to identifying objects , detecting and delineating each distinct object of interest appearing in an image.\\nFollow the post created for Waleed Abdulla explaining how works Mask R-CNN one of the most used algorithm for image segmentation and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3974</td>\n",
       "      <td>A Ydobon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@financial-engineering/tensorflow-2-0-variational-auto-encoder-vae-part-ii-df8adcd02f20?source=tag_archive---------9-----------------------</td>\n",
       "      <td>[TensorFlow 2.0] Variational Auto encoder (VAE) Part II | by A Ydobon | Medium</td>\n",
       "      <td>Nov 17, 2019\\nwww.tensorflow.org\\nLet’s get started!\\nIn the previous posting, we have finished two things, first, loading the dependent libraries to our workspace,\\n54 \\n54 \\n1\\nYdobon is nobody.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n85 Followers\\nYdobon is nobody.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>3975</td>\n",
       "      <td>Synced</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/syncedreview/deepmind-et-al-paper-trumpets-graph-networks-9c74a271b903?source=tag_archive---------9-----------------------</td>\n",
       "      <td>DeepMind et al Paper Trumpets Graph Networks | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nJun 15, 2018\\nThe paper Relational inductive biases, deep learning, and graph networks, published last week on arXiv by researchers from DeepMind, Google Brain, MIT and University of Edinburgh, has stimulated discussion in the artificial intelligence community. The paper introduces a new machine learning framework called Graph Networks, which some believe promises huge potential for approaching the holy grail of artificial general intelligence.\\nDue to the development of big data and increasingly powerful computational resources over the past few years, modern AI technology — primarily deep learning — has show its prowess and even outsmarted humans in tasks such as image recognition and speech detection. However, AI remains challenged by tasks that involve complicated lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3976</td>\n",
       "      <td>Helena Campbell</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/data-science-for-newbies-including-me-d1c6bf3e390b?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Data Science for Newbies (including me!) | by Helena Campbell | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 15, 2015\\nData Science for Newbies (including me!)\\nI’ve studied math, I’ve studied computer science, and of course I’ve focused on machine learning algorithms. But I’m still new to the field of data science. I don’t know yet how or whether I can make an impact. But if I explain what it is, then people will know what I can do, what I could learn to do, and most importantly, what they can ask me to do. Here’s the primer.\\nThere are several types of machine learning algorithms, but my focus is on finding patterns in data. Those patterns could be entirely numerical, they could be graphical, or they could even be written out in words. Humans are very good at finding patterns, even going too far sometimes and making stereotypes. We’re at a point where many people j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>3977</td>\n",
       "      <td>NN Intruder</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@nnintruder/attacking-google-cloud-vision-api-with-adversarial-examples-d02af0174732?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Attacking Google Cloud Vision API with Adversarial Examples | by NN Intruder | Medium</td>\n",
       "      <td>May 11, 2018\\nAdversarial attacks have been a concerning topic in the field of deep learning research in recent years. We’ve long since known that deep neural networks don’t generate perfect classification boundaries (this article in 2013. .. Yes, 2013 is a long time ago in fields related to deep learning.). Researchers have found numerous ways to generate adversarial examples to cause models to make mistakes (see e.g. this review paper and reference therein). This is obviously dangerous in commercial applications such as self-driving cars, automated robots, and other audio/visual recognition tasks. The vulnerability to adversarial examples is one of the major risks for applying deep neural networks in safety-critical scenarios.\\nBefore we go into our implementation, we need to categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3978</td>\n",
       "      <td>Harald Scheidl</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c?source=tag_archive---------2-----------------------</td>\n",
       "      <td>An Intuitive Explanation of Connectionist Temporal Classification | by Harald Scheidl | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 10, 2018\\nIf you want a computer to recognize text, neural networks (NN) are a good choice as they outperform all other approaches at the moment. The NN for such use-cases usually consists of convolutional layers (CNN) to extract a sequence of features and recurrent layers (RNN) to propagate information through this sequence. It outputs character-scores for each sequence-element, which simply is represented by a matrix. Now, there are two things we want to do with this matrix:\\nBoth tasks are achieved by the CTC operation. An overview of the handwriting recognition system is shown in Fig. 1.\\nLet’s have a closer look at the CTC operation and discuss how it works without hiding the clever ideas it is based on behind complicated formulas. At the end, I will poin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>3979</td>\n",
       "      <td>Abdarhman Taha</td>\n",
       "      <td>4</td>\n",
       "      <td>https://blog.agolo.com/knowledge-graphs-for-automatic-multi-longform-document-summarization-8f946e1e1877?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Using Knowledge Graphs to Summarize Long Documents | by Abdarhman Taha | agolo</td>\n",
       "      <td>agolo\\nApr 19, 2021\\nAutomatic text summarization is the task of automatically identifying the salient topics/key-phrases in a document(s) and then either generates or extracts a summary.\\nCurrently, most state-of-the-art summarizers are focused on single, short document summarization. Recent progress in summarization, mostly transformers-based, struggles with long inputs due to the architecture limitations, which have led many researchers to explore using new ideas like the longformer to overcome this issue. However, the final summaries are 5–10 sentences long that lacks coherence, and don’t give enough info about the original document. And of course, such methods can’t handle even tougher situations where the input is more than one long document. Similar observations could be found w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3980</td>\n",
       "      <td>Gerard Maggiolino</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/@gerardmaggiolino/creating-openai-gym-environments-with-pybullet-part-1-13895a622b24?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Creating OpenAI Gym Environments with PyBullet (Part 1) | by Gerard Maggiolino | Medium</td>\n",
       "      <td>Oct 22, 2019\\nThis guide assumes rudimentary knowledge of reinforcement learning and the structure of OpenAI Gym environments, along with proficiency in Python.\\nMany of the standard environments for evaluating continuous control reinforcement learning algorithms are built on the MuJoCo physics engine, a paid and licensed software. Bullet Physics provides a free and open source alternative to physics simulation with OpenAI Gym offering a set of environments built upon it. PyBullet is a library designed to provide Python bindings to the lower level C-API of Bullet. We will use PyBullet to design our own OpenAI Gym environments.\\nThis post will be the first of a two part series.\\nWe’ll go through building an environment step by step with enough explanations for you to learn how to indepe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>3981</td>\n",
       "      <td>Surya Remanan</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Logistic Regression: A Simplified Approach Using Python | by Surya Remanan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 17, 2018\\nIn Logistic Regression, we wish to model a dependent variable(Y) in terms of one or more independent variables(X). It is a method for classification. This algorithm is used for the dependent variable that is Categorical. Y is modeled using a function that gives output between 0 and 1 for all values of X. In Logistic Regression, the Sigmoid (aka Logistic) Function is used.\\nAfter we train a logistic regression model on some training data, we will evaluate the performance of the model on some test data. For this, we use the Confusion Matrix. A Confusion Matrix is a table that is often used to describe the performance of the classification model on a set of test data for which the true values are already known. Given below is a Confusion Matrix.\\nHere, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>3982</td>\n",
       "      <td>Nishanth N</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>3983</td>\n",
       "      <td>Maxime</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04?source=tag_archive---------0-----------------------</td>\n",
       "      <td>What is a Transformer?. An Introduction to Transformers and... | by Maxime | Inside Machine learning | Medium</td>\n",
       "      <td>Inside Machine learning\\nJan 4, 2019\\nNew deep learning models are introduced at an increasing rate and sometimes it’s hard to keep track of all the novelties. That said, one particular neural network model has proven to be especially effective for common natural language processing tasks. The model is called a Transformer and it makes use of several methods and mechanisms that I’ll introduce here. The papers I refer to in the post offer a more detailed and quantitative description.\\nThe paper ‘Attention Is All You Need’ describes transformers and what is called a sequence-to-sequence architecture. Sequence-to-Sequence (or Seq2Seq) is a neural net that transforms a given sequence of elements, such as the sequence of words in a sentence, into another sequence. (Well, this might not surp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>3984</td>\n",
       "      <td>Synced</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/syncedreview/quantum-chemistry-breakthrough-deepmind-uses-neural-networks-to-tackle-schr%C3%B6dinger-equation-a5ad4e3bfea0?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Quantum Chemistry Breakthrough: DeepMind Uses Neural Networks to Tackle Schrödinger Equation | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nSep 18, 2019\\nWave function represents the quantum state of an atom, including the position and movement states of the nucleus and electrons. For decades researchers have struggled to determine the exact wave function when analyzing a normal chemical molecule system, which has its nuclear position fixed and electrons spinning. Fixing wave function has proven problematic even with help from the Schrödinger equation.\\nPrevious research in this field used a Slater-Jastrow Ansatz application of quantum Monte Carlo (QMC) methods, which takes a linear combination of Slater determinants and adds the Jastrow multiplicative term to capture the close-range correlations.\\nNow, a group of DeepMind researchers have brought QMC to a higher level with the Fermionic Neural Network — or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3985</td>\n",
       "      <td>Kamil Mysiak</td>\n",
       "      <td>31</td>\n",
       "      <td>https://towardsdatascience.com/explaining-k-means-clustering-5298dc47bad6?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Explaining K-Means Clustering. Comparing PCA and t-SNE dimensionality... | by Kamil Mysiak | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 13, 2020\\nToday’s data comes in all shapes and sizes. NLP data encompasses the written word, time-series data tracks sequential data movement over time (ie. stocks), structured data which allows computers to learn by example, and unclassified data allows the computer to apply structure. Whichever dataset you possess, you can be sure there is an algorithm ready to decipher its secrets. In this article, we want to cover a clustering algorithm named KMeans which attempts to uncover hidden subgroups hiding in your dataset. Furthermore, we will examine what effects dimension reduction has on the quality of the clusters obtained from KMeans.\\nIn our example, we will be examining a human resources dataset consisting of 15,000 individual employees. The dataset contain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>3986</td>\n",
       "      <td>Josh</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/technology-invention-and-more/everything-you-need-to-know-about-artificial-neural-networks-57fac18245a1?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Everything You Need to Know About Artificial Neural Networks | by Josh | Technology, Invention, App, and More | Medium</td>\n",
       "      <td>Technology, Invention, App, and More\\nDec 28, 2015\\nThe year 2015 was a monumental year in the field of artificial intelligence. Not only are computers learning more and learning faster, but we’re learning more about how to improve their systems. Everything is starting to align, and because of it we’re seeing strides we’ve never thought possible until now. We have programs that can tell stories about pictures. We have cars that are driving themselves. We even have programs that create art. If you want to read more about advancements in 2015, read this article. Here at Josh.ai, with AI technology becoming the core of just about everything we do, we think it’s important to understand some of the common terminology and to get a rough idea of how it all works.\\nA lot of the advances in art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>3987</td>\n",
       "      <td>Jacob Solawetz</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/liquid-neural-networks-in-computer-vision-4a0f718b464e?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Liquid Neural Networks in Computer Vision | by Jacob Solawetz | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 12, 2021\\nExcitement is building in the artificial intelligence community around MIT’s recent release of liquid neural networks. The breakthroughs that Hasani and team have made are incredible.\\nLet’s dive in.\\nArtificial intelligence research and applications involve the construction and training of deep neural networks. Until liquid neural networks, all deep learning systems have shared the same vulnerability — namely, that they learn a fixed mapping from input data to output prediction based on the training data that they are shown, making them brittle to the shifting environment around them. Furthermore, most deep learning models are context independent. For example, when applying an object detection model or a classification model to a video, the video wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>3988</td>\n",
       "      <td>Andrej Karpathy</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Yes you should understand backprop | by Andrej Karpathy | Medium</td>\n",
       "      <td>Dec 19, 2016\\nWhen we offered CS231n (Deep Learning class) at Stanford, we intentionally designed the programming assignments to include explicit calculations involved in backpropagation on the lowest level. The students had to implement the forward and the backward pass of each layer in raw numpy. Inevitably, some students complained on the class message boards:\\n“Why do we have to write the backward pass when frameworks in the real world, such as TensorFlow, compute them for you automatically?”\\nThis is seemingly a perfectly sensible appeal - if you’re never going to write backward passes once the class is over, why practice writing them? Are we just torturing the students for our own amusement? Some easy answers could make arguments along the lines of “it’s worth knowing what’s unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3989</td>\n",
       "      <td>James Faghmous</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4?source=tag_archive---------0-----------------------</td>\n",
       "      <td>New to Machine Learning? Avoid these three mistakes | by James Faghmous | Medium</td>\n",
       "      <td>Nov 7, 2013\\nMachine learning (ML) is one of the hottest fields in data science. As soon as ML entered the mainstream through Amazon, Netflix, and Facebook people have been giddy about what they can learn from their data. However, modern machine learning (i.e. not the theoretical statistical learning that emerged in the...\\n275 \\n275 \\n2\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n548 Followers\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3990</td>\n",
       "      <td>Aqeel Anwar</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Difference between AlexNet, VGGNet, ResNet, and Inception | by Aqeel Anwar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 7, 2019\\nIn this tutorial, I will quickly go through the details of four of the famous CNN architectures and how they differ from each other by explaining their W3H (When, Why, What, and How)\\nWhen?\\nWhy? AlexNet was born out of the need to improve the results of the ImageNet challenge. This was one of the first Deep convolutional networks to achieve considerable accuracy on the 2012 ImageNet LSVRC-2012 challenge with an accuracy of 84.7% as compared to the second-best with an accuracy of 73.8%. The idea of spatial correlation in an image frame was explored using convolutional layers and receptive fields.\\nWhat? The network consists of 5 Convolutional (CONV) layers and 3 Fully Connected (FC) layers. The activation used is the Rectified Linear Unit (ReLU). The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>3991</td>\n",
       "      <td>Thilina Rajapakse</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca?source=tag_archive---------9-----------------------</td>\n",
       "      <td>A Hands-On Guide To Text Classification With Transformer Models (XLNet, BERT, XLM, RoBERTa) | by Thilina Rajapakse | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 3, 2019\\nPlease consider using the Simple Transformers library as it is easy to use, feature-packed, and regularly updated. The article still stands as a reference to BERT models and is likely to be helpful with understanding how BERT works. However, Simple Transformers offers a lot more features, much more straightforward tuning options, all the while being quick and easy to use! The links below should help you get started quickly.\\nThe Pytorch-Transformers (now Transformers) library has moved on quite a bit since this article was written. I recommend using SimpleTransformers as it is kept up to date with the Transformers library and is significantly more user-friendly. While the ideas and concepts in this article still stand, the code and the Github repo are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>3992</td>\n",
       "      <td>Rafi</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@today.rafi/demystifying-object-detection-using-deep-learning-d3f83e2fb832?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Demystifying Object Detection using Deep Learning | by Rafi | Medium</td>\n",
       "      <td>Dec 28, 2019\\nObject detection has been quite a center of attraction nowadays because of its wide range of applications and advancements in Deep Learning technology. Object Detection is a subdomain of image processing and computer vision that deals with identifying and localizing objects in videos or digital images. The credit for the evolution of object detection goes to the breakthrough in deep learning classification algorithms called CNN- Convolutional Neural Network and Graphic Processing Units that have shown great leads in the development of real-world solutions for computer vision problems like autonomous driving car, face detection and recognition, people detection, and tracking, video surveillance, security system design, etc.\\nObject detection can be done either using machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>3993</td>\n",
       "      <td>Adrien Lucas Ecoffet</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/paper-repro-deep-metalearning-using-maml-and-reptile-fd1df1cc81b0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Paper repro: Deep Metalearning using “MAML” and “Reptile” | by Adrien Lucas Ecoffet | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 2, 2018\\nIn this post I reproduce two recent papers in the field of metalearning: MAML and the similar Reptile. The full notebook for this reproduction can be found here.\\nThe goal of both of these papers is to solve the K-shot learning problem. In K-shot learning, we need to train a neural network to generalize based on a very small number of examples (often on the order of 10 or so) instead of the often thousands of examples we see in datasets like ImageNet.\\nHowever, in preparation for K-shot learning, you are allowed to train on many similar K-shot problems to learn the best way to generalize based on only K examples.\\nThis is learning to learn or metalearning. We have already seen metalearning in my post on “Learning to Learn by Gradient Descent by Gradie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3994</td>\n",
       "      <td>Patty Wu</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@pedin024/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%84%AA%E5%8C%96%E5%99%A8ranger-a-synergistic-optimizer-using-radam-rectified-adam-gradient-centralization-and-f022d9dd4217?source=tag_archive---------3-----------------------</td>\n",
       "      <td>深度學習優化器Ranger: a synergistic optimizer using RAdam (Rectified Adam), Gradient Centralization and LookAhead筆記 | by Patty Wu | Medium</td>\n",
       "      <td>Nov 20, 2020\\n今年人工智慧年會中,偶然聽到講師呼籲大家,都2020了,不要再用Adam了,請改用Ranger,因此著手來寫一篇Ranger的筆記。\\n今年有兩篇優化器相關的論文被提出,分別是LookAhead和RAdam,這兩種方法用不同角度對深度學習的優化做改進,後來研究員 Less Wright將兩個方法整合成一個新的優化器:Ranger,得到了更好的成果。\\n廢話不多說,先上PyTorch實現的GitHub:https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\\n要了解RAdam 和 LookAhead 是如何互補的,需要先分別討論他們的概念。\\n全名是Rectified Adam,白話地說,就是自動熱身(warmup)版的Adam。\\n概念\\nAdam是一種常用的自適應學習率 (adptive learning rate) 優化器,但類方法在訓練的初期,adptive learning rate的變異非常大,然後在少量的數據進行過度跳躍,下了錯誤決策,就容易收斂在local minimum。\\n為了解決這個問題,RAdam根據adaptive rate的變異程度去修正learning rate,讓Adam可以自動熱身,不需再手動調整,也避免模型收斂在local minimum。\\n概念是這樣:有個熱身用的開關,閥值為rho,這個rho代表adpative learning rate分配的自由度:\\n優點\\n如此的做法,讓RAdam在享有Adam快速收斂優勢的同時,又達到跟SGD差不多好的收斂結果。RAdam詳細概念可以參考我寫的另一篇文章:https://is.gd/2yxrE7。\\n2020由深度學習教父Geoffrey Hinton團隊發表的論文,LookAhead基於損失空...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3995</td>\n",
       "      <td>Nhan Tran</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-polynomial-regression-with-python-5328e4e8a386?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Machine Learning: Polynomial Regression with Python | by Nhan Tran | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 20, 2019\\nAbbreviations using in this post:\\nIn my previous post, we discussed about Linear Regression. Let’s take a look back. Linear Regression is applied for the data set that their values are linear as below example:\\nAnd real life is not that simple, especially when you observe from many different companies in different industries. Salary of 1 YE teacher is different from 1 YE engineer; even 1 YE civil engineer is different from mechanical engineer; and if you compare 2 mechanical engineers from 2 different companies, their salary mostly different as well. So how can we predict the salary of a candidate?\\nToday, we will use another data set to represent the Polynomial shape.\\nTo get an overview of the increment of salary, let’s visualize the data set into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>3996</td>\n",
       "      <td>thirumalaivasan</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@thirumalaivasudev/how-i-struggled-to-convert-mbr-to-gpt-and-installed-linux-7755b7946b93?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How I struggled to Convert MBR to GPT and Installed Linux? | by thirumalaivasan | Medium</td>\n",
       "      <td>Apr 22, 2019\\nI was supposed to Install Linux in my PC which is having a storage of 500GB with Windows in it ,So as a regular Linux installation procedure I unallocated 60GB and started to install the linux OS during the installation I found something fishy ,The Unallocated space was not showing up as a free space to install the Operating System ,I was like What the heck is this as usual Searched this issue in the Internet and discussed it with my techie friends all they told is “YOU HAVE TO CONVERT GPT TO MBR” and they suggested me some tools too like MINITOOL PARTITION WIZARD,ES PARTITION MASTER but everything ended up in Popping up for PREMIUM ACCESS to perform the particular action .It again started to irritate me a lot , I restarted my Computer several times again and again and en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>3997</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Multi-Class Text Classification Model Comparison and Selection | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 25, 2018\\nWhen working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier. The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\\nThis is what we are going to do today: use everything that we have presented about text classification in the previous articles (and more) and comparing between the tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>3998</td>\n",
       "      <td>dan lee</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/ai%C2%B3-theory-practice-business/what-is-pre-training-in-nlp-introducing-5-key-technologies-455c54933054?source=tag_archive---------1-----------------------</td>\n",
       "      <td>What Is Pre-Training in NLP? Introducing 5 Key Technologies | by dan lee | AI3 | Theory, Practice, Business | Medium</td>\n",
       "      <td>AI3 | Theory, Practice, Business\\nFeb 24, 2020\\nWelcome back to my blog for engineers who want to learn AI!\\nStarting with this post, we’ll be launching into a new series of articles on pre-training in NLP. Today, we’ll begin by forming a big picture.\\n394 \\n394 \\nThe AI revolution is here! Navigate the ever changing industry with our thoughtfully written articles whether your a researcher, engineer, or entrepreneur\\n298 Followers\\nNLP Engineer, Google Developer Expert, AI Specialist in Yodo1\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3999</td>\n",
       "      <td>Pankaj Jainani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/vanishing-exploding-gradient-problem-b5b78c142bb7?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Does your model train too slow? Alleviating Vanishing Gradient Problem | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 11, 2021\\nYou must definitely have encountered the problem when training a model is getting slower for a very Deep Neural Network. This phenomenon happens prominently during the backpropagation training (using Gradient Descent) of the DNNs, wherein, each parameter’s gradient error is propagated along its way to the lower layers of the network. Why? This usually happens because gradients usually get smaller and smaller. As a result, the lower layers weights never change and training never converges to the good solution.\\nThis post categorically discuss about the ways to alleviate the Vanishing Gradient (or the Exploding Gradient) problem while training the DNNs\\nThere are various ways to overcome this challenge —\\nLet’s look into all these in detail...\\nWe know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>4000</td>\n",
       "      <td>Michael Bronstein</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/graph-neural-networks-through-the-lens-of-differential-geometry-and-algebraic-topology-3a7c3c22d5f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Graph Neural Networks through the lens of Differential Geometry and Algebraic Topology | by Michael Bronstein | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 18, 2021\\n“Symmetry, as wide or as narrow as you may define its meaning, is one idea by which man through the ages has tried to comprehend and create order, beauty, and perfection.”\\nThis somewhat poetic description by Hermann Weyl [1] underlines the cornerstone role of symmetry in science. Felix Klein’s 1872 “Erlangen Programme” [2] characterised geometries through symmetry groups. Not only was this a breakthrough in mathematics, unifying the “zoo of geometries,” but also led to the development of modern physical theories that can be entirely derived from the first principles of symmetry [3]. Similar principles have emerged in machine learning under the umbrella of Geometric Deep Learning, a general blueprint for deriving the majority of popular neural networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>4001</td>\n",
       "      <td>Nurlan Kerimov</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@kerimov.nurlan/anomaly-detection-in-brightfield-microscopy-images-c92cdddafcc3?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Anomaly detection in brightfield microscopy images | by Nurlan Kerimov | Medium</td>\n",
       "      <td>Jun 14, 2020\\nDisclaimer: This project was developed by Kaspar Hollo and Nurlan Kerimov for the Neural Networks course at the University of Tartu. The data and the code used in this project are not public and, in this blog-post only a few examples from the dataset will be shown. The data was provided by PerkinElmer.\\nNowadays, microscopy images are often used for doing medical diagnosis. For example, in this paper, a deep learning model was developed to count mitotic cells to help diagnose breast cancer. There is a problem though — the captured microscopy images may contain some so-called anomalies which can be considered as noise. It is found that the cell count and position predictions (cell segmentation) are performing badly in areas with anomalies. In our project, we tried to predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4002</td>\n",
       "      <td>Harald Scheidl</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Beam Search Decoding in CTC-trained Neural Networks | by Harald Scheidl | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 10, 2018\\nNeural networks (NN) consisting of convolutional NN layers and recurrent NN layers combined with a final connectionist temporal classification (CTC) layer are a good choice for (handwritten) text recognition.\\nThe output of the NN is a matrix containing character-probabilities for each time-step (horizontal position), an example is shown in Fig 1. This matrix must be decoded to get the final text. One algorithm to achieve this is beam search decoding which can easily integrate a character-level language model.\\nWe will start our discussion with a recap of CTC and best path decoding. Then we will discuss the building blocks (basic algorithm, CTC scoring, language model) of the CTC beam search decoding algorithm. Finally, I will point you to a Python i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>4003</td>\n",
       "      <td>Mikhail Mew</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/data-scientists-will-be-extinct-in-10-years-a6e5dd77162b?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Data Scientists Will be Extinct in 10 Years | by Mikhail Mew | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 10, 2021\\nAs advances in AI continue to progress in leaps and bounds, accessibility to data science at a base level has become increasingly democratized. Traditional entry barriers to the field such as a lack of data and computing power have been swept aside with a continuous supply of new data startups popping up(some offering access for as little as a cup of coffee a day) and all powerful cloud computing removing the need for expensive onsite hardware. Rounding out the trinity of prerequisites, is the skill and know-how to implement, which has arguably become the most ubiquitous aspect of data science. One does not need to look far to find online tutorials touting taglines like “implement X model in seconds” , “apply Z method to your data in just a few lines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>4004</td>\n",
       "      <td>Park Chansung</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>4005</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>4006</td>\n",
       "      <td>Kerish Heik</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@Dude_Next/the-dropout-tag-i-wear-9425f2cba27b?source=tag_archive---------8-----------------------</td>\n",
       "      <td>The Dropout Tag I Wear. *On a personal note, before reading... | by Kerish Heik | Medium</td>\n",
       "      <td>Jan 8, 2016\\n*On a personal note, before reading this article take a deep breath and relax yourself. In this article, you will neither hear any neighbor’s aunties gossiping ills about you nor see your parents hesitations when you say something cause you are wearing a dropout tag that isn’t sugar coated. This is an article on the bright side of the moon about how I get the inspiration to ultimately drop out.\\nThis moment in my life about a year ago I got the ultimate boredom to drop out of my class to do something of my own that I am really passionate about. Everyone in the class was doing the same thing, solving Irodov’s problems where the task itself would be a terror for every country’s layman and more importantly, till now I don’t find any usefulness of that things beside teaching t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>4007</td>\n",
       "      <td>Anusha Lihala</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Attention and its Different Forms | by Anusha Lihala | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 29, 2019\\nI assume you are already familiar with Recurrent Neural Networks (including the seq2seq encoder-decoder architecture).\\nIn the encoder-decoder architecture, the complete sequence of information must be captured by a single vector. This poses problems in holding on to information at the beginning of the sequence and encoding long-range dependencies.\\nThe core idea of attention is to focus on the most relevant parts of the input sequence for each output. By providing a direct path to the inputs, attention also helps to alleviate the vanishing gradient problem.\\nAssume you have a sequential decoder, but in addition to the previous cell’s output and hidden state, you also feed in a context vector c.\\nWhere c is a weighted sum of the encoder hidden states...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4008</td>\n",
       "      <td>Supervise.ly</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/deep-systems/movix-ai-movie-recommendations-using-deep-learning-5903d6a31607?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Movix.ai — movie recommendations with Deep Learning | by Supervise.ly | Supervisely | Medium</td>\n",
       "      <td>Supervisely\\nMay 2, 2017\\n“What movie should i watch this evening?” — have you ever had to answer this question at least once when you came home from work? As for us — yes, and more than once. Here we will say a few words about what we’ve been working on for the past six months: an interactive movie recommender system Movix.ai. The system is based on Deep Learning and it adapts to the user preferences in real time. As big movie fans we felt the need for such a service, and we believe that it will be useful for every movie lover.\\nAt Deep Systems we are engaged in creating solutions and products based on machine learning and Deep Learning. Among our projects: developing a “mind” for self-driving car prototype and automatic defects detection for roads and airport runways. The important p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>4009</td>\n",
       "      <td>Tobias Skovgaard Jepsen</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=tag_archive---------4-----------------------</td>\n",
       "      <td>How to do Deep Learning on Graphs with Graph Convolutional Networks | by Tobias Skovgaard Jepsen | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 18, 2018\\nMachine learning on graphs is a difficult task due to the highly complex, but also informative graph structure. This post is the first in a series on how to do deep learning on graphs with Graph Convolutional Networks (GCNs), a powerful type of neural network designed to work directly on graphs and leverage their structural information. The posts in the series are:\\nIn this post, I will give an introduction to GCNs and illustrate how information is propagated through the hidden layers of a GCN using coding examples. We’ll see how the GCN aggregates information from the previous layers and how this mechanism produces useful feature representations of nodes in graphs.\\nGCNs are a very powerful neural network architecture for machine learning on graphs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>4010</td>\n",
       "      <td>Merzmensch</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/generative-ai-visual-search-as-a-bridge-between-fiction-and-reality-46d2d78ee15?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Generative AI: Visual Search as a Bridge between Fiction and Reality | by Merzmensch | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 8, 2021\\nFirst, tell me, please, what is fiction and what is reality — in the context of Generative Adversarial Networks?\\nWe’ve seen a lot of things, which hadn’t existed before its AI-driven creation. Sure, the GAN-generated images in This Person Does Not Exist or This Artwork Does Not Exist have no direct reference in the material world — they are products of knowledge and AI models training. But being transported into our world, they might get their own story, specific meaning, and particular use, leaving the Latent Space and become more real than fiction.\\nIndeed, you can use them for making movies; you also can generate fraud and fakes. AI is not to blame for misuse, but us, humans. You cannot fix society by breaking technology.\\nNevertheless, in Digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>4011</td>\n",
       "      <td>Akihiro FUJII</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@akichan-f/efficientnet-b6-autoaug%E3%81%A8%E5%90%8C%E7%AD%89%E7%A8%8B%E5%BA%A6%E3%81%AE%E7%B2%BE%E5%BA%A6%E3%81%A75%E5%80%8D%E6%97%A9%E3%81%84assemble-resnet-c3b8b846e0a2?source=tag_archive---------9-----------------------</td>\n",
       "      <td>EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNet | by Akihiro FUJII | Medium</td>\n",
       "      <td>Feb 2, 2020\\nこの記事は、EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNetを提案した2020/1/17投稿の論文””Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network [1]の解説記事です。\\nこの記事では以下のこと説明します。\\nこの論文のサマリは以下のような感じです。\\n既存のあらゆるテクニックを組み合わせて、EfficientNet B6+AutoAugと同等程度の精度で5倍早いネットワークを構築した研究。著者たちがいうにはAugMix等の最新のものはここでは使ってないので、まだ精度があがる可能性があるとのこと。\\nここでは、Assemble-ResNetのベースライン比較となっているEfficientNet+AutoAugmentの解説をします。EfficientNetは2019年に発表された既存のネットワークより大幅に軽くて高精度なネットワークです。AutoAugmentは2018年に発表された論文で、最適なデータ拡張を自動で探索する研究です。どちらも画像認識では頻繁にベースラインとして登場する強力な手法です。\\nEfficientNet[2]は2019/5/28に投稿された論文で、それまでの既存のネットワークより高速で高精度なネットワークです。論文の内容をまとめると下記のような感じです。今まで成されていなかった解像度・深さ・チャネル数を同時に最適化することによって、高速かつ高精度なネットワークを構築。式3におけるφ=1にしてMnasNetの探索空間でαβγを最適化(B0)、後にφを変...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>4012</td>\n",
       "      <td>Rakshith Vasudev</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/how-are-logistic-regression-ordinary-least-squares-regression-related-1deab32d79f5?source=tag_archive---------9-----------------------</td>\n",
       "      <td>How are Logistic Regression &amp; Ordinary Least Squares Regression (Linear Regression) Related? Why the “Regression” in Logistic? | by Rakshith Vasudev | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 5, 2018\\nIf you are like me bothered by “regression” in “logistic regression” which realistically should be called “logistic classification”, considering it does classification, I have an answer for your botheration!\\nLogistic regression is useful for situations where there could be an ability to predict the presence or absence of a characteristic or outcome, based on values of a set of predictor variables. It is similar to a linear regression model but is suited to models where the dependent variable is dichotomous. It’s coefficients can be used to estimate odd ratios for each of the independent variables in the model. It is applicable to a broader range of research situations than discriminant analysis. Logistic Regression on the other hand is used to ascert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>4013</td>\n",
       "      <td>Thomas HARTMANN</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/datathings/meta-learning-learning-to-learn-a55cadd32b17?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Meta-Learning: Learning to Learn. Although artificial intelligence and... | by Thomas HARTMANN | DataThings | Medium</td>\n",
       "      <td>DataThings\\nFeb 6, 2019\\nAlthough artificial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. Meta-learning aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning algorithm.\\nArtificial intelligence and machine learning are currently extremely fashionable. In recent years, this technology has left the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>4014</td>\n",
       "      <td>Nishanth N</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>4015</td>\n",
       "      <td>Chung-Yi</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81-gradient-descent-e97890236262?source=tag_archive---------7-----------------------</td>\n",
       "      <td>ML入門(十)Gradient Descent. 簡單回顧 | by Chung-Yi | 程式設計之旅 | Medium</td>\n",
       "      <td>程式設計之旅\\nSep 22, 2019\\n簡單回顧\\n在ML入門(五)Linear Regression有介紹什麼是Gradient Descent,就是對loss function做偏微分(切線斜率)就是找極大極小值的概念,找一組參數讓loss function越小越好。在ML入門(五)Linear Regression,我們要更新的是w, b,在這邊用一個theta表示。\\nGradient Descent如何運行\\n這邊可以搭配公式一起看,紅色箭頭就是loss function的gradient方向,當乘上learning rate後再乘上負號(改變方向)就會變成藍色箭頭,一直重複這樣的動作,這就是Gradient Descent的運行模式。\\nLearning Rate對 Loss Function的影響\\n調整learning rate的方法\\n既然learning rate有時候不是太大不然就是太小,是不是有什麼方法可以來讓機器自己調整。當一開始起始點離最低點還很遠的時候,learning rate可以大一點;當越來越接近最低點時,learning rate要小一點,這樣才能收斂在最低點附近。下面那張圖所示,假設定義learning rate是每次跟著更新次數做調整,也就是說你的更新次數越多,learning rate會跟次數的開根號成反比,learning rate會越小。那有人就覺得說可以根據不同參數調整不同的learning rate,以下會列出幾種方法:\\n現在對於每一個參數w都要給一個不同的η,就是每次更新的η就是等於前一次的η再除以σ^t,而 σ^t則代表的是第 t 次以前的所有梯度更新值之平方和開根號(root mean square),而ε只是為了不讓分母為0而加上去的值。\\n下面圖中的式子可以清楚看出,分子的部分(紅色框框)顯示,當g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>4016</td>\n",
       "      <td>João Fernandes</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@joaomariafernandes/why-i-dropped-out-of-college-but-you-shouldn-t-73a4b99f9cf9?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Why I dropped out of college, but you shouldn’t | by João Fernandes | Medium</td>\n",
       "      <td>Oct 26, 2015\\nThis article’s title is even a surprise to me. This is not something that I expected to write and you’re probably wondering what happened to all that advice about “you grow your wings on your way down”. I know, but this is the kind of theme that creates a lot of fuss by itself and a lot of irresponsible advice is given.\\nHere I will clarify my position on pursuing an academic career and how is the life of a college drop out.\\nI’ve always been a decent student, I always knew that I could be one of the top students in the class, but I never felt like going after that status. Video games always seemed more interesting than boring themes with zero practical implication. So school never presented itself as a challenge when it came to studying. Even in college I pass at every s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>4017</td>\n",
       "      <td>ASHNA JAIN</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/voice-tech-podcast/automatic-extractive-text-summarization-using-tfidf-3fc9a7b26f5?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Automatic Extractive Text Summarization using TF-IDF | by ASHNA JAIN | Voice Tech Podcast | Medium</td>\n",
       "      <td>Voice Tech Podcast\\nApr 1, 2019\\nIn the recent years, information grows rapidly along with the development of social media. With the increasing amount of information, it takes more effort and time to review the entire text document and understand its contents. One possible solution to the above problem is to read the summary of the document. The summary will not only retain the essence of the document, but will also save a lot of time and effort. An effective summary of the document will concise and fluent while preserving key information and overall meaning.\\nThere are two major text summarization approaches, abstractive and extractive summarization. The approach of Abstractive summarization selects words on the basis of semantic understanding, and even includes those words which do n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>4018</td>\n",
       "      <td>Eric Elliott</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/javascript-scene/top-javascript-frameworks-and-tech-trends-for-2021-d8cb0f7bda69?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Top JavaScript Frameworks and Tech Trends for 2021 | by Eric Elliott | JavaScript Scene | Medium</td>\n",
       "      <td>JavaScript Scene\\nDec 31, 2020\\nHappy New Year! It’s time to review the big trends in JavaScript and technology in 2020 and consider our momentum going into 2021.\\nOur aim is to highlight the learning topics and technologies with the highest potential job ROI. This is not about which ones are best, but which ones have the most potential to land you (or keep you in) a great job in 2021. We’ll also look at some larger tech trends towards the end.\\nJavaScript still reigns supreme on GitHub and Stack Overflow. Tip #1: Learn JavaScript, and in particular, learn functional programming in JavaScript. Most of JavaScript’s top frameworks, including React, Redux, Lodash, and Ramda, are grounded in functional programming concepts.\\nTypeScript jumped past PHP, and C# into 4th place, behind only Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>4019</td>\n",
       "      <td>Huangwei Wieniawska</td>\n",
       "      <td>10</td>\n",
       "      <td>https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting | by Huangwei Wieniawska | Level Up Coding</td>\n",
       "      <td>Level Up Coding\\nJun 25, 2020\\nDo you want to try some other methods to solve your forecasting problem rather than traditional regression? There are many neural network architectures, which are frequently applied in NLP field, can be used for time series as well. In this article, we are going to build two Seq2Seq Models in Keras, the simple Seq2Seq LSTM Model, and the Seq2Seq LSTM Model with Luong Attention, and compare their forecasting accuracy.\\nFirst of all, let’s create some time series data.\\nWe’ve just created two sequences, x1 and x2, by combining sin waves, trend, and random noise. Next we will preprocess x1 and x2.\\nSince the sequence length is n_ = 1000, the first 800 data points will be used as our train data, while the rest will be used as our test data.\\nIt is not a must ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4020</td>\n",
       "      <td>R. E. Warner</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/minds-on-media/finger-dasher-3332487b5f4e?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Finger Dasher | by R. E. Warner | Banapana | Medium</td>\n",
       "      <td>Banapana\\nJan 4, 2008\\nDasher is a novel piece of software that lets you point at what you want to write. Honestly, it’s kind of difficult to describe without [seeing the demonstration](http://www.youtube.com/watch?v=0d6yIquOKQ0). It’s very novel and makes novel use of some simple AI. I wonder if Apple would ever integrate this in to the iPhone? And it would seem to be of great use were it to be integrated into eye tracking software.\\nOur Minds on Media\\n86 Followers\\nWriter of story, poetry and code. Currently attempting to illustrate one Ism a day — https://ismisms.tumblr.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>4021</td>\n",
       "      <td>m.zaradzki</td>\n",
       "      <td>7</td>\n",
       "      <td>https://becominghuman.ai/a-news-analysis-neuralnet-learns-from-a-language-neuralnet-16646804fdeb?source=tag_archive---------9-----------------------</td>\n",
       "      <td>A news-analysis NeuralNet learns from a language NeuralNet | by m.zaradzki | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nMar 28, 2017\\nPython notebook, using Keras library, available on this GitHub repo.\\nA common way to solve a complex computing task is to chain together specialized components. In data-science this is the pipeline approach. Each component mostly treats the other components as I/O black-boxes. As developers we potentially have the full picture but the system does not.\\nWith Neural Network what happens between I and O is often too interesting to be ignored. One Neural Network can leverage the way another Neural Network processes its inputs.\\nIn this post I discuss the following scenario :\\nTo “understand” english is necessary to analyse news. Thus during training a standalone ’N’ NeuralNet would learn about the semantics of english as a by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>4022</td>\n",
       "      <td>karthic Rao</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/kredo-ai-engineering/blog-series-on-ros-ai-ff28cc116560?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Building smart robots using AI + ROS: Part 1 | by karthic Rao | Kredo.ai Engineering | Medium</td>\n",
       "      <td>Kredo.ai Engineering\\nDec 8, 2017\\nMotivation for writing blog series on AI + Robotic Operating Systems:\\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\\nROS is used to create application for a physical robot without depending on the actual machine, thus saving cost and time. These applications can be transferred onto the physical robot without modifications.\\nThe decision making capability of the robots can be aided with AI. The cases where the robot agent has to learn optimal strategies in high dimensional state space often means that it is impractical to generate sufficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>4023</td>\n",
       "      <td>Thomas Filaire</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Clustering on mixed type data. A proposed approach using R | by Thomas Filaire | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 16, 2018\\nClustering unsupervised data is not an easy task. Indeed, data crunching and exploration is in such a context often driven by domain knowledge, if not pure intuition, and made difficult as there is no way to measure the accuracy of the resulting segmentation (as opposed to supervised learning).\\nIn addition, introductory courses to unsupervised learning quite often discuss ideal use cases, such as k-means tutorials, which only apply to numerical features.\\nHowever, real business situations often deviate from these ideal use cases, and need to analyze datasets made of mixed-type data, where numeric (the difference between two values is meaningful), nominal (categorical, not ordered) or ordinal (categorical, ordered) features coexist.\\nIn this post, I’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>4024</td>\n",
       "      <td>Alex Lenail</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@alexlenail/what-is-the-difference-between-ridge-regression-the-lasso-and-elasticnet-ec19c71c9028?source=tag_archive---------5-----------------------</td>\n",
       "      <td>What is the difference between Ridge Regression, the LASSO, and ElasticNet? | by Alex Lenail | Medium</td>\n",
       "      <td>Jul 31, 2017\\nThis article is about different ways of regularizing regressions. In the context of classification, we might use logistic regression but these ideas apply just as well to any kind of regression or GLM.\\nWith binary logistic regression, the goal is to find a way to separate your two classes. There are a number of ways of visualizing this.\\nNo matter which of these you choose to think of, we can agree logistic regression defines a decision rule\\nh(x|theta) = sigmoid(x dot theta + b)\\nand seeks a theta which minimizes some objective function, usually\\nloss(theta)= ∑ y*log(h(x|theta)) + (1−y)log(1−h(x|theta))\\nwhich is obfuscated by a couple clever tricks. It is derived from the intuitive objective function:\\nloss(theta)= ∑ (y - h(x|theta))\\ni.e. the number of misclassified x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>4025</td>\n",
       "      <td>Michael L. Peng</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@lipeng2/dropout-is-so-important-e517bbe3ffcc?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Improving neural networks by preventing co-adaptation of feature detectors | by Michael L. Peng | Medium</td>\n",
       "      <td>May 7, 2018\\nThis blog post aims to provide readers some insights on deep neural networks and intuition about dropout technique.\\nDeep neural networks are models composed of multiple layers of simple, non-linear neurons. With composition of enough neurons, the model can learn extremely complex functions that can accurately perform complicated tasks that are impossibly difficult to hard code, such as image classification, translation, speech recognition, etc. The key aspect of deep neural networks is that they are able to automatically learn data representation needed for features detection or classification without any a priori knowledge1.\\nFor example, VGG16 (shown below) is a convolutional neural network that is trained on ImageNet Large Scale Visual Recognition Competition (ILSVRC) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>4026</td>\n",
       "      <td>Marco Cerliani</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Extreme Event Forecasting with LSTM Autoencoders | by Marco Cerliani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 22, 2019\\nDealing with extreme event prediction is a frequent nightmare for every Data Scientist. Looking around I found very interesting resources that deal with this problem. Personally, I literally fall in love with the approach released by Uber Researchers. In their papers (two versions are available here and here) they developed an ML solution for daily future prediction of traveler demand. Their methodology stole my attention for its geniality, good explanation, and easy implementation. So my purpose is to reproduce their discovery in pythonic language. I’m very satisfied with this challenge and in the end, I improved my knowledge of regression forecasting.\\nThe most important takeaways from this post can be summarized as:\\nBut Keep Kalm and let’s procee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>4027</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Natural Language Processing for Fuzzy String Matching with Python | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 12, 2018\\nIn computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\\nFuzzy string search can be used in various applications, such as:\\nSpeaking of dedupe, it may not as easy as it sounds, in particular if you have hundred thousands of records. Even Expedia does not make it 100% right:\\nThis post will explain what fuzzy string matching is together with its use cases and give examples using Python’s Fuzzywuzzy library.\\nEach hotel has its own nomenclature to name its rooms, the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>4028</td>\n",
       "      <td>Aji Abraham</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@ajiabs/socialdefender-social-reputation-management-platform-aji-abraham-593dafc771e2?source=tag_archive---------2-----------------------</td>\n",
       "      <td>SocialDefender — Social Reputation Management Platform — Aji Abraham | by Aji Abraham | Medium</td>\n",
       "      <td>Jan 11, 2013\\nSocial media can be hard to control. From small and medium-sized businesses lacking additional manpower to large companies requiring a method for scheduling numerous team members, we decided to create a tool that will add additional value to social media efforts.\\nSocial Defender provides real-time social media monitoring, insights and gives the ability to accurately moderate social media efforts and understand customer sentiment.\\nBy using the tool, businesses can manage multiple social media networks including Facebook, Twitter, Tumblr, YouTube, G+, blogs and forums using just one login. This social media management tool gives businesses the ability to analyze what is being said online about a brand, service, industry, and competitors. Analytics provided by Social Defen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>4029</td>\n",
       "      <td>LucianoSphere</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/the-hype-on-alphafold-keeps-growing-with-this-new-preprint-a8c1f21d15c8?source=tag_archive---------6-----------------------</td>\n",
       "      <td>The hype on AlphaFold keeps growing with this new preprint | by LucianoSphere | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 18, 2021\\nI am sure you read about AlphaFold in late 2020 when it “won” the CASP14 “contest” on modeling protein structures, and in July 2021 when the peer-reviewed paper and AI model were released. If not, or if you want to refresh what protein structures are, why biologists prayed for decades for programs to accurately predict them, and how AlphaFold works and performs, then check this story and this one, then come back here.\\nThis new story brings you the latest news, based on a just-published preprint.\\nTable of contents\\nThis story is based on a preprint just posted in the bioRxiv that formally describes a tool dubbed ColabFold under the moto Making protein folding accessible to all (which I would have rather phrased Making modern protein structure modeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4030</td>\n",
       "      <td>Eitan Kosman</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@eitan-kosman/neural-image-retrieval-72029a0dbd00?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Neural Image Retrieval. Assume you have an image I and an image... | by Eitan Kosman | Medium</td>\n",
       "      <td>Jul 4, 2020\\nAssume you have an image I and an image database X containing thousands of other images. You want to find a subset S⊆X containing images that are most similar to I. This is a task called image retrieval. However, before solving this, you may ask yourself, what is the meaning of similar images? Is it based on the colors in the images? Or maybe the content? In the second case, two images containing dogs could be considered similar regardless of their breed, which obviously may have different colors. In this post, I will describe a simple implementation of this. The implementation is based on neural networks and is done by comparing the similarity between the embeddings of the two images.\\nGiven a query image I, I extract the features using VGG-19 and use the output of the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>4031</td>\n",
       "      <td>Benedict Neo</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/top-20-movies-about-machine-learning-ai-and-data-science-8382d408c8c3?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Top 20 Must-Watch Artificial Intelligence movies | by Benedict Neo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 9, 2020\\nMovies are more than just blockbusters hit with explosions and superpowers, it’s the main idea behind the movie that changes people and injects a notion in the viewer’s head.\\nTo illustrate, the movie Joker wasn’t a hero vs villain film, fighting with superpowers and wreaking havoc on New York City. It portrayed how there is a distinct chasm between the rich and the poor, the lucky and the unlucky, and how mental illness can distort a person’s morality and value system.\\nSo, movies are more than just an activity for enjoyment and amusement, it plays an imperative role in shaping our view on the world and communal consciousness.\\nIn short, movies educate people and spread ideas in ways a paperback book early does today.\\nOne reason for the effectivenes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>4032</td>\n",
       "      <td>Luuk Derksen</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@luckylwk/transfer-learning-in-tensorflow-on-the-kaggle-rainforest-competition-4e978fadb571?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Transfer Learning in TensorFlow on the Kaggle Rainforest competition | by Luuk Derksen | Medium</td>\n",
       "      <td>Jul 31, 2017\\nWhen I first noticed the Kaggle competition: “Planet: Understanding the Amazon from space” I was immediately thinking of trying out Transfer Learning using a pre-trained model. I had never really played with Transfer Learning before so I thought this would be a good one to try it out on. Transfer Learning is described by Wikipedia as:\\n“a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem”\\nwhere in this case the ‘relatedness’ of the problem is that both the Kaggle competition and the pre-trained model(s) are addressing computer vision problems. For more information on Transfer Learning there is a good resource from Stanfords CS class and a fun blog by Sebastian Ruder.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>4033</td>\n",
       "      <td>Ryan Kemmer</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/clustering-on-mixed-data-types-in-python-7c22b3898086?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Clustering on Mixed Data Types in Python | by Ryan Kemmer | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJan 25, 2021\\nDuring my first ever data science internship, I was given a seemingly simple task to find clusters within a dataset. Given my basic knowledge of clustering algorithms like K-Means, DBSCAN, and GMM I thought that I could easily get this task done. However, as I took a closer look into the dataset, I realized the data contained a mixture of categorical and continuous data, and many common methods of clustering I knew would not easily work.\\nCategorical data consists of multiple discrete categories that commonly do not have any clear order or relationship to each-other. This data might look like “Android” or “iOS”.\\nContinuous data consists of real numbers that can take any value. This data might look like “3.14159” or “43\".\\nMany datasets contain a mixture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>4034</td>\n",
       "      <td>Haripriya Reddy</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/insight-into-faster-r-cnn-for-object-detection-f1e64240eee1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Insight into Faster R-CNN for Object Detection. | by Haripriya Reddy | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJan 23, 2020\\nFaster R-CNN is an object detection architecture presented by Ross Girshick, Shaoqing Ren, Kaiming He and Jian Sun in 2015, and is one of the famous object detection architectures that uses convolution neural networks.It detects and classifies objects in an image as shown below:\\nBefore diving into Faster R-CNN let’s learn about R-CNN, Fast R-CNN and RPN which are the building blocks...\\n303 \\n303 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n24 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>4035</td>\n",
       "      <td>Masumi Mutsuda</td>\n",
       "      <td>2</td>\n",
       "      <td>https://blog.mutsuda.com/intelligent-agent-based-wastewater-management-system-741b793f1c5c?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Intelligent Agent Based Wastewater Management System | by Masumi Mutsuda | mutsuda</td>\n",
       "      <td>mutsuda\\nMar 22, 2012\\nFa dos anys, a l’assignatura d’AIA (Aplicacions de la Intel·ligència Artificial), ens van fer implementar un sistema intel·ligent que dominaria tot el procés de depuració d’aigua de Catalunya. Les diferents plantes havien de ser intel·ligents i tenir suficient coneixement del seu entorn com per decidir, entre elles, de quina manera actuar en cas de detecció d’un contaminant, pluja torrencial, etc. Elles soles decidien mitjançant diverses polítiques què fer en cadascuna de les situacions per tal de resoldre els problemes.\\nLes plantes entre si es comunicaven mitjançant missatges en format d’ontologia, que ve a ser una representació lògica del context en què s’està treballant. En aquest cas l’ontologia contenia informació sobre els tòxics, l’aigua, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>4036</td>\n",
       "      <td>Uri Eliabayev</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Springer has released 65 Machine Learning and Data books for free | by Uri Eliabayev | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 26, 2020\\nHundreds of books are now free to download\\nSpringer has released hundreds of free books on a wide range of topics to the general public. The list, which includes 408 books in total, covers a wide range of scientific and technological topics. In order to save you some time, I have created one list of all the books (65 in number) that are relevant to the data and Machine Learning field.\\nAmong the books, you will find those dealing with the mathematical side of the domain (Algebra, Statistics, and more), along with more advanced books on Deep Learning and other advanced topics. You also could find some good books in various programming languages such as Python, R, and MATLAB, etc.\\nIf you are looking for more recommended books about Machine Learning a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>4037</td>\n",
       "      <td>Ravindra Kompella</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/using-lstms-to-forecast-time-series-4ab688386b1f?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Using LSTMs to forecast time-series | by Ravindra Kompella | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 17, 2018\\nThere are several time-series forecasting techniques like auto regression (AR) models, moving average (MA) models, Holt-winters, ARIMA etc., to name a few. So, what is the need for yet another model like LSTM-RNN to forecast time-series? This is quite a valid question to begin with and here are the reasons that I could come up with (respond below if you are aware of more, I will be curious to know)—\\nOn the other hand, there are the usual downsides that one needs to be careful about, while using LSTM’s (or any DNN architectures for that matter) — requirement of lots of data, multiple hyper-parameters to be tuned etc., I also came across few articles that mentioned that LSTM’s are not supposedly good at auto regression type of series. So take this wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>4038</td>\n",
       "      <td>Roland Hewage</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models | by Roland Hewage | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 12, 2020\\nKeras provides a set of deep learning models that are made available alongside pre-trained weights on ImageNet dataset. These models can be used for prediction, feature extraction, and fine-tuning. Here I’m going to discuss how to extract features, visualize filters and feature maps for the pretrained models VGG16 and VGG19 for a given image.\\nHere we first import the VGG16 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG16 model. The numpy module is imported for array-processing. Then the VGG16 model is loaded with the pretrained weights for the imagenet dataset. VGG16 model is a series of convolutional layers followed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>4039</td>\n",
       "      <td>Tan</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/ai-academy-taiwan/%E5%B8%B6%E4%BD%A0%E8%AA%8D%E8%AD%98vector-quantized-variational-autoencoder-%E7%90%86%E8%AB%96%E7%AF%87-49a1829497bb?source=tag_archive---------6-----------------------</td>\n",
       "      <td>帶你認識Vector-Quantized Variational AutoEncoder - 理論篇 | by Tan | Taiwan AI Academy | Medium</td>\n",
       "      <td>Taiwan AI Academy\\nApr 28, 2020\\n說到近年來最火紅以深度學習為主的生成模型,大家必定會想到生成對抗網路(Generative Adversarial Network, GAN),然而在GAN(2014)還沒被提出來之前,有另外一個同樣屬於生成模型的Variational AutoEnoder (VAE)常被大家所使用,很可惜的是當時GAN在許多任務上所產生的圖片清晰度較高,因此VAE類型的模型相對而言就勢弱了一些(當然GAN在訓練的特性上有一些難以克服的問題至今也尚未完全解決)。\\n故事總不會就這樣結束,2017年DeepMind在NIPS研討會上提出了Vector-Quantized Variational AutoEncoder模型,雖然在效果上仍然是先與VAE做比較,但VQ-VAE提出的概念讓它擁有比其它生成模型更獨特的地方,甚至在後續2019年6月提出的VQ-VAE2甚至宣稱在生成1024*1024的高解析度人臉時與當時效果最佳的BigGAN可作比擬。如果你開始對VQ-VAE感到好奇,就跟著我們一起看下去吧。\\n註1:如果你對Variational AutoEncoder甚至是AutoEncoder的概念還沒那麼熟的話,可以參考此篇AutoEncoder介紹、此篇VAE介紹、或是尋找其他資源唷。\\n我們可以這樣解讀AutoEncoder家族在做的事情,Encoder試圖找出輸入圖片x在潛在空間上的表徵(representation),在大多數的狀況中,大家使用連續型的分布去模擬z的樣貌(e.g. AE將輸入x投影至潛在空間的一個點;VAE則改為使用高斯分布模擬輸入x在潛在空間的樣貌),然而VQVAE的作者提到離散的潛在表徵在很多情境上也許才是比較適合的,例如語言概念,因此VQ-VAE主要的突破就是試圖讓Encoder產出離散的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>4040</td>\n",
       "      <td>Progress</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/stories-by-progress/true-democratization-of-analytics-with-meta-learning-cdefe3c7ddd5?source=tag_archive---------4-----------------------</td>\n",
       "      <td>True Democratization of Analytics with Meta-Learning | by Progress | Stories by Progress | Medium</td>\n",
       "      <td>Stories by Progress\\nAug 14, 2017\\nThe democratization of analytics has become a popular term, and a quick Google search will generate results that explore the necessity of empowering more people with analytics and the rise of citizen data scientists. The ability to easily make better use of your (constantly growing) pool of data is a critical driver of business success, but many of the existing solutions that claim to democratize analytics only do so within severe limits. If you have a complex business scenario and are looking to get revolutionary insights using them, it’s easy to come away disappointed.\\nHowever, the democratization of analytics isn’t just a buzzword that refers to a narrow approach. It’s possible to do so much more. Let’s quickly review the current state of the mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>4041</td>\n",
       "      <td>Md Shahidullah Kawsar</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@kawsar34/machine-learning-quiz-05-decision-tree-part-1-3ea71fa312e5?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Machine Learning Quiz 05: Decision Tree (Part 1) | by Md Shahidullah Kawsar | Medium</td>\n",
       "      <td>Jun 1, 2021\\nLet’s check your basic knowledge of Decision Tree. Here are 10 multiple-choice questions for you and there’s no time limit. Have fun!\\nQuestion 1: Decision trees are also known as CART. What is CART?(A) Classification and Regression Trees(B) Customer Analysis and Research Tool(C) Communication Access Real-time Translation(D) Computerized Automatic Rating Technique\\nQuestion 2: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees implicitly perform variable screening or feature selection(B) Can handle both numerical and categorical data(C) Can handle multi-output problems.(D) All of the above\\nQuestion 3: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees require relatively less effort from users for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>4042</td>\n",
       "      <td>Dmitry Kan</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/speeding-up-bert-search-in-elasticsearch-750f1f34f455?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Speeding up BERT Search in Elasticsearch | by Dmitry Kan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 15, 2021\\nIn two previous blog posts on my journey with BERT: Neural Search with BERT and Solr and Fun with Apache Lucene and BERT I’ve taken you through the practice of what it takes to enable semantic search powered by BERT in Solr (in fact, you can plug in any other dense embeddings method, other than BERT, as long as it outputs a float vector; a binary vector can also work). While it feels cool and modern to empower your search experience with a tech like BERT, making it performant is still important for productization. You want your search engine operations team to be happy in a real industrial setting. And you want your users to enjoy your search solution.\\nDevops cares about disk sizes, RAM and CPU consumption a lot. In some companies, they also care ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>4043</td>\n",
       "      <td>Justin Chen</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@interjc/%E5%86%99%E5%9C%A8%E7%9C%8B%E5%AE%8C%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9Aii%E4%B9%8B%E5%90%8E-ea5d294d2bd3?source=tag_archive---------0-----------------------</td>\n",
       "      <td>写在看完变形金刚II之后 | by Justin Chen | Medium</td>\n",
       "      <td>Jun 29, 2009\\n变形金刚II(Transformers:ROF)这样一部电影,从我从电影院看完他的第一部就开始期待了,昨天终于有幸去电影院看了。画面很,庞大,震撼说不上,可能在1的时候已经给我震完了吧。影院的效果就是好,所以看这个电影确实是一种享受的。当然就我个人看来他想超越1或者是原版动漫是没有多大可能了。我不是一个喜欢搞剧透的人,所以我非常不想说剧情。\\n只说一下对于剧情的感受:1. 剧情太商业化,变形金刚这么强大的战斗力和防御力,我不知道拿着枪的人类可以对他们造成什么样的威胁呢?美国大兵们与变形金刚们短兵相接,难道是为了方便狂派们刷数据么?2. 由于是美国电影,所以一定要展现美国军备的强大,所以战舰上的秘密武器可以KO看上去甚是强大的纸老虎 — — 狂派合体机器人;3. 主角一定得是人类,为了烘托人类主角的伟大性,不惜牺牲同样伟大但没有他伟大的各位领袖同志,主角由于起点比较低,所以随便摸一下某个能量体就可以吸收里面的精髓;4. 赶新潮,年轻人做网站办公司、经济危机,再在电影里融入一点青春元素,把学生宿舍比喻为霍格沃茨,可惜这方面的篇幅太短,如果开发一下说不定会为本集贫乏的剧情添加一点色彩;5. 冷兵器,变形金刚们之间的斗争,如果想要解决对方,就必须使用冷兵器或者蛮力,这方面是我所欣赏的,我可不希望擎天柱、威震天是被一把麦林爆头干掉的;6. HappyEnding,每一部想拍续集的电影都有那么一个HappyEnding,狂派还会回来的誓言也是必需的~\\n综上所述,这的确是一部好电影,看的时候请放松您的大脑,因为没什么可以让你去思考的。\\nBTW:搬到cosbeta的主机以后速度很快,很快,我非常欣慰。\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Follower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>4044</td>\n",
       "      <td>Jhen Hilario</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@ellehilly/classes-of-novels-c8207342dc0b?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Classes of Novels. According to Creative Writing Now, the... | by Jhen Hilario | Medium</td>\n",
       "      <td>Oct 31, 2015\\nAccording to Creative Writing Now, the publishing world tends to classify Fiction as either Commercial (built to make money), or Literary (a work of art). There are no further explanations why art cannot also make money, but things just doesn’t work that way. Observe how Commercial Fiction and Literary Fiction are handled as separate categories. Commercial Fiction is divided into several genres. This kind of classification can help readers to determine what kind of novel do they like to read. Each genre also has its own rubric. Literary fiction has been generally chunked all together in bookstores as “General Fiction”. Because the precedence of literary authors is to produce works of art, while selling books is only a second thought. Literary authors are less likely to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>4045</td>\n",
       "      <td>Akshika Wijesundara</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@akshikawijesundara/object-recognition-with-opencv-on-android-6435277ab285?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Object Recognition with OpenCV on Android | by Akshika Wijesundara | Medium</td>\n",
       "      <td>Dec 20, 2016\\nThis article is for a person who has some knowledge on Android and OpenCV. We will look at how to use the OpenCV library to recognize objects on Android using feature extraction.\\nI am using Android Studio and you can follow this link to download and install Android studio and SDK tools but if you are a die hard eclipse fan you also can follow this tutorial( no hard feelings ;) )\\n2. Setting up OpenCV library inside Android Studio\\nYou have to download and import OpenCV library to android studio and there is a stackoverflow answer which you can follow to setup everything. If you are using Eclipse use this link.\\nNow you are ready to mingle with me ;). The algorithm we are going to use is ORB(Oriented FAST and Rotated BRIEF). As an OpenCV enthusiast, the most important thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>4046</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@jonathan-hui/ssd-object-detection-single-shot-multibox-detector-for-real-time-processing-9bd8deac0e06?source=tag_archive---------7-----------------------</td>\n",
       "      <td>SSD object detection: Single Shot MultiBox Detector for real-time processing | by Jonathan Hui | Medium</td>\n",
       "      <td>Mar 14, 2018\\nSSD is designed for object detection in real-time. Faster R-CNN uses a region proposal network to create boundary boxes and utilizes those boxes to classify objects. While it is considered the start-of-the-art in accuracy, the whole process runs at 7 frames per second. Far below what real-time processing needs. SSD speeds up the process by eliminating the need for the region proposal network. To recover the drop in accuracy, SSD applies a few improvements including multi-scale features and default boxes. These improvements allow SSD to match the Faster R-CNN’s accuracy using lower resolution images, which further pushes the speed higher. According to the following comparison, it achieves the real-time processing speed and even beats the accuracy of the Faster R-CNN. (Accu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4047</td>\n",
       "      <td>Kai Stinchcombe</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Blockchain is not only crappy technology but a bad vision for the future | by Kai Stinchcombe | Medium</td>\n",
       "      <td>Apr 5, 2018\\nBlockchain is not only crappy technology but a bad vision for the future. Its failure to achieve adoption to date is because systems built on trust, norms, and institutions inherently function better than the type of no-need-for-trusted-parties systems blockchain envisions. That’s permanent: no matter how much blockchain improves it is still headed in the wrong direction.\\nThis December I wrote a widely-circulated article on the inapplicability of blockchain to any actual problem. People objected mostly not to the technology argument, but rather hoped that decentralization could produce integrity.\\nLet’s start with this: Venmo is a free service to transfer dollars, and bitcoin transfers are not free. Yet after I wrote an article last December saying bitcoin had no use, som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>4048</td>\n",
       "      <td>Luiz Fonseca</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>4049</td>\n",
       "      <td>Haaya Naushan</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/swlh/transformer-based-sentence-embeddings-cd0935b3b1e0?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Transformer-based Sentence Embeddings | by Haaya Naushan | The Startup | Medium</td>\n",
       "      <td>The Startup\\nDec 22, 2020\\nNatural language processing (NLP) is a diverse field; the approaches and techniques are as varied...\\n172 \\n172 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n637 Followers\\nResearch Consultant and Data Scientist. Enthusiastic about machine learning, social justice, video games and philosophy.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>4050</td>\n",
       "      <td>Jerome Bouchon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@botcho/stash-data-center-%E3%83%99%E3%83%BC%E3%82%BF%E7%89%88%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9-git-%E3%82%92%E5%A4%A7%E8%A6%8F%E6%A8%A1%E3%81%AB%E5%88%A9%E7%94%A8-2f0f46d5f2dd?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Stash Data Center ベータ版リリース。Git を大規模に利用 | by Jerome Bouchon | Medium</td>\n",
       "      <td>Sep 16, 2014\\nこれまで Stash は常に、最高のスピードと安全性を実現する Git リポジトリ管理ツール製品となってきました。そして今回、最高の拡張性も提供します。Stash Data Center のリリースの発表です (本日、ベータ版リリース)! このクラスタリング搭載の Stash Data Center デプロイメント オプションは、エンタープライズの大規模システムでのニーズを満たすことを目的としています。\\n今すぐベータ版トライアル\\nStash Data Center はアクティブ/アクティブ クラスタリングを提供し、ユーザーは途切れることなく確実に Git リポジトリにアクセスできます。 Data Center は負荷バランシング技術と冗長化技術を使い、ハードウェア障害による予期せぬシステムのダウンタイムのリスクを軽減します。データベースクラスタリングと共有ファイルシステムの業界標準技術を組み合わせ、Stash は単一障害点を排除します。Stash Data Center の初期設定プロセスの中で、クラスタリングは簡単に設定できますので、チームはすぐに立ち上げ稼働することができます。さらに、稼働規模を拡張するためのノードの追加や削除にダウンタイムは不要ですので、開発チームやビルドプロセスを妨害することはありません。\\n組織内で Git ベースのソリューションを利用するチームが増えるにつれ、開発者とビルドサーバーからのトラフィック量が急速に増加し、リソースを圧迫することがあります。Stash Data Center は、負荷継続時やピーク負荷時に、より高いアプリケーションスループットに対応でき、ユーザーやビルドの追加...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4051</td>\n",
       "      <td>Halil Ertan</td>\n",
       "      <td>19</td>\n",
       "      <td>https://towardsdatascience.com/cnn-lstm-based-models-for-multiple-parallel-input-and-multi-step-forecast-6fe2172f7668?source=tag_archive---------2-----------------------</td>\n",
       "      <td>CNN-LSTM-Based Models for Multiple Parallel Input and Multi-Step Forecast | by Halil Ertan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 17, 2021\\nTime series forecasting is a very popular field of machine learning. The reason behind this is the widespread usage of time series in daily life in almost every domain. Going into details for time series forecasting, we encounter lots of different kinds of sub-fields and approaches. In this writing, I will focus on a specific subdomain that is performing multi-step forecasts by receiving multiple parallel time series, and also mention basic key points that should be taken into consideration in time series forecasting. Note that forecasting models differ from predictive models at various points.\\nLet's think about lots of network devices spread over a large geography, and traffic flows through these devices continuously. Another example might be about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4052</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/sentiment-analysis-using-rnns-lstm-60871fa6aeba?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Sentiment analysis using RNNs(LSTM) | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 21, 2017\\nHere we use the example of reviews to predict sentiment (even though it can be applied more generically to other domains for example sentiment analysis for tweets, comments, customer feedback, etc). Whole idea here is that movie reviews are made of sequence of words and order of words encode lot of information that is useful to predict sentiment. Step 1 is to map words to word embeddings (see post 1 and 2 for more context on word embeddings). Step 2 is the RNN that receives a sequence of vectors as input and considers the order of the vectors to generate prediction.\\nThe architecture for this network is shown below.\\nHere, we’ll pass in words to an embedding layer. You can actually train up an embedding with word2vec and use it here. But it’s good en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4053</td>\n",
       "      <td>Chinmay</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@chinmaychetan04/activation-functions-78a99738a47c?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Activation Functions | by Chinmay | Medium</td>\n",
       "      <td>Aug 15, 2021\\nWhat are Activation Functions? Why are they used? why are there so many types? Does one works better than other?\\nFirstly, lets recap. A deep layer neural network as seen below receives the input and makes the decision based on its weights and biases which are learned during its backpropagation. As the Hidden layers increases , the decision making becomes more complex and sometimes leads to taking noise into consideration. When output is produced , mot all the neurons in the layers have equal say/contribution, and its because of the weights and bias updated during backpropagation. Done.\\nThen were is Activation function used? And Why?\\nSo basically, Activation functions decide whether the particular neuron or node to be fired /activated or not.\\nAs said, Activation functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4054</td>\n",
       "      <td>Sourav kumar</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Sentence correction using Deep learning techniques | by Sourav kumar | Medium</td>\n",
       "      <td>Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4055</td>\n",
       "      <td>ProjectAGI</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/project-agi/introduction-71d920ed051c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction | by ProjectAGI | Project AGI | Medium</td>\n",
       "      <td>Project AGI\\nApr 7, 2014\\nby David Rawlinson and Gideon Kowadlo\\nThis blog will be written by several people. Other contributors are welcome — send us an email to introduce yourself!\\nThe content will be a series of short articles about a set of common architectures for artificial general intelligence (AGI). Specifically, we will look at the commonalities in Deep Belief Networks and Numenta’s Memory Prediction Framework (MPF). MPF is these days better known by its concrete implementations CLA (Cortical Learning Algorithm) and HTM (Hierarchical Temporal Memory). For an introduction to Deep Belief Networks, read one of the papers by Hinton et al.\\nThis blog will typically use the term MPF to collectively describe all the current implementations — CLA, HTM, NUPIC etc. We see MPF as an int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4056</td>\n",
       "      <td>Stepan Ulyanin</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Implementing Grad-CAM in PyTorch. Recently I have come across a chapter... | by Stepan Ulyanin | Medium</td>\n",
       "      <td>Feb 22, 2019\\nRecently I have come across a chapter in François Chollet’s “Deep Learning With Python” book, describing the implementation of Class Activation Mapping for the VGG16 network. He implemented the algorithm using Keras as he is the creator of the library. Hence, my instinct was to re-implement the CAM algorithm using PyTorch.\\nGrad-CAM\\nThe algorithm itself comes from this paper. It was a great addition to the computer vision analysis tools for a single primary reason. It provides us with a way to look into what particular parts of the image influenced the whole model’s decision for a specifically assigned label. It is particularly useful in analyzing wrongly classified samples. The Grad-CAM algorithm is very intuitive and reasonably simple to implement.\\nThe intuition behi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>4057</td>\n",
       "      <td>Adam King</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Creating Bitcoin trading bots don’t lose money | by Adam King | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 27, 2019\\nIn this article we are going to create deep reinforcement learning agents that learn to make money trading Bitcoin. In this tutorial we will be using OpenAI’s gym and the PPO agent from the stable-baselines library, a fork of OpenAI’s baselines library.\\nThe purpose of this series of articles is to experiment with state-of-the-art deep reinforcement learning technologies to see if we can create profitable Bitcoin trading bots. It seems to be the status quo to quickly shut down any attempts to create reinforcement learning algorithms, as it is “the wrong way to go about building a trading algorithm”. However, recent advances in the field have shown that RL agents are often capable of learning much more than supervised learning agents within the same p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>4058</td>\n",
       "      <td>Sachin Abeywardana</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@sachin-abeywardana/hi-tal-7212811eeb03?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Hi Tal,. Maybe I’m missing something here, but... | by Sachin Abeywardana | Medium</td>\n",
       "      <td>Dec 22, 2016\\nTal Perry\\nHi Tal,\\nMaybe I’m missing something here, but 1. I don’t think your first layer is a embedding layer but a dense layer. You are converting 4000 NUMBERS into 300 by multiplying by a matrix. Embedding layer is when you have categorical variables mapped to vectors, which doesn’t seem to be what’s happening. Unless you are using the name of the stock.\\n2. You mentioned that your output is 5 minute data, but your input is daily data. This is a bit confusing since the time intervals of the input and output have to be the same? If you are getting 5 minute stock data, where do you download them from (I haven’t been able to find anything of the sort).\\nCheers\\n11 \\n11 \\nPhD in Machine Learning | Founder of DeepSchool.io\\nLove podcasts or audiobooks? Learn on the go wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>4059</td>\n",
       "      <td>Brian Ward</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/using-word-embeddings-to-identify-company-names-and-stock-tickers-f194e3648a66?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Using Word Embeddings to Identify Company Names and Stock Tickers | by Brian Ward | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 13, 2021\\nProject Goal: Using word embeddings identify company names and stock tickers from natural text.\\nAssumption: Stock tickers and company names are used in similar context in natural text such as a Reddit post or a tweet.\\nUnder this assumption, word embeddings should be a good fit for identifying these target words as word embeddings are trained by the context in which words are found.\\nIn this post, I will skip describing what word embeddings are and how the Word2Vec algorithm works. I have written a much more detailed paper on the same project which can be found here. In this paper, I explain the details of what word embeddings are as well as how the Word2Vec Algorithm works. I also detail sentiment analysis via Naive Bayes. In this post, I will just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4060</td>\n",
       "      <td>Kyle Dorman</td>\n",
       "      <td>19</td>\n",
       "      <td>https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Building a Bayesian deep learning classifier | by Kyle Dorman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 17, 2017\\nIn this blog post, I am going to teach you how to train a Bayesian deep learning classifier using Keras and tensorflow. Before diving into the specific training example, I will cover a few important high level concepts:\\nI will then cover two techniques for including uncertainty in a deep learning model and will go over a specific example using Keras to train fully connected layers over a frozen ResNet50 encoder on the cifar10 dataset. With this example, I will also discuss methods of exploring the uncertainty predictions of a Bayesian deep learning classifier and provide suggestions for improving the model in the future.\\nThis post is based on material from two blog posts (here and here) and a white paper on Bayesian deep learning from the Universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>4061</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>20</td>\n",
       "      <td>https://medium.com/free-code-camp/every-single-machine-learning-course-on-the-internet-ranked-by-your-reviews-3c4a7b8026c0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Every single Machine Learning course on the internet, ranked by your reviews | by David Venturi | We’ve moved to freeCodeCamp.org/news | Medium</td>\n",
       "      <td>We’ve moved to freeCodeCamp.org/news\\nMay 3, 2017\\nA year and a half ago, I dropped out of one of the best computer science programs in Canada. I started creating my own data science master’s program using online resources. I realized that I could learn everything I needed through edX, Coursera, and Udacity instead. And I could learn it faster, more efficiently, and for a fraction of the cost.\\nI’m almost finished now. I’ve taken many data science-related courses and audited portions of many more. I know the options out there, and what skills are needed for learners preparing for a data analyst or data scientist role. So I started creating a review-driven guide that recommends the best courses for each subject within data science.\\nFor the first guide in the series, I recommended a few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>4062</td>\n",
       "      <td>Nick Kasten</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/codait/art-ai-the-logic-behind-deep-learning-style-transfer-1f59f51441d1?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Art &amp; AI: The Logic Behind Deep Learning ‘Style Transfer’ | by Nick Kasten | Center for Open Source Data and AI Technologies | Medium</td>\n",
       "      <td>Center for Open Source Data and AI Technologies\\nFeb 21, 2019\\nWhen humans and machines collaborate, we can produce things neither would create on their own. The intersection of art and AI is an area that I find really exciting, but with all the business impact AI can have, I personally feel it doesn’t always get enough attention. In this spirit, I recently set out on a personal quest to learn more about PyTorch, the machine learning library that’s been creating a lot of buzz since its 1.0 release late last year, and I was pleasantly surprised by what I found.\\nFor me, PyTorch turned out to be more than just an interesting alternative to TensorFlow, with dynamic graphs and an imperative coding style. One of the examples from their official docs inspired me to track down some academic p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4063</td>\n",
       "      <td>Jiahao Weng</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/how-to-perform-abstractive-summarization-with-pegasus-3dd74e48bafb?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How to Perform Abstractive Summarization with PEGASUS | by Jiahao Weng | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 4, 2021\\nNote: For those of you who prefer watching videos, please feel free to play above video on the same content.\\nGiven long documents to read, our natural preference is to not read, or at least, to scan just the main points. So having a summary would always be great to save us time ⏳ and brain processing power.\\nHowever, auto-summarization used to be an impossible task. Specifically, abstractive summarization is very challenging. Differing from extractive summarization (which extracts important sentences from a document and combines them to form a “summary”), abstractive summarization involves paraphrasing words and hence, is more difficult but can potentially give a more coherent and polished summary.\\nIt was not until the development of techniques like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>4064</td>\n",
       "      <td>Wenchen's ai fantasy</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@wenchen-li/text-summarization-applications-ed319f0bb13c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>text summarization: applications. this article is mainly a summarization... | by Wenchen's ai fantasy | Medium</td>\n",
       "      <td>May 25, 2017\\nthis article is mainly a summarization of Yasemin Altun’s presentation in May 2014 on how google applies text summarization.\\ntext summarization is highly related to google knowledge graph project:\\nentities description within red circle use text summarization from wiki to give a one sentence description of the entity.\\n7 \\n7 \\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n83 Followers\\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4065</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313?source=tag_archive---------5-----------------------</td>\n",
       "      <td>🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning | by Thomas Wolf | HuggingFace | Medium</td>\n",
       "      <td>HuggingFace\\nMay 9, 2019\\nA few years ago, creating a chatbot -as limited as they were back then- could take months 🗓, from designing the rules to actually writing thousands of answers to cover some of the conversation topics.\\nWith the recent progress in deep-learning for NLP, we can now get rid of this petty work and build much more powerful conversational AI 🌟 in just a matter of hours 🍃 as you will see in this tutorial.\\nWe’ve set up a demo running the pretrained model we’ll build together in this tutorial at convai.huggingface.co. Be sure to check it out! 🎮\\nHere is what we will learn and play with today:\\nTogether with this post, we released a clean and commented code base with a pretrained model! Check the Github repo here ✈️\\nThe story of this post began a few months ago in Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4066</td>\n",
       "      <td>Neelabh Pant</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/cube-dev/time-series-prediction-using-recurrent-neural-networks-lstms-807fa6ca7f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs) | by Neelabh Pant | Cube Dev | Medium</td>\n",
       "      <td>Cube Dev\\nSep 7, 2017\\nThe Statsbot team has already published the article about using time series analysis for anomaly detection. Today, we’d like to discuss time series prediction with a long short-term memory model (LSTMs). We asked a data scientist, Neelabh Pant, to tell you about his experience of forecasting exchange rates using recurrent neural networks.\\nAs an Indian guy living in the US, I have a constant flow of money from home to me and vice versa. If the USD is stronger in the market, then the Indian rupee (INR) goes down, hence, a person from India buys a dollar for more rupees. If the dollar is weaker, you spend less rupees to buy the same dollar.\\nIf one can predict how much a dollar will cost tomorrow, then this can guide one’s decision making and can be very important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4067</td>\n",
       "      <td>TokenGo Platform_RU</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------0-----------------------</td>\n",
       "      <td>ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium</td>\n",
       "      <td>May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4068</td>\n",
       "      <td>Chandra Churh Chatterjee</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>4069</td>\n",
       "      <td>Arun Kumar</td>\n",
       "      <td>16</td>\n",
       "      <td>https://towardsdatascience.com/semantic-image-segmentation-using-fully-convolutional-networks-bf0189fa3eb8?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Semantic Image Segmentation using Fully Convolutional Networks | by Arun Kumar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 10, 2020\\nHumans have the innate ability to identify the objects that they see in the world around them. The visual cortex present in our brain can distinguish between a cat and a dog effortlessly in almost no time. This is true not only with cats and dogs but with almost all the objects that we see. But a computer is not as smart as a human brain to be able to this on its own. Over the past few decades, Deep Learning researchers have tried to bridge this gap between human brain and computer through a special type of artificial neural networks called Convolutional Neural Networks(CNNs).\\nAfter a lot of research to study mammalian brains, researchers found that specific parts of the brain get activated to specific type of stimulus. For example, some parts in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4070</td>\n",
       "      <td>Ceshine Lee</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/the-artificial-impostor/build-a-summarization-system-in-minutes-5f10c141bfe6?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Building a Summarization System in Minutes | by Ceshine Lee | Veritable | Medium</td>\n",
       "      <td>Veritable\\nNov 1, 2018\\n(This is sort of a sequel or an update to “Building a Translation System in Minutes” published a year ago. This time we use a publicly available dataset, a different NLP task, and some task-specific evaluation metrics)\\nSummarization is the task of producing a shorter version of one or several documents that preserves most of the input’s meaning. [1]\\nThe text summarization task is mostly solved using variants of the seq2seq structure [2] these days. The seq2seq structure is much more complicated than the usual RNN models, and that makes implementing the model from scratch a rather daunting task. Luckily, OpenNMT project [3] provides ready-to-use implementations of seq2seq models that are close to state-of-the-art. We can use it as a starting point.\\nIn this pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>4071</td>\n",
       "      <td>Jack Morris</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/what-are-adversarial-examples-in-nlp-f928c574478e?source=tag_archive---------6-----------------------</td>\n",
       "      <td>What are adversarial examples in NLP? | by Jack Morris | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 28, 2020\\nThis article talks about the concept of adversarial examples as applied to NLP (natural language processing). The terminology can be confusing at times, so we’ll begin with an overview of the language used to talk about adversarial examples and adversarial attacks. Then, we’ll talk about TextAttack, our open-source Python library for adversarial examples, data augmentation, and adversarial training in NLP that’s changing the way people research the robustness of NLP models. We’ll conclude with some thoughts on the future of this area of research.\\nAn adversarial example is an input designed to fool a machine learning model [1]. An adversarial example crafted as a change to a benign input is known as an adversarial perturbation. ‘Adversarial perturbat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4072</td>\n",
       "      <td>William Ryan</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@williamr/reducing-memory-usage-in-r-especially-for-regressions-8ed8070ae4d8?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Reducing Memory Usage in R (especially for regressions) | by William Ryan | Medium</td>\n",
       "      <td>Jun 28, 2016\\nR uses a ton of memory. Here are ways to make it use a little less. Definitely not an expert, this is largely a resource/reference for myself, but thought it might be useful for others as well.\\nThe best introduction to how R uses memory is likely this guide, by Hadley Wickham.\\nGarbage collector: gc()\\nMy impression is that this function used to be more useful. R uses it to release memory it isn’t using, but will usually run it automatically. So you shouldn’t have to call it explicitly. However, if you want to see when this is happening, use gcinfo(TRUE) — you probably won’t want to leave this on all the time, it will get annoying. But, it can be very useful for finding the peak memory used by a function.\\nObject size: object.size()\\nTo find the size of a given R object,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>4073</td>\n",
       "      <td>Satyam Kumar</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/6-applications-of-auto-encoders-every-data-scientist-should-know-dc703cbc892b?source=tag_archive---------5-----------------------</td>\n",
       "      <td>7 Applications of Auto-Encoders every Data Scientist should know | by Satyam Kumar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 20, 2021\\nAuto-Encoders are a popular type of unsupervised artificial neural network that takes un-labeled data and learns efficient codings about the structure of the data that can be used for another context. Auto-Encoders approximates the function that maps the data from full input space to lower dimension coordinates and further approximates to the same dimension of input space with minimum loss.\\nFor classification or regression tasks, auto-encoders can be used to extract features from the raw data to improve the robustness of the model. There are various other applications of an Auto-Encoder network, that can be used for some other context. We will 7 of such applications of auto-encoder in this article:\\nBefore diving into the applications of AutoEncoder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>4074</td>\n",
       "      <td>Park Chansung</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>4075</td>\n",
       "      <td>Shiva Verma</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Understanding 1D and 3D Convolution Neural Network | Keras | by Shiva Verma | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 20, 2019\\nWhen we say Convolution Neural Network (CNN), generally we refer to a 2 dimensional CNN which is used for image classification. But there are two other types of Convolution Neural Networks used in the real world, which are 1 dimensional and 3-dimensional CNNs. In this guide, we are going to cover 1D and 3D CNNs and their applications in the real world. I am assuming you are already familiar with the concept of Convolutions Networks in general.\\nThis is the standard Convolution Neural Network which was first introduced in Lenet-5 architecture. Conv2D is generally used on Image data. It is called 2 dimensional CNN because the kernel slides along 2 dimensions on the data as shown in the following image.\\nThe whole advantage of using CNN is that it can e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4076</td>\n",
       "      <td>Anuj shah (Exploring Neurons)</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/when-neural-networks-saw-the-first-image-of-black-hole-3205e28b6578?source=tag_archive---------7-----------------------</td>\n",
       "      <td>When Neural Networks saw the first image of Black Hole. | by Anuj shah (Exploring Neurons) | Medium</td>\n",
       "      <td>Apr 19, 2019\\nOn April 10th, scientists and engineers from Event Horizon Telescope team achieved a remarkable breakthrough in quest to understand the cosmos by unveiling the first image of black hole. This furthers strengthens Einstein theory of general relativity — “ massive objects cause a distortion in space-time, which is felt as gravity”.\\nWell I am not a physicist or astronomer to comprehend and explain in detail about this but like me there are millions and millions of people who despite being in different fields are fascinated by cosmos and specially black hole. The first image of black hole has send wave of excitement all over the world. I am a Deep learning engineer who mainly works with convolution neural network and I wanted to see what AI algorithms thinks about the black ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4077</td>\n",
       "      <td>Ethan Siegel</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/starts-with-a-bang/weekend-diversion-the-ultimate-superhero-cake-129a990c35c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Weekend Diversion: The Ultimate Superhero Cake | by Ethan Siegel | Starts With A Bang! | Medium</td>\n",
       "      <td>Starts With A Bang!\\nAug 30, 2015\\nThanks to 3D printing, creativity and a lot of effort, this DIY Optimus Prime cake is unlike any other.\\n“When he came home, I could see a change. He was quieter and he was a man and a hero to me. I watched him and listened to him. I’d never had an opportunity to do a superhero, and when that came, [that voice] just came right out of me and I sounded like Optimus.” -Peter Cullen, on his brother\\nBeing a hero is something we all dream about in our own way. On our birthdays, everyone deserves to live out that fantasy, if only for a day. Have a listen to Tracy Chapman’s reflective and provocative song, Change,\\nwhile you consider the ultimate in “changing” superheros: Optimus Prime.\\nUnlike the flashy Decepticons, who transformed from robots into fighter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>4078</td>\n",
       "      <td>Prakash Pandey</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/deep-generative-models-25ab2821afd3?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Deep Generative Models | by Prakash Pandey | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 31, 2018\\nA Generative Model is a powerful way of learning any kind of data distribution using unsupervised learning and it has achieved tremendous success in just few years. All types of generative models aim at learning the true data distribution of the training set so as to generate new data points with some variations. But it is not always possible to learn the exact distribution of our data either implicitly or explicitly and so we try to model a distribution which is as similar as possible to the true data distribution. For this, we can leverage the power of neural networks to learn a function which can approximate the model distribution to the true distribution.\\nTwo of the most commonly used and efficient approaches are Variational Autoencoders (VAE) a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4079</td>\n",
       "      <td>Hubert Baniecki</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/responsibleml/adversarial-attacks-on-explainable-ai-f65d41e83c5f?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Adversarial attacks on Explainable AI | by Hubert Baniecki | ResponsibleML</td>\n",
       "      <td>ResponsibleML\\nJan 23, 2021\\nAre explainability methods black-box themselves?\\nThere are various adversarial attacks on machine learning models; hence, ways of defending, e.g. by using Explainable AI methods. Nowadays, attacks on model explanations come to light, so does the defense to such adversary. Here, we introduce fundamental concepts related to the domain. A further reference list is available at https://github.com/hbaniecki/adversarial-explainable-ai.\\nWhen considering an explanation as a function of model and data, there is a possibility to change one of these variables to achieve a different result.\\nThe first concept is to manipulate model explanations via data change. Dombrowski et al. [2019] showcase that perturbed images produce arbitrarily made visual explanations (e.g. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>4080</td>\n",
       "      <td>Charles Kapelke</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/cltc-bulletin/adversarial-machine-learning-43b6de6aafdb?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Adversarial Machine Learning. A Brief Introduction for Non-Technical... | by Charles Kapelke | CLTC Bulletin | Medium</td>\n",
       "      <td>CLTC Bulletin\\nDec 3, 2019\\nA Brief Introduction for Non-Technical Audiences\\nRecent years have seen a rapid increase in the use of machine learning, through which computers can be programmed to identify patterns in information and make increasingly accurate predictions over time. Machine learning is a key enabling technology behind artificial intelligence (AI), and is used for such valuable applications as email spam filters and malware detection, as well as more complex technologies like speech recognition, facial recognition, robotics, and self-driving cars.\\nWhile machine learning models have many potential benefits, they may be vulnerable to manipulation. Cybersecurity researchers refer to this risk as “adversarial machine learning,” as AI systems can be deceived (by attackers or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4081</td>\n",
       "      <td>Alfi Salim</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/bisa-ai/intersection-over-union-a8d1532899b3?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Intersection Over Union. Pada masalah deteksi objek, output yang... | by Alfi Salim | BISA.AI | Medium</td>\n",
       "      <td>BISA.AI\\nMar 25, 2020\\nPada masalah deteksi objek, output yang dihasilkan berupa bounding box (kotak pembatas) hasil prediksi sistem terhadap objek yang telah ditentukan. Bounding box ini merepresentasikan posisi objek dalam sebuah gambar. Untuk mengevaluasi model deteksi objek yang telah kita latih terdapat beberapa cara, salah satu caranya adalah dengan menggunakan metode Intersection Over Union (IOU). IOU memanfaatkan bounding box yang terdapat pada gambar.\\nIntersection Over Union (IOU) adalah nilai berdasarkan statistik kesamaan dan keragaman set sampel yang tujuannya untuk mengevaluasi area tumpang tindih (area yang beririsan) antara dua bounding box, yaitu bounding box hasil prediksi dan bounding box ground truth (kebenaran). Jadi, syarat untuk menerapkan IOU adalah mempunyai ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>4082</td>\n",
       "      <td>Marie Imokoyende</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/variational-autoencoder-in-finance-53ee5eb9ed98?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Variational Autoencoder In Finance | by Marie Imokoyende | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 15, 2019\\nThis article explores the use of a variational autoencoder to reduce the dimensions of financial time series with Keras and Python. We will further detect similarities between financial instruments in different markets and will use the results obtained to construct a custom index.\\nDisclaimer: The research presented in this article comes from our Winter 2019 Term Project for the Deep Learning course at the University of Toronto School of Continuing Studies. It was done in collaboration with Humberto Ribeiro de Souza. The concepts and ideas are our own. We are in no way representing our current or previous employers.\\nIn this section, we will discuss:\\nCreating The Geometric Moving Average Dataset\\nIn order to compare time series of various price rang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>4083</td>\n",
       "      <td>Stefan Kojouharov</td>\n",
       "      <td>8</td>\n",
       "      <td>https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning &amp; Big Data | by Stefan Kojouharov | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nJul 9, 2017\\nOver the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.\\nThis is the most complete list and the Big-O is at the very end, enjoy...\\n&gt;&gt;&gt; Update: We have recently redesigned these cheat sheets into a Super High Definition PDF. Check them out below:\\nbecominghuman.ai\\nchatbotslife.com\\naijobsboard.com\\nThis machine learning cheat sheet will help you find the right estimator for the job which is the most difficult part. The flowchart will help you che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>4084</td>\n",
       "      <td>Sambasivarao. K</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Region of Interest Pooling. A Technique which allowed a new... | by Sambasivarao. K | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 22, 2019\\nThe major hurdle for going from image classification to object detection is fixed size input requirement to the network because of existing fully connected layers. In object detection, each proposal will be of a different shape. So there is a need for converting all the proposals to fixed shape as required by fully connected layers. ROI Pooling is exactly doing this.\\nRegion of Interest (ROI) pooling is used for utilising single feature map for all the proposals generated by RPN in a single pass. ROI pooling solves the problem of fixed image size requirement for object detection network.\\nROI pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>4085</td>\n",
       "      <td>Jimmi Dyson</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.fabric8.io/clustering-on-kubernetes-openshift3-using-dns-d786bfd681d9?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Clustering on Kubernetes &amp; OpenShift3 using DNS | by Jimmi Dyson | fabric8 io</td>\n",
       "      <td>fabric8 io\\nApr 17, 2015\\nOne of the big promises of Kubernetes &amp; OpenShift is really easy management of your containerised applications. For standalone or load-balanced stateless applications, Kubernetes works brilliantly, but one thing that I had a bit of trouble figuring out was how do perform cluster discovery for my applications? Say one of my applications needs to know about at least one other node (seed node) that it should join a cluster with.\\nThere is an example in the Kubernetes repo for Cassandra that requests existing service endpoints from the Kubernetes API server &amp; use those as the seed servers. You can see the code for it here. That works great for a cluster that allows unauthenticated/unauthorized access to the API server, but hopefully most people are going to lock d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>4086</td>\n",
       "      <td>DataAnalysis For Beginner</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@univprofblog1/support-vector-machine-matlab-r-and-python-codes-856a342fc35d?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Support Vector Machine: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium</td>\n",
       "      <td>Aug 17, 2016\\nI release MATLAB, R and Python codes of Support Vector Machine (SVM). They are very easy to use. You prepare data set, and just run the code! Then, SVM and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/XdZSo Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/OyXVZ Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/AtOvT Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>4087</td>\n",
       "      <td>Viet Hoang Tran Duong</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Intro to reinforcement learning: temporal difference learning, SARSA vs. Q-learning | by Viet Hoang Tran Duong | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 23, 2021\\nReinforcement learning (RL) is surely a rising field, with the huge influence from the performance of AlphaZero (the best chess engine as of now). RL is a subfield of machine learning that teaches agents to perform in an environment to maximize rewards overtime.\\nAmong RL’s model-free methods is temporal difference (TD) learning, with SARSA and Q-learning (QL) being two of the most used algorithms. I chose to explore SARSA and QL to highlight a subtle difference between on-policy learning and off-learning, which we will discuss later in the post.\\nThis post assumes you have basic knowledge of the agent, environment, action, and rewards within RL's scope. A brief introduction can be found here.\\nThe outline of this post include:\\nWe will compare these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>4088</td>\n",
       "      <td>Chris Fotache</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/object-detection-and-tracking-in-pytorch-b3cf1a696a98?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Object detection and tracking in PyTorch | by Chris Fotache | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 10, 2018\\nIn my previous story, I went over how to train an image classifier in PyTorch, with your own images, and then use it for image recognition. Now I’ll show you how to use a pre-trained classifier to detect multiple objects in an image, and later track them across a video.\\nWhat’s the difference between image classification (recognition) and object detection? In classification, you identify what’s the main object in the image and the entire image is classified by a single class. In detection, multiple objects are identified in the image, classified, and a location is also determined (as a bounding box).\\nThere are several algorithms for object detection, with YOLO and SSD among the most popular. For this story, I’ll use YOLOv3. I won’t get into the tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4089</td>\n",
       "      <td>Thomas Smith</td>\n",
       "      <td>9</td>\n",
       "      <td>https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------0-----------------------</td>\n",
       "      <td>I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero</td>\n",
       "      <td>OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder &amp; CEO of Gado Images. I write, speak &amp; consult about tech, food, privacy, AI &amp; photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>4090</td>\n",
       "      <td>Robin Vinod</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/a-detailed-explanation-of-the-attention-u-net-b371a5590831?source=tag_archive---------4-----------------------</td>\n",
       "      <td>A detailed explanation of the Attention U-Net | by Robin Vinod | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 1, 2020\\nIn this story, I explain the Attention U-Net from Attention U-Net:Learning Where to Look for the Pancreas written by Oktay et. al. The paper was written in 2018 and proposed a novel attention gate (AG) mechanism that allows the U-Net to focus on target structures of varying size and shape.\\nAttention, in the context of image segmentation, is a way to highlight only the relevant activations during training. This reduces the computational resources wasted on irrelevant activations, providing the network with better generalisation power. Essentially, the network can pay “attention” to certain parts of the image.\\na. Hard Attention\\nAttention comes in two forms, hard and soft. Hard attention works on the basis of highlighting relevant regions by cropping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4091</td>\n",
       "      <td>Ravish Chawla</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/ml2vec/overview-of-conditional-random-fields-68a2a20fa541?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Overview of Conditional Random Fields | by Ravish Chawla | ML 2 Vec | Medium</td>\n",
       "      <td>ML 2 Vec\\nAug 7, 2017\\nConditional Random Fields are a discriminative model, used for predicting sequences. They use contextual information from previous labels, thus increasing the amount of information the model has to make a good prediction. In this post, I will go over some topics that will introduce CRFs. I will go over:\\nMachine Learning models have two common categorizations, Generative and Discriminative. Conditional Random Fields are a type of Discriminative classifier, and as such, they model the decision boundary between the different classes. Generative models, on the other hand, model how the data was generated, which after having learnt, can be used to make classifications. As a simple example, Naive Bayes, a very simple and popular probabilistic classifier, is a Generati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4092</td>\n",
       "      <td>Frank Bonsal III</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/bonsal-capital/the-charm-of-a-gritty-city-82bc645a4313?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The Charm of a Gritty City. Baltimore as Entrepreneurship Hub | by Frank Bonsal III | Bonsal Capital | Medium</td>\n",
       "      <td>Bonsal Capital\\nJan 25, 2014\\nSome people ask me Why Baltimore? Couldn’t you do what you do from anywhere in the U.S.? Isn’t this the place where the acclaimed HBO series The Wire was filmed? Has Baltimore ever been on a tech entrepreneur-friendly list? Aren’t there more voluminous entrepreneurial hubs? While the concise response is pegged to an authentic and ever-congealing entrepreneurial ecosystem more focused on the act of doing (the scoreboard) than a Top Ten List, the more interesting answer is found in an array of professional and personal attributes. Let me paint a picture as to why Baltimore is a great city to build a business, a career, a life.\\nBaltimore has a nearly three hundred year history of resilience and determination. What many do not grasp is that Baltimore is a top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4093</td>\n",
       "      <td>Ekin Tiu</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Understanding Latent Space in Machine Learning | by Ekin Tiu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 4, 2020\\nIf I have to describe latent space in one sentence, it simply means a representation of compressed data.\\nImagine a large dataset of handwritten digits (0–9) like the one shown above. Handwritten images of the same number (i.e. images that are 3’s) are the most similar to each other compared to other images of different numbers (i.e. 3s vs. 7s). But can we train an algorithm to recognize these similarities? How?\\nIf you have trained a model to classify digits, then you have also trained the model to learn the ‘structural similarities’ between images. In fact, this is how the model is able to classify digits in the first place- by learning the features of each digit.\\nIf it seems that this process is ‘hidden’ from you, it’s because it is. Latent, by de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4094</td>\n",
       "      <td>Ryan Burke</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/bitcoin-bonanza-2cb208026bbd?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Bitcoin Bonanza!. Comparing the efficacy of GRU, LSTM... | by Ryan Burke | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 25, 2021\\nI have been following crypto prices for several years now. I am fascinated with the evolution of the blockchain and its implications. I’ve chuckled more than once at the idea of digital currency. Not that it’s new, but I was born in the 80’s when we had to fill out a paper and speak with a human if we wanted to withdraw actual paper money...Remember paper money?\\nIn any case, today I want to share one of my recent projects with you. I will be comparing three models to determine their efficacy at predicting the price of Bitcoin, the King of Crypto. For this project, I used gated recurrent units (GRU), long short term memory units (LSTM), and bidirectional LSTM units (BiLSTM). First, let’s take a quick dive into the workings of these mysterious predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4095</td>\n",
       "      <td>Matt Schlicht</td>\n",
       "      <td>11</td>\n",
       "      <td>https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca?source=tag_archive---------7-----------------------</td>\n",
       "      <td>The Complete Beginner’s Guide To Chatbots | by Matt Schlicht | Chatbots Magazine</td>\n",
       "      <td>Chatbots Magazine\\nApr 20, 2016\\nWhat are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?\\nThese are the questions we’re going to answer for you right now.\\nReady? Let’s do this.\\n(Do you work in ecommerce? Stop reading and click here, we made something for you.)\\n(p.s. here is where I believe the future of bots is headed, you will probably disagree with me at first.)\\n(p.p.s. My newest guide about conversational commerce is up, I think you’ll find it super interesting.)\\n“~90% of our time on mobile is spent on email and messaging platforms. I would love to back teams that build stuff for places where the consumers hang out!” — Niko Bonatsos, Managing Director at General Catalyst\\nA chatbot is a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4096</td>\n",
       "      <td>Manish Nayak</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011?source=tag_archive---------9-----------------------</td>\n",
       "      <td>An Introduction To Conditional GANs (CGANs) | by Manish Nayak | DataDrivenInvestor</td>\n",
       "      <td>DataDrivenInvestor\\nMay 9, 2019\\nConditional GANs (CGANs) are an extension of the GANs model. You can read about a variant of GANs called DCGANs in my previous post here. CGANs are allowed to generate images that have certain conditions or attributes.\\nLike DCGANs, Conditional GANs also has two components.\\nwww.datadriveninvestor.com\\nConditional GANs (CGANs): The Generator and Discriminator both receive some additional conditioning input information. This could be the class of the current image or some other property.\\nFor example, if we train a DCGANs to generate new MNIST images, There is no control over which specific digits will be produced by the Generator. There is no mechanism for how to request a particular digit from the Generator. This problem can be addressed by a variation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>4097</td>\n",
       "      <td>Prem Prakash</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Perturbation Theory in Deep Neural Network (DNN) Training | by Prem Prakash | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 23, 2020\\nVanishing Gradient, Saddle Point, Adversarial Training\\nPrerequisite- this post assumes the reader has an introductory-level understanding of neural network architectures, and have trained some form of deep networks, during which might have faced some issues related to training or robustness of a model.\\nA small perturbation or nudge in various parameters/components associated with training such as gradients, weights, inputs etc. can affect DNN training in overcoming some of the issues one might bump into, for example, vanishing gradient problem, saddle point trap, or creating a robust model to avoid malicious attacks through adversarial training etc.\\nTypically, perturbation theory is the study of a small change in a system which can be as a result ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>4098</td>\n",
       "      <td>Mohantysandip</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289?source=tag_archive---------8-----------------------</td>\n",
       "      <td>A Step by Step approach to Solve DBSCAN Algorithms by tuning its hyper parameters | by Mohantysandip | Medium</td>\n",
       "      <td>Mar 12, 2020\\nDBSCAN is a clustering method that is used in machine learning to separate clusters of high density from clusters of low density region. Its a very efficient clustering algorithm as it used to segregate the data points with high density observations vs data points of low density observations in form of various clusters.It can sort the data into various shapes of clusters as well. Major challenge of using DBSCAN algorithm is to find right set hyper parameters(eps and min_samples values) to fit in to the algorithm for getting accurate result.\\nLet’s look at a Spatial data of two dimensional coordinates (x,y) using we need to find out various possible star coagulation or dense clusters from this data.\\nRead the input data using Pandas dataframe.\\nAn initial plotting of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>4099</td>\n",
       "      <td>Mohammed AL-Ma'amari</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Deep Neural Networks for Regression Problems | by Mohammed AL-Ma'amari | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 29, 2018\\nNeural networks are well known for classification problems, for example, they are used in handwritten digits classification, but the question is will it be fruitful if we used them for regression problems?\\nIn this article I will use a deep neural network to predict house pricing using a dataset from Kaggle .\\nYou can download the dataset from Here\\nI highly recommend you to try running the code using my notebook on Google colab [Here]\\n1- Process the dataset2- Make the deep neural network3- Train the DNN4- Test the DNN5- Compare the result from the DNN to another ML algorithm\\nFirst of all, we will import the needed dependencies :\\nWe will not go deep in processing the dataset, all we want to do is getting the dataset ready to be fed into our models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4100</td>\n",
       "      <td>Vishal Maini</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Machine Learning for Humans, Part 2.1: Supervised Learning | by Vishal Maini | Machine Learning for Humans | Medium</td>\n",
       "      <td>Machine Learning for Humans\\nAug 19, 2017\\nHow much money will we make by spending more dollars on digital advertising? Will this loan applicant pay back the loan or not? What’s going to happen to the stock market tomorrow?\\nIn supervised learning problems, we start with a data set containing training examples with associated correct labels. For example, when learning to classify handwritten digits, a supervised learning algorithm takes thousands of pictures of handwritten digits along with labels containing the correct number each image represents. The algorithm will then learn the relationship between the images and their associated numbers, and apply that learned relationship to classify completely new images (without labels) that the machine hasn’t seen before. This is how you’re a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4101</td>\n",
       "      <td>Nikhil Parmar</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@nikhilparmar9/simple-sgd-implementation-in-python-for-linear-regression-on-boston-housing-data-f63fcaaecfb1?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Simple SGD implementation in Python for Linear Regression on Boston Housing Data | by Nikhil Parmar | Medium</td>\n",
       "      <td>Dec 11, 2019\\nHello Folks, in this article we will build our own Stochastic Gradient Descent (SGD) from scratch in Python and then we will use it for Linear Regression on Boston Housing Dataset. Just after a short recap of SGD, we will start building our own custom SGD.\\nTo keep the concept simple and easy to understand, we will touch the math calculations in an extremely simple step by step manner with its Python Code.\\nThen in the end we will combine all the code to solve the Linear Regression on Boston Housing Dataset.\\nWikipedia says: “ Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties. ”\\nLet’s begin, the Linear Regression optimization problem is to optimize or MINimize the SQUARED ERROR as shown below.\\nBut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>4102</td>\n",
       "      <td>Akanksha Rawat</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/implementing-binary-logistic-regression-in-r-7d802a9d98fe?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Binary Logistic Regression. An overview and implementation in R | by Akanksha Rawat | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 31, 2017\\nHave you ever come across a situation where you want to predict a binary outcome like:\\nA very simple Machine Learning algorithm which will come to your rescue is Logistic Regression.\\nLogistic Regression is a classification algorithm which is used when we want to predict a categorical variable (Yes/No, Pass/Fail) based on a set of independent variable(s).\\nIn the Logistic Regression model, the log of odds of the dependent variable is modeled as a linear combination of the independent variables.\\nLet’s get more clarity on Binary Logistic Regression using a practical example in R.\\nConsider a situation where you are interested in classifying an individual as diabetic or non-diabetic based on features like glucose concentration, blood pressure, age etc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4103</td>\n",
       "      <td>Hemant Ranvir</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/@hemantranvir/spam-detection-using-rnn-simplernn-lstm-with-step-by-step-explanation-530367608071?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Intuitive guide to word embedding, RNN (SimpleRNN, LSTM) with step by step implementation in keras for spam detection | by Hemant Ranvir | Medium</td>\n",
       "      <td>Jun 20, 2019\\nThis tutorial will guide you through the implementation and intuitive grasp on what is actually happening underneath the RNN networks.\\nThere has been extensive writing on this subject but I could not find a single source where the complete walk through of word...\\n68 \\n68 \\n2\\nSoftware Design and Product Management\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n14 Followers\\nSoftware Design and Product Management\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>4104</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/@jonathan-hui/yolov4-c9901eaa8e61?source=tag_archive---------3-----------------------</td>\n",
       "      <td>YOLOv4. While object detection matures in the... | by Jonathan Hui | Medium</td>\n",
       "      <td>May 4, 2020\\nEven object detection starts maturing in the last few years, the competition remains fierce. As shown below, YOLOv4 claims to have state-of-the-art accuracy while maintains a high processing frame rate. It achieves an accuracy of 43.5% AP (65.7% AP50) for the MS COCO with an approximately 65 FPS inference speed on Tesla V100. In object detection, high accuracy is not the only holy grail anymore. We want the model to run smoothly in the edge devices. How to process input video in real-time with low-cost hardware becomes important also.\\nThe fun part of reading the YOLOv4 development is what new technologies have been evaluated, modified, and integrated into YOLOv4. And it also makes changes to make the detector more suitable for training on a single GPU.\\nImprovements can b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>4105</td>\n",
       "      <td>Geneonline-基因線上</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@geneonline/%E7%99%8C%E7%B4%B0%E8%83%9E%E7%94%9F%E9%95%B7%E7%9A%84%E9%96%8B%E9%97%9C-%E5%9F%BA%E5%9B%A0%E5%95%9F%E5%8B%95%E5%AD%90-promoter-ed16fab2e013?source=tag_archive---------0-----------------------</td>\n",
       "      <td>癌細胞生長的開關:基因啟動子(Promoter)?. 啟動子 (Promoter)... | by Geneonline-基因線上 | Medium</td>\n",
       "      <td>May 19, 2016\\n啟動子 (Promoter) 在人體遺傳基因扮演著重要角色,宛如人體一個開關,可以決定基因的活動,並控制細胞開始生產人體所需的蛋白質。當啟動子發生突變時,將可能導致基因表現的調節障礙。近期國際學者在癌細胞基因組的研究中發現,基因啟動子中的 DNA 突變數量增加,是因結合 DNA 控制基因表現的某些蛋白質,阻止人體的一個細胞修復系統去修復損傷的 DNA。啟動子突變的多寡與 DNA 修復系統相互作用,引發癌細胞生長有了重要的發現。\\n皮膚癌啟動子的突變密度特別高\\n2016 年 4 月發表在《Nature》的研究指出,科學家們分析來自 14 種癌症類型、1,161 個腫瘤的 2000 多萬 DNA 突變。他們發現在許多癌症類型,尤其是皮膚癌中,基因啟動子的基因組區域內突變數量特別高。研究進一步探究發現,人體控制基因表達的一些蛋白質,降低人體細胞修復系統的功能發揮,導致無法正常修復受損的 DNA,這個系統被稱為核苷酸切除修復 (NER, Nucleotide Excision-Repair)。NER 是唯一能修復紫外線造成的 DNA 損傷的系統,不僅如此,它還能處理抽煙誘導的遺傳損傷。\\n(上圖為DNA修復示意圖)\\n延伸閱讀:腫瘤的轉移與「偽轉移」 基因定序分析癌細胞親緣\\nDNA 修復如何參與癌細胞生長\\n西班牙研究團隊人員利用來自人類黑色素瘤樣本的全基因組序列分析調控區域的突變,並進一步分析核苷酸切除修復 (NER) 活性位點。結果發現,NER 功能的下降可導致一些轉錄因子位點的突變率增高。除此,在肺癌樣本中,他們也證實一些轉錄因子結合位點的突變率增高,尤其是與抽煙相關的突變。另一研究中,研究人員則分析多個癌症類型調控元件的突變。結果發現預測轉錄因子將結合的位置,即調控區域的核心,比側翼序列的突變率高達 5 倍。\\n總結,這項研究提示,在...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4106</td>\n",
       "      <td>Hemanth Pedamallu</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/rnn-vs-gru-vs-lstm-863b0b7b1573?source=tag_archive---------4-----------------------</td>\n",
       "      <td>RNN vs GRU vs LSTM. In this post, I will make you go... | by Hemanth Pedamallu | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nNov 14, 2020\\nIn this post, I will make you go through the theory of RNN, GRU and LSTM first and then I will show you how to implement and use them with code.\\nThere are already many posts on these topics out there. But in this post, I wanted to provide a much better understanding and comparison with help of code.\\nLet’s start with RNN!\\nRecurrent Neural Networks (RNN) are designed to work with sequential data. Sequential data(can be time-series) can be in form of text, audio, video etc.\\nRNN uses the previous information in the sequence to produce the current output. To understand this better I’m taking an example sentence.\\n“My class is the best class.”\\nAt the time(T0 ), the first step is to feed the word “My” into the network. the RNN produces an output.\\nAt the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>4107</td>\n",
       "      <td>Maximus Mutschler</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/fancy-and-custom-neural-style-transfer-filters-for-video-conferencing-7eba2be1b6d5?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Fancy and custom Neural Style Transfer filters for video conferencing | by Maximus Mutschler | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 27, 2021\\nMy open-source GitHub script provides AI-based filters which apply a rather new technology called Artistic Neural Style Transfer to the input stream of your physical webcam device. In contrast to traditional filters, these AI-based filters are feature-aware. Depending on what kind of features are apparent in the video, the AI adapts the output. In addition, these kinds of filters can be learned from any real-world image. Since the provided filters are directly applied on the webcam video stream, they can be used in all types of video conferencing tools, such as Zoom, Skype, Discord, MS-Teams....\\nIn detail, my script sets up a virtual webcam device that applies Artistic Neural Style Transfer to the input stream of the physical webcam device. This new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>4108</td>\n",
       "      <td>Nick Komissarenko</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@bigdataschool/3-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%B0-%D0%B4%D0%B5%D1%82%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2-c-deep-learning-r-cnn-fast-r-cnn-%D0%B8-faster-r-cnn-acdf6380fd33?source=tag_archive---------4-----------------------</td>\n",
       "      <td>3 метода детектирования объектов c Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN | by Nick Komissarenko | Medium</td>\n",
       "      <td>Jul 24, 2020\\nПроблема классификации объекта на изображении уже решена — сверточные нейронные сети (Convolutional Neural Networks, CNN) уже неплохо справляются с определением кошек или собак. Но если на изображении много объектов, которые нужно найти, задача сразу усложняется. На смену обычным сверточным нейросетям пришли более сложные модели. В этой статье рассмотрим 3 популярных способа детектирования изображений методами Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN.\\nРаспознавание образов — это общий термин, описывающий круг задач компьютерного зрения, которые решают проблему обнаружения объектов на изображении или видеокадрах. К ним относятся классификация изображения, локализация объектов, детектирование объектов и сегментация. Проведем между ними грань:\\nКлассификация и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>4109</td>\n",
       "      <td>Ryan Kwok</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>4110</td>\n",
       "      <td>Puneet Singh</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/puneetsl/1-creating-a-q-a-system-introduction-81d404dfb3e4?source=tag_archive---------0-----------------------</td>\n",
       "      <td>1. Creating a Q-A system (Introduction) | by Puneet Singh | techpsl | Medium</td>\n",
       "      <td>techpsl\\nNov 11, 2013\\nWikipedia says, “Question Answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.”As I have taken the course of “Information Retrieval” this fall at UB, my final project is decided to be a Q-A system. Well we (me and my 3 group partners) have not decided much on features, which can make our project stand out, but for now we would like to start with a small goal. Somehow index the infobox of Wikipedia, and try to query it using natural language. My initial research suggests that IBM has already created something similar but on a very large scale, and they call it Watson.As we d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>4111</td>\n",
       "      <td>Saket Dingliwal</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@saketdingliwal97/model-agnostic-meta-learning-maml-an-intuitive-way-f7539e043c0b?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Model Agnostic Meta-Learning (MAML): An Intuitive Way | by Saket Dingliwal | Medium</td>\n",
       "      <td>Jan 22, 2020\\nThere has been a great advancement in the research in the area of meta-learning in recent years. And so has been an expansion in the available literature and blog posts.\\nModel Agnostic Meta-Learning (MAML) lies at the heart of the developments in the area. There have been many excellent blog-posts explaining meta-learning in general (here and here) and MAML in particular (here and here). The heavy terms and complex equations make the algorithm to look like a big shot rocket science. However, through this blog, I want to provide intuitive reasoning behind the algorithm that can be easy to understand for a person who has no idea about meta-learning. All one needs to know is the basic idea all machine learning researchers have been following from its inception: “Throw all y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4112</td>\n",
       "      <td>Shivon Zilis</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@shivon/the-current-state-of-machine-intelligence-f76c20db2fe1?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The Current State of Machine Intelligence | by Shivon Zilis | Medium</td>\n",
       "      <td>Dec 10, 2014\\n(The 2016 Machine Intelligence landscape and post can be found here)\\nI spent the last three months learning about every artificial intelligence, machine learning, or data related startup I could find — my current list has 2,529 of them to be exact. Yes, I should find better things to do with my evenings and weekends but until then...\\nWhy do this?\\nA few years ago, investors and startups were chasing “big data” (I helped put together a landscape on that industry). Now we’re seeing a similar explosion of companies calling themselves artificial intelligence, machine learning, or somesuch — collectively I call these “machine intelligence” (I’ll get into the definitions in a second). Our fund, Bloomberg Beta, which is focused on the future of work, has been investing in thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4113</td>\n",
       "      <td>Shiva Verma</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@shiva-verma/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Understanding Input and Output shapes in LSTM | Keras | by Shiva Verma | Medium</td>\n",
       "      <td>Jan 14, 2019\\nEven if we understand LSTMs theoretically, still many of us are confused about its input and output shapes while fitting the data to the network. This guide will help you understand the Input and Output shapes of the LSTM.\\nLet’s first understand the Input and its shape in LSTM Keras. The input data to LSTM looks like the following diagram.\\n1.95K \\n1.95K \\n17\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n918 Followers\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>4114</td>\n",
       "      <td>Akash Deep</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/analytics-vidhya/keras-embedding-layer-and-programetic-implementation-of-glove-pre-trained-embeddings-step-by-step-7a4b2fa71544?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Keras Embedding layer and Programetic Implementation of GLOVE Pre-Trained Embeddings | by Akash Deep | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 23, 2020\\nKeras Embedding layer is first of Input layer for the neural networks. After the conversion of our raw input data in the token and padded sequence, now its time to feed the prepared input to the neural networks. In our previous two post we had covered step by step conversion of words into token and padded sequence, so i highly recommend to just...\\n53 \\n53 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n28 Followers\\nData scientist, (NLP, CV,ML,DL) Expert 007011\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4115</td>\n",
       "      <td>Shashank Yadav</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@shashank7-iitd/understanding-vector-quantized-variational-autoencoders-vq-vae-323d710a888a?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Understanding Vector Quantized Variational Autoencoders (VQ-VAE) | by Shashank Yadav | Medium</td>\n",
       "      <td>Sep 1, 2019\\nFrom my most recent escapade into the deep learning literature I present to you this paper by Oord et. al. which presents the idea of using discrete latent embeddings for variational auto encoders. The proposed model is called Vector Quantized Variational Autoencoders (VQ-VAE). I really liked the idea and the results that came with it but found surprisingly few resources to develop an understanding. Here’s an attempt to help other who might venture into this domain after me.\\nLike numerous other people Variational Autoencoders (VAEs) are my choice of generative models. Unlike GANs they are easier to train and reason about (No offence intended dear GANs). Going forward I assume you have some understanding of VAEs. If you don’t I suggest going through this post, I found it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>4116</td>\n",
       "      <td>Jaimin Mungalpara</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/what-does-it-mean-by-bidirectional-lstm-63d6838e34d9?source=tag_archive---------8-----------------------</td>\n",
       "      <td>What does it mean by Bidirectional LSTM? | by Jaimin Mungalpara | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 9, 2021\\nThis has turn the old approach by giving an input from both the direction and by this it can remember the long sequences.\\nIn my previous article we discussed about RNN, LSTM and GRU. Now, there are certain limitations are still persist with LSTM because it is not able to remember the context for a longer period of time.\\nYou can see in this LSTM architecture that information is still have to pass from longer path. LSTM and GRU are introduced to overcome the problem of vanishing gradient and sequential data memory but the architecture of both are having multiple sequential path. Thus, vanishing gradient problem is still persist. Also, LSTM and GRU can remember sequences of 10s and 100s but not 1000s or more.\\nBidirectional Network\\nNow, when we are dealin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>4117</td>\n",
       "      <td>Ekta Sharma</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------4-----------------------</td>\n",
       "      <td>K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>4118</td>\n",
       "      <td>Jordi TORRES.AI</td>\n",
       "      <td>23</td>\n",
       "      <td>https://towardsdatascience.com/drl-01-a-gentle-introduction-to-deep-reinforcement-learning-405b79866bf4?source=tag_archive---------4-----------------------</td>\n",
       "      <td>A gentle introduction to Deep Reinforcement Learning | by Jordi TORRES.AI | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 15, 2020\\nThis is the first post of the series “Deep Reinforcement Learning Explained”; an introductory series that gradually and with a practical approach introduces the reader to the basic concepts and methods used in modern Deep Reinforcement Learning.\\nSpanish version of this publication:\\nmedium.com\\nDeep Reinforcement Learning (DRL), a very fast-moving field, is the combination of Reinforcement Learning and Deep Learning. It is also the most trending type of Machine Learning because it can solve a wide range of complex decision-making tasks that were previously out of reach for a machine to solve real-world problems with human-like intelligence.\\nToday I’m starting a series about Deep Reinforcement Learning that will bring the topic closer to the reader....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>4119</td>\n",
       "      <td>Tejas Morkar</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/generative-adversarial-networks-gans-89ef35a60b69?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Learning to Build a Model for Sketch-to-Color Image Generation using Conditional GANs | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 23, 2020\\nThis article is a part of the Gans-Series published by me on TowardsDataScience Publication on Medium. If you do not know what GANs are or if you have an idea about it but wish to quickly go over it again, I highly recommend you read the previous article which is just a 7 minutes long read and provides a simple understanding of GANs for people who are new to this amazing domain of Deep Learning.\\nAs you can tell from the gif shown above, this article is going to be all about learning how to create a Conditional GAN to predict colorful images from the given black and white sketch inputs without knowing the actual ground truth.\\nSketch to Color Image generation is an image-to-image translation model using Conditional Generative Adversarial Networks as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>4120</td>\n",
       "      <td>Matheus Jacques</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.datadriveninvestor.com/batch-vs-mini-batch-vs-stochastic-gradient-descent-with-code-examples-cd8232174e14?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Batch vs Mini-batch vs Stochastic Gradient Descent with Code Examples | by Matheus Jacques | DataDrivenInvestor</td>\n",
       "      <td>DataDrivenInvestor\\nMay 5, 2020\\nOne of the main questions that arise when studying Machine Learning and Deep Learning is the several types of Gradient Descent. Should I use Batch Gradient Descent? Mini-batch Gradient Descent or Stochastic Gradient Descent? In this post, we are going to understand the difference between those concepts and take a look at code implementations from Gradient Descent, to clarify these methods.\\nEdit: Updated version here.\\nAt this point, we know that our matrix of weights W and our vector of bias b are the core values of our Neural Networks (NN) (Check the Deep Learning Basics post). We can make an analogy with these concepts with the memory in which a NN stores patterns, and it is through tuning these parameters that we teach a NN. The acting of tuning is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4121</td>\n",
       "      <td>Susan Maina</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/lambda-functions-with-practical-examples-in-python-45934f3653a8?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Lambda Functions with Practical Examples in Python | by Susan Maina | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 17, 2021\\nWhen I first came across lambda functions in python, I was very much intimidated and thought they were for advanced Pythonistas. Beginner python tutorials applaud the language for its readable syntax, but lambdas sure didn’t seem user-friendly.\\nHowever, once I understood the general syntax and examined some simple use cases, using them was less scary.\\nSimply put, a lambda function is just like any normal python function, except that it has no name when defining it, and it is contained in one line of code.\\nA lambda function evaluates an expression for a given argument. You give the function a value (argument) and then provide the operation (expression). The keyword lambda must come first. A full colon (:) separates the argument and the expression.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4122</td>\n",
       "      <td>Mohammed Sunasra</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Performance Metrics for Classification problems in Machine Learning | by Mohammed Sunasra | Medium</td>\n",
       "      <td>Nov 11, 2017\\n“Numbers have an important story to tell. They rely on you to give them a voice.” — Stephen Few\\nAfter doing the usual Feature Engineering, Selection, and of course, implementing a model and getting some output in forms of a probability or a class, the next step is to find out how effective is the model based on some metric using test datasets. Different performance metrics are used to evaluate different Machine Learning Algorithms. For now, we will be focusing on the ones used for Classification problems. We can use classification performance metrics such as Log-Loss, Accuracy, AUC(Area under Curve) etc. Another example of metric for evaluation of machine learning algorithms is precision, recall, which can be used for sorting algorithms primarily used by search engines.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>4123</td>\n",
       "      <td>Igor Susmelj</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/few-shot-learning-with-fast-ai-81c66064e372?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Few-Shot Learning with fast.ai. In few-shot learning, we train a model... | by Igor Susmelj | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 27, 2020\\nLately, posts and tutorials about new deep learning architectures and training strategies have dominated the community. However, one very interesting research area, namely few-shot learning, is not getting the attention it deserves. If we want widespread adoption of ML we need to find ways to train them efficiently, with little data and code. In this tutorial, we will go through a Google Colab Notebook to train an image classification model using only 5 labeled samples per class. Using only 5 exemplary samples is also called 5-shot learning.\\nDon’t forget to check out our Google Colab Notebook for the full code of this tutorial!\\nJupyter Notebook (Google Colab)The full code of this tutorial will be provided as a notebook. Jupyter Notebooks are python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>4124</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c?source=tag_archive---------4-----------------------</td>\n",
       "      <td>GAN — Introduction and Implementation — PART1: Implement a simple GAN in TF for MNIST handwritten digit generation | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 27, 2017\\nThe idea behind GANs is that you have two networks, a generator GG and a discriminator DD, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it’s received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistinguishable from real data to the discriminator.\\nThis is equilibrium state and expectation is discriminator is emitting a probability of 0.5 for both real and fake data.\\nThe general structure of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>4125</td>\n",
       "      <td>Ajinkya Sonawane</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.goodaudience.com/solving-8-puzzle-using-a-algorithm-7b509c331288?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Solving 8-Puzzle using A* Algorithm | Good Audience</td>\n",
       "      <td>Good Audience\\nSep 15, 2018\\nSolving the sliding puzzle using a basic AI algorithm.\\nN-Puzzle or sliding puzzle is a popular puzzle that consists of N tiles where N can be 8, 15, 24, and so on. In our example N = 8. The puzzle is divided into sqrt(N+1) rows and sqrt(N+1) columns. Eg. 15-Puzzle will have 4 rows and 4 columns and an 8-Puzzle will have 3 rows and 3 columns. The puzzle consists of N tiles and one empty space where the tiles can be moved. Start and Goal configurations (also called state) of the puzzle are provided. The puzzle can be solved by moving the tiles one by one in the single empty space and thus achieving the Goal configuration.\\nThe tiles in the initial(start) state can be moved in the empty space in a particular order and thus achieve the goal state.\\nNote: There...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>4126</td>\n",
       "      <td>Ashish Singhal</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/datapy-ai/nlp-building-text-summarizer-part-1-902fec337b81?source=tag_archive---------9-----------------------</td>\n",
       "      <td>NLP: Building Text Summarizer — Part 1 | by Ashish Singhal | DataPy.ai | Medium</td>\n",
       "      <td>DataPy.ai\\nNov 18, 2019\\n105 \\n105 \\n3\\nSchool for Data Science\\n98 Followers\\nTrying to become ( .* ?) | MSc @ University of Twente | ML-NLP-Big Data-DL | tencsor.github.io | theguywithblacktie.github.io\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>4127</td>\n",
       "      <td>Hely Marleena</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@helymarleena/from-metaphor-to-reality-15790952657?source=tag_archive---------4-----------------------</td>\n",
       "      <td>From metaphor to reality. When does artificial intelligence stop... | by Hely Marleena | Medium</td>\n",
       "      <td>Jul 19, 2014\\n“A mind is like a computer program that is executed in our brain” says the computer metaphor of the mind. It was developed in the 1950s. It basically compares the human mind to a computer program, suggesting that computers and our brain function on the same principles.\\nIn the philosophy of artificial intelligence (AI), the brain is perceived as a similar information processing machine as a digital computer.\\nThere is no doubt that some of our thinking processes, such as mental calculation and logical reasoning, are algorithmic. The digital computer functions with binary computer language where the symbols ‘1’ and ‘0’ represent the state of circuit’s gate. This means that an electrical impulse either goes through (state ‘1’) or does not (state ‘0’). It is similar to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>4128</td>\n",
       "      <td>Wolf Garbe</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------2-----------------------</td>\n",
       "      <td>1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium</td>\n",
       "      <td>Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is &lt;=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>4129</td>\n",
       "      <td>Klas Leino</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/training-provably-robust-neural-networks-1e15f2d80be2?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Training Provably-Robust Neural Networks | by Klas Leino | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2021\\nOver the last several years, deep networks have extensively been shown to be vulnerable to attackers that can cause the network to make perplexing mistakes, simply by feeding maliciously-perturbed inputs to the network. Clearly, this raises concrete safety concerns for neural networks deployed in the wild, especially in safety-critical settings, e.g., in autonomous vehicles. In turn, this has motivated a volume of work on practical defenses, ranging from attack detection strategies to modified training routines that aim to produce networks that are difficult — or impossible — to attack. In this article, we’ll take a look at an elegant and effective defense I designed with my colleagues at CMU (appearing in ICML 2021) that modifies the architecture of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>4130</td>\n",
       "      <td>Udacity India</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@UdacityINDIA/tensorflow-or-pytorch-the-force-is-strong-with-which-one-68226bb7dab4?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Tensorflow or PyTorch : The force is strong with which one? | by Udacity India | Medium</td>\n",
       "      <td>Apr 24, 2018\\nBy — Yashwardhan Jain\\nSo, since you’re reading this article, I’m going to assume you have started your deep learning journey and have been playing around for a while with artificial neural nets. Or maybe, you’re just thinking of starting. Whichever case it be, you find yourself in a bit of a dilemma. You have read about various deep learning frameworks and libraries and maybe two really stand out. The two most popular deep learning libraries: Tensorflow and PyTorch. And you can’t quite figure out what exactly is the difference. Fret not! I’m here to add one more article to the unending repository of the Internet. And maybe, help you get some clarity. Also, I’m going to make it easier and quicker for you, and give you just five points. Five points of comparison, no more. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4131</td>\n",
       "      <td>Kacper Kubara</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/gaussian-mixture-models-vs-k-means-which-one-to-choose-62f2736025f0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Gaussian Mixture Models vs K-Means. | by K.Kubara | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 8, 2020\\nK-Means and Gaussian Mixtures (GMs) are both clustering models. Many data scientist, however, tend to choose a more popular K-Means algorithm. Even if GMs can prove superior in certain clustering problems.\\nIn this article, we will see that both models offer a different performance in terms of speed and robustness. We will also see that it is possible to use K-Means as an initializer for GMs which tends to boost the performance of the clustering model.\\nFirst, let’s review the theoretical part of these algorithms. It will help us to understand their behaviour later in the article.\\nK-Means is a popular non-probabilistic clustering algorithm. The goal of the algorithm is to minimize the distortion measure J. We achieve that by the following iterative p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>4132</td>\n",
       "      <td>Emil Lykke Jensen</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras | by Emil Lykke Jensen | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 25, 2020\\nThe internet is full of text classification articles, most of which are BoW-models combined with some kind of ML-model typically solving a binary text classification problem. With the rise of NLP, and in particular BERT (take a look here, if you are not familiar with BERT) and other multilingual transformer based models, more and more text classification problems can now be solved.\\nHowever, when it comes to solving a multi-label, multi-class text classification problem using Huggingface Transformers, BERT, and Tensorflow Keras, the number of articles are indeed very limited and I for one, haven’t found any... Yet!\\nTherefore, with the help and inspiration of a great deal of blog posts, tutorials and GitHub code snippets all relating to either BERT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>4133</td>\n",
       "      <td>Victor Roman</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/unsupervised-classification-project-building-a-movie-recommender-with-clustering-analysis-and-4bab0738efe6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Unsupervised Classification Project: Building a Movie Recommender with Clustering Analysis and K-Means | by Victor Roman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 19, 2019\\nThe goal of this project is to find out similarities within groups of people in order to build a movie recommending system for users. We are going to analyze a dataset from Netflix database to explore the characteristics that people share in movies’ taste, based on how they rate them.\\nData will come from the MovieLens user rating dataset.\\nThis dataset has two files, we will import both and work with both of them.\\nWe will want to find out how the structure of the dataset works and how many records do we have in each of these tables.\\nWe will start by considering a subset of users and discovering what are their favourite genre. We will do this by defining a function that will calculate each user’s average rating for all science fiction and romance m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>4134</td>\n",
       "      <td>Jane Huang</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/data-science-at-microsoft/causal-inference-part-2-of-3-selecting-algorithms-a966f8228a2d?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Causal inference (Part 2 of 3): Selecting algorithms | by Jane Huang | Data Science at Microsoft | Medium</td>\n",
       "      <td>Data Science at Microsoft\\nNov 5, 2020\\nBy Jane Huang, Daniel Yehdego, and Siddharth Kumar\\nThis is the second article of a series focusing on causal inference methods and applications. In Part 1, we discussed when and why causal models can help with different business problems. We also provided fundamentals for causal inference analysis and compared a few popular Python packages for causal analysis. In this article, we dive into details of various causal inference estimation methods and discuss algorithm selection for your own problem settings. Causal inference can be used on top of A/B tests in multiple ways to extract insights, but this article focuses mainly on estimation methods under unconfoundedness or on quasi-experimental bases when a randomized control trial (RCT) is not feas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>4135</td>\n",
       "      <td>Mayank Mishra</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Convolutional Neural Networks, Explained | by Mayank Mishra | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 26, 2020\\nA Convolutional Neural Network, also known as CNN or ConvNet, is a class of neural networks that specializes in processing data that has a grid-like topology, such as an image. A digital image is a binary representation of visual data. It contains a series of pixels arranged in a grid-like fashion that contains pixel values to denote how bright and what color each pixel should be.\\nThe human brain processes a huge amount of information the second we see an image. Each neuron works in its own receptive field and is connected to other neurons in a way that they cover the entire visual field. Just as each neuron responds to stimuli only in the restricted region of the visual field called the receptive field in the biological vision system, each neuron i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>4136</td>\n",
       "      <td>Pau Labarta Bajo</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/adversarial-examples-to-break-deep-learning-models-e7f543833eae?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Adversarial Examples to Break Deep Learning Models | by Pau Labarta Bajo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 16, 2021\\nDo you think it is impossible to fool the vision system of a self-driving Tesla car?\\nOr that machine learning models used in malware detection software are too good to be evaded by hackers?\\nOr that face recognition systems in airports are bulletproof?\\nLike any of us machine learning enthusiasts, you might fall into the trap of thinking that deep models used out there are perfect.\\nWell, you are WRONG.\\nThere are easy ways to build adversarial examples that can fool any deep learning model and create security issues. In this post, we will cover the following:\\nLet’s start!\\nIn the last 10 years, deep learning models have left the academic kindergarten, become big boys, and transformed many industries. This is especially true for computer vision mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>4137</td>\n",
       "      <td>Madeline Schiappa</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/understanding-the-backbone-of-video-classification-the-i3d-architecture-d4011391692?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Understanding the Backbone of Video Classification: The I3D Architecture | by Madeline Schiappa | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 7, 2020\\nOne of the distinctive differences between information in a single image and information in a video is the temporal element. This has led to improvements of deep learning model architectures to incorporate 3D processing in order to additionally process temporal information. This article summarizes the architectural changes from images to video through the I3D model.\\nThe I3D model was presented by researchers from DeepMind and the University of Oxford in a paper called “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” [1]. The paper compares previous approaches to the problem of action detection in videos while additionally presenting a new architecture, the focus here. Their approach starts with a 2D architecture and inflates all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>4138</td>\n",
       "      <td>DataAnalysis For Beginner</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@univprofblog1/random-forests-classification-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-fb60ff088db4?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Random Forests Classification: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium</td>\n",
       "      <td>Aug 23, 2016\\nI release MATLAB, R and Python codes of Random Forests Classification (RFC). They are very easy to use. You prepare data set, and just run the code! Then, RFC and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/RciDk Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/gdJgy Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/nDrmZ Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>4139</td>\n",
       "      <td>Pranoy Radhakrishnan</td>\n",
       "      <td>8</td>\n",
       "      <td>https://becominghuman.ai/transformers-in-vision-e2e87b739feb?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Why Transformers are Slowly Replacing CNNs in Computer Vision? | by Pranoy Radhakrishnan | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nAug 31, 2021\\nBefore getting into Transformers, let’s understand why researchers were interested in building something like Transformers inspite of having MLPs , CNNs and RNNs.\\nEveryone wants a universal model to solve different tasks with accuracy and speed. Just like MLPs which are universal function approximators, Transformer models are universal approximators of sequence-to-sequence functions.\\nTransformers use the concept of Attention mechanism. Let’s look what is attention and briefly go through self attention mechanisms.\\nAttention mechanism enhances the important parts of the input data and fades out the rest. Take the example of you captioning an image. You will have to focus on the relevant part of the image to generate meani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>4140</td>\n",
       "      <td>platfarm tech team</td>\n",
       "      <td>14</td>\n",
       "      <td>https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225?source=tag_archive---------6-----------------------</td>\n",
       "      <td>어텐션 메커니즘과 transfomer(self-attention) | by platfarm tech team | mojitok | Medium</td>\n",
       "      <td>mojitok\\nMar 10, 2019\\n어텐션 메커니즘은 자연어 기계 번역을 위한 Seq2Seq 모델에 처음 도입되었습니다. 어텐션 메커니즘은 NLP 태스크 뿐만 아니라, 도메인에 관계 없이 다양하게 쓰이고 있습니다. 현재의 SOTA NLP모델들은 대부분 어텐션 메커니즘을 적용하고 있으니 최근 논문을 이해함에 있어 이해하고 넘어가야 하는 부분입니다.\\n코드는 이곳(https://github.com/graykode/nlp-tutorial)을 참고해주세요 .\\n1. Seq2Seq (링크)2. Seq2Seq with Attention (링크)3. Bi-LSTM with Attention (링크)4. Transformer (링크)\\nSeq2Seq 모델은 대중적이므로 가볍게 짚고만 넘어가겠습니다. Seq2Seq 모델에 대한 자세한 설명들은 ratsgo님의 블로그를 참조하면 볼 수 있습니다. 더불어 자세한 내용은 원작 논문인 Neural Machine Translation by Jointly Learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>4141</td>\n",
       "      <td>Parul Pandey</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Understanding the Mathematics behind Gradient Descent. | by Parul Pandey | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 18, 2019\\n“Premature optimization is the root of all evil.” ― Donald Ervin Knuth\\nAgile is a pretty well-known term in the software development process. The basic idea behind it is simple: build something quickly, ➡️ get it out there, ➡️ get some feedback ➡️ make changes depending upon the feedback ➡️ repeat the process. The goal is to get the product near the user and guide you with feedback to obtain the best possible product with the least error. Also, the steps taken for improvement need to be small and should constantly involve the user. In a way, an Agile software development process involves rapid iterations. The idea of — start with a solution as soon as possible, measure and iterate as frequently as possible, is Gradient descent under the hood.\\nGradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>4142</td>\n",
       "      <td>Martín Pellarolo</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Logistic Regression from scratch in Python | by Martín Pellarolo | Medium</td>\n",
       "      <td>Feb 23, 2018\\nWhile Python’s scikit-learn library provides the easy-to-use and efficient LogisticRegression class, the objective of this post is to create an own implementation using NumPy. Implementing basic models is a great idea to improve your comprehension about how they work.\\nWe will use the well known Iris data set. It contains 3 classes of 50 instances each, where each class refers to a type of iris plant. To simplify things, we take just the first two feature columns. Also, the two non-linearly separable classes are labeled with the same category, ending up with a binary classification problem.\\nGiven a set of inputs X, we want to assign them to one of two possible categories (0 or 1). Logistic regression models the probability that each input belongs to a particular category...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>4143</td>\n",
       "      <td>Reo Neo</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-3-9d686d0d85d9?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Beginner Guide to Variational Autoencoders (VAE) with PyTorch Lightning (Part 3) | by Reo Neo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 10, 2021\\nThis blog post is part of a mini-series that talks about the different aspects of building a PyTorch Deep Learning project using Variational Autoencoders.\\nPart 1: Mathematical Foundations and ImplementationPart 2: Supercharge with PyTorch LightningPart 3: Convolutional VAE, Inheritance and Unit TestingPart 4: Streamlit Web App and Deployment\\nIn this section, we will look at how we can use the code we wrote in the previous section and use it to build a convolutional VAE. This VAE would be better at identifying important features in the images and thus generate even better images.\\nThe best part is that this new model can be built with minimal additional code thanks to PyTorch modules and class inheritance.\\nConvolution is an operation commonly used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4144</td>\n",
       "      <td>Aman Kharwal</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/coders-camp/60-python-projects-with-source-code-919cd8a6e512?source=tag_archive---------5-----------------------</td>\n",
       "      <td>60 Python Projects with Source Code | by Aman Kharwal | Coders Camp | Medium</td>\n",
       "      <td>Coders Camp\\nJan 14, 2021\\nPython has been in the top 10 popular programming languages for a long time, as the community of Python programmers has grown a lot due to its easy syntax and library support. In this article, I will introduce you to 60 amazing Python projects with source code solved and explained for free.\\nIf you’re a newbie to Python where you’ve just learned lists, tuples, dictionaries, and some basic Python modules like the random module, here are some Python projects with source code for beginners for you:\\nIf you have learned the fundamental Python libraries and some of the external libraries, you should now know how to install external libraries and work with them. So if you are at that level now, you can work on all the advanced Python projects with source code menti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>4145</td>\n",
       "      <td>Haihan Lan</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/the-softmax-function-neural-net-outputs-as-probabilities-and-ensemble-classifiers-9bd94d75932?source=tag_archive---------9-----------------------</td>\n",
       "      <td>The Softmax Function, Neural Net Outputs as Probabilities, and Ensemble Classifiers | by Haihan Lan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2017\\nIn this article, we’ll look at:\\nLinks to my other articles:\\nIn many cases when using neural network models such as regular deep feedforward nets and convolutional nets for classification tasks over some set of class labels, one wonders whether it is possible to interpret the output, for example y = [0.02, 0, 0.005, 0.975], as the probability of some input being in a class equal to the respective component values yi in the output vector. Skipping straight to the long answer: no, unless you have a softmax layer as your output layer and train the net with the cross-entropy loss function. This point is important because it is sometimes omitted in online sources and even in some textbooks regarding classification with neural networks. We’ll take a look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>4146</td>\n",
       "      <td>Pranav Budhwant</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/binaryandmore/beginners-guide-to-deriving-and-implementing-backpropagation-e3c1a5a1e536?source=tag_archive---------3-----------------------</td>\n",
       "      <td>A beginner’s guide to deriving and implementing backpropagation | by Pranav Budhwant | binaryandmore | Medium</td>\n",
       "      <td>binaryandmore\\nJul 16, 2018\\nThis article is divided into two sections:1. Derivation — In this section, we will be deriving all the required formulae for performing backpropagation. I strongly recommend that you derive the equations on paper as you read through the article.2. Implementation — In this part, we will use the derived formulae to implement backpropagation from scratch. We will be solving a binary classification problem in python using numpy.\\nDisclaimerThis article assumes a basic understanding of neural networks and how they work. If you are not familiar with neural networks, or think your concepts are a little rusty, you may want to review chapter 1 of the amazing book, Neural Networks and Deep Learning, by Michael Nielsen, or if you prefer video lectures, you might want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>4147</td>\n",
       "      <td>Shivy Yohanandan</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2?source=tag_archive---------1-----------------------</td>\n",
       "      <td>mAP (mean Average Precision) might confuse you! | by Shivy Yohanandan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 9, 2020\\nOne can be forgiven for taking mAP (mean average precision) to literally mean the average of precisions. Nevertheless, you couldn’t be further from the truth!\\nLet me explain.\\nIn computer vision, mAP is a popular evaluation metric used for object detection (i.e. localisation and classification). Localization determines the location of an instance (e.g. bounding box coordinates) and classification tells you what it is (e.g. a dog or cat).\\nMany object detection algorithms, such as Faster R-CNN, MobileNet SSD, and YOLO, use mAP to evaluate their models for publishing their research.\\nYou might ask, if it’s such a popular metric, why is it still confusing?\\nFair enough!\\nmAP stands for Mean Average Precision (as you might already have guessed looking at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>4148</td>\n",
       "      <td>Kyle McDonald</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How to recognize fake AI-generated images | by Kyle McDonald | Medium</td>\n",
       "      <td>Dec 5, 2018\\nIn 2014 machine learning researcher Ian Goodfellow introduced the idea of generative adversarial networks or GANs. “Generative” because they output things like images rather than predictions about input (like “hotdog or not”); “adversarial networks” because they use two neural networks competing with each other in a “cat-and-mouse game”, like a cashier and a counterfeiter: one trying to fool the other into thinking it can generate real examples, the other trying to distinguish real from fake.\\nThe first GAN images were easy for humans to identify. Consider these faces from 2014.\\nBut the latest examples of GAN-generated faces, published in October 2017, are more difficult to identify.\\nHere are some things you can look for when trying to recognize an image produced by a GA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4149</td>\n",
       "      <td>Peter Bulyaki</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@peter.bulyaki/a-brief-introduction-to-artificial-neural-networks-9962114c3bad?source=tag_archive---------3-----------------------</td>\n",
       "      <td>A brief introduction to artificial neural networks | by Peter Bulyaki | Medium</td>\n",
       "      <td>Nov 2, 2012\\nThis post will try to give you a brief introduction to artificial neural networks or at least to some types of them. I will skip the introduction to biological neural networks as I am neither a biologist nor a doctor, I prefer not to write about what I do not fully understand.\\nOverview of artificial neural networks and supervised learning\\nI think it is very important to note that artificial neural networks are neither magical AI circuits nor oracles with the ability of predicting stock market movements. You can save one as a file on the disk and you can name it skynet if you like but it will not get more intelligent from that. In reality they are simply mathematical tools that can come very handy in solving certain problems (and can prove to be completely useless for oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>4150</td>\n",
       "      <td>Synced</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/syncedreview/biggan-a-new-state-of-the-art-in-image-synthesis-cf2ec5694024?source=tag_archive---------2-----------------------</td>\n",
       "      <td>BigGAN: A New State of the Art in Image Synthesis | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nOct 2, 2018\\n“Best GAN samples ever yet? Very impressive ICLR submission! BigGAN improves Inception Scores by &gt;100.”\\nThe above Tweet is from renowned Google DeepMind research scientist Oriol Vinyals. It was retweeted last week by Google Brain researcher and “Father of Generative Adversarial Networks” Ian Goodfellow, and picked up momentum and praise from AI researchers on social media.\\n402 \\n402 \\n5\\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology &amp; Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4151</td>\n",
       "      <td>Nir Ben-Zvi</td>\n",
       "      <td>22</td>\n",
       "      <td>https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86?source=tag_archive---------7-----------------------</td>\n",
       "      <td>A 2022-Ready Deep Learning Hardware Guide | by Nir Ben-Zvi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 15, 2020\\nThis is as up to date as: 3/1/2022\\nThis is a vastly revised version of the older version you all know and love.Almost every part of this guide has been thoroughly rewritten. The original guide has been getting updated over the course of 6 years, so I decided it’s time to basically (almost) write it from scratch.This time I tried to make this a bit more thorough and general. I’ll keep updating this, but I also want to make sure my readers can understand the topic even if I stop doing so one day.\\nSo, you’ve decided you want to purchase a machine dedicated to training machine learning models. Or, rather, you work in an organization where the buzzwords of this guide are constantly thrown around and you simply want to know a bit more about what they mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4152</td>\n",
       "      <td>Nathan Cooper Jones</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@nathancooperjones/these-bored-apes-do-not-exist-6bed2c73f02c?source=tag_archive---------1-----------------------</td>\n",
       "      <td>These Bored Apes Do Not Exist: GAN to NFT Pipeline | Medium</td>\n",
       "      <td>Dec 6, 2021\\nTL;DR — I complain about NFTs, then attempt to train both a GAN and super-resolution model to generate Bored Apes that do not exist. You can check out all the generated images on thisboredapedoesnotexist.nathancooperjones.com.\\nFriday, November 12th, 2021 started out as a normal day for me. Before starting my day at work, I decided to open Twitter to see if I missed anything since the night before.\\nThen, it happened. I saw this Tweet:\\nSay what you will about how Jimmy Fallon tells and reacts to jokes, but if this was a joke, I did not understand it. An animated monkey dressed in a sailor cap? I soon learned that this wasn’t just any animated ape, but one of exactly 10,000 unique images produced in a collection called Bored Ape Yacht Club. After ten minutes down a Twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4153</td>\n",
       "      <td>Ahmet Genç</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@ahmetxgenc/detecting-empty-car-parking-lot-with-mask-rcnn-model-4f6202794a6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Detecting Empty Parking Lots With Mask RCNN Model | by Ahmet Genç | Medium</td>\n",
       "      <td>Dec 20, 2019\\nNowadays, there are big problems about parking areas. The large number of vehicles in the cities and the scarcity of parking spaces lead to parking problems in the cities. The biggest solution that can be brought to this problem is to provide people with the information whether the parking spaces are automatically empty or full. Using a mask...\\n17 \\n17 \\n1\\nSoftware Engineer\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n49 Followers\\nSoftware Engineer\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>4154</td>\n",
       "      <td>Max Pagels</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/value-stream-design/online-machine-learning-515556ff72c5?source=tag_archive---------6-----------------------</td>\n",
       "      <td>What is Online Machine Learning?. Making machines learn in real time | by Max Pagels | The Hands-on Advisors | Medium</td>\n",
       "      <td>The Hands-on Advisors\\nApr 20, 2018\\nDuring the start of my career, I was fortunate enough to work on a subfield of machine learning known as online learning (also known as incremental or out-of-core learning). Compared to “traditional” ML solutions, online learning is a fundamentally different approach, one that embraces the fact that learning environments can (and do) change from second to second. It’s tricky to get right, but when applied correctly, the results you can achieve with online learning are nothing short of remarkable. In this post, I’ll give a quick introduction to the technique.\\nUpdate 27/09/2019: lots of people have asked if there exist any purpose-built incremental learning libraries. Yes! Vowpal Wabbit is extremely powerful, and has been around for quite a while. Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>4155</td>\n",
       "      <td>Chris Loughnane</td>\n",
       "      <td>7</td>\n",
       "      <td>https://pdnotebook.com/image-analysis-intro-using-python-opencv-18791f4edf22?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Image analysis intro using python &amp; opencv | by Chris Loughnane | Product Development Notebook</td>\n",
       "      <td>Product Development Notebook\\nOct 26, 2015\\nIt’s been a while since I first wrote about how useful computer vision can be in product development, and I recently put together a quick demo for other engineers at my new gig (@ Continuum) that is cleaner and more thorough than previous versions (plus it uses the cv2 library instead of the deprecated cv library I used before).\\n(and of course it’s written in python)\\n...\\n...\\n...\\nImage analysis is hugely powerful, particularly in the context of product development. Most of the challenges in computer vision (and AI in general) comes from trying to process unstructured and/or uncontrolled information.\\nFortunately, we product development engineers spend a bunch of time setting up experiments in the lab. In those cases we have much more cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>4156</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Multi Class Text Classification with LSTM using TensorFlow 2.0 | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 8, 2019\\nA lot of innovations on NLP have been how to add context into word vectors. One of the common ways of doing it is using Recurrent Neural Networks. The following are the concepts of Recurrent Neural Networks:\\nThe above is the architecture of Recurrent Neural Networks.\\nAssuming we are solving document classification problem for a news article data set.\\nTherefore, we generally do not use vanilla RNNs, and we use Long Short Term Memory instead. LSTM is a type of RNNs that can solve this long term dependency problem.\\nIn our document classification for news article example, we have this many-to- one relationship. The input are sequences of words, output is one single class or label.\\nNow we are going to solve a BBC news document classification problem w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>4157</td>\n",
       "      <td>Pandorabots</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/pandorabots-blog/using-oob-tags-in-aiml-part-i-21214b4d2fcd?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Using OOB Tags in AIML: Part I. Suppose you are building an Intelligent... | by Pandorabots | pandorabots-blog | Medium</td>\n",
       "      <td>pandorabots-blog\\nOct 9, 2014\\nSuppose you are building an Intelligent Virtual Agent or Virtual Personal Assistant (VPA) that uses a Pandorabot as the natural language processing engine. You might want this VPA to be able to perform tasks such as sending a text message, adding an event to a calendar, or even just initiating a phone call. OOB tags allow you to do just that!\\nOOB stands for “out of band,” which is an engineering term used to refer to activity performed on a separate, hidden channel. For a Pandorabot VPA, this translates to activities which fall outside of the scope of an ordinary conversation, such as placing a phone call, checking dynamic information like the weather, or searching wikipedia for the answer to some question. The task is executed, but does not necessarily ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>4158</td>\n",
       "      <td>Harsh Sharma</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Understanding Encoders-Decoders with Attention Based Mechanism | DataX Journal</td>\n",
       "      <td>DataX Journal\\nFeb 1, 2021\\nHow attention-based mechanism completely transformed the working of neural machine translations while exploring contextual relations in sequences!\\nWhen it comes to applying deep learning principles to natural language processing, contextual information weighs in a lot! In the past few years, it has been shown that various improvement in existing neural network architectures concerned with NLP has shown an amazing performance in extracting featured information from textual data and performing various operations for a day to day life. One of the models which we will be discussing in this article is encoder-decoder architecture along with the attention model.\\nThe encoder-decoder architecture for recurrent neural networks is actually proving to be powerful for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4159</td>\n",
       "      <td>Prajwal Paudyal</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/should-ai-explain-itself-or-should-we-design-explainable-ai-so-that-it-doesnt-have-to-90e75bb6089e?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Should AI explain itself? or should we design Explainable AI so that it doesn’t have to | by Prajwal Paudyal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 4, 2019\\nIn this article, I’ll go over:\\nThis article got longer that what I originally intended, so for the busy souls, here is a synopsis.\\nExplanations for AI behavior that are generated Ad-hoc or post-hoc are more like justifications and may not be capture the truth of the decision process. If trust and accountability is needed, that has to be taken into account early on in the design process. Explainable AI (XAI )is NOT an AI that can explain itself, it is a design decision by developers. It is AI that is transparent enough so that the explanations that are needed are part of the design process.\\nNow, the full story.\\nA self driving car knocked down and killed a pedestrian in Tempe, AZ in 2018. Issues like who is to blame (accountability), who to prevent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4160</td>\n",
       "      <td>Yang S</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/an-introduction-to-perceptron-algorithm-40f2ab4e2099?source=tag_archive---------2-----------------------</td>\n",
       "      <td>An Introduction to Perceptron Algorithm | by Yang S | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 19, 2019\\nThis blog will cover following questions and topics\\n1. What is Perceptron?\\n2. Stochastic Gradient Descent for Perceptron\\n3. Implementation in Python\\n1. What is Perceptron?\\nPerceptron set the foundations for Neural Network models in 1980s. The algorithm was developed by Frank Rosenblatt and was encapsulated in the paper “Principles of Neuro-dynamics: Perceptrons and the Theory of Brain Mechanisms” published in 1962. At that time, Rosenblatt’s work was criticized by Marvin Minksy and Seymour Papert, arguing that neural networks were flawed and could only solve linear separation problem. However, such limitation only occurs in the single layer neural network.\\nPerceptron can be used to solve two-class classification problem. The generalized form of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4161</td>\n",
       "      <td>Karl N.</td>\n",
       "      <td>7</td>\n",
       "      <td>https://gab41.lab41.org/taking-keras-to-the-zoo-9a76243152cb?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Taking Keras to the Zoo. If you follow any of the popular blogs... | by Karl N. | Gab41</td>\n",
       "      <td>Gab41\\nDec 13, 2015\\nIf you follow any of the popular blogs like Google’s research, FastML, Smola’s Adventures in Data Land, or one of the indie-pop ones like Edwin Chen’s blog, you’ve probably also used ModelZoo. Actually, if you’re like our boss, you affectionately call it “The Zoo”. (Actually x 2, if you have interesting blogs that you read, feel free to let us know!)\\nUnfortunately, ModelZoo is only supported in Caffe. Fortunately, we’ve taken a look at the difference between the kernels in Keras, Theano, and Caffe for you, and after reading this blog, you’ll be able to load models from ModelZoo into any of your favorite Python tools.\\nWhy this post? Why not just download our Github code?\\nIn short, it’s better you figure out how these things work before you use them. That way, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4162</td>\n",
       "      <td>ASHISH RANA</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction: Reinforcement Learning with OpenAI Gym | by ASHISH RANA | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 21, 2018\\nUnderstand the basic goto concepts to get a quick start on reinforcement learning and learn to test your algorithms with OpenAI gym to achieve research centric reproducible results.\\nThis article first walks you through the basics of reinforcement learning, its current advancements and a somewhat detailed practical use-case of autonomous driving. After that we get dirty with code and learn about OpenAI Gym, a tool often used by researchers for standardization and benchmarking results. When the coding section comes please open your terminal and get ready for some hands on.A time saver tip: You can directly skip to ‘Conceptual Understanding’ section if you want to skip basics and only want try out Open AI gym directly.\\nMainly three categories of learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4163</td>\n",
       "      <td>Volkan Levent Soylu</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@vlknlvnt/reinforcement-learning-peki%C5%9Ftirmeli-%C3%B6%C4%9Frenme-i%CC%87nsan-beyniyle-aradaki-fark-kapan%C4%B1rken-c0d0a6f7c2e8?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Reinforcement Learning (Pekiştirmeli Öğrenme) — İnsan Beyniyle Aradaki Fark Kapanırken | by Volkan Levent Soylu | Medium</td>\n",
       "      <td>Nov 23, 2017\\nHatırlarsınız, önce 1997’de DeepMind’ın bilgisayarı Deep Blue Kasparov’u satrançta yenmişti. Bir sonraki adımdaysa AlphaGo önce dünya Go şampiyonu Ke Jie’yi, sonrasında da bir üst model AlphaGo Zero en iyi Go oyuncularından biri sayılan Lee Sedol’u 2016’da 3 kez yendi. Şimdi yeni adımın StarCraft olacağı söyleniyor; ki bilen bilir StarCraft koordinasyon, hızlı karar alma, dikkat olarak epey zorlayıcı bir oyundur. AlphaGo bütün bunları Reinforcement Learning (Pekiştirmeli Öğrenme) ile yaptı.\\nPekiştirmeli Öğrenme, Makine Öğrenmesi’nin alt kollarından biri. Makine Öğrenmesi’nde genellikle Markov Karar Süreci adı verilen bir model kullanılıyor. Bu model yapay zekânın önceden bilgilendirilmesine ve yönlendirilmesine dayalı. Kesin bir neden sonuç ili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>4164</td>\n",
       "      <td>editorCapire.info</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/capire-info/sugerencias-para-definir-un-men%C3%BA-de-navegaci%C3%B3n-e6efe33bfe22?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Sugerencias para definir un menú de navegación | by editorCapire.info | Capire.info | Medium</td>\n",
       "      <td>Capire.info\\nJun 18, 2008\\nEscribe Jorge Garrido G.\\nAlgunas sugerencias sobre cómo construir un menú que entregue orientación y control al usuario, sin perder claridad en su forma de presentarse.¿Qué es un menú? ¿Qué representa? ¿Qué comunica? ¿Para qué sirve? ¿Todo sitio web o aplicación debe tener un menú?\\nLas respuestas no son tan sencillas ni están tan claras; mucho menos se puede considerar este como un tema superado. No lo creo por lo que percibo cuando navego, periódicamente. Veo menús poco cuidados, incomprendidos, mal diseñados, desenfocados.\\nHay muchos otros recursos, fuera de los menús de navegación, para destacar los contenidos más importantes: Accesos directos con características gráficas sobresalientes, listados de hotlinks, nubes de tags y un largo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>4165</td>\n",
       "      <td>Enoch Kan</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How to implement an Adam Optimizer from Scratch | by Enoch Kan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 6, 2020\\nIt’s not as hard as you think!\\nTl;dr if you want to skip the tutorial. Here is the notebook I created.\\nAdam is algorithm the optimizes stochastic objective functions based on adaptive estimates of moments. The update rule of Adam is a combination of momentum and the RMSProp optimizer.\\nThe rules are simple. Code Adam from scratch without the help of any external ML libraries such as PyTorch, Keras, Chainer or Tensorflow. Only libraries we are allowed to use arenumpy and math .\\n(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ\\nThe easiest way to learn how Adam’s works is to watch Andrew Ng’s video. Alternatively, you can read Adam’s original paper to get a better understanding of the motivation and intuition behind it.\\nTwo values that Adam depend on are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>4166</td>\n",
       "      <td>Towards AI Editorial Team</td>\n",
       "      <td>26</td>\n",
       "      <td>https://pub.towardsai.net/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Machine Learning Algorithms For Beginners with Code Examples in Python | by Towards AI Editorial Team | Towards AI</td>\n",
       "      <td>Towards AI\\nJun 3, 2020\\nAuthor(s): Pratik Shukla, Roberto Iriondo, Sherwin Chen\\nLast updated April 14, 2021\\nmembers.towardsai.net\\nMachine learning (ML) is rapidly changing the world, from diverse types of applications and research pursued in industry and academia. Machine learning is affecting every part of our daily lives. From voice assistants using NLP and machine learning to make appointments, check our calendar, and play music, to programmatic advertisements — that are so accurate that they can predict what we will need before we even think of it.\\nMore often than not, the complexity of the scientific field of machine learning can be overwhelming, making keeping up with “what is important” a very challenging task. However, to make sure that we provide a learning path to those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>4167</td>\n",
       "      <td>Francesco Gadaleta</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/hackernoon/gradient-descent-vs-coordinate-descent-9b5657f1c59f?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Gradient descent vs coordinate descent | by Francesco Gadaleta | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nMay 31, 2014\\nWhen it comes to function minimization, it’s time to open a book of optimization and linear algebra. I am currently working on variable selection and lasso-based solutions in genetics. What lasso does is basically minimizing the loss function and an penalty in order to set to zero some regression coefficients and select only those covariates that are really associated with the response. Pheew, the shortest summary of lasso ever!\\nWe all know that, provided the function to be minimized is convex, a good direction to follow, in order to find a local minimum, is towards the negative gradient of the function. Now, my question is how good or bad is following the negative gradient with respect to a coordinate descent approach that loops across all dimensions and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>4168</td>\n",
       "      <td>surendranath bobba</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/hackernoon/how-i-deployed-my-spark-document-classification-logistic-regression-model-s-as-a-standalone-app-64b05b44e102?source=tag_archive---------3-----------------------</td>\n",
       "      <td>How I deployed my spark document classification(Logistic Regression) model/s as a standalone app for real-time prediction | by surendranath bobba | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nOct 4, 2016\\nTLDR — Use pipelines to save TF-IDF model generated from the training set, and SVM model for prediction. So essentially save two models, one for feature extraction and transformation of input, the other for prediction.\\nOne of the big challenges when you develop a text classification model, the trained model which you get is not enough for prediction if your plan was to train offline and deploy only the model for prediction in some cases. Especially in the case where we are extracting features from the training set using `Hashing Trick` and to normalise the importance of a feature/term to the document using `Inverse Document Frequency`, the most frequent terms in documents actually have lesser importance to the whole corpus. This is all commonly labelled ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>4169</td>\n",
       "      <td>Hshan.T</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/mlearning-ai/demonstrating-customers-segmentation-with-dbscan-clustering-using-python-8a2ba0db2a2e?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Demonstrating Customers Segmentation with DBSCAN Clustering Using Python | by Hshan.T | MLearning.ai | Medium</td>\n",
       "      <td>MLearning.ai\\nMar 4, 2021\\n4 \\n4 \\nData Scientists must think like an artist when finding a solution when creating a piece of code. ⚪️ Artists enjoy working on interesting problems, even if there is no obvious answer ⚪️ linktr.ee/mlearning 🔵 Follow to join our 18K+ Unique DAILY Readers 🟠\\n36 Followers\\nData.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>4170</td>\n",
       "      <td>Sudip Shrestha, PhD</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/nlp-spam-detection-in-sms-text-data-using-deep-learning-b8632db85cc8?source=tag_archive---------7-----------------------</td>\n",
       "      <td>NLP: Spam Detection in SMS (text) data using Deep Learning | by Sudip Shrestha, PhD | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 27, 2020\\nToday, internet and social media have become the fastest and easiest ways to get information. In this age, reviews, opinions, feedbacks, messages and recommendations have become significant source of information. Thanks to advancement in technologies, we are now able to extract meaningful information from such data using various Natural Language Processing (NLP) techniques. NLP , a branch of Artificial Intelligence (AI), makes use of computers and human natural language to output valuable information. NLP is commonly used in text classification task such as spam detection and sentiment analysis, text generation, language translations and document classification.\\nThe purpose of this article is to understand how we can use TensorFlow2 to build SMS spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>4171</td>\n",
       "      <td>Tanya Dayanand</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/pos-tagging-using-rnn-7f08a522f849?source=tag_archive---------4-----------------------</td>\n",
       "      <td>POS Tagging Using RNN. Learn how to use RNNs to tag words in... | by Tanya Dayanand | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 3, 2020\\nThe classical way of doing POS tagging is using some variant of Hidden Markov Model. Here we'll see how we could do that using Recurrent neural networks. The original RNN architecture has some variants too. It has a novel RNN architecture — the Bidirectional RNN which is capable of reading sequences in the ‘reverse order’ as well and has proven to boost performance significantly.\\nThen two important cutting-edge variants of the RNN which have made it possible to train large networks on real datasets. Although RNNs are capable of solving a variety of sequence problems, their architecture itself is their biggest enemy due to the problems of exploding and vanishing gradients that occur during the training of RNNs. This problem is solved by two popular ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4172</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/geekculture/deep-convolutional-generative-adversarial-network-using-pytorch-ece1260acc47?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Deep Convolutional Generative Adversarial Network using PyTorch | by Renu Khandelwal | Geek Culture | Medium</td>\n",
       "      <td>Geek Culture\\nMay 6, 2021\\nThis post will learn to create a DCGAN using PyTorch on the MNIST dataset.\\nA basic understanding of CNN\\nA sample implementation using CNN\\nUnderstanding Deep Convolutional GAN\\nGANs were invented by Ian Goodfellow in 2014 and first described in the paper Generative...\\n3 \\n3 \\n1\\nA new tech publication by Start it up (https://medium.com/swlh).\\n3.7K Followers\\nLoves learning, sharing, and discovering myself. Passionate about Machine Learning and Deep Learning\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>4173</td>\n",
       "      <td>Chi-Feng Wang</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------5-----------------------</td>\n",
       "      <td>A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>4174</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/@jonathan-hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3 | by Jonathan Hui | Medium</td>\n",
       "      <td>Mar 18, 2018\\nYou only look once (YOLO) is an object detection system targeted for real-time processing. We will introduce YOLO, YOLOv2 and YOLO9000 in this article. For those only interested in YOLOv3, please forward to the bottom of the article. Here is the accuracy and speed comparison provided by the YOLO web site.\\nA demonstration from the YOLOv2.\\nLet’s start with our own testing image below.\\nThe objects detected by YOLO:\\nGrid cell\\nFor our discussion, we crop our original photo. YOLO divides the input image into an S×S grid. Each grid cell predicts only one object. For example, the yellow grid cell below tries to predict the “person” object whose center (the blue dot) falls inside the grid cell.\\nEach grid cell predicts a fixed number of boundary boxes. In this example, the ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>4175</td>\n",
       "      <td>Arun Kumar</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/mercari-price-suggestion-97ff15840dbd?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Price Prediction using Machine Learning Regression — a case study | by Arun Kumar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 30, 2020\\nThis article is a detailed account of my approach to solving a regression problem, which is also a popular Kaggle competition. Hope you find it useful and enjoy reading it :)\\nArtificial Intelligence is an integral part of all major e-commerce companies today. With the evolution of the information industry and extensive research in the field of AI in the past two decades, businesses have started to explore the ways to automate various activities using state of the art Machine Learning algorithms and Deep Neural Networks. Many IT giants and start-ups have already taken a big leap in this field and have dedicated teams and resources for research and development of cutting edge AI applications. Online retail platforms today are extensively driven by AI-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>4176</td>\n",
       "      <td>Bayan Bennett</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/swlh/embeddings-in-machine-learning-548eef7b2b5?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Embeddings in Machine Learning. Embeddings are a basic method to encode... | by Bayan Bennett | The Startup | Medium</td>\n",
       "      <td>The Startup\\nAug 13, 2020\\nI first came across the concept of embeddings while developing the RNN typing practice app.\\nEven though I am just beginning to understand the range of uses for embeddings, I thought it would be useful to write down some of the basics.\\nFirst, let’s look at what I knew before embeddings, one-hot vectors.\\n52 \\n52 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n13 Followers\\nMy goal is to serve humanity and to bring happiness to others. I want to understand the problems around us and help find solutions. https://www.bayanbennett.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>4177</td>\n",
       "      <td>George Seif</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------3-----------------------</td>\n",
       "      <td>The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>4178</td>\n",
       "      <td>Shashank Yadav</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@shashank7-iitd/understanding-attention-mechanism-35ff53fc328e?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Understanding Attention Mechanism | by Shashank Yadav | Medium</td>\n",
       "      <td>Feb 5, 2019\\nAttention mechanism for sequence modelling was first introduced in the paper: Neural Machine Translation by jointly learning to align and translate, Bengio et. al. ICLR 2015. Even though the paper itself mentions the word “attention” scarcely (3 times total in 2 consecutive lines!!) the term has caught on. A lot of prominent work that came later on uses the same naming convention (Well, I for one think it’s more of a “soft memory” rather than “attention”).\\nThis post focuses on Bengio et. al. 2015 and tries to give a step by step explanation of the (attention) model explained in their paper. Probably it’s just me but the explanation given in the paper and the diagrams that came with it left a lot to the imagination. This post tries to make understanding their great work a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>4179</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking | by Joseph Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 23, 2019\\nThis post was co-written with Baptiste Rocca.\\n“Unity is strength”. This old saying expresses pretty well the underlying idea that rules the very powerful “ensemble methods” in machine learning. Roughly, ensemble learning methods, that often trust the top rankings of many machine learning competitions (including Kaggle’s competitions), are based on the hypothesis that combining multiple models together can often produce a much more powerful model.\\nThe purpose of this post is to introduce various notions of ensemble learning. We will give the reader some necessary keys to well understand and use related methods and be able to design adapted solutions when needed. We will discuss some well known notions such as boostrapping, bagging, random forest, bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>4180</td>\n",
       "      <td>Kopal Jain</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How to Improve Naive Bayes?. Section 3: Tuning the Model in Python | by Kopal Jain | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nApr 2, 2021\\nReference How to Implement Naive Bayes? Section 2: Building the Model in Python, prior to continuing...\\n[10] Define Grid Search Parameters\\nWhy this step: To set the selected parameters used to find the optimal combination. By referencing the sklearn.naive_bayes.GaussianNB documentation, you can find a completed list of parameters with descriptions that can be used in grid search functionalities.\\n[11] Hyperparameter Tune using Training Data\\nNote: Total number of fits is 1000 since the cv is defined as 10 and there are 100 candidates (var_smoothing has 100 defined parameters). Therefore, the calculation for a total number of fits → 10 x [100] = 1000.\\nWhy this step: To find an optimal combination of hyperparameters that minimizes a predefined loss funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>4181</td>\n",
       "      <td>Amin Ag</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/ai%C2%B3-theory-practice-business/object-detection-in-deep-learning-part2-855b78689f13?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Object detection in Deep learning (Part2) | by Amin Ag | AI3 | Theory, Practice, Business | Medium</td>\n",
       "      <td>AI3 | Theory, Practice, Business\\nSep 22, 2019\\nR-CNN &amp; Fast R-CNN\\nFollowing part1, an object-detection-algorithm has to draw up to several bounding boxes representing different objects of interest within the image and you would not know how many beforehand.\\nA direct approach (brut force) to solve this issue would be to take different regions of interest from the image and use a CNN to classify the presence of the object within that region. The problem here, the objects of interest might have different spatial locations within the image and different aspect ratios. Hence, you would have to select a huge number of regions and this could computationally hard (increasingly hard). Therefore, algorithms like R-CNN, YOLO, etc have been developed to find these occurrences and find them fast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>4182</td>\n",
       "      <td>Sema Zeynep Bulut</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/mlearning-ai/a-brief-overview-of-r-cnn-fast-r-cnn-and-faster-r-cnn-9c6843c9ffc0?source=tag_archive---------1-----------------------</td>\n",
       "      <td>A brief overview of R-CNN, Fast R-CNN and Faster R-CNN | by Sema Zeynep Bulut | MLearning.ai | Medium</td>\n",
       "      <td>MLearning.ai\\nMay 6, 2021\\nR-CNN architecture is used to detect the classes of objects in the images and the bounding boxes of these objects. RCNN architecture has been developed since classification cannot be made for more than one object with CNN in visuals containing more than one object.\\nThe general working principle of R-CNN takes place in two steps. First, the features where the object can be found in the visual are determined with selective search, then after the regions are determined, each region is given as an input to a CNN model and the prediction process is performed for classes and bounding boxes.\\nSelective Search:\\nIt is used to determine the regions on the image that should be captured. Small areas are determined first. Then, similar regions are combined to create lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>4183</td>\n",
       "      <td>ilmoi</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/evasion-attacks-on-machine-learning-or-adversarial-examples-12f2283e06a1?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Evasion attacks on Machine Learning (or “Adversarial Examples”) | by ilmoi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 14, 2019\\nMachine learning is exciting. However, just like any new technology or invention, not only does ML enable new amazing capabilities — but also, unfortunately, new vulnerabilities.\\nPreviously I’ve discussed how to think about these vulnerabilities in a structured way (or how to develop a “threat model” for your ML). This time I’d like to dive deep into how your ML system can be exploited during inference time through what is known as an evasion attack.\\nWith no time to waste, let’s get started.\\nAn evasion attack happens when the network is fed an “adversarial example” — a carefully perturbed input that looks and feels exactly the same as its untampered copy to a human — but that completely throws off the classifier.\\nDespite all the hype around adver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>4184</td>\n",
       "      <td>Andrew Marmon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@andrewmarmon/fine-tuned-named-entity-recognition-with-hugging-face-bert-d51d4cb3d7b5?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Fine-Tuned Named Entity Recognition with Hugging Face BERT | by Andrew Marmon | Medium</td>\n",
       "      <td>Aug 5, 2021\\nIn many organizations, there is a unique vocabulary that maps names to known entities within that domain. At the United Nations, for instance, we have many specific entities which it is useful to identify in documents, including specific named committees and assemblies, important topics like the Sustainable Development Goals (SGDs), and many different countries and cultural groups that must be identified correctly. Exhaustively naming each and every important topic that may appear in a document, however, is not reasonable considering the shear number that may be important, especially considering the context of a document or sentence in which this entity is present. Instead, we want to be able to automatically identify and predict named entities using Named Entity Recogniti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>4185</td>\n",
       "      <td>Prince Grover</td>\n",
       "      <td>8</td>\n",
       "      <td>https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Gradient Boosting from scratch. Simplifying a complex algorithm | by Prince Grover | ML Review</td>\n",
       "      <td>ML Review\\nDec 9, 2017\\nSimplifying a complex algorithm\\nAlthough most of the Kaggle competition winners use stack/ensemble of various models, one particular model that is part of most of the ensembles is some variant of Gradient Boosting (GBM) algorithm. Take for an example the winner of latest Kaggle competition: Michael Jahrer’s solution with representation learning in Safe Driver Prediction. His solution was a blend of 6 models. 1 LightGBM (a variant of GBM) and 5 Neural Nets. Although his success is attributed to the semi-supervised learning that he used for the structured data, but gradient boosting model has done the useful part too.\\nEven though GBM is being used widely, many practitioners still treat it as complex black-box algorithm and just run the models using pre-built lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>4186</td>\n",
       "      <td>Andre Violante</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning: Q-learning | by Andre Violante | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 18, 2019\\nOne of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it seemed to make sense. In this quick post I’ll discuss q-learning and provide the basic background to understanding the algorithm.\\nQ-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It’s considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn’t needed. More specifically, q-learning seeks to learn a policy that maximizes the total reward.\\nThe ‘q’ in q-learning stands for quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>4187</td>\n",
       "      <td>Arthur Juliani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4188</td>\n",
       "      <td>Rizky Luthfianto</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/blog-rilut/neural-networks-without-backpropagation-direct-feedback-alignment-30d5d4848f5?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Neural Networks without Backpropagation: Direct Feedback Alignment | by Rizky Luthfianto | Blog rilut | Medium</td>\n",
       "      <td>Blog rilut\\nJan 3, 2017\\nHere’s a quick summary on Arild Nøkland’s 2016 paper “Direct Feedback Alignment” which is not only written clearly but also interesting. Both Lillicrap et al. (2016) and Nøkland (2016) were able to train a Neural Network (NN) without Backpropagation.\\nFirst, create a simple NN like this:\\nwith cross-entropy as its loss function.\\nSo here is our implementation so far:\\nTo train a NN, we have to get the loss function derivative w.r.t to softmax function. Let’s take a look at Equation 5 from Nøkland’s paper.\\nwhich simply corresponds to:\\nI am sorry as I am not going to explain the Calculus behind this. Should you refer to Sadowski’s Notes on Backpropagation if you want the explanation.\\nThis is our implementation of Backpropagation:\\nWhere d1, d2, and ewill be us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4189</td>\n",
       "      <td>Azad Soni</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/clustering-with-gaussian-mixture-model/clustering-with-gaussian-mixture-model-c695b6cd60da?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Clustering with Gaussian Mixture Model | by Azad Soni | Clustering with Gaussian Mixture Model | Medium</td>\n",
       "      <td>Clustering with Gaussian Mixture Model\\nDec 5, 2017\\nOne of the popular problems in unsupervised learning is clustering. Clustering is the assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense.\\nAs in above diagram the result of clustering is colouring of the squares into three clusters.\\nOne of the basic approach to solve cluster analysis problem is K-means. K-means algorithm partitioned the data into K clusters .\\nK means:\\nIn general, suppose we have n data points, that have to be partitioned in K clusters. The goal is to assign a cluster to each data point. K-means is a clustering method that aims to find the K positions of the clusters that minimize the distance(for example Euclidian distance) from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>4190</td>\n",
       "      <td>JP Zamanillo</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/training-a-spacy-ner-pipeline-with-prodigy-ca58350cb868?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Training a spaCy NER Pipeline with Prodigy | by JP Zamanillo | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nApr 26, 2021\\nThe success of a custom Named Entity Recognition (NER) model is dependent on the quality of data passed to it. However, supplying a model with sufficient examples of training data is typically a time-consuming and exhaustive process. Using Prodigy, the task of labeling your data for building a custom NER pipeline to a spaCy model is much quicker and simpler.\\nAccording to the official Prodigy site:\\nProdigy is a modern annotation tool for creating training and evaluation data for machine learning models. You can also use Prodigy to help you inspect and clean your data, do error analysis and develop rule-based systems to use in combination with your statistical models.\\nProdigy makes it easy to label your data to use in model training. For this overview, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>4191</td>\n",
       "      <td>Anson Wong</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/solving-the-multi-armed-bandit-problem-b72de40db97c?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Solving the Multi-Armed Bandit Problem | by Anson Wong | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 25, 2017\\nThe multi-armed bandit problem is a classic reinforcement learning example where we are given a slot machine with n arms (bandits) with each arm having its own rigged probability distribution of success. Pulling any one of the arms gives you a stochastic reward of either R=+1 for success, or R=0 for failure. Our objective is to pull the arms one-by-one in sequence such that we maximize our total reward collected in the long run.\\nThe non-triviality of the multi-armed bandit problem lies in the fact that we (the agent) cannot access the true bandit probability distributions — all learning is carried out via the means of trial-and-error and value estimation. So the question is:\\nHow can we design a systematic strategy that adapts to these stochastic re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>4192</td>\n",
       "      <td>Patrick Langechuan Liu</td>\n",
       "      <td>16</td>\n",
       "      <td>https://towardsdatascience.com/single-stage-instance-segmentation-a-review-1eeb66e0cc49?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Single Stage Instance Segmentation — A Review | by Patrick Langechuan Liu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 28, 2020\\nUpdate:\\nInstance segmentation is a challenging computer vision task that requires the prediction of object instances and their per-pixel segmentation mask. This makes it a hybrid of semantic segmentation and object detection.\\nEver since Mask R-CNN was invented, the state-of-the-art method for instance segmentation has largely been Mask RCNN and its variants (PANet, Mask Score RCNN, etc). It adopts the detect-then-segment approach, first perform object detection to extract bounding boxes around each object instances, and then perform binary segmentation inside each bounding box to separate the foreground (object) and the background.\\nThere are some other instance segmentation methods other than the top-down approach of detect-then-segment (or segmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>4193</td>\n",
       "      <td>Aqeel Anwar</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Difference between AutoEncoder (AE) and Variational AutoEncoder (VAE) | by Aqeel Anwar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 3, 2021\\nThe ability to simplify means to eliminate the unnecessary so that the necessary may speak — Hans Hofmann\\nData compression is an essential phase in training a network. The idea is to compress the data so that the same amount of information can be represented by fewer bits. This also helps with the problem of the curse of dimensionality. A dataset with many attributes is different to train with because it tends to overfit the model. Hence dimensionality reduction techniques need to be applied before the dataset can be used for training.\\nThis is where the Autoencoder (AE) and Variational Autoencoder (VAE) come into play. They are end-to-end networks that are used to compress the input data. Both Autoencoder and Variational Autoencoder are used to tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>4194</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/predict-customer-churn-with-r-9e62357d47b4?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Predict Customer Churn with R. For any service company that bills on a... | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 16, 2017\\nFor any service company that bills on a recurring basis, a key variable is the rate of churn. Harvard Business Review, March 2016\\nFor just about any growing company in this “as-a-service” world, two of the most important metrics are customer churn and lifetime value. Entrepreneur, February 2016\\nCustomer churn occurs when customers or subscribers stop doing business with a company or service, also known as customer attrition. It is also referred as loss of clients or customers. One industry in which churn rates are particularly useful is the telecommunications industry, because most customers have multiple options from which to choose within a geographic location.\\nSimilar concept with predicting employee turnover, we are going to predict customer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>4195</td>\n",
       "      <td>Boris Knyazev</td>\n",
       "      <td>16</td>\n",
       "      <td>https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Anisotropic, Dynamic, Spectral and Multiscale Filters Defined on Graphs | by Boris Knyazev | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 12, 2019\\nI’m presenting an overview of important Graph Neural Network works, by distilling key ideas and explaining simple intuition behind milestone methods using Python and PyTorch. This post continues the first part of my tutorial.\\nIn the “Graph of Graph Neural Network (GNN) and related works” above, I added papers on graphs that I have come across in the last year. In this graph, a directed edge between two works denotes that one paper is based on the other (while not necessary citing it) and a color of the work denotes:\\nNote, that some other important works and edges are not shown to avoid further clutter, and only a tiny fraction of works, highlighted in bold boxes, will be covered in this post. Disclaimer: I still found room to squeeze our own recent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>4196</td>\n",
       "      <td>Sabina Pokhrel</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/important-topics-in-machine-learning-you-need-to-know-21ad02cc6be5?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Important Topics in Machine Learning You Need to Know | by Sabina Pokhrel | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 4, 2019\\nMachine learning is a hot topic right now and everyone is trying to get their hands on any information they can get about the topic. With the amount of information that is out there about machine learning, one can get overwhelmed. In this post, I have listed some of the most important topics in machine learning that you need to know, along with some resources which can help you in further reading about the topics which you are interested to know in-depth.\\nAI is a branch of computer science that aims to create intelligent machines that mimic human behaviour such as knowledge, reasoning, problem-solving, perception, learning, planning, ability to manipulate and move objects\\nAI is an area of computer science that emphasizes the creation of intelligent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>4197</td>\n",
       "      <td>Essam Wisam</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Deriving Backpropagation with Cross-Entropy Loss | by Essam Wisam | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 2, 2021\\nThere is a myriad of loss functions that you can choose for your neural network. The choice of loss function is imperative for the network’s performance because eventually the parameters in the network are going to be set such that the loss is minimized.\\nCross-Entropy loss is a popular choice if the problem at hand is a classification problem, and in and of itself it can be classified into either categorical cross-entropy or multi-class cross-entropy (with binary cross-entropy being a special case of the former.) In case you’re scratching your head about how different are these, I’ll try to introduce each before delving into the derivation.\\nLet’s start with categorical cross-entropy. For this loss function our y’s are one-hot encoded to denote the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>4198</td>\n",
       "      <td>Zijing Zhu</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/wthe-ultimate-guide-to-clustering-algorithms-and-topic-modeling-4f7757c115?source=tag_archive---------4-----------------------</td>\n",
       "      <td>The Ultimate Guide to Clustering Algorithms and Topic Modeling | by Zijing Zhu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 23, 2021\\nClustering is one of the most used unsupervised machine learning algorithms. You can think of clustering as putting unorganized data points into different categories so that you can learn more about the structures of your data. Clustering has a variety of applications in extracting information from data without labels. For example, companies cluster customers based on their characteristics, like purchasing behaviors, to make better market campaigns, to set pricing strategies to make more profit, etc. Clustering algorithms are also widely used in natural language processing (NLP) to extract information from unstructured textual data, and topic modeling is one example.\\nThe series of articles aims to provide readers with a thorough view of two common b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>4199</td>\n",
       "      <td>Varun Saravanan</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/text-summarization-from-scratch-using-encoder-decoder-network-with-attention-in-keras-5fa80d12710e?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Text Summarization from scratch using Encoder-Decoder network with Attention in Keras | by Varun Saravanan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 14, 2020\\nDuring our school days, most of us would have encountered the reading comprehension section of our English paper. We would be given a paragraph or Essay based on which we need to answer several questions.\\nHow do we as humans approach this task at hand? We go through the entire text, make sense of the context in which the question is asked and then we write answers. Is there a way we can use AI and deep learning techniques to mimic this behavior of us?\\nAutomatic text summarization is a common problem in machine learning and natural language processing (NLP). There are two approaches to this problem.\\n2. Abstractive Summarization-Abstractive text summarization, on the other hand, is a technique in which the summary is generated by generating novel se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>4200</td>\n",
       "      <td>DataAnalysis For Beginner</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@univprofblog1/linear-discriminant-analysis-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-4acfffc4726?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Linear Discriminant Analysis: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium</td>\n",
       "      <td>Aug 26, 2016\\nI release MATLAB, R and Python codes of Linear Discriminant Analysis (LDA). They are very easy to use. You prepare data set, and just run the code! Then, LDA and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/uVtRo Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/bZPL Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/JHFt Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>4201</td>\n",
       "      <td>Carlos E. Perez</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/intuitionmachine/the-strange-loop-in-alphago-zeros-self-play-6e3274fcdd9f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Why AlphaGo Zero is a Quantum Leap Forward in Deep Learning | by Carlos E. Perez | Intuition Machine | Medium</td>\n",
       "      <td>Intuition Machine\\nOct 22, 2017\\nSelf-play is Automated Knowledge Creation\\nThe 1983 movie “War Games” has a memorable climax where the supercomputer known as WOPR (War Operation Plan Response) is asked to train on itself to discover the concept of an un-winnable game. The character played by Mathew Broderick asks “Is there any way that it can play itself?”\\n34 years later, DeepMind has shown how this is exactly done in real life! The solution is the same, set the number of players to zero (i.e. zero humans).\\nThere is plenty to digest about this latest breakthrough in Deep Learning technology. DeepMind authors use the term “self-play reinforcement learning”. As I remarked in the piece about “Tribes of AI”, DeepMind is particularly fond of their Reinforcement Learning (RL) approach. De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>4202</td>\n",
       "      <td>Ilma Arifiany</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@arifiany/segmentasi-semantik-untuk-klasifikasi-citra-a004b3906250?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Segmentasi Semantik untuk Klasifikasi Citra | by Ilma Arifiany | Medium</td>\n",
       "      <td>Sep 3, 2018\\nSegmentasi citra merupakan bagian dari proses pengolahan citra. Segmentasi citra (image segmentation) mempunyai arti membagi suatu citra menjadi wilayah-wilayah yang homogen berdasarkan kriteria keserupaan tertentu antara suatu piksel dengan piksel — piksel tetangganya, kemudian hasil dari proses segmentasi ini akan digunakan untuk proses tingkat tinggi lebih lanjut yang dapat dilakukan terhadap suatu citra, misalnya proses klasifikasi citra dan proses identifikasi objek.\\nSegmentasi semantik adalah proses klasifikasi setiap piksel dari sebuah citra sebagai sebuah label kelas untuk memahami citra dalam tingkat per piksel. Label kelas yang yang dimaksud adalah kelas objek, seperti rumah, buku, manusia, dan lain-lain.\\nSelain mengenali dan membedakan pengendara dan motor, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>4203</td>\n",
       "      <td>Dinesh</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@humble_bee/rnn-recurrent-neural-networks-lstm-842ba7205bbf?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Beginner’s Guide to RNN &amp; LSTMs. Let’s understand how exactly RNN and... | by Dinesh | Medium</td>\n",
       "      <td>Dec 5, 2019\\nWhat is RNN?\\nRecurrent Neural Network is basically a generalization of feed-forward neural network that has an internal memory. RNNs are a special kind of neural networks that are designed to effectively deal with sequential data. This kind of data includes time series (a list of values of some parameters over a certain period of time) text documents, which can be seen as a sequence of words, or audio, which can be seen as a sequence of sound frequencies over time.RNN is recurrent in nature as it performs the same function for every input of data while the output of the current input depends on the past one computation. For making a decision, it considers the current input and the output that it has learned from the previous input.\\nCells that are a function of inputs fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>4204</td>\n",
       "      <td>Boris Anthony</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@borisanthony/puppyslugs-r-us-part-1-88461c2104ba?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Puppyslugs ‘R Us: Part 1. In “Puppyslugs ‘R Us: Part 0”, I... | by Boris Anthony | Medium</td>\n",
       "      <td>Aug 5, 2015\\nIn “Puppyslugs ‘R Us: Part 0”, I started out quite cheekily on a topic I hope to explore here in a bit more serious detail.\\nI am going to start with the recent Google “DeepDream” release and the so-called Puppyslug images you’ve likely encountered, explaining roughly what those are and how they come to be. I will connect that to AI and algorithms in general and then move specifically to how they already appear in your everyday mobile experience. From there we can paint a picture of what’s in store for us, and why I say... the Puppyslugs are Us. I’ll conclude by setting up Part 2, and how all of this lands squarely in the lap of Design to deal with.\\nPuppyslugs. Quick background:\\nAbout two months ago (early June 2015), Google Researchers start showing off some algorithmic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>4205</td>\n",
       "      <td>Shuchen Du</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/ai-salon/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Understanding Deep Self-attention Mechanism in Convolution Neural Networks | by Shuchen Du | AI Salon | Medium</td>\n",
       "      <td>AI Salon\\nJan 8, 2020\\nConvolution neural networks (CNN) are broadly used in deep learning and computer vision algorithms. Even though many CNN-based algorithms meet industry standards and can be embedded in commercial products...\\n422 \\n422 \\n1\\nA tea drinking place to talk about AI\\n198 Followers\\nMachine learning engineer based in Tokyo\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>4206</td>\n",
       "      <td>Rising Odegua</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Transfer learning and Image classification using Keras on Kaggle kernels. | by Rising Odegua | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 2, 2018\\nIn my last post, we trained a convnet to differentiate dogs from cats. We trained the convnet from scratch and got an accuracy of about 80%. Not bad for a model trained on very little dataset (4000 images).\\nBut in real world/production scenarios, our model is actually under-performing.\\nAlthough we suggested tuning some hyperparameters — epochs, learning rates, input size, network depth, backpropagation algorithms e.t.c — to see if we could increase our accuracy.\\nWell, I did try...\\nAnd truth is, after tuning, re-tuning, not-tuning , my accuracy wouldn’t go above 90% and at a point It was useless.\\nOf course having more data would have helped our model; But remember we’re working with a small dataset, a common problem in the field of deep learning.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>4207</td>\n",
       "      <td>Prem Chandra Singh</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/understanding-the-stylegan-and-stylegan2-architecture-add9e992747d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Understanding the StyleGAN and StyleGAN2 Architecture | by Prem Chandra Singh | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 12, 2021\\nThe article contains the introduction of StyleGAN and StyleGAN2 architecture which will give you an idea. It may help you to start with StyleGAN. You will find some metric or the operations name which you don’t know, to gain a deep understanding of StyleGAN and StyleGAN2 you can go through the paper whose link is provided in the resources section.\\nLet’s start with the StyleGAN and then we move towards StyleGAN 2.\\nThe major changes they have done in the Generator part of the “Progressive Growing of GANs” architecture. Below you can see both the traditional and the style-based generator (new one or StyleGAN network) network.\\nIn the traditional network, latent vectors directly pass into the block just after the normalization whereas in the StyleGAN netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>4208</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@jonathan-hui/map-mean-average-precision-for-object-detection-45c121a31173?source=tag_archive---------1-----------------------</td>\n",
       "      <td>mAP (mean Average Precision) for Object Detection | by Jonathan Hui | Medium</td>\n",
       "      <td>Mar 7, 2018\\nAP (Average precision) is a popular metric in measuring the accuracy of object detectors like Faster R-CNN, SSD, etc. Average precision computes the average precision value for recall value over 0 to 1. It sounds complicated but actually pretty simple as we illustrate it with an example. But before that, we will do a quick recap on precision, recall, and IoU first.\\nPrecision &amp; recall\\nPrecision measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\\nRecall measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions.\\nHere are their mathematical definitions:\\nFor example, in the testing for cancer:\\nIoU (Intersection over union)\\nIoU measures the overlap between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>4209</td>\n",
       "      <td>EarnSkins</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@earnskins/guide-pop-slots-casino-level-27-13-easy-a387f127d9f3?source=tag_archive---------7-----------------------</td>\n",
       "      <td>GUIDE: POP! Slots Casino — Level 27 &amp; 34 ($13+) [EASY] | by EarnSkins | Medium</td>\n",
       "      <td>Jul 8, 2020\\nGuide made for EarnSkins users, by JaxStart the offer now at www.earnskins.gg to earn some side money!Use referral code ‘wolf’ to get yourself a free 50 points to start with.\\nUPDATE: The offer is currently to finish Level 34, this strategy still works, tested and confirmed, however it takes a bit longer now.\\nVideo Guide: https://youtu.be/AIEBGMRPe7I\\nThe POP! Slots offer is a casino/slots based app offer that exists for both iOS and Android phones. The offer required me to reach level 27 in the app, which was easily obtainable and you can automate it really easy making the time spent actually doing anything is extremely low.\\nThere’s three different types of this offer that I’m aware of. One requires you to reach level 27, one level 26 while the last one requires you to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>4210</td>\n",
       "      <td>Gene Su</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-2-cf81bf32c73d?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Seq2seq pay Attention to Self Attention: Part 2 | by Gene Su | Medium</td>\n",
       "      <td>Oct 3, 2018\\nPart 1 https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-1-d332e85e9aad\\nChinese Version https://medium.com/%40bgg/seq2seq-pay-attention-to-self-attention-part-2-%E4%B8%AD%E6%96%87%E7%89%88-ef2ddf8597a4\\nWe have talked about Seq2seq and Attention model in the first part. In this part, I will be focusing on Self attention, proposed by Google in the paper “Attention is all you need”. Self attention is the concept of “The transformer”model, which outperforms the attention model in various tasks. Two main concepts of the “transformer” model are “self attention” and “multi-head”.\\nThe biggest advantage comes from how The Transformer lends itself to parallelization and self attention.\\nHope you enjoy it.\\nI will use the figure in part 1 as a quick overview. We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>4211</td>\n",
       "      <td>Isaac Godfried</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Attention for time series forecasting and classification | by Isaac Godfried | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 10, 2019\\nTransformers (specifically self-attention) have powered significant recent progress in NLP. They have enabled models like BERT, GPT-2, and XLNet to form powerful language models that can be used to generate text, translate text, answer questions, classify documents, summarize text, and much more. With their recent success in NLP one would expect widespread adaptation to problems like time series forecasting and classification. After all, both involve processing sequential data. However, to this point research on their adaptation to time series problems has remained limited. Moreover, while some results are promising, others remain more mixed. In this article, I will review current literature on applying transformers as well as attention more broadly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>4212</td>\n",
       "      <td>Ashutosh Bhardwaj</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Silhouette Coefficient. This is my first medium story, so... | by Ashutosh Bhardwaj | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 26, 2020\\nAfter learning and applying several supervised ML algorithms like least square regression, logistic regression, SVM, decision tree etc. most of us try to have some hands-on unsupervised learning by implementing some clustering techniques like K-Means, DBSCAN or HDBSCAN.\\nWe usually start with K-Means clustering. After going through several tutorials and Medium stories you will be able to implement k-means clustering easily. But as you implement it, a question starts to bug your mind: how can we measure its goodness of fit? Supervised algorithms have lots of metrics to check their goodness of fit like accuracy, r-square value, sensitivity, specificity etc. but what can we calculate to measure the accuracy or goodness of our clustering technique? The a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>4213</td>\n",
       "      <td>Destin Gong</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/clustering-algorithm-for-customer-segmentation-e2d79e28cbc3?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Clustering Algorithm for Customer Segmentation | by Destin Gong | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 4, 2021\\nIn a business context: Clustering algorithm is a technique that assists customer segmentation which is a process of classifying similar customers into the same segment. Clustering algorithm helps to better understand customers, in terms of both static demographics and dynamic behaviors. Customer with comparable characteristics often interact with the business similarly, thus business can benefit from this technique by creating tailored marketing strategy for each segment.\\nIn a data science context: Clustering algorithm is an unsupervised machine learning algorithm that discovers groups of data points that are closely related. The fundamental difference between supervised and unsupervised algorithm is that:\\nAfter giving an overview of what is cluster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>4214</td>\n",
       "      <td>Sagi eppel</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/train-neural-net-for-semantic-segmentation-with-pytorch-in-50-lines-of-code-830c71a6544f?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Train a neural net for semantic segmentation in 50 lines of code, with Pytorch | by Sagi eppel | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 3, 2021\\nHow to train a neural net for semantic segmentation in less than 50 lines of code (40 if you exclude imports). The goal here is to give the fastest simplest overview of how to train semantic segmentation neural net in PyTorch using the built-in Torchvision neural nets (DeepLabV3).\\nCode is available: https://github.com/sagieppel/Train-Semantic-Segmentation-Net-with-Pytorch-In-50-Lines-Of-Code\\nThe goal is semantic segmentation is to take images and identify regions belonging to specific classes. This is done by processing the image through a convolution neural network that outputs a map with a class per pixel. The classes are given as a set of numbers. For example, in this case, we will use the LabPics V1 dataset with three classes (shown in the figur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>4215</td>\n",
       "      <td>Jake Grigsby</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/multivariate-time-series-forecasting-with-transformers-384dc6ce989b?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Multivariate Time Series Forecasting with Transformers | by Jake Grigsby | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 28, 2021\\nMany real-world applications of Machine Learning involve making predictions about the outcomes of a group of related variables based on historical context. We might want to forecast the traffic conditions on connected roads, the weather at nearby locations, or the demand for similar products. By modeling multiple time series together, we hope that changes in one variable may reveal key information about the behavior of related variables. Multivariate Time Series Forecasting (TSF) datasets have two axes of difficulty: we need to learn temporal relationships to understand how values change over time and spatial relationships to know how variables impact one another.\\nPopular statistical approaches to TSF can struggle to interpret long context sequences...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>4216</td>\n",
       "      <td>Piero Esposito</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/blitz-a-bayesian-neural-network-library-for-pytorch-82f9998916c7?source=tag_archive---------4-----------------------</td>\n",
       "      <td>BLiTZ — A Bayesian Neural Network library for PyTorch | by Piero Esposito | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 4, 2020\\nThis is a post on the usage of a library for Deep Bayesian Learning. If you are new to the theme, you may want to seek one of the many posts on medium about it or just the documentation section on Bayesian DL of our lib repo.\\nAs there is a rising need for gathering uncertainty over neural network predictions, using Bayesian Neural Network layers became one of the most intuitive approaches — and that can be confirmed by the trend of Bayesian Networks as a study field on Deep Learning.\\nIt occurs that, despite the trend of PyTorch as a main Deep Learning framework (for research, at least), no library lets the user introduce Bayesian Neural Network layers intro their models with as ease as they can do it with nn.Linear and nn.Conv2d, for example.\\nLogic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>4217</td>\n",
       "      <td>Adrian Yijie Xu</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/gradientcrescent/neural-art-style-transfer-with-keras-theory-and-implementation-91b7fb08ee81?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Neural Art Style Transfer with Keras — Theory and Implementation | by Adrian Yijie Xu | GradientCrescent | Medium</td>\n",
       "      <td>GradientCrescent\\nFeb 4, 2019\\nIntroduction\\nOver the past five years, neural networks have received attention through AI-generated art pieces, whether these be paintings, poetry, or music. During October of last year, an AI-generated art piece sold for over $400,000 at an auction at Christie’s, sparking debate and discussion over the intrinsic value and nature of art generated by machines.\\nWhile most of these mentioned art pieces were original pieces generated through Generative Adversarial Networks (GAN’s, which we will discuss in a future tutorial), apps such as PRISMA have been receiving attention for being able to apply the styles of famous paintings to one’s own photos. The concept, known as neural style transfer (henceforth NST), was first introduced in a paper by Leon Gatys et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>4218</td>\n",
       "      <td>Maryam Fallah</td>\n",
       "      <td>12</td>\n",
       "      <td>https://techblog.ezra.com/different-embedding-models-7874197dc410?source=tag_archive---------6-----------------------</td>\n",
       "      <td>What are the common word embeddings? | The Ezra Tech Blog</td>\n",
       "      <td>The Ezra Tech Blog\\nMar 4, 2021\\nEmbeddings are an important component of natural language processing pipelines. They refer to the vector representation of textual data. You can think of embeddings as a transformation from human-readable text to computer-readable numbers or vectors as seen in Fig. 1. These embeddings can be used in any machine learning task that takes text as the input, e.g. question answering, classification, text generation.\\nDifferent embedding techniques vary in their complexity and capabilities. For instance, the most simple form of word embeddings can be represented with one-hot encodings where each word in the corpus of size V is mapped to a unique index in a vector of the same size. This gives us a vector of all zeros except for one element that indicates the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>4219</td>\n",
       "      <td>The NYT Open Team</td>\n",
       "      <td>3</td>\n",
       "      <td>https://open.nytimes.com/equake-85b6566b7f2?source=tag_archive---------8-----------------------</td>\n",
       "      <td>EQuake. Riley Davis and David Souther... | by The NYT Open Team | NYT Open</td>\n",
       "      <td>NYT Open\\nSep 30, 2013\\nBy RILEY DAVIS and DAVID SOUTHER\\nRiley Davis and David Souther collaborated on EQuake, a 3D earthquake visualizer they developed in about a day. They discuss their motivations and approach in this piece.\\nWe were inspired by this xkcd comic imagining a situation in which tweets about an earthquake spread faster than the earthquake’s seismic waves.\\nWe both like to make complex scientific information more accessible by tying it to scales that people already understand. We thought it would be interesting to plot waves from real earthquakes onto a globe to show how fast the waves actually travel through the crust. This tool could easily be used to map out tweets (or any other geographic data) when other earthquakes occurred. To implement this, we were able to use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>4220</td>\n",
       "      <td>Kenny Jones</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/gangogh-creating-art-with-gans-8d087d8f74a1?source=tag_archive---------1-----------------------</td>\n",
       "      <td>GANGogh: Creating Art with GANs. Introduction: | by Kenny Jones | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 18, 2017\\nIntroduction:\\nThe work here presented is the result of a semester long independent research performed by Kenny Jones and Derrick Bonafilia (both Williams College 2017) under the guidance of Professor Andrea Danyluk. The code associated with this project can be found at https://github.com/rkjones4/GANGogh. Kenny and Derrick are both heading to Facebook next year as Software Engineers and hope to continue studying GANs in whatever capacity is available to them.\\nBackground:\\nGenerative Adversarial Networks (GANS) were introduced by Ian Goodfellow et. al. in a 2014 paper. GANs address the lack of relative success of deep generative models compared to deep discriminative models. The authors cite the intractable nature of the maximum likelihood estimatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>4221</td>\n",
       "      <td>Charlie Kufs</td>\n",
       "      <td>6</td>\n",
       "      <td>https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English</td>\n",
       "      <td>Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>4222</td>\n",
       "      <td>Boris Knyazev</td>\n",
       "      <td>17</td>\n",
       "      <td>https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-1-3d9fada3b80d?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Tutorial on Graph Neural Networks for Computer Vision and Beyond | by Boris Knyazev | Medium</td>\n",
       "      <td>Aug 4, 2019\\nI’m answering questions that AI/ML/CV people not familiar with graphs or graph neural networks typically ask. I provide PyTorch examples to clarify the idea behind this relatively new and exciting kind of model.\\nThe questions addressed in this part of my tutorial are:\\nTo answer them, I’ll provide motivating examples, papers and Python code making it a tutorial on Graph Neural Networks (GNNs). Some basic knowledge of machine learning and computer vision is expected, however, I’ll provide some background and intuitive explanation as we go.\\nFirst of all, let’s briefly recall what is a graph? A graph G is a set of nodes (vertices) connected by directed/undirected edges. Nodes and edges typically come from some expert knowledge or intuition about the problem. So, it can be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>4223</td>\n",
       "      <td>DataCrafts @ DataWeave</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/dataweave/smartphones-vs-tablets-does-size-matter-963ab7dd6052?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Smartphones vs Tablets: Does size matter? | by DataCrafts @ DataWeave | DataWeave | Medium</td>\n",
       "      <td>DataWeave\\nAug 4, 2015\\nWe have seen a steady increase in the number of smartphones and tablets since the last five years. Looking at the number of smartphones, tablets and now wearables ( smart watches and fitbits ) that are being launched in the mobiles market, we can truly call this ‘The Mobile Age’.\\nWe, at DataWeave, deal with millions of data points related to products which vary from electronics to apparel. One of the main challenges we encounter while dealing with this data is the amount of noise and variation present for the same products across different stores.\\nOne particular problem we have been facing recently is detecting whether a particular product is a mobile phone (smartphone) or a tablet. If it is mentioned explicitly somewhere in the product information or metadata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>4224</td>\n",
       "      <td>Baptiste Monpezat</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/stochastic-gradient-descent-for-machine-learning-clearly-explained-cadcc17d3d11?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Stochastic Gradient Descent for machine learning clearly explained | by Baptiste Monpezat | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 1, 2020\\nAs you may know, supervised machine learning consists in finding a function, called a decision function, that best models the relation between input/output pairs of data. In order to find this function, we have to formulate this learning problem into an optimization problem.\\nLet’s consider the following task: finding the best linear function that maps the input space, the variable X to the output space, the variable Y.\\nAs we try to model the relation between X and Y by a linear function, the set of functions that the learning algorithm is allowed to select is the following :\\nThe term b is the intercept, also called bias in machine learning. This set of functions is our hypothesis space.But how do we choose the values for the parameters a,b and how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>4225</td>\n",
       "      <td>Maarten Grootendorst</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Keyword Extraction with BERT | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 29, 2020\\nWhen we want to understand key information from specific documents, we typically turn towards keyword extraction. Keyword extraction is the automated process of extracting the words and phrases that are most relevant to an input text.\\nWith methods such as Rake and YAKE! we already have easy-to-use packages that can be used to extract keywords and keyphrases. However, these models typically work based on the statistical properties of a text and not so much on semantic similarity.\\nIn comes BERT. BERT is a bi-directional transformer model that allows us to transform phrases and documents to vectors that capture their meaning.\\nWhat if we were to use BERT instead of statistical models?\\nAlthough there are many great papers and solutions out there that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4226</td>\n",
       "      <td>Chi-Feng Wang</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------0-----------------------</td>\n",
       "      <td>A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>4227</td>\n",
       "      <td>Bruce MacDonald</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/fooling-facial-detection-with-fashion-d668ed919eb?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Fooling Facial Detection with Fashion | by Bruce MacDonald | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 4, 2019\\nUsage of facial recognition is on the rise. With the recent debates over the ethics of facial recognition potential adversarial attacks against facial detection have been on my mind. Facial recognition is being used everywhere from airports to social media. It seems to be near impossible to opt-out of having your face scanned.\\nAn ideal attack on facial detection would be an article of clothing that looks inconspicuous to the uninformed. With inspiration from the Hyperface project I decided to research and implement a wearable adversarial example. In this article I’ll detail the process of creating an adversarial image to fool a selected type of facial detection and how I implemented a practical example on a face mask.\\nThe first thing it’s important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>4228</td>\n",
       "      <td>Connor Shorten</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/stylegan2-ace6d3da405d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>StyleGAN2. This article explores changes made in... | by Connor Shorten | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 17, 2019\\nThe first version of the StyleGAN architecture yielded incredibly impressive results on the facial image dataset known as Flicker-Faces-HQ (FFHQ). The most impressive characteristic of these results, compared to early iterations of GANs such as Conditional GANs or DCGANs, is the high resolution (10242) of the generated images. In addition to resolution, GANs are compared along dimensions such as the diversity of images generated (avoiding mode collapse) and a suite of quantitative metrics comparing real and generated images such as FID, Inception Score, and Precision and Recall.\\nFrechet Inception Distance (FID) is one of the most common automated metrics used to evaluate images sampled from generative models. This metric is based on comparing activa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>4229</td>\n",
       "      <td>Pankaj Mathur</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/pankajmathur/logistic-regression-with-tensorflow-a02c2bd2bd1e?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Quick Logistic Regression with TensorFlow | by Pankaj Mathur | Pankaj Mathur | Medium</td>\n",
       "      <td>Pankaj Mathur\\nApr 1, 2016\\nHere is a simple logistic regression model built with TensorFlow. We are using MNIST Image example data set which is provided by default with Tensorflow package.\\nHere are the hyperparameters we choose to run initial model:\\nWe achieved impressive 90.8% accuracy in 20 epochs with a learning rate of 0.01 by running simple logistic regression model build with Tensorflow on MNIST dataset.\\nI am using Conda to install TensorFlow. You might already have a TensorFlow environment, but please check below to make sure you have all the necessary packages. If you have never used Conda environments before, please go through my other tutorial What is Anaconda and Why should I bother about it?\\nAssuming you have conda install on your machine, please run the following comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>4230</td>\n",
       "      <td>Luiz Fonseca</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4231</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/time-series-of-price-anomaly-detection-13586cd5ff46?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Time Series of Price Anomaly Detection | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 23, 2019\\nAlso known as outlier detection, anomaly detection is a data mining process used to determine types of anomalies found in a data set and to determine details about their occurrences. Automatic anomaly detection is critical in today’s world where the sheer volume of data makes it impossible to tag outliers manually. Auto anomaly detection has a wide range of applications such as fraud detection, system health monitoring, fault detection, and event detection systems in sensor networks, and so on.\\nBut I would like to apply anomaly detection to hotel room prices. The reason is somewhat selfish.\\nHave you had experience that, lets say, you travel to a certain destination for business regularly and you always stay at the same hotel. While most of the time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4232</td>\n",
       "      <td>Zhi Li</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92?source=tag_archive---------2-----------------------</td>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model | by Zhi Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 30, 2019\\nWord embedding is one of the most important techniques in natural language processing(NLP), where words are mapped to vectors of real numbers. Word embedding is capable of capturing the meaning of a word in a document, semantic and syntactic similarity, relation with other words. It also has been widely used for recommender systems and text classification. This tutorial will show a brief introduction of genism word2vec model with an example of generating word embedding for the vehicle make model.\\nWord2vec is one of the most popular technique to learn word embeddings using a two-layer neural network. Its input is a text corpus and its output is a set of vectors. Word embedding via word2vec can make natural language computer-readable, then further imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>4233</td>\n",
       "      <td>Chi-Feng Wang</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The Vanishing Gradient Problem. The Problem, Its Causes, Its... | by Chi-Feng Wang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 8, 2019\\nAs more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\\nCertain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.\\nAs an example, Image 1 is the sigmoid function and its derivative. Note how when the inputs of the sigmoid function becomes larger or smaller (when |x| becomes bigger), the derivative becomes close to zero.\\nFor shallow network with only a few layers that use these activations, this isn’t a big problem. However, when more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>4234</td>\n",
       "      <td>Prashant Gupta</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Regularization in Machine Learning | by Prashant Gupta | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 15, 2017\\nOne of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don’t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.\\nThe concept of balancing bias and variance, is helpful in understanding the phenomenon of overfitting.\\nmedium.com\\nOne of the ways of avoiding overfitting is using cross validation, that helps in estimating the error over test set, and in deciding what parameters work best for your model.\\nmedium.com\\nThis arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>4235</td>\n",
       "      <td>Saul Dobilas</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/gmm-gaussian-mixture-models-how-to-successfully-use-it-to-cluster-your-data-891dc8ac058f?source=tag_archive---------7-----------------------</td>\n",
       "      <td>GMM: Gaussian Mixture Models — How to Successfully Use It to Cluster Your Data? | by Saul Dobilas | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 23, 2021\\nThis article is part of the series that explains how different Machine Learning algorithms work and provides you a range of Python examples to help you get started with your own Data Science project.\\nWhile it is not always possible to categorize every algorithm perfectly, it is still beneficial to try and do so. The below interactive chart is my attempt to help you see the broader universe of Machine Learning.\\nMake sure to click👇 on different categories to enlarge and reveal more.\\nNote, in many cases, the same algorithm can be used to solve multiple types of problems. E.g., one can use Neural Networks for classification, regression, and as part of the reinforcement learning.\\nIf you enjoy Data Science and Machine Learning, please subscribe to get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>4236</td>\n",
       "      <td>Vincenzo Lavorini</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/hackernoon/speeding-up-your-code-2-vectorizing-the-loops-with-numpy-e380e939bed3?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Speeding up your code (2): vectorizing the loops with Numpy | by Vincenzo Lavorini | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nAug 18, 2017\\nFrom this series:\\nIn the previous post I described the working environment and the basic code for clusterize points in the Poincaré ball space. Here I will improve that code transforming two loops to matrix operations.\\nI ended that post with a very promising plot about the speed improvement on a element-wise product of two vectors. So let’s detail it.\\nSuppose we have two arrays:\\nand we want to obtain as result an array where the elements are the element-wise multiplication of them:\\nWe can do it in two ways: with a loop over the elements, or with a vectorized operation. Now: what happens in terms of execution time? I did this calculations with arrays of different dimensions, ranging from 100.000 to 10.000.000.\\nIn the right plot you see the execution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>4237</td>\n",
       "      <td>Dr. Robert Kübler</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Bayesian Linear Regression in Python via PyMC3 | by Dr. Robert Kübler | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 30, 2020\\nIn this article, we will see how to conduct Bayesian linear regression with PyMC3. If you got here without knowing what Bayes or PyMC3 is, don’t worry! You can use my articles as a primer\\nYou can view Bayesian linear regression as a more verbose version of standard linear regression. Linear regression gives you single values, for the model parameters as well as the predictions. Bayesian linear regression, in turn, gives you distributions.\\nWe will see what this exactly means in a second. Let us quickly introduce a simple dataset to be able to compare both linear regression approaches.\\nWe have done it all several times: Grabbing a dataset containing features and continuous labels, then shoving a line through the data, and call it a day. As a running...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>4238</td>\n",
       "      <td>Baptiste Rocca</td>\n",
       "      <td>22</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Introduction to recommender systems | by Baptiste Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 2, 2019\\nThis post was co-written with Joseph Rocca.\\nDuring the last few decades, with the rise of Youtube, Amazon, Netflix and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\\nIn a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy or anything else depending on industries).\\nRecommender systems are really critical in some industries as they can generate a huge amount of income wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>4239</td>\n",
       "      <td>Kenneth Cortés Aguas</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b?source=tag_archive---------1-----------------------</td>\n",
       "      <td>A guide to transfer learning with Keras using ResNet50 | by Kenneth Cortés Aguas | Medium</td>\n",
       "      <td>Jul 4, 2020\\nIn this blog post we will provide a guide through for transfer learning with the main aspects to take into account in the process, some tips and an example implementation in Keras using ResNet50 as the trained model. The task is to transfer the learning of a ResNet50 trained with Imagenet to a model that identify images from CIFAR-10 dataset. Several methods were tested to achieve a greater accuracy which we provide to show the variety of options for a training. However with the final model of this blog we get an accuracy of 94% on test set.\\nLearning something new takes time and practice but we find it easy to do similar tasks. This is thanks to human association involved in learning. We have the capability to identify patterns from previous knowledge an apply it into new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4240</td>\n",
       "      <td>Dave Gershgorn</td>\n",
       "      <td>8</td>\n",
       "      <td>https://onezero.medium.com/gpt-3-is-an-amazing-research-tool-openai-isnt-sharing-the-code-d048ba39bbfd?source=tag_archive---------4-----------------------</td>\n",
       "      <td>GPT-3 Is an Amazing Research Tool. But OpenAI Isn’t Sharing the Code. | by Dave Gershgorn | OneZero</td>\n",
       "      <td>OneZero\\nAug 20, 2020\\nFor years, A.I. research lab OpenAI has been chasing the dream of an algorithm that can write like a human.\\nIts latest iteration on that concept, a language-generation algorithm called GPT-3...\\n532 \\n532 \\n4\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n19.1K Followers\\nSenior Writer at OneZero covering surveillance, facial recognition, DIY tech, and artificial intelligence. Previously: Qz, PopSci, and NYTimes.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4241</td>\n",
       "      <td>Ayush Pant</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to-machine-learning-for-beginners-eed6024fdb08?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Introduction to Machine Learning for Beginners | by Ayush Pant | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 7, 2019\\nWe have seen Machine Learning as a buzzword for the past few years, the reason for this might be the high amount of data production by applications, the increase of computation power in the past few years and the development of better algorithms.\\nMachine Learning is used anywhere from automating mundane tasks to offering intelligent insights, industries in every sector try to benefit from it. You may already be using a device that utilizes it. For example, a wearable fitness tracker like Fitbit, or an intelligent home assistant like Google Home. But there are much more examples of ML in use.\\nIt was in the 1940s when the first manually operated computer system, ENIAC (Electronic Numerical Integrator and Computer), was invented. At that time the word ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>4242</td>\n",
       "      <td>Jeff Nickoloff</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/on-docker/federated-clusters-with-docker-swarm-dce5516ecc8d?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Federated Clusters with Docker Swarm | by Jeff Nickoloff | On Docker | Medium</td>\n",
       "      <td>On Docker\\nMar 30, 2016\\nTL;DR Federated clustering overview with a focus on Swarm. Includes architecture diagrams and tools for building an experiment in AWS. Swarm’s API is a great building block that helps you create much more sophisticated deployment architectures or scale/diversify underlying infrastructure. Whale-Mullet is a Swarm fork I built to make the whole thing work.\\nDocker Swarm provides an abstraction that allows a user to treat a cluster like a single node. That is the case as long as the Swarm API is mostly compatible with the Docker API. This begs the question, “If I can treat a Swarm like a single machine can I create a Swarm of Swarm clusters?” This is called cluster federation. This article describes what how I tried to build a federated Swarm cluster, what problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4243</td>\n",
       "      <td>Syed Sadat Nazrul</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/clustering-based-unsupervised-learning-8d705298ae51?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Clustering Based Unsupervised Learning | by Syed Sadat Nazrul | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 3, 2018\\nUnsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from “unlabeled” data (a classification or categorization is not included in the observations). Common scenarios for using unsupervised learning algorithms include:- Data Exploration- Outlier Detection- Pattern Recognition\\nWhile there is an exhaustive list of clustering algorithms available (whether you use R or Python’s Scikit-Learn), I will attempt to cover the basic concepts.\\nThe most common and simplest clustering algorithm out there is the K-Means clustering. This algorithms involve you telling the algorithms how many possible cluster (or K) there are in the dataset. The algorithm then iteratively moves the k-centers and selects the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4244</td>\n",
       "      <td>Utkarsh Desai</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Training a Conditional DC-GAN on CIFAR-10 | by Utkarsh Desai | Medium</td>\n",
       "      <td>Jun 8, 2018\\nAfter some promising results and tons of learning (summarized in my previous post) with a basic DC-GAN on CIFAR-10 data, I wanted to play some more with GANs. One issue with a traditional DC-GAN was that the data is expected to have similar properties in order for the training to converge properly. For instance, in case of CIFAR-10, training the DC-GAN on images of a single class was much easier and more likely to produce sharp images than training on all 10 classes. In that post on GAN learnings, I had casually mentioned Conditional GANs as an improvement over traditional GANs when the training data might come from different classes. This post describes how to setup a Conditional DC-GAN to generate images from all the classes of CIFAR-10 data.\\nGenerative Adversarial Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>4245</td>\n",
       "      <td>Félix Revert</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/the-proper-way-to-use-machine-learning-metrics-4803247a2578?source=tag_archive---------8-----------------------</td>\n",
       "      <td>The proper way to use Machine Learning metrics | by Félix Revert | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 10, 2019\\nNote I focus on binary classification problems in this article, but the approach would be similar with multi classification and regression problems.\\nTry to convince someone that your ML model is accurate and should be trusted because it has a LogLoss of 0.34. Non data scientists will surely gawk at you while data scientists will ask for a lot more information.\\nAs a data scientist, you know it’s hard to make it clear (particularly to non data scientists) why your model should be trusted because you cannot easily translate complex measures of accuracy into tangible elements. And that’s 100% legitimate, models should be understood by everyone, at least their accuracy.\\nOn top of it, if your approach is scientifically correct, your model should have at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>4246</td>\n",
       "      <td>Alexander Hirner</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/moonvision/few-shot-object-detection-in-practice-4f8fa98cba57?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Few-shot Object Detection in Practice | by Alexander Hirner | Moonvision | Medium</td>\n",
       "      <td>Moonvision\\nApr 12, 2019\\nObject detection is vital to automate manual tasks, such as checking the completeness of objects and the exact types of its parts. In contrast to segmentation, objects are located and classified as discrete instances. This is achieved by decoding regression and activation maps after a cascade of convolutions. You can read more about state-of-the art in object detection in this survey.\\nHowever, contemporary issues in object detection are often studied in isolation. In production use cases though, multiple constraints must be solved at once. In this post, we describe the combination of techniques that we’ve developed over time that meet many of these constraints.\\nAs with any machine learning task, the amount of training data is limited. As we will review below...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>4247</td>\n",
       "      <td>Gabriel Cassimiro</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Object detection with Tensorflow model and OpenCV | by Gabriel Cassimiro | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 15, 2021\\nIn this article, I’m going to demonstrate how to use a trained model to detect objects in images and videos using two of the best libraries for this kind of problem. For the detection, we need a model capable of predicting multiple classes in an image and returning the location of those objects so that we can place boxes on the image.\\nWe are going to use a model from the Tensorflow Hub library, which has multiple ready to deploy models trained in all kinds of datasets and to solve all kinds of problems. For our use, I filtered models trained for object detection tasks and models in the TFLite format. This format is usually used for IoT applications, for its small size and faster performance than bigger models. I choose this format because I intend t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>4248</td>\n",
       "      <td>Lavanya Gupta</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/how-batch-normalization-and-relu-solve-vanishing-gradients-3f1a8ace1c88?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Batch Normalization and ReLU for solving Vanishing Gradients | by Lavanya Gupta | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nApr 26, 2021\\nA logical and sequential roadmap to understanding the advanced concepts in training deep neural networks.\\nWe will break our discussion into 4 logical parts that build upon each other. For the best reading experience, please go through them sequentially:\\n1. What is Vanishing Gradient? Why is it a problem? Why does it happen?2. What is Batch Normalization? How does it help in Vanishing Gradient?3. How does ReLU help in Vanishing Gradient?4. Batch Normalization for Internal Covariate Shift\\nFirst, let’s understand what vanishing means:\\nVanishing means that it goes towards 0 but will never really be 0.\\nVanishing gradient refers to the fact that in deep neural networks, the backpropagated error signal (gradient) typically decreases exponentially as a func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>4249</td>\n",
       "      <td>Tim Löhr</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/k-means-clustering-and-the-gap-statistics-4c5d414acd29?source=tag_archive---------5-----------------------</td>\n",
       "      <td>K-Means Clustering and the Gap-Statistics | by Tim Löhr | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 22, 2020\\nThere is a lot of code going on under the hood. That’s why I provide my Github repository at the end of this post and I show just a little code of the K-Means.\\nClustering is an important technique in Pattern Analysis to identify distinct groups in data. Due to data being mostly more than three-dimensional, we perform dimensionality reduction methods like PCA or Laplacian Eigenmaps before applying a clustering technique. The data is then available in 2D or 3D and this allows us to visualize the found clusters very nicely to humans. Even though this is a basic workflow, it is not always the case.\\nData is also often unlabeled. This means you have no clear definition of what you want to find within this data. That’s why clustering is a good data explor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>4250</td>\n",
       "      <td>Dan Hill</td>\n",
       "      <td>20</td>\n",
       "      <td>https://medium.com/dark-matter-and-trojan-horses/of-brains-and-cities-neuroscience-and-cultures-of-decision-making-6bc6abb48d4b?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Of brains and cities; neuroscience and cultures of decision-making | by Dan Hill | Dark Matter and Trojan Horses | Medium</td>\n",
       "      <td>Dark Matter and Trojan Horses\\nDec 21, 2011\\nA chilly December night in 2011. I had been invited to take part in an evening event called the North House Salon, one of a series of salons...\\nArticles, cases and considerations regarding strategic design practice and thinking.\\n21K Followers\\nDesigner, urbanist, etc. Director of Strategic Design at Vinnova, Swedish govt. Prof. AHO Oslo, Visiting Prof. UCL Bartlett IIPP, Design Academy Eindhoven, RMIT\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4251</td>\n",
       "      <td>Tiago M. Leite</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/ensina-ai/redes-neurais-perceptron-multicamadas-e-o-algoritmo-backpropagation-eaf89778f5b8?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Redes Neurais, Perceptron Multicamadas e o Algoritmo Backpropagation | by Tiago M. Leite | Ensina.AI | Medium</td>\n",
       "      <td>Ensina.AI\\nMay 10, 2018\\nVocê já se perguntou como funcionam os sistemas de reconhecimento de imagem? Como um aplicativo do seu celular faz para detectar rostos, ou um teclado inteligente sugere a próxima palavra? As chamadas Redes Neurais tem sido amplamente usadas para tarefas como essas, mas mostraram-se úteis também em outras áreas, como aproximação de funções, previsão de séries temporais e processamento de linguagem natural.\\nNeste artigo, explico como funciona um tipo básico de Rede Neural, o Perceptron Multicamadas, e um fascinante algoritmo responsável pelo aprendizado da rede, o backpropagation. Tal modelo de rede serviu de base para os modelos mais complexos hoje existentes, como as Redes Convolucionais, que são o estado da arte para classificação de imagens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4252</td>\n",
       "      <td>Tejan Karmali</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Spam Classifier in Python from scratch | by Tejan Karmali | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 2, 2017\\nWe all face the problem of spams in our inboxes. Let’s build a spam classifier program in python which can tell whether a given message is spam or not! We can do this by using a simple, yet powerful theorem from probability theory called Baye’s Theorem. It is mathematically expressed as\\nWe have a message m = (w1, w2, . . . . , wn), where (w1, w2, . . . . , wn) is a set of unique words contained in the message. We need to find\\nIf we assume that occurrence of a word are independent of all other words, we can simplify the above expression to\\nIn order to classify we have to determine which is greater\\nWe are going to make use of NLTK for processing the messages, WordCloud and matplotlib for visualization and pandas for loading data, NumPy for generatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4253</td>\n",
       "      <td>Insight</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.insightdatascience.com/preparing-for-insight-ca7cc6087f91?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Preparing for Insight | by Insight | Insight</td>\n",
       "      <td>Insight\\nApr 16, 2014\\nJohn Joo is an Insight alumnus from the August 2013 session with a PhD in applied physics from Harvard. He recently joined Insight as a Program Director in January, leading the most recent cohort of Fellows in their transition from academia to industry.\\nWhen I was first considering making the transition from applied physics to data science, I had a lot of questions. What skills did I need to develop to get started in data science? What courses should I take? Did I need to know how to program and code? What languages? How much statistics did I need to know? The list goes on. Now that I’ve spent a few months as a Program Director here at Insight, I think it’s time I shared with you the tools and tips that got me, and nearly 100 other Insight Fellows, started on ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4254</td>\n",
       "      <td>Aleksey Tikhonov</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/altsoph/google-ai-contest-eed23cfdeb6f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>GOOGLE AI CONTEST | by Aleksey Tikhonov | Altsoph’s blog | Medium</td>\n",
       "      <td>Altsoph’s blog\\nSep 16, 2010\\nВчера узнал, что сейчас идет Google AI Contest.\\nВ двух словах, задача состоит в написании логики бота, играющего в некоторый аналог игры Galcon — космической стратегии, основанной на разделении ресурсов. Прием ботов на конкурс идет до 27 ноября, а потом их будут стравливать и выявлять победителя. Языки доступны из списка C++, C#, Java, Python.\\nБыло бы времени побольше, я бы, наверное, поучавствовал.\\nВспоминаются стародавние времена, когда мы еще в школе рубились в RobotBattle, а потом на первом курсе с группой сотоварищей писали интерпретатор RedCode на придуманной нами модели тороидальной памяти (ToroWars).\\nRandom notes on people and machines\\n274 Followers\\nhttp://altsoph.com, Senior Data Analyst, Researcher.\\nHelp\\nStatus\\nWriters\\nBlog\\nCar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4255</td>\n",
       "      <td>Victor Sanh</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/huggingface/distilbert-8cf3380435b5?source=tag_archive---------5-----------------------</td>\n",
       "      <td>🏎 Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT | by Victor Sanh | HuggingFace | Medium</td>\n",
       "      <td>HuggingFace\\nAug 28, 2019\\n2019, October 3rd — Update: We are releasing our NeurIPS 2019 workshop paper describing our approach on DistilBERT with improved results: 97% of BERT’s performance on GLUE (the results in the paper superseed the results presented here). The approach is slightly different from the one explained in this present blog post so this blog post should be a good entry point to the paper! We applied the same method to GPT2 and are releasing DistilGPT2! Training code and pre-trained weights for DistilBERT and DistilGPT2 are available here. 🤗\\nIn the last 18 months, transfer learning from large-scale language models has significantly improved upon the state-of-the-art on pretty much every Natural Language Processing task.\\nUsually based on the Transformer architecture of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c2fd3ba-33b1-4e1e-8c46-ae5e9256a332')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4c2fd3ba-33b1-4e1e-8c46-ae5e9256a332 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4c2fd3ba-33b1-4e1e-8c46-ae5e9256a332');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       id                           author  reading_time  \\\n",
       "0    3756                     Rohit Thakur             8   \n",
       "1    3757               Giuliano Giacaglia            14   \n",
       "2    3758                  Darshan Adakane             7   \n",
       "3    3759                   Sachin Palewar             1   \n",
       "4    3760                      SDGCounting             2   \n",
       "5    3761                         Tam Pham             7   \n",
       "6    3762                   Virginia Peón             1   \n",
       "7    3763                          The Awl            10   \n",
       "8    3764                      Ekta Sharma             9   \n",
       "9    3765                    Igor de Sousa             3   \n",
       "10   3766                     Adam Geitgey            15   \n",
       "11   3767                            Viraf            10   \n",
       "12   3768                   Pankaj Kishore            17   \n",
       "13   3769                  Ruben Winastwan             9   \n",
       "14   3770                    Ronak Nathani             9   \n",
       "15   3771                      George Seif            11   \n",
       "16   3772                 Record Evolution            18   \n",
       "17   3773                   Lachlan Miller             5   \n",
       "18   3774                     Julia Powles             8   \n",
       "19   3775                    Pulkit Sharma            13   \n",
       "20   3776                        Ryan Kwok             9   \n",
       "21   3777                       Hongri Jia             7   \n",
       "22   3778                    Justin Davies             1   \n",
       "23   3779                 Johannes Schmidt             6   \n",
       "24   3780                   Harsh Pokharna             5   \n",
       "25   3781                  Debmalya Biswas             8   \n",
       "26   3782                      Javaid Nabi             9   \n",
       "27   3783                  Renu Khandelwal             8   \n",
       "28   3784            Hrishikesh Huilgolkar             4   \n",
       "29   3785                    Jan Schultink             1   \n",
       "30   3786                 Siladittya Manna             4   \n",
       "31   3787                            Knoyd             4   \n",
       "32   3788                       Ryan Burke            10   \n",
       "33   3789                   Jeremie Harris             4   \n",
       "34   3790                  Pavel Shestakov             2   \n",
       "35   3791                      Saidakbar P            15   \n",
       "36   3792                     Prince Yadav             9   \n",
       "37   3793                     Julia Powles             8   \n",
       "38   3794                 Gabriel Pierobon             5   \n",
       "39   3795                    Anas Al-Masri            10   \n",
       "40   3796                       Matt Kiser             4   \n",
       "41   3797                  Pedro Marcelino            14   \n",
       "42   3798                      michaelulin            10   \n",
       "43   3799               Chi-Lan Yang | 楊期蘭             7   \n",
       "44   3800                    Manjeet Singh             6   \n",
       "45   3801                      Elior Cohen             9   \n",
       "46   3802                 Sambit Mahapatra             6   \n",
       "47   3803                      Ceshine Lee             3   \n",
       "48   3804                   Daniel Voshart             4   \n",
       "49   3805         Chandra Churh Chatterjee             8   \n",
       "50   3806                  Gustavo Chávez             6   \n",
       "51   3807                   Apdullah Yayik             4   \n",
       "52   3808                  Renu Khandelwal            12   \n",
       "53   3809                  Erik Hallström             7   \n",
       "54   3810                   Veysel Kocaman            11   \n",
       "55   3811          Marcio Geovani Jasinski             3   \n",
       "56   3812                    Vicente Luego             2   \n",
       "57   3813                    LucianoSphere            22   \n",
       "58   3814               Jean-Marc Beaujour             4   \n",
       "59   3815                       Justin Lee            11   \n",
       "60   3816                       Yash Patel            13   \n",
       "61   3817                     Victor Roman            17   \n",
       "62   3818               Kaustubh Mhaisekar             8   \n",
       "63   3819                     James Briggs             7   \n",
       "64   3820               Maneesha Rajaratne             8   \n",
       "65   3821                      Essam Wisam            10   \n",
       "66   3822                    John Olafenwa            12   \n",
       "67   3823                    Arsh Chowdhry             8   \n",
       "68   3824                  Kaushal Trivedi             7   \n",
       "69   3825                        commander             6   \n",
       "70   3826               Acuity Derivatives             2   \n",
       "71   3827                    Jehill Parikh             8   \n",
       "72   3828                       Wolf Garbe             6   \n",
       "73   3829           Amanda Iglesias Moreno            11   \n",
       "74   3830                       Paul Ellis             8   \n",
       "75   3831                  Olga Chernytska            13   \n",
       "76   3832                     Praveenkumar             5   \n",
       "77   3833                  Chijioke Nwagwu             3   \n",
       "78   3834                    Shivam Duseja             9   \n",
       "79   3835            Jonny Brooks-Bartlett             8   \n",
       "80   3836                     Rishit Dagli             6   \n",
       "81   3837                  Sanne de Roever             7   \n",
       "82   3838                Kirill Bondarenko             6   \n",
       "83   3839                     Goibibo Tech             1   \n",
       "84   3840                          Shi Yan             7   \n",
       "85   3841                     Pavan Gurram             7   \n",
       "86   3842                           Synced             4   \n",
       "87   3843                     Rajneesh Jha             6   \n",
       "88   3844            Dimitris Panagopoulos             4   \n",
       "89   3845                          Mo Hajr             7   \n",
       "90   3846                      Javaid Nabi            13   \n",
       "91   3847                     SAGAR SHARMA             5   \n",
       "92   3848                   Moses Olafenwa             9   \n",
       "93   3849             Vincenzo Santopietro             6   \n",
       "94   3850                   Connor Shorten             6   \n",
       "95   3851                    Akash Panchal            10   \n",
       "96   3852                Vincenzo Lavorini             7   \n",
       "97   3853                 Supriya Secherla             5   \n",
       "98   3854                    Hucker Marius            10   \n",
       "99   3855                   Craig Villamor             1   \n",
       "100  3856                     Pranay Dugar             6   \n",
       "101  3857                   Arthur Juliani             6   \n",
       "102  3858                  Dario Radečić             5   \n",
       "103  3859                  André Ferreira            24   \n",
       "104  3860                 Kate Marie Lewis             8   \n",
       "105  3861                 Taras Bakusevych             7   \n",
       "106  3862                    Joshua Holmes             4   \n",
       "107  3863                    Roan Gylberth             6   \n",
       "108  3864              TokenGo Platform_RU             4   \n",
       "109  3865                      karthic Rao             2   \n",
       "110  3866                          Pallawi             9   \n",
       "111  3867                        Unchainet             2   \n",
       "112  3868                           Justin             3   \n",
       "113  3869                   Daniel Emaasit             1   \n",
       "114  3870                           RomRoc             5   \n",
       "115  3871                     Javed Shaikh             7   \n",
       "116  3872                       Bruce Yang            15   \n",
       "117  3873                          Firefox             4   \n",
       "118  3874                      Ketan Doshi            14   \n",
       "119  3875          Chunguang (Wayne) Zhang             8   \n",
       "120  3876                       Uday Paila             7   \n",
       "121  3877                  Manish Chablani             5   \n",
       "122  3878                     Charlie Kufs             6   \n",
       "123  3879                      Tara Mullin             3   \n",
       "124  3880            Amirhossein Heydarian             5   \n",
       "125  3881                   Learner Subodh             8   \n",
       "126  3882                     Walid Amamou             7   \n",
       "127  3883                   Arthur Juliani             6   \n",
       "128  3884                        Becky Zhu             3   \n",
       "129  3885                    Utkarsh Ankit            13   \n",
       "130  3886                   Venkatesh Tata            10   \n",
       "131  3887                     Sarthak Jain            10   \n",
       "132  3888                  Renu Khandelwal             6   \n",
       "133  3889                   Brandon Walker             6   \n",
       "134  3890                       bitsofinfo            16   \n",
       "135  3891                 Andreas Yonathan             6   \n",
       "136  3892          Rostyslav Neskorozhenyi            13   \n",
       "137  3893                  Manish Chablani             4   \n",
       "138  3894                      Anne Bonner             8   \n",
       "139  3895                  Diego Lopez Yse            13   \n",
       "140  3896                  Jessica Dafflon             9   \n",
       "141  3897  Matthew Stewart, PhD Researcher             9   \n",
       "142  3898                 Md Sohel Mahmood             6   \n",
       "143  3899                 Vladimir Shapiro             7   \n",
       "144  3900                         Susan Li             5   \n",
       "145  3901                  Neeraj Varshney            10   \n",
       "146  3902                     Aakanksha NS             6   \n",
       "147  3903                  Animesh Agarwal             7   \n",
       "148  3904              Vindula Jayawardana             5   \n",
       "149  3905              Dhruv Parthasarathy            11   \n",
       "150  3906                Sebastian Theiler             7   \n",
       "151  3907                 Himanshu Chandra             8   \n",
       "152  3908                    William Scott            19   \n",
       "153  3909                      Kevin Luxem            10   \n",
       "154  3910                     Sourav kumar            12   \n",
       "155  3911                     Elif Meşeci             4   \n",
       "156  3912                     M Bharathwaj            11   \n",
       "157  3913                    Sairaj Neelam            11   \n",
       "158  3914                    Rowel Atienza             6   \n",
       "159  3915                      Michael Phi            10   \n",
       "160  3916                    IPG Media Lab             1   \n",
       "161  3917                       Gabe Flomo             6   \n",
       "162  3918                       Sumit Saha             7   \n",
       "163  3919                   Diganta Kalita             6   \n",
       "164  3920               Lihi Gur Arie, PhD             7   \n",
       "165  3921                   Isaac Godfried             8   \n",
       "166  3922                     Oleg Polosin             4   \n",
       "167  3923                      Luís Roque            11   \n",
       "168  3924                     Adam Pickard             5   \n",
       "169  3925                      Jongdae Lim            24   \n",
       "170  3926                     Daniel Godoy            21   \n",
       "171  3927                     Debarko De 🦁            12   \n",
       "172  3928                 Ayushi choudhary             4   \n",
       "173  3929                 Samuele Mazzanti             6   \n",
       "174  3930                      Mukul Malik             8   \n",
       "175  3931                Dr. Varshita Sher            12   \n",
       "176  3932                       Rob Parkin             5   \n",
       "177  3933                      Steven Shen            15   \n",
       "178  3934                    Robbie Tilton            15   \n",
       "179  3935                       Kyle Huang            11   \n",
       "180  3936                        James Lee             7   \n",
       "181  3937                   Korbinian Koch            15   \n",
       "182  3938                      Shay Geller            13   \n",
       "183  3939                        jiawei hu            17   \n",
       "184  3940                      Vivek Yadav             2   \n",
       "185  3941                SYED JUNAID IQBAL            12   \n",
       "186  3942           Snehal Reddy Koukuntla             6   \n",
       "187  3943                        Aerin Kim             8   \n",
       "188  3944                       Suhyun Kim             7   \n",
       "189  3945                 Aneesha Bakharia             3   \n",
       "190  3946                           Matt.0            15   \n",
       "191  3947                     Joseph Rocca            20   \n",
       "192  3948                          Insight             5   \n",
       "193  3949                       Kaustubh N             3   \n",
       "194  3950                     Thomas Smith             9   \n",
       "195  3951              Ravi Prakash pandey             6   \n",
       "196  3952              Aleksi Pietikäinen            14   \n",
       "197  3953                  Darshan Adakane             7   \n",
       "198  3954                   Anish Shrestha            17   \n",
       "199  3955                           Synced             5   \n",
       "200  3956                Bhuvana Kundumani             5   \n",
       "201  3957                     Sourav kumar            12   \n",
       "202  3958                       Wamika Jha             5   \n",
       "203  3959                   Maria Neumayer             1   \n",
       "204  3960                         Susan Li             5   \n",
       "205  3961                      Mark Garvey             7   \n",
       "206  3962                           Synced             5   \n",
       "207  3963                     Gorkem Polat             7   \n",
       "208  3964                 Taras Bakusevych            10   \n",
       "209  3965              RAVI SHEKHAR TIWARI             9   \n",
       "210  3966                           Synced             4   \n",
       "211  3967                       Ayush Pant             9   \n",
       "212  3968              TokenGo Platform_RU             3   \n",
       "213  3969                     Boaz Shmueli             7   \n",
       "214  3970                 Thiago Julio, MD             3   \n",
       "215  3971          Netflix Technology Blog             5   \n",
       "216  3972                      Victor Zhou             9   \n",
       "217  3973                  Bernardo Caldas             6   \n",
       "218  3974                         A Ydobon             5   \n",
       "219  3975                           Synced             3   \n",
       "220  3976                  Helena Campbell             5   \n",
       "221  3977                      NN Intruder            15   \n",
       "222  3978                   Harald Scheidl             8   \n",
       "223  3979                   Abdarhman Taha             4   \n",
       "224  3980                Gerard Maggiolino             9   \n",
       "225  3981                    Surya Remanan             6   \n",
       "226  3982                       Nishanth N             3   \n",
       "227  3983                           Maxime            13   \n",
       "228  3984                           Synced             3   \n",
       "229  3985                     Kamil Mysiak            31   \n",
       "230  3986                             Josh             9   \n",
       "231  3987                   Jacob Solawetz             4   \n",
       "232  3988                  Andrej Karpathy             7   \n",
       "233  3989                   James Faghmous             6   \n",
       "234  3990                      Aqeel Anwar             9   \n",
       "235  3991                Thilina Rajapakse             8   \n",
       "236  3992                             Rafi             5   \n",
       "237  3993             Adrien Lucas Ecoffet             8   \n",
       "238  3994                         Patty Wu             7   \n",
       "239  3995                        Nhan Tran             5   \n",
       "240  3996                  thirumalaivasan             2   \n",
       "241  3997                         Susan Li             7   \n",
       "242  3998                          dan lee             8   \n",
       "243  3999                   Pankaj Jainani             6   \n",
       "244  4000                Michael Bronstein            11   \n",
       "245  4001                   Nurlan Kerimov            13   \n",
       "246  4002                   Harald Scheidl             9   \n",
       "247  4003                      Mikhail Mew             4   \n",
       "248  4004                    Park Chansung             9   \n",
       "249  4005                  Renu Khandelwal            12   \n",
       "250  4006                      Kerish Heik             3   \n",
       "251  4007                    Anusha Lihala             6   \n",
       "252  4008                     Supervise.ly            11   \n",
       "253  4009          Tobias Skovgaard Jepsen             9   \n",
       "254  4010                       Merzmensch             7   \n",
       "255  4011                    Akihiro FUJII            13   \n",
       "256  4012                 Rakshith Vasudev             8   \n",
       "257  4013                  Thomas HARTMANN             7   \n",
       "258  4014                       Nishanth N             3   \n",
       "259  4015                         Chung-Yi             5   \n",
       "260  4016                  João Fernandes             5   \n",
       "261  4017                       ASHNA JAIN            10   \n",
       "262  4018                     Eric Elliott            11   \n",
       "263  4019              Huangwei Wieniawska            10   \n",
       "264  4020                     R. E. Warner             1   \n",
       "265  4021                       m.zaradzki             7   \n",
       "266  4022                      karthic Rao             6   \n",
       "267  4023                   Thomas Filaire             7   \n",
       "268  4024                      Alex Lenail             7   \n",
       "269  4025                  Michael L. Peng             4   \n",
       "270  4026                   Marco Cerliani             7   \n",
       "271  4027                         Susan Li             5   \n",
       "272  4028                      Aji Abraham             2   \n",
       "273  4029                    LucianoSphere             9   \n",
       "274  4030                     Eitan Kosman             6   \n",
       "275  4031                     Benedict Neo            14   \n",
       "276  4032                     Luuk Derksen             6   \n",
       "277  4033                      Ryan Kemmer             5   \n",
       "278  4034                  Haripriya Reddy             6   \n",
       "279  4035                   Masumi Mutsuda             2   \n",
       "280  4036                    Uri Eliabayev             4   \n",
       "281  4037                Ravindra Kompella             7   \n",
       "282  4038                    Roland Hewage            11   \n",
       "283  4039                              Tan            10   \n",
       "284  4040                         Progress             5   \n",
       "285  4041            Md Shahidullah Kawsar             3   \n",
       "286  4042                       Dmitry Kan            13   \n",
       "287  4043                      Justin Chen             2   \n",
       "288  4044                     Jhen Hilario             1   \n",
       "289  4045              Akshika Wijesundara             6   \n",
       "290  4046                     Jonathan Hui            11   \n",
       "291  4047                  Kai Stinchcombe            11   \n",
       "292  4048                     Luiz Fonseca             8   \n",
       "293  4049                    Haaya Naushan             8   \n",
       "294  4050                   Jerome Bouchon             5   \n",
       "295  4051                      Halil Ertan            19   \n",
       "296  4052                  Manish Chablani             4   \n",
       "297  4053                          Chinmay             5   \n",
       "298  4054                     Sourav kumar            12   \n",
       "299  4055                       ProjectAGI             5   \n",
       "300  4056                   Stepan Ulyanin            11   \n",
       "301  4057                        Adam King            14   \n",
       "302  4058               Sachin Abeywardana             1   \n",
       "303  4059                       Brian Ward             8   \n",
       "304  4060                      Kyle Dorman            19   \n",
       "305  4061                    David Venturi            20   \n",
       "306  4062                      Nick Kasten             9   \n",
       "307  4063                      Jiahao Weng             5   \n",
       "308  4064             Wenchen's ai fantasy             3   \n",
       "309  4065                      Thomas Wolf            12   \n",
       "310  4066                     Neelabh Pant            11   \n",
       "311  4067              TokenGo Platform_RU             3   \n",
       "312  4068         Chandra Churh Chatterjee             8   \n",
       "313  4069                       Arun Kumar            16   \n",
       "314  4070                      Ceshine Lee             6   \n",
       "315  4071                      Jack Morris             7   \n",
       "316  4072                     William Ryan             5   \n",
       "317  4073                     Satyam Kumar             5   \n",
       "318  4074                    Park Chansung             9   \n",
       "319  4075                      Shiva Verma             5   \n",
       "320  4076    Anuj shah (Exploring Neurons)             6   \n",
       "321  4077                     Ethan Siegel             5   \n",
       "322  4078                   Prakash Pandey            12   \n",
       "323  4079                  Hubert Baniecki             4   \n",
       "324  4080                  Charles Kapelke            10   \n",
       "325  4081                       Alfi Salim             5   \n",
       "326  4082                 Marie Imokoyende             9   \n",
       "327  4083                Stefan Kojouharov             8   \n",
       "328  4084                  Sambasivarao. K             4   \n",
       "329  4085                      Jimmi Dyson             5   \n",
       "330  4086        DataAnalysis For Beginner             4   \n",
       "331  4087            Viet Hoang Tran Duong             9   \n",
       "332  4088                    Chris Fotache             7   \n",
       "333  4089                     Thomas Smith             9   \n",
       "334  4090                      Robin Vinod             5   \n",
       "335  4091                    Ravish Chawla             7   \n",
       "336  4092                 Frank Bonsal III             8   \n",
       "337  4093                         Ekin Tiu             9   \n",
       "338  4094                       Ryan Burke             9   \n",
       "339  4095                    Matt Schlicht            11   \n",
       "340  4096                     Manish Nayak             5   \n",
       "341  4097                     Prem Prakash             7   \n",
       "342  4098                    Mohantysandip             4   \n",
       "343  4099             Mohammed AL-Ma'amari             5   \n",
       "344  4100                     Vishal Maini            13   \n",
       "345  4101                    Nikhil Parmar             6   \n",
       "346  4102                   Akanksha Rawat             6   \n",
       "347  4103                    Hemant Ranvir             9   \n",
       "348  4104                     Jonathan Hui            18   \n",
       "349  4105                  Geneonline-基因線上             4   \n",
       "350  4106                Hemanth Pedamallu             7   \n",
       "351  4107                Maximus Mutschler             3   \n",
       "352  4108                Nick Komissarenko             4   \n",
       "353  4109                        Ryan Kwok             9   \n",
       "354  4110                     Puneet Singh             4   \n",
       "355  4111                  Saket Dingliwal             4   \n",
       "356  4112                     Shivon Zilis            10   \n",
       "357  4113                      Shiva Verma             3   \n",
       "358  4114                       Akash Deep             8   \n",
       "359  4115                   Shashank Yadav             5   \n",
       "360  4116                Jaimin Mungalpara             7   \n",
       "361  4117                      Ekta Sharma             9   \n",
       "362  4118                  Jordi TORRES.AI            23   \n",
       "363  4119                     Tejas Morkar            11   \n",
       "364  4120                  Matheus Jacques             5   \n",
       "365  4121                      Susan Maina             6   \n",
       "366  4122                 Mohammed Sunasra            10   \n",
       "367  4123                     Igor Susmelj             5   \n",
       "368  4124                  Manish Chablani             5   \n",
       "369  4125                 Ajinkya Sonawane             5   \n",
       "370  4126                   Ashish Singhal             5   \n",
       "371  4127                    Hely Marleena            10   \n",
       "372  4128                       Wolf Garbe             6   \n",
       "373  4129                       Klas Leino            11   \n",
       "374  4130                    Udacity India             3   \n",
       "375  4131                    Kacper Kubara             6   \n",
       "376  4132                Emil Lykke Jensen             8   \n",
       "377  4133                     Victor Roman            13   \n",
       "378  4134                       Jane Huang            18   \n",
       "379  4135                    Mayank Mishra             9   \n",
       "380  4136                 Pau Labarta Bajo            10   \n",
       "381  4137                Madeline Schiappa             4   \n",
       "382  4138        DataAnalysis For Beginner             3   \n",
       "383  4139             Pranoy Radhakrishnan             8   \n",
       "384  4140               platfarm tech team            14   \n",
       "385  4141                     Parul Pandey            10   \n",
       "386  4142                Martín Pellarolo             4   \n",
       "387  4143                          Reo Neo             8   \n",
       "388  4144                     Aman Kharwal             2   \n",
       "389  4145                       Haihan Lan             7   \n",
       "390  4146                  Pranav Budhwant            10   \n",
       "391  4147                 Shivy Yohanandan             5   \n",
       "392  4148                    Kyle McDonald             7   \n",
       "393  4149                    Peter Bulyaki             5   \n",
       "394  4150                           Synced             3   \n",
       "395  4151                      Nir Ben-Zvi            22   \n",
       "396  4152              Nathan Cooper Jones            12   \n",
       "397  4153                      Ahmet Genç             5   \n",
       "398  4154                       Max Pagels             7   \n",
       "399  4155                  Chris Loughnane             7   \n",
       "400  4156                         Susan Li             7   \n",
       "401  4157                      Pandorabots             3   \n",
       "402  4158                     Harsh Sharma             9   \n",
       "403  4159                  Prajwal Paudyal             9   \n",
       "404  4160                           Yang S             6   \n",
       "405  4161                          Karl N.             7   \n",
       "406  4162                      ASHISH RANA            12   \n",
       "407  4163              Volkan Levent Soylu             4   \n",
       "408  4164                editorCapire.info             5   \n",
       "409  4165                        Enoch Kan             3   \n",
       "410  4166        Towards AI Editorial Team            26   \n",
       "411  4167               Francesco Gadaleta             4   \n",
       "412  4168               surendranath bobba             5   \n",
       "413  4169                          Hshan.T             7   \n",
       "414  4170              Sudip Shrestha, PhD            17   \n",
       "415  4171                   Tanya Dayanand            15   \n",
       "416  4172                  Renu Khandelwal             8   \n",
       "417  4173                    Chi-Feng Wang             8   \n",
       "418  4174                     Jonathan Hui            18   \n",
       "419  4175                       Arun Kumar            17   \n",
       "420  4176                    Bayan Bennett             3   \n",
       "421  4177                      George Seif            11   \n",
       "422  4178                   Shashank Yadav             5   \n",
       "423  4179                     Joseph Rocca            20   \n",
       "424  4180                       Kopal Jain             4   \n",
       "425  4181                          Amin Ag             4   \n",
       "426  4182                Sema Zeynep Bulut             6   \n",
       "427  4183                            ilmoi            12   \n",
       "428  4184                    Andrew Marmon             5   \n",
       "429  4185                    Prince Grover             8   \n",
       "430  4186                   Andre Violante             5   \n",
       "431  4187                   Arthur Juliani             6   \n",
       "432  4188                 Rizky Luthfianto             4   \n",
       "433  4189                        Azad Soni             3   \n",
       "434  4190                     JP Zamanillo             5   \n",
       "435  4191                       Anson Wong             6   \n",
       "436  4192           Patrick Langechuan Liu            16   \n",
       "437  4193                      Aqeel Anwar             8   \n",
       "438  4194                         Susan Li            10   \n",
       "439  4195                    Boris Knyazev            16   \n",
       "440  4196                   Sabina Pokhrel            13   \n",
       "441  4197                      Essam Wisam             6   \n",
       "442  4198                       Zijing Zhu             8   \n",
       "443  4199                  Varun Saravanan            15   \n",
       "444  4200        DataAnalysis For Beginner             3   \n",
       "445  4201                  Carlos E. Perez            12   \n",
       "446  4202                    Ilma Arifiany             4   \n",
       "447  4203                           Dinesh            13   \n",
       "448  4204                    Boris Anthony             6   \n",
       "449  4205                       Shuchen Du             4   \n",
       "450  4206                    Rising Odegua            11   \n",
       "451  4207               Prem Chandra Singh             5   \n",
       "452  4208                     Jonathan Hui             7   \n",
       "453  4209                        EarnSkins             4   \n",
       "454  4210                          Gene Su            13   \n",
       "455  4211                   Isaac Godfried            14   \n",
       "456  4212                Ashutosh Bhardwaj             3   \n",
       "457  4213                      Destin Gong            11   \n",
       "458  4214                       Sagi eppel             9   \n",
       "459  4215                     Jake Grigsby             8   \n",
       "460  4216                   Piero Esposito             5   \n",
       "461  4217                  Adrian Yijie Xu             8   \n",
       "462  4218                    Maryam Fallah            12   \n",
       "463  4219                The NYT Open Team             3   \n",
       "464  4220                      Kenny Jones            13   \n",
       "465  4221                     Charlie Kufs             6   \n",
       "466  4222                    Boris Knyazev            17   \n",
       "467  4223           DataCrafts @ DataWeave             3   \n",
       "468  4224                Baptiste Monpezat             7   \n",
       "469  4225             Maarten Grootendorst             7   \n",
       "470  4226                    Chi-Feng Wang             8   \n",
       "471  4227                  Bruce MacDonald             7   \n",
       "472  4228                   Connor Shorten             8   \n",
       "473  4229                    Pankaj Mathur             4   \n",
       "474  4230                     Luiz Fonseca             8   \n",
       "475  4231                         Susan Li             9   \n",
       "476  4232                           Zhi Li             8   \n",
       "477  4233                    Chi-Feng Wang             3   \n",
       "478  4234                   Prashant Gupta             7   \n",
       "479  4235                     Saul Dobilas             9   \n",
       "480  4236                Vincenzo Lavorini             6   \n",
       "481  4237               Dr. Robert Kübler            10   \n",
       "482  4238                   Baptiste Rocca            22   \n",
       "483  4239            Kenneth Cortés Aguas            11   \n",
       "484  4240                   Dave Gershgorn             8   \n",
       "485  4241                       Ayush Pant             6   \n",
       "486  4242                   Jeff Nickoloff             8   \n",
       "487  4243                Syed Sadat Nazrul             6   \n",
       "488  4244                    Utkarsh Desai             6   \n",
       "489  4245                    Félix Revert             8   \n",
       "490  4246                 Alexander Hirner             5   \n",
       "491  4247                Gabriel Cassimiro             3   \n",
       "492  4248                    Lavanya Gupta             7   \n",
       "493  4249                        Tim Löhr            10   \n",
       "494  4250                         Dan Hill            20   \n",
       "495  4251                   Tiago M. Leite             9   \n",
       "496  4252                    Tejan Karmali             6   \n",
       "497  4253                          Insight             5   \n",
       "498  4254                 Aleksey Tikhonov             1   \n",
       "499  4255                      Victor Sanh            10   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                     link  \\\n",
       "0                                                                                                                                                                                https://towardsdatascience.com/step-by-step-r-cnn-implementation-from-scratch-in-python-e97101ccde55?source=tag_archive---------0-----------------------   \n",
       "1                                                                                                                                                                                                                            https://towardsdatascience.com/transformers-141e32e69591?source=tag_archive---------8-----------------------   \n",
       "2                                                                                                                                                                                                   https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------4-----------------------   \n",
       "3                                                                                                                                                                                                 https://medium.com/@palewar/amazons-artificial-artificial-intelligence-a5d89253184e?source=tag_archive---------0-----------------------   \n",
       "4                                                                                                                                                                                                 https://medium.com/sdg-counting/this-week-in-the-sdgs-february-17-2017-d88bc4d62dac?source=tag_archive---------0-----------------------   \n",
       "5                                                                                                                                                                                     https://medium.com/@mrtampham/my-unconventional-year-after-dropping-out-of-college-befb536852dc?source=tag_archive---------3-----------------------   \n",
       "6                                                                                                                                                                                                    https://lab.elconfidencial.com/introducci%C3%B3n-a-machine-learning-e3caed58e37a?source=tag_archive---------2-----------------------   \n",
       "7                                                                                                                                                                                                   https://medium.com/the-awl/when-exactly-did-it-get-cool-to-be-a-geek-44d360e98ba5?source=tag_archive---------0-----------------------   \n",
       "8                                                                                                                                                                                                            https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------7-----------------------   \n",
       "9                                                                                                                                                                                             https://medium.com/@igordesousa/lou-reed-entre-transformer-e-berlin-o-mito-3c5ff2c36f59?source=tag_archive---------3-----------------------   \n",
       "10                                                                                                                                                                                                                  https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471?source=tag_archive---------1-----------------------   \n",
       "11                                                                                                                                                                    https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047?source=tag_archive---------5-----------------------   \n",
       "12                                                                                                                                                  https://towardsdatascience.com/it-support-ticket-classification-and-deployment-using-machine-learning-and-aws-lambda-8ef8b82643b6?source=tag_archive---------2-----------------------   \n",
       "13                                                                                                                                                                                               https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f?source=tag_archive---------0-----------------------   \n",
       "14                                                                                                                                                                                        https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db?source=tag_archive---------0-----------------------   \n",
       "15                                                                                                                                                                                https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------0-----------------------   \n",
       "16                                                                                                                                                               https://medium.com/iot-and-cloud/iot-learning-algorithms-and-predictive-maintenance-3-few-shot-learning-95154b606197?source=tag_archive---------6-----------------------   \n",
       "17                                                                                                                                       https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd?source=tag_archive---------5-----------------------   \n",
       "18                                                                                                                                                                                 https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------7-----------------------   \n",
       "19                                                                                                                                          https://medium.com/analytics-vidhya/computer-vision-tutorial-implementing-mask-r-cnn-for-image-segmentation-with-python-code-fe34da5b99cd?source=tag_archive---------8-----------------------   \n",
       "20                                                                                                                                                                                                 https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------0-----------------------   \n",
       "21                                                                                                                                                                                                                 https://medium.com/henry-jia/how-to-score-your-credit-1c08dd73e2ed?source=tag_archive---------7-----------------------   \n",
       "22                                                                                                                                                                                    https://medium.com/@justindavies/from-gensim-models-doc2vec-import-labeledsentence-9b631f9f567f?source=tag_archive---------5-----------------------   \n",
       "23                                                                                                                                        https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862?source=tag_archive---------3-----------------------   \n",
       "24                                                                                                                                                           https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8?source=tag_archive---------9-----------------------   \n",
       "25                                                                                                                                                      https://medium.com/@debmalyabiswas/i-had-an-opportunity-to-attend-the-oreilly-ai-london-conference-oct-9-11-2018-bf304ad69fd8?source=tag_archive---------6-----------------------   \n",
       "26                                                                                                                                                                   https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456?source=tag_archive---------0-----------------------   \n",
       "27                                                                                                                                                                                  https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1?source=tag_archive---------0-----------------------   \n",
       "28                                                                                                                                                                              https://medium.com/@hrishikeshio/traveling-santa-problem-an-incompetent-algorists-attempt-49ad9d26b26?source=tag_archive---------9-----------------------   \n",
       "29                                                                                                                                                                                          https://medium.com/slidemagic/data-without-context-is-meaningless-and-boring-c4a9944959a8?source=tag_archive---------4-----------------------   \n",
       "30                                                                                                                                                                                                           https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538?source=tag_archive---------4-----------------------   \n",
       "31                                                                                                                                                                                                    https://medium.com/@Knoyd/gotta-catch-them-all-but-which-one-first-7d808378de72?source=tag_archive---------5-----------------------   \n",
       "32                                                                                                                                                                                                                        https://towardsdatascience.com/glove-elmo-bert-9dbbc9226934?source=tag_archive---------6-----------------------   \n",
       "33                                                                                                                                                                                                   https://towardsdatascience.com/ai-safety-and-the-scaling-hypothesis-76bfee57f924?source=tag_archive---------8-----------------------   \n",
       "34                                                                                                                                  https://medium.com/@am1goo/%D0%BF%D0%BE%D0%B4%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D0%B5-%D0%BA%D0%B0%D0%BC%D0%BD%D0%B8-unet-%D0%B2-unity-5-8e78a0e673b8?source=tag_archive---------0-----------------------   \n",
       "35                                                                                                                                                                                                      https://medium.com/@saidakbarp/real-time-face-recognition-tflite-3fb818ac039a?source=tag_archive---------4-----------------------   \n",
       "36                                                                                                                                                                                                      https://towardsdatascience.com/decision-tree-in-machine-learning-e380942a4c96?source=tag_archive---------4-----------------------   \n",
       "37                                                                                                                                                                                 https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------1-----------------------   \n",
       "38                                                                                                                                                                   https://towardsdatascience.com/dbscan-clustering-for-data-shapes-k-means-cant-handle-well-in-python-6be89af4e6ea?source=tag_archive---------0-----------------------   \n",
       "39                                                                                                                                                                            https://towardsdatascience.com/how-does-back-propagation-in-artificial-neural-networks-work-c7cad873ea7?source=tag_archive---------4-----------------------   \n",
       "40                                                                                                                                                          https://medium.com/emergent-future/teslas-big-plans-deepmind-pays-for-itself-internet-drones-and-moore-s-law-54e6bd8e2750?source=tag_archive---------8-----------------------   \n",
       "41                                                                                                                                                                                              https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751?source=tag_archive---------1-----------------------   \n",
       "42                                                                                                                                                                                 https://medium.com/@michaelulin/serving-pytorch-models-on-aws-lambda-with-caffe2-onnx-7b096806cfac?source=tag_archive---------8-----------------------   \n",
       "43                                                                                                                                       https://medium.com/%E4%BA%BA%E6%A9%9F%E5%85%B1%E7%94%9F%E4%BD%A0%E6%88%91%E5%AE%83/explainable-ai-for-intelligent-systems-part2-be9296529582?source=tag_archive---------5-----------------------   \n",
       "44                                                                                                                                                                  https://medium.com/data-science-group-iitr/artistic-style-transfer-with-convolutional-neural-network-7ce2476039fd?source=tag_archive---------0-----------------------   \n",
       "45                                                                                                                                                                             https://blog.mlreview.com/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07?source=tag_archive---------5-----------------------   \n",
       "46                                                                                                                                                                          https://towardsdatascience.com/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15?source=tag_archive---------3-----------------------   \n",
       "47                                                                                                                                                                                              https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66?source=tag_archive---------1-----------------------   \n",
       "48                                                                                                                                                                                                        https://medium.com/@voshart/appearance-of-the-principate-pt-ii-3df539f18fe5?source=tag_archive---------4-----------------------   \n",
       "49                                                                                                                                                                                                              https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------9-----------------------   \n",
       "50                                                                                                                                                                                         https://towardsdatascience.com/understanding-logistic-regression-step-by-step-704a78be7e0a?source=tag_archive---------2-----------------------   \n",
       "51                                                                                                                                                                https://medium.com/@apdullahyayik/mask-rcnn-object-recognition-and-segmentation-with-colab-application-cd0b5e490130?source=tag_archive---------8-----------------------   \n",
       "52                                                                                                                                                                              https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------0-----------------------   \n",
       "53                                                                                                                                                                                                                      https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767?source=tag_archive---------1-----------------------   \n",
       "54                                                                                                                                                             https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32?source=tag_archive---------1-----------------------   \n",
       "55                                                                                                                                                                                        https://medium.com/@marciogj/dbscan-on-trajectories-determining-eps-and-minpts-ba3aa7c4ed7c?source=tag_archive---------2-----------------------   \n",
       "56                                                                                                                                                                         https://medium.com/@vicenteluego/tiktoks-new-feature-anime-filter-got-million-posts-in-3-days-c18a866e842e?source=tag_archive---------7-----------------------   \n",
       "57                                                                                                                                                 https://towardsdatascience.com/alphafold-based-databases-and-fully-fledged-easy-to-use-alphafold-interfaces-poised-to-baf865c6d75e?source=tag_archive---------2-----------------------   \n",
       "58                                                                                                                                                                               https://medium.com/@jmlbeaujour/real-time-matting-of-webcam-video-on-the-browser-part-1-2c71a330ed08?source=tag_archive---------1-----------------------   \n",
       "59                                                                                                                                                                                                https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=tag_archive---------7-----------------------   \n",
       "60                                                                                                                                                                              https://towardsdatascience.com/reinforcement-learning-w-keras-openai-actor-critic-models-f084612cfd69?source=tag_archive---------1-----------------------   \n",
       "61                                                                                                                                                                https://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d?source=tag_archive---------2-----------------------   \n",
       "62                                                                                                                                                                             https://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af?source=tag_archive---------0-----------------------   \n",
       "63                                                                                                                                                                                                 https://towardsdatascience.com/how-to-train-a-bert-model-from-scratch-72cfce554fc6?source=tag_archive---------6-----------------------   \n",
       "64                                                                                                                                                                                  https://towardsdatascience.com/credit-card-fraud-detection-using-autoencoders-in-h2o-399cbb7ae4f1?source=tag_archive---------7-----------------------   \n",
       "65                                                                                                                                                                                                      https://towardsdatascience.com/backpropagation-the-natural-proof-946c5abf63b1?source=tag_archive---------7-----------------------   \n",
       "66                                                                                                                                                                                                https://heartbeat.comet.ml/basics-of-image-classification-with-pytorch-2f8973c51864?source=tag_archive---------9-----------------------   \n",
       "67                                                                                                                                                                                                 https://blog.clairvoyantsoft.com/music-genre-classification-using-cnn-ef9461553726?source=tag_archive---------7-----------------------   \n",
       "68                                                                                                                                                                      https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d?source=tag_archive---------2-----------------------   \n",
       "69                                                                                                                                                                         https://medium.com/@mst3c/google-deepmind-style-datacenter-optimization-ai-model-on-the-cheap-75f054330d27?source=tag_archive---------2-----------------------   \n",
       "70                                                                                                                                                              https://medium.com/acuity-derivatives/the-volcker-metric-known-as-inventory-aging-and-thoughts-of-whisky-a6011bf720d4?source=tag_archive---------1-----------------------   \n",
       "71                                                                                                                                                                                                  https://towardsdatascience.com/prior-over-functions-gaussian-process-1c58e8c40272?source=tag_archive---------4-----------------------   \n",
       "72                                                                                                                                                                                         https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------1-----------------------   \n",
       "73                                                                                                                                                                                      https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c?source=tag_archive---------0-----------------------   \n",
       "74                                                                                                                                                                                                                         https://medium.com/swlh/ner-spacy-and-lasagne-51b56fdad57e?source=tag_archive---------6-----------------------   \n",
       "75                                                                                                                                                                                      https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0?source=tag_archive---------5-----------------------   \n",
       "76                                                                                                                                                                                                   https://medium.com/analytics-vidhya/a-short-introduction-of-stylegan-898fe781937?source=tag_archive---------5-----------------------   \n",
       "77                                                                                                                                                                                                             https://medium.com/@wyhzest/css-box-model-and-positioning-9f0263d60759?source=tag_archive---------9-----------------------   \n",
       "78                                                                                                                                                                                          https://towardsdatascience.com/text-summarization-using-deep-neural-networks-e7ee7521d804?source=tag_archive---------4-----------------------   \n",
       "79                                                                                                                                                                           https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1?source=tag_archive---------8-----------------------   \n",
       "80                                                                                                                                                                                                 https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875?source=tag_archive---------8-----------------------   \n",
       "81                                                                                                                                                                                                      https://towardsdatascience.com/using-resnet-for-time-series-data-4ced1f5395e3?source=tag_archive---------8-----------------------   \n",
       "82                                                                                                                                                                                                      https://medium.com/@bond-kirill-alexandrovich/understanding-unet-27de538e08d8?source=tag_archive---------3-----------------------   \n",
       "83                                                                                                                                                                                                                  https://tech.goibibo.com/presenting-goibibo-insights-6b2ea7b3abc4?source=tag_archive---------5-----------------------   \n",
       "84                                                                                                                                                                                                         https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714?source=tag_archive---------5-----------------------   \n",
       "85                                                                                                                                                                                   https://medium.com/@gurrampavan6/fast-and-faster-region-based-convolutional-network-6a391a5a247a?source=tag_archive---------3-----------------------   \n",
       "86                                                                                                                                                                                         https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf?source=tag_archive---------4-----------------------   \n",
       "87                                                                                                                                                                                               https://medium.com/analytics-vidhya/automated-feature-engineering-tools-44d00be56e3a?source=tag_archive---------4-----------------------   \n",
       "88                                                                                                                                                                                                       https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d?source=tag_archive---------3-----------------------   \n",
       "89                                                                                                                                                                      https://medium.com/@mohamedhajr/ophow-i-got-my-first-android-job-without-a-degree-and-experience-98c70b931a9d?source=tag_archive---------2-----------------------   \n",
       "90                                                                                                                                                                                                          https://towardsdatascience.com/machine-learning-basics-part-1-a36d38c7916?source=tag_archive---------8-----------------------   \n",
       "91                                                                                                                                                                                                   https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6?source=tag_archive---------9-----------------------   \n",
       "92                                                                                                                                                                                         https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff?source=tag_archive---------7-----------------------   \n",
       "93                                                                                                                                                                        https://medium.com/intel-student-ambassadors/diving-into-abstractive-text-summarization-part-1-e8570d370021?source=tag_archive---------5-----------------------   \n",
       "94                                                                                                                                                                                                                https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=tag_archive---------0-----------------------   \n",
       "95                                                                                                                                                                                                        https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3?source=tag_archive---------3-----------------------   \n",
       "96                                                                                                                                                  https://towardsdatascience.com/gaussian-mixture-model-clusterization-how-to-select-the-number-of-components-clusters-553bef45f6e4?source=tag_archive---------6-----------------------   \n",
       "97                                                                                                                                                                              https://towardsdatascience.com/understanding-optimization-algorithms-in-machine-learning-edfdb4df766b?source=tag_archive---------9-----------------------   \n",
       "98                                                                                                                                                        https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=tag_archive---------4-----------------------   \n",
       "99                                                                                                                                                                                                                         https://cvil.ly/no-home-for-ipad-on-apple-com-88074e5ad99f?source=tag_archive---------4-----------------------   \n",
       "100                                                                                                                                                                                                      https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263?source=tag_archive---------3-----------------------   \n",
       "101                                                                                                                                   https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------2-----------------------   \n",
       "102                                                                                                                                                                                     https://towardsdatascience.com/read-text-from-image-with-one-line-of-python-code-c22ede074cac?source=tag_archive---------4-----------------------   \n",
       "103                                                                                                                                                                    https://towardsdatascience.com/interpreting-recurrent-neural-networks-on-multivariate-time-series-ebec0edb8f5a?source=tag_archive---------4-----------------------   \n",
       "104                                                                                                                                                                      https://towardsdatascience.com/how-i-went-from-zero-coding-skills-to-data-scientist-in-6-months-c2207b65f2f3?source=tag_archive---------0-----------------------   \n",
       "105                                                                                                                                                                                                           https://uxdesign.cc/20-ideas-for-better-data-visualization-73f7e3c2782d?source=tag_archive---------3-----------------------   \n",
       "106                                                                                                                                                                                                       https://medium.com/@JoshDHolmes/blog-9-information-architecture-3bc96dabdc0?source=tag_archive---------2-----------------------   \n",
       "107                                                                                                                                                                                                                   https://medium.com/konvergen/understanding-dropout-ddb60c9f98aa?source=tag_archive---------2-----------------------   \n",
       "108                                                                                                                                                                    https://medium.com/@RU_TokenGo/tokengo-%D0%B7%D0%B0%D0%BF%D1%83%D1%81%D0%BA%D0%B0%D0%B5%D1%82-ico-15ed47e79fb7?source=tag_archive---------3-----------------------   \n",
       "109                                                                                                                                                                     https://medium.com/@hackintoshrao/tips-to-avoid-the-pitfall-of-over-fitting-in-linear-regression-468e590c4f92?source=tag_archive---------6-----------------------   \n",
       "110                                                                                                                                                             https://medium.com/@pallawi-ds/step-by-step-understand-the-architecture-of-region-proposal-network-r-cnn-695a14a060a7?source=tag_archive---------2-----------------------   \n",
       "111                                                                                                                                                                       https://medium.com/@unchainet/invest-in-unchainet-heterogeneous-cloud-computing-infrastructure-b61dd2ba36e0?source=tag_archive---------5-----------------------   \n",
       "112                                                                                                                                                                                                                    https://medium.com/teklit/coding-is-a-trap-get-out-14a6beb28c8?source=tag_archive---------7-----------------------   \n",
       "113                                                                                                                                                                           https://medium.com/emaasit/in-case-you-missed-it-my-webinar-on-model-based-machine-learning-1ca6bef79ae?source=tag_archive---------1-----------------------   \n",
       "114                                                                                                                                                                              https://medium.com/hackernoon/instance-segmentation-in-google-colab-with-custom-dataset-b3099ac23f35?source=tag_archive---------5-----------------------   \n",
       "115                                                                                                                                                           https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a?source=tag_archive---------0-----------------------   \n",
       "116                                                                                                                                                                               https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02?source=tag_archive---------9-----------------------   \n",
       "117                                                                                                                                                                   https://medium.com/the-official-unofficial-firefox-blog/the-first-inaugural-firefox-census-results-a1a05327ed7f?source=tag_archive---------2-----------------------   \n",
       "118                                                                                                                                                         https://towardsdatascience.com/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706?source=tag_archive---------8-----------------------   \n",
       "119                                                                                                                                        https://towardsdatascience.com/eagleview-super-high-resolution-image-segmentation-with-deeplabv3-mask-rcnn-using-keras-arcgis-9be08caac42c?source=tag_archive---------5-----------------------   \n",
       "120                                                                                                                                                                           https://medium.com/@udaybhaskarpaila/everything-you-need-to-know-about-logistic-regression-18e740be87a0?source=tag_archive---------8-----------------------   \n",
       "121                                                                                                                                                             https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be?source=tag_archive---------4-----------------------   \n",
       "122                                                                                                                                                                                                                   https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------3-----------------------   \n",
       "123                                                                                                                                                                                                          https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd?source=tag_archive---------1-----------------------   \n",
       "124                                                                                                                                                                          https://towardsdatascience.com/u-net-for-semantic-segmentation-on-unbalanced-aerial-imagery-3474fa1d3e56?source=tag_archive---------4-----------------------   \n",
       "125                                                                                                                                                                          https://medium.com/analytics-vidhya/dimensionality-reduction-by-stochastic-gradient-descent-f617ebde3c1b?source=tag_archive---------4-----------------------   \n",
       "126                                                                                                                                                                                        https://towardsdatascience.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647?source=tag_archive---------7-----------------------   \n",
       "127                                                                                                                                   https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------6-----------------------   \n",
       "128                                                                                                                                                                                                        https://medium.com/unpackai/sgd-mnist-putting-it-all-together-2b09d21c9e9a?source=tag_archive---------8-----------------------   \n",
       "129                                                                                                                                                                        https://towardsdatascience.com/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f?source=tag_archive---------9-----------------------   \n",
       "130                                                                                                                                             https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8?source=tag_archive---------2-----------------------   \n",
       "131                                                                                                                                                                           https://medium.com/nanonets/how-to-easily-detect-objects-with-deep-learning-on-raspberrypi-225f29635c74?source=tag_archive---------2-----------------------   \n",
       "132                                                                                                                                                                                               https://towardsdatascience.com/an-intuitive-explanation-of-beam-search-9b1d744e7a0f?source=tag_archive---------1-----------------------   \n",
       "133                                                                                                                                                                                                                 https://towardsdatascience.com/the-games-that-ai-won-ff8fd4a71efc?source=tag_archive---------6-----------------------   \n",
       "134                                                                                                                                                          https://medium.com/@bitsofinfo/clustering-liferay-globally-across-data-centers-gslb-with-jgroups-and-relay2-7786b8dbbb96?source=tag_archive---------3-----------------------   \n",
       "135                                                                                                                                                                                                           https://medium.com/@andreasyonathan/kuliah-itu-gak-penting-292defe6d476?source=tag_archive---------3-----------------------   \n",
       "136                                                                                                                                                                                     https://towardsdatascience.com/word-embeddings-in-2020-review-with-code-examples-11eb39a1ee6d?source=tag_archive---------1-----------------------   \n",
       "137                                                                                                                                                                                          https://towardsdatascience.com/autoencoders-introduction-and-implementation-3f40483b0a85?source=tag_archive---------1-----------------------   \n",
       "138                                                                                                                                                                                                     https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c?source=tag_archive---------8-----------------------   \n",
       "139                                                                                                                                                                                         https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1?source=tag_archive---------3-----------------------   \n",
       "140                                                                                                                                                                                                                  https://towardsdatascience.com/pixelcnns-blind-spot-84e19a3797b9?source=tag_archive---------6-----------------------   \n",
       "141                                                                                                                                                                                  https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac?source=tag_archive---------2-----------------------   \n",
       "142                                                                                                                                                                               https://towardsdatascience.com/practical-implementation-of-outlier-detection-in-python-90680453b3ce?source=tag_archive---------2-----------------------   \n",
       "143                                                                                                                                                                                                         https://medium.com/sap-design/explaining-system-intelligence-68f8fcc07a64?source=tag_archive---------2-----------------------   \n",
       "144                                                                                                                                                                              https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24?source=tag_archive---------0-----------------------   \n",
       "145                                                                                                                                                       https://medium.com/analytics-vidhya/step-by-step-implementation-of-conditional-generative-adversarial-networks-54e4b47497d6?source=tag_archive---------9-----------------------   \n",
       "146                                                                                                                                                                                  https://towardsdatascience.com/multiclass-text-classification-using-lstm-in-pytorch-eac56baed8df?source=tag_archive---------3-----------------------   \n",
       "147                                                                                                                                                                                                        https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2?source=tag_archive---------2-----------------------   \n",
       "148                                                                                                                                                                                          https://towardsdatascience.com/autoencoders-bits-and-bytes-of-deep-learning-eaba376f23ad?source=tag_archive---------0-----------------------   \n",
       "149                                                                                                                                                                                   https://medium.com/@dhruvp/how-to-write-a-neural-network-to-play-pong-from-scratch-956b57d4f6e0?source=tag_archive---------0-----------------------   \n",
       "150                                                                                                                                                                              https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db?source=tag_archive---------9-----------------------   \n",
       "151                                                                                                                                                 https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156?source=tag_archive---------0-----------------------   \n",
       "152                                                                                                                                                              https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089?source=tag_archive---------2-----------------------   \n",
       "153                                                                                                                                                                                 https://towardsdatascience.com/deep-latent-variable-models-unravel-hidden-structures-a5df0fd32ae2?source=tag_archive---------4-----------------------   \n",
       "154                                                                                                                                                                                 https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------6-----------------------   \n",
       "155                                                                                                                                                                                                                  https://medium.com/@elifmeseci/r-cnn-ailesi-part-ii-76cce9e4a9d6?source=tag_archive---------4-----------------------   \n",
       "156                                                                                                                                                                               https://towardsdatascience.com/clustering-techniques-hierarchical-and-non-hierarchical-b520b5d6a022?source=tag_archive---------7-----------------------   \n",
       "157                                                                                                                                                                         https://medium.com/analytics-vidhya/introduction-to-object-detection-with-rcnn-family-models-310558ce2033?source=tag_archive---------0-----------------------   \n",
       "158                                                                                                                                                                                                      https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537?source=tag_archive---------0-----------------------   \n",
       "159                                                                                                                                                                       https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=tag_archive---------8-----------------------   \n",
       "160                                                                                                                                                                                  https://medium.com/ipg-media-lab/amazon-adds-photographic-product-search-to-ios-app-3c023e5d71ed?source=tag_archive---------1-----------------------   \n",
       "161                                                                                                                                                                                      https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34?source=tag_archive---------8-----------------------   \n",
       "162                                                                                                                                                                   https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53?source=tag_archive---------2-----------------------   \n",
       "163                                                                                                                                                         https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438?source=tag_archive---------8-----------------------   \n",
       "164                                                                                                                                                                                   https://towardsdatascience.com/neural-networks-backpropagation-by-dr-lihi-gur-arie-27be67d8fdce?source=tag_archive---------5-----------------------   \n",
       "165                                                                                                                                                                 https://towardsdatascience.com/icml-2018-advances-in-transfer-multitask-and-semi-supervised-learning-2a15ef7208ec?source=tag_archive---------1-----------------------   \n",
       "166                                                                                                                                                                                  https://towardsdatascience.com/run-stylegan2-ada-on-an-aws-spot-instance-in-no-time-d2022fc1e119?source=tag_archive---------4-----------------------   \n",
       "167                                                                                                                                                          https://towardsdatascience.com/generating-text-with-recurrent-neural-networks-based-on-the-work-of-f-pessoa-1e804d88692d?source=tag_archive---------6-----------------------   \n",
       "168                                                                                                                                                                             https://medium.com/@adampickard_44261/advancements-in-machine-learning-assisted-ideation-5c42cdf69c37?source=tag_archive---------8-----------------------   \n",
       "169                                                                                                                                  https://medium.com/@jongdae.lim/%EA%B8%B0%EA%B3%84-%ED%95%99%EC%8A%B5-machine-learning-%EC%9D%80-%EC%A6%90%EA%B2%81%EB%8B%A4-part-5-83b7a44b797a?source=tag_archive---------8-----------------------   \n",
       "170                                                                                                                                                                         https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?source=tag_archive---------9-----------------------   \n",
       "171                                                                                                                                                                                              https://medium.com/hackernoon/rnn-or-recurrent-neural-network-for-noobs-a9afbb00e860?source=tag_archive---------6-----------------------   \n",
       "172                                                                                                                                                                                                          https://medium.com/@2809ayushic/optimizers-in-deep-learning-31db684c73cf?source=tag_archive---------0-----------------------   \n",
       "173                                                                                                                                                       https://towardsdatascience.com/isolation-forest-the-anomaly-detection-algorithm-any-data-scientist-should-know-1a99622eec2d?source=tag_archive---------1-----------------------   \n",
       "174                                                                                                                                                                                                                        https://medium.com/hackernoon/word2vec-part-1-fe2ec6514d70?source=tag_archive---------9-----------------------   \n",
       "175                                                                                                                                                                              https://towardsdatascience.com/keywords-to-know-before-you-start-reading-papers-on-gans-8a08a665b40c?source=tag_archive---------7-----------------------   \n",
       "176                                                                                                                                                                                                 https://medium.com/@robparkin_38642/bayesian-variational-autoencoder-4bb698c84644?source=tag_archive---------9-----------------------   \n",
       "177                                                                                                                                                                                     https://medium.com/cubo-ai/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540?source=tag_archive---------5-----------------------   \n",
       "178                                                                                                                                                                                                         https://medium.com/@robbietilton/emotional-computing-with-ai-3513884055fa?source=tag_archive---------2-----------------------   \n",
       "179                                                                                                                                                                  https://medium.com/@huangkaikai/computational-creativity-generative-creature-design-for-concept-art-c4a1180ae0e6?source=tag_archive---------1-----------------------   \n",
       "180                                                                                                                                                                                                   https://medium.com/nurture-ai/learning-artistic-styles-from-images-a07037fa46e3?source=tag_archive---------6-----------------------   \n",
       "181                                                                                                                                                                                            https://towardsdatascience.com/a-friendly-introduction-to-text-clustering-fa996bcefd04?source=tag_archive---------6-----------------------   \n",
       "182                                                                                                                                                                                https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf?source=tag_archive---------4-----------------------   \n",
       "183                                                                                                                                                                                           https://towardsdatascience.com/an-overview-for-text-representations-in-nlp-311253730af1?source=tag_archive---------6-----------------------   \n",
       "184                                                                                                                                                                        https://medium.com/@vivek-yadav/why-is-gradient-descent-robust-to-non-linearly-separable-data-a50c543e8f4a?source=tag_archive---------2-----------------------   \n",
       "185                                                                                                                                                                                                                        https://medium.com/edureka/k-means-clustering-1db7b018a0a2?source=tag_archive---------0-----------------------   \n",
       "186                                                                                                                                                                                                          https://towardsdatascience.com/meta-learning-ai-generalised-1007b9695fe1?source=tag_archive---------2-----------------------   \n",
       "187                                                                                                                                                                                      https://towardsdatascience.com/gamma-function-intuition-derivation-and-examples-5e5f72517dee?source=tag_archive---------7-----------------------   \n",
       "188                                                                                                                                                                               https://towardsdatascience.com/a-beginners-guide-to-convolutional-neural-networks-cnns-14649dbddce8?source=tag_archive---------4-----------------------   \n",
       "189                                                                                                                                                                   https://medium.com/@aneesha/using-affinity-propagation-to-find-the-number-of-clusters-in-a-dataset-52f5dd3b0760?source=tag_archive---------1-----------------------   \n",
       "190                                                                                                                                                                                   https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92?source=tag_archive---------6-----------------------   \n",
       "191                                                                                                                                                                                     https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29?source=tag_archive---------6-----------------------   \n",
       "192                                                                                                                                                                   https://blog.insightdatascience.com/data-visualization-in-python-advanced-functionality-in-seaborn-20d217f1a9a6?source=tag_archive---------6-----------------------   \n",
       "193                                                                                                                                                                                              https://medium.com/somx-labs/lets-talk-clustering-unsupervised-learning-1c89bc27e908?source=tag_archive---------3-----------------------   \n",
       "194                                                                                                                                                                                     https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------5-----------------------   \n",
       "195                                                                                                                                      https://medium.com/@ravipandey71998/image-classifier-using-vgg-19-deep-learning-model-in-google-colab-notebook-dishes-detection-34861168e055?source=tag_archive---------3-----------------------   \n",
       "196                                                                                                                                  https://medium.com/@aleksipietikinen/an-analysis-on-how-deepminds-starcraft-2-ai-s-superhuman-speed-could-be-a-band-aid-fix-for-the-1702fb8344d6?source=tag_archive---------2-----------------------   \n",
       "197                                                                                                                                                                                                 https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------3-----------------------   \n",
       "198                                                                                                                                                              https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4?source=tag_archive---------2-----------------------   \n",
       "199                                                                                                                                                                                              https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129?source=tag_archive---------0-----------------------   \n",
       "200                                                                                                                                                                                                              https://medium.com/analytics-vidhya/ner-tensorflow-2-2-0-9f10dcf5a0a?source=tag_archive---------8-----------------------   \n",
       "201                                                                                                                                                                                 https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------3-----------------------   \n",
       "202                                                                                                                                                         https://medium.com/analytics-vidhya/implementation-of-principal-component-analysis-pca-in-k-means-clustering-b4bc0aa79cb6?source=tag_archive---------4-----------------------   \n",
       "203                                                                                                                                                                               https://medium.com/a-problem-like-maria/ai-class-com-a-classroom-with-160-000-students-9c16f6e31390?source=tag_archive---------4-----------------------   \n",
       "204                                                                                                                                                                                             https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17?source=tag_archive---------1-----------------------   \n",
       "205                                                                                                                                                                                   https://towardsdatascience.com/polynomial-regression-gradient-descent-from-scratch-279db2936fe9?source=tag_archive---------3-----------------------   \n",
       "206                                                                                                                                                                              https://medium.com/syncedreview/from-faces-to-kitties-to-apartments-gan-fakes-the-world-ae04e5cbddf6?source=tag_archive---------6-----------------------   \n",
       "207                                                                                                                                                                            https://medium.com/swlh/deep-learning-architectures-that-you-can-use-with-a-very-few-data-8e5b4fa1d5da?source=tag_archive---------8-----------------------   \n",
       "208                                                                                                                                                                                                            https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c?source=tag_archive---------1-----------------------   \n",
       "209                                                                                                                                                                                                https://becominghuman.ai/transfer-learning-part-4-0-vgg-16-and-vgg-19-d7f0045032de?source=tag_archive---------4-----------------------   \n",
       "210                                                                                                                                                       https://medium.com/syncedreview/google-deepmind-releases-structure-predictions-for-coronavirus-linked-proteins-7dfb2fad05b6?source=tag_archive---------8-----------------------   \n",
       "211                                                                                                                                                                                                https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94?source=tag_archive---------4-----------------------   \n",
       "212                                                                                                                                            https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------9-----------------------   \n",
       "213                                                                                                                                                                                   https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1?source=tag_archive---------7-----------------------   \n",
       "214                                                                                                                                                                                          https://medium.com/sa%C3%BAde-digital/rsna-2013-top-5-tend%C3%AAncias-em-ti-528f595225b7?source=tag_archive---------8-----------------------   \n",
       "215                                                                                                                                                                                                       https://netflixtechblog.com/extracting-image-metadata-at-scale-c89c60a2b9d2?source=tag_archive---------6-----------------------   \n",
       "216                                                                                                                                                                     https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9?source=tag_archive---------3-----------------------   \n",
       "217                                                                                                                                                                      https://medium.com/analytics-vidhya/using-maskrcnn-to-predict-tropical-fruits-in-custom-dataset-4f079d05fbe1?source=tag_archive---------4-----------------------   \n",
       "218                                                                                                                                                                        https://medium.com/@financial-engineering/tensorflow-2-0-variational-auto-encoder-vae-part-ii-df8adcd02f20?source=tag_archive---------9-----------------------   \n",
       "219                                                                                                                                                                                         https://medium.com/syncedreview/deepmind-et-al-paper-trumpets-graph-networks-9c74a271b903?source=tag_archive---------9-----------------------   \n",
       "220                                                                                                                                                                                                 https://towardsdatascience.com/data-science-for-newbies-including-me-d1c6bf3e390b?source=tag_archive---------0-----------------------   \n",
       "221                                                                                                                                                                           https://medium.com/@nnintruder/attacking-google-cloud-vision-api-with-adversarial-examples-d02af0174732?source=tag_archive---------3-----------------------   \n",
       "222                                                                                                                                                                        https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c?source=tag_archive---------2-----------------------   \n",
       "223                                                                                                                                                                          https://blog.agolo.com/knowledge-graphs-for-automatic-multi-longform-document-summarization-8f946e1e1877?source=tag_archive---------8-----------------------   \n",
       "224                                                                                                                                                                           https://medium.com/@gerardmaggiolino/creating-openai-gym-environments-with-pybullet-part-1-13895a622b24?source=tag_archive---------6-----------------------   \n",
       "225                                                                                                                                                                                https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31?source=tag_archive---------5-----------------------   \n",
       "226                                                                                                                                                                                       https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------2-----------------------   \n",
       "227                                                                                                                                                                                                     https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04?source=tag_archive---------0-----------------------   \n",
       "228                                                                                                                                     https://medium.com/syncedreview/quantum-chemistry-breakthrough-deepmind-uses-neural-networks-to-tackle-schr%C3%B6dinger-equation-a5ad4e3bfea0?source=tag_archive---------3-----------------------   \n",
       "229                                                                                                                                                                                                         https://towardsdatascience.com/explaining-k-means-clustering-5298dc47bad6?source=tag_archive---------5-----------------------   \n",
       "230                                                                                                                                                        https://medium.com/technology-invention-and-more/everything-you-need-to-know-about-artificial-neural-networks-57fac18245a1?source=tag_archive---------6-----------------------   \n",
       "231                                                                                                                                                                                             https://towardsdatascience.com/liquid-neural-networks-in-computer-vision-4a0f718b464e?source=tag_archive---------8-----------------------   \n",
       "232                                                                                                                                                                                                      https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b?source=tag_archive---------3-----------------------   \n",
       "233                                                                                                                                                                                  https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4?source=tag_archive---------0-----------------------   \n",
       "234                                                                                                                                                                                        https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96?source=tag_archive---------1-----------------------   \n",
       "235                                                                                                                                                     https://towardsdatascience.com/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca?source=tag_archive---------9-----------------------   \n",
       "236                                                                                                                                                                                     https://medium.com/@today.rafi/demystifying-object-detection-using-deep-learning-d3f83e2fb832?source=tag_archive---------2-----------------------   \n",
       "237                                                                                                                                                                                  https://towardsdatascience.com/paper-repro-deep-metalearning-using-maml-and-reptile-fd1df1cc81b0?source=tag_archive---------2-----------------------   \n",
       "238                                                                                    https://medium.com/@pedin024/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%84%AA%E5%8C%96%E5%99%A8ranger-a-synergistic-optimizer-using-radam-rectified-adam-gradient-centralization-and-f022d9dd4217?source=tag_archive---------3-----------------------   \n",
       "239                                                                                                                                                                                    https://towardsdatascience.com/machine-learning-polynomial-regression-with-python-5328e4e8a386?source=tag_archive---------1-----------------------   \n",
       "240                                                                                                                                                                      https://medium.com/@thirumalaivasudev/how-i-struggled-to-convert-mbr-to-gpt-and-installed-linux-7755b7946b93?source=tag_archive---------8-----------------------   \n",
       "241                                                                                                                                                                        https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568?source=tag_archive---------8-----------------------   \n",
       "242                                                                                                                                                      https://medium.com/ai%C2%B3-theory-practice-business/what-is-pre-training-in-nlp-introducing-5-key-technologies-455c54933054?source=tag_archive---------1-----------------------   \n",
       "243                                                                                                                                                                                                  https://towardsdatascience.com/vanishing-exploding-gradient-problem-b5b78c142bb7?source=tag_archive---------3-----------------------   \n",
       "244                                                                                                                                                 https://towardsdatascience.com/graph-neural-networks-through-the-lens-of-differential-geometry-and-algebraic-topology-3a7c3c22d5f?source=tag_archive---------1-----------------------   \n",
       "245                                                                                                                                                                                https://medium.com/@kerimov.nurlan/anomaly-detection-in-brightfield-microscopy-images-c92cdddafcc3?source=tag_archive---------8-----------------------   \n",
       "246                                                                                                                                                                                   https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7?source=tag_archive---------5-----------------------   \n",
       "247                                                                                                                                                                                           https://towardsdatascience.com/data-scientists-will-be-extinct-in-10-years-a6e5dd77162b?source=tag_archive---------2-----------------------   \n",
       "248                                                                                                                                                                                                           https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------3-----------------------   \n",
       "249                                                                                                                                                                             https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------1-----------------------   \n",
       "250                                                                                                                                                                                                                 https://medium.com/@Dude_Next/the-dropout-tag-i-wear-9425f2cba27b?source=tag_archive---------8-----------------------   \n",
       "251                                                                                                                                                                                                     https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc?source=tag_archive---------5-----------------------   \n",
       "252                                                                                                                                                                                   https://medium.com/deep-systems/movix-ai-movie-recommendations-using-deep-learning-5903d6a31607?source=tag_archive---------9-----------------------   \n",
       "253                                                                                                                                                                   https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=tag_archive---------4-----------------------   \n",
       "254                                                                                                                                                                    https://towardsdatascience.com/generative-ai-visual-search-as-a-bridge-between-fiction-and-reality-46d2d78ee15?source=tag_archive---------3-----------------------   \n",
       "255                                                                                    https://medium.com/@akichan-f/efficientnet-b6-autoaug%E3%81%A8%E5%90%8C%E7%AD%89%E7%A8%8B%E5%BA%A6%E3%81%AE%E7%B2%BE%E5%BA%A6%E3%81%A75%E5%80%8D%E6%97%A9%E3%81%84assemble-resnet-c3b8b846e0a2?source=tag_archive---------9-----------------------   \n",
       "256                                                                                                                                                                 https://towardsdatascience.com/how-are-logistic-regression-ordinary-least-squares-regression-related-1deab32d79f5?source=tag_archive---------9-----------------------   \n",
       "257                                                                                                                                                                                                        https://medium.com/datathings/meta-learning-learning-to-learn-a55cadd32b17?source=tag_archive---------9-----------------------   \n",
       "258                                                                                                                                                                                       https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------1-----------------------   \n",
       "259                                                                                                                                                                                          https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81-gradient-descent-e97890236262?source=tag_archive---------7-----------------------   \n",
       "260                                                                                                                                                                                https://medium.com/@joaomariafernandes/why-i-dropped-out-of-college-but-you-shouldn-t-73a4b99f9cf9?source=tag_archive---------7-----------------------   \n",
       "261                                                                                                                                                                             https://medium.com/voice-tech-podcast/automatic-extractive-text-summarization-using-tfidf-3fc9a7b26f5?source=tag_archive---------4-----------------------   \n",
       "262                                                                                                                                                                               https://medium.com/javascript-scene/top-javascript-frameworks-and-tech-trends-for-2021-d8cb0f7bda69?source=tag_archive---------8-----------------------   \n",
       "263                                                                                                                                                     https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb?source=tag_archive---------2-----------------------   \n",
       "264                                                                                                                                                                                                                      https://medium.com/minds-on-media/finger-dasher-3332487b5f4e?source=tag_archive---------2-----------------------   \n",
       "265                                                                                                                                                                                  https://becominghuman.ai/a-news-analysis-neuralnet-learns-from-a-language-neuralnet-16646804fdeb?source=tag_archive---------9-----------------------   \n",
       "266                                                                                                                                                                                                        https://medium.com/kredo-ai-engineering/blog-series-on-ros-ai-ff28cc116560?source=tag_archive---------9-----------------------   \n",
       "267                                                                                                                                                                                                         https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3?source=tag_archive---------5-----------------------   \n",
       "268                                                                                                                                                              https://medium.com/@alexlenail/what-is-the-difference-between-ridge-regression-the-lasso-and-elasticnet-ec19c71c9028?source=tag_archive---------5-----------------------   \n",
       "269                                                                                                                                                                                                                  https://medium.com/@lipeng2/dropout-is-so-important-e517bbe3ffcc?source=tag_archive---------7-----------------------   \n",
       "270                                                                                                                                                                                      https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037?source=tag_archive---------5-----------------------   \n",
       "271                                                                                                                                                                     https://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49?source=tag_archive---------6-----------------------   \n",
       "272                                                                                                                                                                          https://medium.com/@ajiabs/socialdefender-social-reputation-management-platform-aji-abraham-593dafc771e2?source=tag_archive---------2-----------------------   \n",
       "273                                                                                                                                                                            https://towardsdatascience.com/the-hype-on-alphafold-keeps-growing-with-this-new-preprint-a8c1f21d15c8?source=tag_archive---------6-----------------------   \n",
       "274                                                                                                                                                                                                              https://medium.com/@eitan-kosman/neural-image-retrieval-72029a0dbd00?source=tag_archive---------6-----------------------   \n",
       "275                                                                                                                                                                              https://towardsdatascience.com/top-20-movies-about-machine-learning-ai-and-data-science-8382d408c8c3?source=tag_archive---------7-----------------------   \n",
       "276                                                                                                                                                                    https://medium.com/@luckylwk/transfer-learning-in-tensorflow-on-the-kaggle-rainforest-competition-4e978fadb571?source=tag_archive---------7-----------------------   \n",
       "277                                                                                                                                                                                         https://medium.com/analytics-vidhya/clustering-on-mixed-data-types-in-python-7c22b3898086?source=tag_archive---------7-----------------------   \n",
       "278                                                                                                                                                                                   https://medium.com/analytics-vidhya/insight-into-faster-r-cnn-for-object-detection-f1e64240eee1?source=tag_archive---------7-----------------------   \n",
       "279                                                                                                                                                                                        https://blog.mutsuda.com/intelligent-agent-based-wastewater-management-system-741b793f1c5c?source=tag_archive---------8-----------------------   \n",
       "280                                                                                                                                                                     https://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189?source=tag_archive---------2-----------------------   \n",
       "281                                                                                                                                                                                                   https://towardsdatascience.com/using-lstms-to-forecast-time-series-4ab688386b1f?source=tag_archive---------7-----------------------   \n",
       "282                                                                                                                                                     https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0?source=tag_archive---------8-----------------------   \n",
       "283                                                                                                                        https://medium.com/ai-academy-taiwan/%E5%B8%B6%E4%BD%A0%E8%AA%8D%E8%AD%98vector-quantized-variational-autoencoder-%E7%90%86%E8%AB%96%E7%AF%87-49a1829497bb?source=tag_archive---------6-----------------------   \n",
       "284                                                                                                                                                                          https://medium.com/stories-by-progress/true-democratization-of-analytics-with-meta-learning-cdefe3c7ddd5?source=tag_archive---------4-----------------------   \n",
       "285                                                                                                                                                                                           https://medium.com/@kawsar34/machine-learning-quiz-05-decision-tree-part-1-3ea71fa312e5?source=tag_archive---------5-----------------------   \n",
       "286                                                                                                                                                                                              https://towardsdatascience.com/speeding-up-bert-search-in-elasticsearch-750f1f34f455?source=tag_archive---------5-----------------------   \n",
       "287                                                                                                                                             https://medium.com/@interjc/%E5%86%99%E5%9C%A8%E7%9C%8B%E5%AE%8C%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9Aii%E4%B9%8B%E5%90%8E-ea5d294d2bd3?source=tag_archive---------0-----------------------   \n",
       "288                                                                                                                                                                                                                      https://medium.com/@ellehilly/classes-of-novels-c8207342dc0b?source=tag_archive---------7-----------------------   \n",
       "289                                                                                                                                                                                     https://medium.com/@akshikawijesundara/object-recognition-with-opencv-on-android-6435277ab285?source=tag_archive---------1-----------------------   \n",
       "290                                                                                                                                                         https://medium.com/@jonathan-hui/ssd-object-detection-single-shot-multibox-detector-for-real-time-processing-9bd8deac0e06?source=tag_archive---------7-----------------------   \n",
       "291                                                                                                                                                       https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec?source=tag_archive---------0-----------------------   \n",
       "292                                                                                                                                                                                                https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------1-----------------------   \n",
       "293                                                                                                                                                                                                        https://medium.com/swlh/transformer-based-sentence-embeddings-cd0935b3b1e0?source=tag_archive---------7-----------------------   \n",
       "294                                                                            https://medium.com/@botcho/stash-data-center-%E3%83%99%E3%83%BC%E3%82%BF%E7%89%88%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9-git-%E3%82%92%E5%A4%A7%E8%A6%8F%E6%A8%A1%E3%81%AB%E5%88%A9%E7%94%A8-2f0f46d5f2dd?source=tag_archive---------4-----------------------   \n",
       "295                                                                                                                                                             https://towardsdatascience.com/cnn-lstm-based-models-for-multiple-parallel-input-and-multi-step-forecast-6fe2172f7668?source=tag_archive---------2-----------------------   \n",
       "296                                                                                                                                                                                                    https://towardsdatascience.com/sentiment-analysis-using-rnns-lstm-60871fa6aeba?source=tag_archive---------9-----------------------   \n",
       "297                                                                                                                                                                                                             https://medium.com/@chinmaychetan04/activation-functions-78a99738a47c?source=tag_archive---------9-----------------------   \n",
       "298                                                                                                                                                                                 https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------0-----------------------   \n",
       "299                                                                                                                                                                                                                          https://medium.com/project-agi/introduction-71d920ed051c?source=tag_archive---------0-----------------------   \n",
       "300                                                                                                                                                                                                   https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82?source=tag_archive---------8-----------------------   \n",
       "301                                                                                                                                                                                    https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29?source=tag_archive---------3-----------------------   \n",
       "302                                                                                                                                                                                                                        https://medium.com/@sachin-abeywardana/hi-tal-7212811eeb03?source=tag_archive---------4-----------------------   \n",
       "303                                                                                                                                                                     https://towardsdatascience.com/using-word-embeddings-to-identify-company-names-and-stock-tickers-f194e3648a66?source=tag_archive---------9-----------------------   \n",
       "304                                                                                                                                                                                           https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09?source=tag_archive---------7-----------------------   \n",
       "305                                                                                                                                                        https://medium.com/free-code-camp/every-single-machine-learning-course-on-the-internet-ranked-by-your-reviews-3c4a7b8026c0?source=tag_archive---------2-----------------------   \n",
       "306                                                                                                                                                                                       https://medium.com/codait/art-ai-the-logic-behind-deep-learning-style-transfer-1f59f51441d1?source=tag_archive---------2-----------------------   \n",
       "307                                                                                                                                                                                 https://towardsdatascience.com/how-to-perform-abstractive-summarization-with-pegasus-3dd74e48bafb?source=tag_archive---------0-----------------------   \n",
       "308                                                                                                                                                                                                       https://medium.com/@wenchen-li/text-summarization-applications-ed319f0bb13c?source=tag_archive---------0-----------------------   \n",
       "309                                                                                                                                                              https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313?source=tag_archive---------5-----------------------   \n",
       "310                                                                                                                                                                               https://medium.com/cube-dev/time-series-prediction-using-recurrent-neural-networks-lstms-807fa6ca7f?source=tag_archive---------3-----------------------   \n",
       "311                                                                                                                                            https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------0-----------------------   \n",
       "312                                                                                                                                                                                                             https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------2-----------------------   \n",
       "313                                                                                                                                                                        https://towardsdatascience.com/semantic-image-segmentation-using-fully-convolutional-networks-bf0189fa3eb8?source=tag_archive---------1-----------------------   \n",
       "314                                                                                                                                                                                   https://medium.com/the-artificial-impostor/build-a-summarization-system-in-minutes-5f10c141bfe6?source=tag_archive---------7-----------------------   \n",
       "315                                                                                                                                                                                                  https://towardsdatascience.com/what-are-adversarial-examples-in-nlp-f928c574478e?source=tag_archive---------6-----------------------   \n",
       "316                                                                                                                                                                                   https://medium.com/@williamr/reducing-memory-usage-in-r-especially-for-regressions-8ed8070ae4d8?source=tag_archive---------4-----------------------   \n",
       "317                                                                                                                                                                      https://towardsdatascience.com/6-applications-of-auto-encoders-every-data-scientist-should-know-dc703cbc892b?source=tag_archive---------5-----------------------   \n",
       "318                                                                                                                                                                                                           https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------1-----------------------   \n",
       "319                                                                                                                                                                              https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610?source=tag_archive---------6-----------------------   \n",
       "320                                                                                                                                                                           https://medium.com/analytics-vidhya/when-neural-networks-saw-the-first-image-of-black-hole-3205e28b6578?source=tag_archive---------7-----------------------   \n",
       "321                                                                                                                                                                                   https://medium.com/starts-with-a-bang/weekend-diversion-the-ultimate-superhero-cake-129a990c35c?source=tag_archive---------0-----------------------   \n",
       "322                                                                                                                                                                                                                https://towardsdatascience.com/deep-generative-models-25ab2821afd3?source=tag_archive---------2-----------------------   \n",
       "323                                                                                                                                                                                               https://medium.com/responsibleml/adversarial-attacks-on-explainable-ai-f65d41e83c5f?source=tag_archive---------4-----------------------   \n",
       "324                                                                                                                                                                                                        https://medium.com/cltc-bulletin/adversarial-machine-learning-43b6de6aafdb?source=tag_archive---------3-----------------------   \n",
       "325                                                                                                                                                                                                                   https://medium.com/bisa-ai/intersection-over-union-a8d1532899b3?source=tag_archive---------4-----------------------   \n",
       "326                                                                                                                                                                                                    https://towardsdatascience.com/variational-autoencoder-in-finance-53ee5eb9ed98?source=tag_archive---------7-----------------------   \n",
       "327                                                                                                                                                                 https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463?source=tag_archive---------1-----------------------   \n",
       "328                                                                                                                                                                                                            https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af?source=tag_archive---------1-----------------------   \n",
       "329                                                                                                                                                                                                https://blog.fabric8.io/clustering-on-kubernetes-openshift3-using-dns-d786bfd681d9?source=tag_archive---------2-----------------------   \n",
       "330                                                                                                                                                                                   https://medium.com/@univprofblog1/support-vector-machine-matlab-r-and-python-codes-856a342fc35d?source=tag_archive---------4-----------------------   \n",
       "331                                                                                                                                                      https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978?source=tag_archive---------6-----------------------   \n",
       "332                                                                                                                                                                                              https://towardsdatascience.com/object-detection-and-tracking-in-pytorch-b3cf1a696a98?source=tag_archive---------7-----------------------   \n",
       "333                                                                                                                                                                                     https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------0-----------------------   \n",
       "334                                                                                                                                                                                         https://towardsdatascience.com/a-detailed-explanation-of-the-attention-u-net-b371a5590831?source=tag_archive---------4-----------------------   \n",
       "335                                                                                                                                                                                                      https://medium.com/ml2vec/overview-of-conditional-random-fields-68a2a20fa541?source=tag_archive---------9-----------------------   \n",
       "336                                                                                                                                                                                                         https://medium.com/bonsal-capital/the-charm-of-a-gritty-city-82bc645a4313?source=tag_archive---------0-----------------------   \n",
       "337                                                                                                                                                                                        https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d?source=tag_archive---------3-----------------------   \n",
       "338                                                                                                                                                                                                                       https://towardsdatascience.com/bitcoin-bonanza-2cb208026bbd?source=tag_archive---------5-----------------------   \n",
       "339                                                                                                                                                                                               https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca?source=tag_archive---------7-----------------------   \n",
       "340                                                                                                                                                                                      https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011?source=tag_archive---------9-----------------------   \n",
       "341                                                                                                                                                                               https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b?source=tag_archive---------5-----------------------   \n",
       "342                                                                                                                                                  https://medium.com/@mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289?source=tag_archive---------8-----------------------   \n",
       "343                                                                                                                                                                                          https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33?source=tag_archive---------9-----------------------   \n",
       "344                                                                                                                                                                                                   https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab?source=tag_archive---------2-----------------------   \n",
       "345                                                                                                                                                   https://medium.com/@nikhilparmar9/simple-sgd-implementation-in-python-for-linear-regression-on-boston-housing-data-f63fcaaecfb1?source=tag_archive---------0-----------------------   \n",
       "346                                                                                                                                                                                          https://towardsdatascience.com/implementing-binary-logistic-regression-in-r-7d802a9d98fe?source=tag_archive---------3-----------------------   \n",
       "347                                                                                                                                                               https://medium.com/@hemantranvir/spam-detection-using-rnn-simplernn-lstm-with-step-by-step-explanation-530367608071?source=tag_archive---------6-----------------------   \n",
       "348                                                                                                                                                                                                                              https://medium.com/@jonathan-hui/yolov4-c9901eaa8e61?source=tag_archive---------3-----------------------   \n",
       "349                                                                                                       https://medium.com/@geneonline/%E7%99%8C%E7%B4%B0%E8%83%9E%E7%94%9F%E9%95%B7%E7%9A%84%E9%96%8B%E9%97%9C-%E5%9F%BA%E5%9B%A0%E5%95%9F%E5%8B%95%E5%AD%90-promoter-ed16fab2e013?source=tag_archive---------0-----------------------   \n",
       "350                                                                                                                                                                                                               https://medium.com/analytics-vidhya/rnn-vs-gru-vs-lstm-863b0b7b1573?source=tag_archive---------4-----------------------   \n",
       "351                                                                                                                                                                 https://towardsdatascience.com/fancy-and-custom-neural-style-transfer-filters-for-video-conferencing-7eba2be1b6d5?source=tag_archive---------6-----------------------   \n",
       "352  https://medium.com/@bigdataschool/3-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%B0-%D0%B4%D0%B5%D1%82%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2-c-deep-learning-r-cnn-fast-r-cnn-%D0%B8-faster-r-cnn-acdf6380fd33?source=tag_archive---------4-----------------------   \n",
       "353                                                                                                                                                                                                https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------1-----------------------   \n",
       "354                                                                                                                                                                                                     https://medium.com/puneetsl/1-creating-a-q-a-system-introduction-81d404dfb3e4?source=tag_archive---------0-----------------------   \n",
       "355                                                                                                                                                                              https://medium.com/@saketdingliwal97/model-agnostic-meta-learning-maml-an-intuitive-way-f7539e043c0b?source=tag_archive---------9-----------------------   \n",
       "356                                                                                                                                                                                                 https://medium.com/@shivon/the-current-state-of-machine-intelligence-f76c20db2fe1?source=tag_archive---------0-----------------------   \n",
       "357                                                                                                                                                                                   https://medium.com/@shiva-verma/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e?source=tag_archive---------8-----------------------   \n",
       "358                                                                                                                                https://medium.com/analytics-vidhya/keras-embedding-layer-and-programetic-implementation-of-glove-pre-trained-embeddings-step-by-step-7a4b2fa71544?source=tag_archive---------2-----------------------   \n",
       "359                                                                                                                                                                    https://medium.com/@shashank7-iitd/understanding-vector-quantized-variational-autoencoders-vq-vae-323d710a888a?source=tag_archive---------9-----------------------   \n",
       "360                                                                                                                                                                                          https://medium.com/analytics-vidhya/what-does-it-mean-by-bidirectional-lstm-63d6838e34d9?source=tag_archive---------8-----------------------   \n",
       "361                                                                                                                                                                                                          https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------4-----------------------   \n",
       "362                                                                                                                                                                           https://towardsdatascience.com/drl-01-a-gentle-introduction-to-deep-reinforcement-learning-405b79866bf4?source=tag_archive---------4-----------------------   \n",
       "363                                                                                                                                                                                                  https://towardsdatascience.com/generative-adversarial-networks-gans-89ef35a60b69?source=tag_archive---------8-----------------------   \n",
       "364                                                                                                                                                          https://medium.datadriveninvestor.com/batch-vs-mini-batch-vs-stochastic-gradient-descent-with-code-examples-cd8232174e14?source=tag_archive---------7-----------------------   \n",
       "365                                                                                                                                                                                    https://towardsdatascience.com/lambda-functions-with-practical-examples-in-python-45934f3653a8?source=tag_archive---------5-----------------------   \n",
       "366                                                                                                                                                             https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b?source=tag_archive---------5-----------------------   \n",
       "367                                                                                                                                                                                                        https://towardsdatascience.com/few-shot-learning-with-fast-ai-81c66064e372?source=tag_archive---------6-----------------------   \n",
       "368                                                                                                                                          https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c?source=tag_archive---------4-----------------------   \n",
       "369                                                                                                                                                                                                     https://blog.goodaudience.com/solving-8-puzzle-using-a-algorithm-7b509c331288?source=tag_archive---------9-----------------------   \n",
       "370                                                                                                                                                                                                     https://medium.com/datapy-ai/nlp-building-text-summarizer-part-1-902fec337b81?source=tag_archive---------9-----------------------   \n",
       "371                                                                                                                                                                                                             https://medium.com/@helymarleena/from-metaphor-to-reality-15790952657?source=tag_archive---------4-----------------------   \n",
       "372                                                                                                                                                                                        https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------2-----------------------   \n",
       "373                                                                                                                                                                                              https://towardsdatascience.com/training-provably-robust-neural-networks-1e15f2d80be2?source=tag_archive---------2-----------------------   \n",
       "374                                                                                                                                                                            https://medium.com/@UdacityINDIA/tensorflow-or-pytorch-the-force-is-strong-with-which-one-68226bb7dab4?source=tag_archive---------4-----------------------   \n",
       "375                                                                                                                                                                                https://towardsdatascience.com/gaussian-mixture-models-vs-k-means-which-one-to-choose-62f2736025f0?source=tag_archive---------8-----------------------   \n",
       "376                                                                                                                                                           https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a?source=tag_archive---------2-----------------------   \n",
       "377                                                                                                                                         https://towardsdatascience.com/unsupervised-classification-project-building-a-movie-recommender-with-clustering-analysis-and-4bab0738efe6?source=tag_archive---------4-----------------------   \n",
       "378                                                                                                                                                                       https://medium.com/data-science-at-microsoft/causal-inference-part-2-of-3-selecting-algorithms-a966f8228a2d?source=tag_archive---------1-----------------------   \n",
       "379                                                                                                                                                                                               https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939?source=tag_archive---------4-----------------------   \n",
       "380                                                                                                                                                                                    https://towardsdatascience.com/adversarial-examples-to-break-deep-learning-models-e7f543833eae?source=tag_archive---------1-----------------------   \n",
       "381                                                                                                                                                                https://towardsdatascience.com/understanding-the-backbone-of-video-classification-the-i3d-architecture-d4011391692?source=tag_archive---------5-----------------------   \n",
       "382                                                                                                                                       https://medium.com/@univprofblog1/random-forests-classification-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-fb60ff088db4?source=tag_archive---------6-----------------------   \n",
       "383                                                                                                                                                                                                                      https://becominghuman.ai/transformers-in-vision-e2e87b739feb?source=tag_archive---------4-----------------------   \n",
       "384                                                                                                                                      https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225?source=tag_archive---------6-----------------------   \n",
       "385                                                                                                                                                                                 https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e?source=tag_archive---------1-----------------------   \n",
       "386                                                                                                                                                                                           https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac?source=tag_archive---------3-----------------------   \n",
       "387                                                                                                                                                          https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-3-9d686d0d85d9?source=tag_archive---------8-----------------------   \n",
       "388                                                                                                                                                                                                   https://medium.com/coders-camp/60-python-projects-with-source-code-919cd8a6e512?source=tag_archive---------5-----------------------   \n",
       "389                                                                                                                                                      https://towardsdatascience.com/the-softmax-function-neural-net-outputs-as-probabilities-and-ensemble-classifiers-9bd94d75932?source=tag_archive---------9-----------------------   \n",
       "390                                                                                                                                                                        https://medium.com/binaryandmore/beginners-guide-to-deriving-and-implementing-backpropagation-e3c1a5a1e536?source=tag_archive---------3-----------------------   \n",
       "391                                                                                                                                                                                          https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2?source=tag_archive---------1-----------------------   \n",
       "392                                                                                                                                                                                                  https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842?source=tag_archive---------0-----------------------   \n",
       "393                                                                                                                                                                                 https://medium.com/@peter.bulyaki/a-brief-introduction-to-artificial-neural-networks-9962114c3bad?source=tag_archive---------3-----------------------   \n",
       "394                                                                                                                                                                                     https://medium.com/syncedreview/biggan-a-new-state-of-the-art-in-image-synthesis-cf2ec5694024?source=tag_archive---------2-----------------------   \n",
       "395                                                                                                                                                                                                  https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86?source=tag_archive---------7-----------------------   \n",
       "396                                                                                                                                                                                                  https://medium.com/@nathancooperjones/these-bored-apes-do-not-exist-6bed2c73f02c?source=tag_archive---------1-----------------------   \n",
       "397                                                                                                                                                                                   https://medium.com/@ahmetxgenc/detecting-empty-car-parking-lot-with-mask-rcnn-model-4f6202794a6?source=tag_archive---------4-----------------------   \n",
       "398                                                                                                                                                                                                       https://medium.com/value-stream-design/online-machine-learning-515556ff72c5?source=tag_archive---------6-----------------------   \n",
       "399                                                                                                                                                                                                      https://pdnotebook.com/image-analysis-intro-using-python-opencv-18791f4edf22?source=tag_archive---------3-----------------------   \n",
       "400                                                                                                                                                                        https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35?source=tag_archive---------9-----------------------   \n",
       "401                                                                                                                                                                                                    https://medium.com/pandorabots-blog/using-oob-tags-in-aiml-part-i-21214b4d2fcd?source=tag_archive---------2-----------------------   \n",
       "402                                                                                                                                                         https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581?source=tag_archive---------1-----------------------   \n",
       "403                                                                                                                                                 https://towardsdatascience.com/should-ai-explain-itself-or-should-we-design-explainable-ai-so-that-it-doesnt-have-to-90e75bb6089e?source=tag_archive---------2-----------------------   \n",
       "404                                                                                                                                                                                               https://towardsdatascience.com/an-introduction-to-perceptron-algorithm-40f2ab4e2099?source=tag_archive---------2-----------------------   \n",
       "405                                                                                                                                                                                                                      https://gab41.lab41.org/taking-keras-to-the-zoo-9a76243152cb?source=tag_archive---------9-----------------------   \n",
       "406                                                                                                                                                                                                    https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2?source=tag_archive---------0-----------------------   \n",
       "407                                                                                                                            https://medium.com/@vlknlvnt/reinforcement-learning-peki%C5%9Ftirmeli-%C3%B6%C4%9Frenme-i%CC%87nsan-beyniyle-aradaki-fark-kapan%C4%B1rken-c0d0a6f7c2e8?source=tag_archive---------5-----------------------   \n",
       "408                                                                                                                                                                              https://medium.com/capire-info/sugerencias-para-definir-un-men%C3%BA-de-navegaci%C3%B3n-e6efe33bfe22?source=tag_archive---------0-----------------------   \n",
       "409                                                                                                                                                                                       https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc?source=tag_archive---------0-----------------------   \n",
       "410                                                                                                                                                                     https://pub.towardsai.net/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa?source=tag_archive---------4-----------------------   \n",
       "411                                                                                                                                                                                                 https://medium.com/hackernoon/gradient-descent-vs-coordinate-descent-9b5657f1c59f?source=tag_archive---------0-----------------------   \n",
       "412                                                                                                                                        https://medium.com/hackernoon/how-i-deployed-my-spark-document-classification-logistic-regression-model-s-as-a-standalone-app-64b05b44e102?source=tag_archive---------3-----------------------   \n",
       "413                                                                                                                                                             https://medium.com/mlearning-ai/demonstrating-customers-segmentation-with-dbscan-clustering-using-python-8a2ba0db2a2e?source=tag_archive---------7-----------------------   \n",
       "414                                                                                                                                                                               https://towardsdatascience.com/nlp-spam-detection-in-sms-text-data-using-deep-learning-b8632db85cc8?source=tag_archive---------7-----------------------   \n",
       "415                                                                                                                                                                                                                 https://towardsdatascience.com/pos-tagging-using-rnn-7f08a522f849?source=tag_archive---------4-----------------------   \n",
       "416                                                                                                                                                                       https://medium.com/geekculture/deep-convolutional-generative-adversarial-network-using-pytorch-ece1260acc47?source=tag_archive---------9-----------------------   \n",
       "417                                                                                                                                                                                        https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------5-----------------------   \n",
       "418                                                                                                                                                                                         https://medium.com/@jonathan-hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088?source=tag_archive---------2-----------------------   \n",
       "419                                                                                                                                                                                                              https://towardsdatascience.com/mercari-price-suggestion-97ff15840dbd?source=tag_archive---------6-----------------------   \n",
       "420                                                                                                                                                                                                                https://medium.com/swlh/embeddings-in-machine-learning-548eef7b2b5?source=tag_archive---------7-----------------------   \n",
       "421                                                                                                                                                                               https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------3-----------------------   \n",
       "422                                                                                                                                                                                                 https://medium.com/@shashank7-iitd/understanding-attention-mechanism-35ff53fc328e?source=tag_archive---------8-----------------------   \n",
       "423                                                                                                                                                                                        https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205?source=tag_archive---------3-----------------------   \n",
       "424                                                                                                                                                                                                       https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba?source=tag_archive---------8-----------------------   \n",
       "425                                                                                                                                                                         https://medium.com/ai%C2%B3-theory-practice-business/object-detection-in-deep-learning-part2-855b78689f13?source=tag_archive---------8-----------------------   \n",
       "426                                                                                                                                                                                https://medium.com/mlearning-ai/a-brief-overview-of-r-cnn-fast-r-cnn-and-faster-r-cnn-9c6843c9ffc0?source=tag_archive---------1-----------------------   \n",
       "427                                                                                                                                                                           https://towardsdatascience.com/evasion-attacks-on-machine-learning-or-adversarial-examples-12f2283e06a1?source=tag_archive---------2-----------------------   \n",
       "428                                                                                                                                                                          https://medium.com/@andrewmarmon/fine-tuned-named-entity-recognition-with-hugging-face-bert-d51d4cb3d7b5?source=tag_archive---------5-----------------------   \n",
       "429                                                                                                                                                                                                             https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d?source=tag_archive---------7-----------------------   \n",
       "430                                                                                                                                                                                              https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56?source=tag_archive---------1-----------------------   \n",
       "431                                                                                                                                   https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------0-----------------------   \n",
       "432                                                                                                                                                                       https://medium.com/blog-rilut/neural-networks-without-backpropagation-direct-feedback-alignment-30d5d4848f5?source=tag_archive---------6-----------------------   \n",
       "433                                                                                                                                                                     https://medium.com/clustering-with-gaussian-mixture-model/clustering-with-gaussian-mixture-model-c695b6cd60da?source=tag_archive---------3-----------------------   \n",
       "434                                                                                                                                                                                       https://medium.com/analytics-vidhya/training-a-spacy-ner-pipeline-with-prodigy-ca58350cb868?source=tag_archive---------1-----------------------   \n",
       "435                                                                                                                                                                                                https://towardsdatascience.com/solving-the-multi-armed-bandit-problem-b72de40db97c?source=tag_archive---------8-----------------------   \n",
       "436                                                                                                                                                                                           https://towardsdatascience.com/single-stage-instance-segmentation-a-review-1eeb66e0cc49?source=tag_archive---------5-----------------------   \n",
       "437                                                                                                                                                                     https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2?source=tag_archive---------1-----------------------   \n",
       "438                                                                                                                                                                                                         https://towardsdatascience.com/predict-customer-churn-with-r-9e62357d47b4?source=tag_archive---------6-----------------------   \n",
       "439                                                                                                                                                               https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49?source=tag_archive---------4-----------------------   \n",
       "440                                                                                                                                                                                 https://towardsdatascience.com/important-topics-in-machine-learning-you-need-to-know-21ad02cc6be5?source=tag_archive---------9-----------------------   \n",
       "441                                                                                                                                                                                      https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9?source=tag_archive---------1-----------------------   \n",
       "442                                                                                                                                                                         https://towardsdatascience.com/wthe-ultimate-guide-to-clustering-algorithms-and-topic-modeling-4f7757c115?source=tag_archive---------4-----------------------   \n",
       "443                                                                                                                                                 https://towardsdatascience.com/text-summarization-from-scratch-using-encoder-decoder-network-with-attention-in-keras-5fa80d12710e?source=tag_archive---------6-----------------------   \n",
       "444                                                                                                                                         https://medium.com/@univprofblog1/linear-discriminant-analysis-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-4acfffc4726?source=tag_archive---------5-----------------------   \n",
       "445                                                                                                                                                                                      https://medium.com/intuitionmachine/the-strange-loop-in-alphago-zeros-self-play-6e3274fcdd9f?source=tag_archive---------3-----------------------   \n",
       "446                                                                                                                                                                                             https://medium.com/@arifiany/segmentasi-semantik-untuk-klasifikasi-citra-a004b3906250?source=tag_archive---------8-----------------------   \n",
       "447                                                                                                                                                                                                    https://medium.com/@humble_bee/rnn-recurrent-neural-networks-lstm-842ba7205bbf?source=tag_archive---------7-----------------------   \n",
       "448                                                                                                                                                                                                              https://medium.com/@borisanthony/puppyslugs-r-us-part-1-88461c2104ba?source=tag_archive---------7-----------------------   \n",
       "449                                                                                                                                                               https://medium.com/ai-salon/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251?source=tag_archive---------5-----------------------   \n",
       "450                                                                                                                                                              https://towardsdatascience.com/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649?source=tag_archive---------2-----------------------   \n",
       "451                                                                                                                                                                            https://medium.com/analytics-vidhya/understanding-the-stylegan-and-stylegan2-architecture-add9e992747d?source=tag_archive---------2-----------------------   \n",
       "452                                                                                                                                                                                     https://medium.com/@jonathan-hui/map-mean-average-precision-for-object-detection-45c121a31173?source=tag_archive---------1-----------------------   \n",
       "453                                                                                                                                                                                                https://medium.com/@earnskins/guide-pop-slots-casino-level-27-13-easy-a387f127d9f3?source=tag_archive---------7-----------------------   \n",
       "454                                                                                                                                                                                               https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-2-cf81bf32c73d?source=tag_archive---------8-----------------------   \n",
       "455                                                                                                                                                                              https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d?source=tag_archive---------4-----------------------   \n",
       "456                                                                                                                                                                               https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c?source=tag_archive---------5-----------------------   \n",
       "457                                                                                                                                                                                        https://towardsdatascience.com/clustering-algorithm-for-customer-segmentation-e2d79e28cbc3?source=tag_archive---------0-----------------------   \n",
       "458                                                                                                                                                           https://towardsdatascience.com/train-neural-net-for-semantic-segmentation-with-pytorch-in-50-lines-of-code-830c71a6544f?source=tag_archive---------8-----------------------   \n",
       "459                                                                                                                                                                                https://towardsdatascience.com/multivariate-time-series-forecasting-with-transformers-384dc6ce989b?source=tag_archive---------2-----------------------   \n",
       "460                                                                                                                                                                                   https://towardsdatascience.com/blitz-a-bayesian-neural-network-library-for-pytorch-82f9998916c7?source=tag_archive---------4-----------------------   \n",
       "461                                                                                                                                                                   https://medium.com/gradientcrescent/neural-art-style-transfer-with-keras-theory-and-implementation-91b7fb08ee81?source=tag_archive---------9-----------------------   \n",
       "462                                                                                                                                                                                                                 https://techblog.ezra.com/different-embedding-models-7874197dc410?source=tag_archive---------6-----------------------   \n",
       "463                                                                                                                                                                                                                                       https://open.nytimes.com/equake-85b6566b7f2?source=tag_archive---------8-----------------------   \n",
       "464                                                                                                                                                                                                        https://towardsdatascience.com/gangogh-creating-art-with-gans-8d087d8f74a1?source=tag_archive---------1-----------------------   \n",
       "465                                                                                                                                                                                                                   https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------1-----------------------   \n",
       "466                                                                                                                                                            https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-1-3d9fada3b80d?source=tag_archive---------0-----------------------   \n",
       "467                                                                                                                                                                                                 https://medium.com/dataweave/smartphones-vs-tablets-does-size-matter-963ab7dd6052?source=tag_archive---------3-----------------------   \n",
       "468                                                                                                                                                                    https://towardsdatascience.com/stochastic-gradient-descent-for-machine-learning-clearly-explained-cadcc17d3d11?source=tag_archive---------6-----------------------   \n",
       "469                                                                                                                                                                                                          https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea?source=tag_archive---------5-----------------------   \n",
       "470                                                                                                                                                                                        https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------0-----------------------   \n",
       "471                                                                                                                                                                                                  https://towardsdatascience.com/fooling-facial-detection-with-fashion-d668ed919eb?source=tag_archive---------4-----------------------   \n",
       "472                                                                                                                                                                                                                             https://towardsdatascience.com/stylegan2-ace6d3da405d?source=tag_archive---------2-----------------------   \n",
       "473                                                                                                                                                                                                  https://medium.com/pankajmathur/logistic-regression-with-tensorflow-a02c2bd2bd1e?source=tag_archive---------1-----------------------   \n",
       "474                                                                                                                                                                                                https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------6-----------------------   \n",
       "475                                                                                                                                                                                                https://towardsdatascience.com/time-series-of-price-anomaly-detection-13586cd5ff46?source=tag_archive---------4-----------------------   \n",
       "476                                                                                                                                                                        https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92?source=tag_archive---------2-----------------------   \n",
       "477                                                                                                                                                                                                        https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484?source=tag_archive---------0-----------------------   \n",
       "478                                                                                                                                                                                                    https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a?source=tag_archive---------9-----------------------   \n",
       "479                                                                                                                                                           https://towardsdatascience.com/gmm-gaussian-mixture-models-how-to-successfully-use-it-to-cluster-your-data-891dc8ac058f?source=tag_archive---------7-----------------------   \n",
       "480                                                                                                                                                                               https://medium.com/hackernoon/speeding-up-your-code-2-vectorizing-the-loops-with-numpy-e380e939bed3?source=tag_archive---------6-----------------------   \n",
       "481                                                                                                                                                                                        https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211?source=tag_archive---------2-----------------------   \n",
       "482                                                                                                                                                                                                    https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada?source=tag_archive---------6-----------------------   \n",
       "483                                                                                                                                                                              https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b?source=tag_archive---------1-----------------------   \n",
       "484                                                                                                                                                                            https://onezero.medium.com/gpt-3-is-an-amazing-research-tool-openai-isnt-sharing-the-code-d048ba39bbfd?source=tag_archive---------4-----------------------   \n",
       "485                                                                                                                                                                                        https://towardsdatascience.com/introduction-to-machine-learning-for-beginners-eed6024fdb08?source=tag_archive---------3-----------------------   \n",
       "486                                                                                                                                                                                                    https://medium.com/on-docker/federated-clusters-with-docker-swarm-dce5516ecc8d?source=tag_archive---------6-----------------------   \n",
       "487                                                                                                                                                                                                https://towardsdatascience.com/clustering-based-unsupervised-learning-8d705298ae51?source=tag_archive---------7-----------------------   \n",
       "488                                                                                                                                                                                            https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610?source=tag_archive---------9-----------------------   \n",
       "489                                                                                                                                                                                        https://towardsdatascience.com/the-proper-way-to-use-machine-learning-metrics-4803247a2578?source=tag_archive---------8-----------------------   \n",
       "490                                                                                                                                                                                                  https://medium.com/moonvision/few-shot-object-detection-in-practice-4f8fa98cba57?source=tag_archive---------3-----------------------   \n",
       "491                                                                                                                                                                                     https://towardsdatascience.com/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=tag_archive---------6-----------------------   \n",
       "492                                                                                                                                                                       https://medium.com/analytics-vidhya/how-batch-normalization-and-relu-solve-vanishing-gradients-3f1a8ace1c88?source=tag_archive---------0-----------------------   \n",
       "493                                                                                                                                                                                             https://towardsdatascience.com/k-means-clustering-and-the-gap-statistics-4c5d414acd29?source=tag_archive---------5-----------------------   \n",
       "494                                                                                                                                                   https://medium.com/dark-matter-and-trojan-horses/of-brains-and-cities-neuroscience-and-cultures-of-decision-making-6bc6abb48d4b?source=tag_archive---------0-----------------------   \n",
       "495                                                                                                                                                                     https://medium.com/ensina-ai/redes-neurais-perceptron-multicamadas-e-o-algoritmo-backpropagation-eaf89778f5b8?source=tag_archive---------5-----------------------   \n",
       "496                                                                                                                                                                                                https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73?source=tag_archive---------7-----------------------   \n",
       "497                                                                                                                                                                                                            https://blog.insightdatascience.com/preparing-for-insight-ca7cc6087f91?source=tag_archive---------3-----------------------   \n",
       "498                                                                                                                                                                                                                         https://medium.com/altsoph/google-ai-contest-eed23cfdeb6f?source=tag_archive---------3-----------------------   \n",
       "499                                                                                                                                                                                                                            https://medium.com/huggingface/distilbert-8cf3380435b5?source=tag_archive---------5-----------------------   \n",
       "\n",
       "                                                                                                                                                                                   title  \\\n",
       "0                                                                                      Step-by-Step R-CNN Implementation From Scratch In Python | by Rohit Thakur | Towards Data Science   \n",
       "1                                                                             How Transformers Work. Transformers are a type of neural... | by Giuliano Giacaglia | Towards Data Science   \n",
       "2                                                                                                      Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science   \n",
       "3                                                                                                               Amazon’s Artificial Artificial Intelligence | by Sachin Palewar | Medium   \n",
       "4                                                                                                     This week in the #SDGs- February 17, 2017 | by SDGCounting | SDG Counting | Medium   \n",
       "5                                                                                                     Views From A College Dropout’s Unconventional Life — Year 2 | by Tam Pham | Medium   \n",
       "6                                                                              Introducción a Machine Learning. Machine Learning, Big Data, Deep... | by Virginia Peón | ECLaboratorio   \n",
       "7                                                                                                             When Exactly Did It Get Cool To Be A Geek? | by The Awl | The Awl | Medium   \n",
       "8                                                                                                  K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science   \n",
       "9                                                                                                           Lou Reed: Entre “Transformer” e “Berlin” o mito. | by Igor de Sousa | Medium   \n",
       "10                                                                                           Machine Learning is Fun!. The world’s easiest introduction to... | by Adam Geitgey | Medium   \n",
       "11                                                                               Master the COCO Dataset for Semantic Image Segmentation — Part 1 of 2 | by Viraf | Towards Data Science   \n",
       "12                                                      IT Support Ticket Classification and Deployment using Machine Learning and AWS Lambda | by Pankaj Kishore | Towards Data Science   \n",
       "13                                                                                                  Text Classification with BERT in PyTorch | by Ruben Winastwan | Towards Data Science   \n",
       "14                                                                                                              Anatomy of an Elasticsearch Cluster: Part I | by Ronak Nathani | Insight   \n",
       "15                                                                                      The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science   \n",
       "16                                                  IoT Learning Algorithms and Predictive Maintenance — Part III: Few-shot Learning | by Record Evolution | IoT & Data Science | Medium   \n",
       "17                                                                Machine Learning week 1: Cost Function, Gradient Descent and Univariate Linear Regression | by Lachlan Miller | Medium   \n",
       "18                                                                                              DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero   \n",
       "19                                            Computer Vision Tutorial: Implementing Mask R-CNN for Image Segmentation (with Python Code) | by Pulkit Sharma | Analytics Vidhya | Medium   \n",
       "20                                                                                                          Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science   \n",
       "21                                                                                              Credit Scoring with Machine Learning | by Hongri Jia | Passion for Data Science | Medium   \n",
       "22                                                        If you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works... | by Justin Davies | Medium   \n",
       "23                                 Creating and training a U-Net model with PyTorch for 2D & 3D semantic segmentation: Model building [2/4] | by Johannes Schmidt | Towards Data Science   \n",
       "24                                                              The best explanation of Convolutional Neural Networks on the Internet! | by Harsh Pokharna | TechnologyMadeEasy | Medium   \n",
       "25                                                                                           Key takeaways — O’reilly AI London Conference, Oct 9–11, 2018 | by Debmalya Biswas | Medium   \n",
       "26                                                                      Machine Learning — Word Embedding & Sentiment Classification using Keras | by Javaid Nabi | Towards Data Science   \n",
       "27                                                                                    Computer Vision: Instance Segmentation with Mask R-CNN | by Renu Khandelwal | Towards Data Science   \n",
       "28                                                                                       Traveling santa Problem — An incompetent algorist’s attempt | by Hrishikesh Huilgolkar | Medium   \n",
       "29                                                                                             Data without context is meaningless (and boring) | by Jan Schultink | SlideMagic | Medium   \n",
       "30                                                                                 K-Fold Cross Validation for Deep Learning Models using Keras | by Siladittya Manna | The Owl | Medium   \n",
       "31                                                                                                                        Gotta catch them all, but which one first? | by Knoyd | Medium   \n",
       "32                                                                                        GloVe, ELMo & BERT. A guide to state-of-the-art text... | by Ryan Burke | Towards Data Science   \n",
       "33                                                                                                       AI Safety and the Scaling Hypothesis | by Jeremie Harris | Towards Data Science   \n",
       "34                                                                                   Подводные камни UNet в Unity 5. или то, что не описано в документации | by Pavel Shestakov | Medium   \n",
       "35                                                     Real-time face recognition: training and deploying on Android using Tensorflow lite — transfer learning | by Saidakbar P | Medium   \n",
       "36                                                                                                            Decision Tree in Machine Learning | by Prince Yadav | Towards Data Science   \n",
       "37                                                                                              DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero   \n",
       "38                                                                  DBSCAN clustering for data shapes k-means can’t handle well (in Python) | by Gabriel Pierobon | Towards Data Science   \n",
       "39                                                                               How Does Back-Propagation in Artificial Neural Networks Work? | by Anas Al-Masri | Towards Data Science   \n",
       "40                                                           Tesla’s Big Plans, DeepMind Pays For Itself, Internet Drones, and Moore’s Law | by Matt Kiser | Emergent // Future | Medium   \n",
       "41                                                                                                 Transfer learning from pre-trained models | by Pedro Marcelino | Towards Data Science   \n",
       "42                                                                                                     Serving PyTorch Models on AWS Lambda with Caffe2 & ONNX | by michaelulin | Medium   \n",
       "43                                                                                         [談理解] 電競賽評也能告訴我們如何設計智慧系統的解釋機制?. 「蟲苔已經撲到人家的臉上了!」... | by Chi-Lan Yang | 楊期蘭 | 人機共生你我它 | Medium   \n",
       "44                                                                      Artistic Style Transfer with Convolutional Neural Network | by Manjeet Singh | Data Science Group, IITR | Medium   \n",
       "45                                                                                         How to predict Quora Question Pairs using Siamese Manhattan LSTM | by Elior Cohen | ML Review   \n",
       "46                                                                           Use-cases of Google’s Universal Sentence Encoder in Production | by Sambit Mahapatra | Towards Data Science   \n",
       "47                                                                                                    Understanding Bidirectional RNN in PyTorch | by Ceshine Lee | Towards Data Science   \n",
       "48                                                                                                                    Appearance of The Principate [Pt. II] | by Daniel Voshart | Medium   \n",
       "49                                                            Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science   \n",
       "50                                                                                            Understanding Logistic Regression step by step | by Gustavo Chávez | Towards Data Science   \n",
       "51                                                                                                              Object Detection & Segmentation with Python | by Apdullah Yayik | Medium   \n",
       "52                                                                       Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science   \n",
       "53                                                                                             How to build a Recurrent Neural Network in TensorFlow (1/7) | by Erik Hallström | Medium   \n",
       "54                                                                 Text Classification in Spark NLP with Bert and Universal Sentence Encoders | by Veysel Kocaman | Towards Data Science   \n",
       "55                                                                                             DBScan on trajectories — Determining Eps and MinPts | by Marcio Geovani Jasinski | Medium   \n",
       "56                                                                                           TikTok’s new feature — anime filter got million posts in 3 days | by Vicente Luego | Medium   \n",
       "57                       AlphaFold-based databases and fully-fledged, easy-to-use, online AlphaFold interfaces poised to revolutionize biology | by LucianoSphere | Towards Data Science   \n",
       "58                                                                               Background Removal in Real-Time Video Chats using TensorflowJS, Part 1 | by Jean-Marc Beaujour | Medium   \n",
       "59                                                                                               Chatbots were the next big thing: what happened? | by Justin Lee | The Startup | Medium   \n",
       "60                                                                                  Reinforcement Learning w/ Keras + OpenAI: Actor-Critic Models | by Yash Patel | Towards Data Science   \n",
       "61                                                                     Machine Learning Project: Predicting Boston House Prices With Regression | by Victor Roman | Towards Data Science   \n",
       "62                                                                          AdaBelief Optimizer: fast as Adam, generalizes as well as SGD | by Kaustubh Mhaisekar | Towards Data Science   \n",
       "63                                                                                                                           Train New BERT Model on Any Language | Towards Data Science   \n",
       "64                                                                                  Credit Card Fraud Detection using Autoencoders in H2O | by Maneesha Rajaratne | Towards Data Science   \n",
       "65                                                                                                             Backpropagation: The Simple Proof | by Essam Wisam | Towards Data Science   \n",
       "66                                                                                                            Basics of Image Classification with PyTorch | by John Olafenwa | Heartbeat   \n",
       "67                                                                                                            Music Genre Classification Using CNN | by Arsh Chowdhry | Clairvoyant Blog   \n",
       "68                                                                       Multi-label Text Classification using BERT – The Mighty Transformer | by Kaushal Trivedi | HuggingFace | Medium   \n",
       "69                                                                                         Google DeepMind-style datacenter optimization AI model (on the cheap) | by commander | Medium   \n",
       "70                                                           The Volcker metric known as inventory aging... and thoughts of Whisky | by Acuity Derivatives | Acuity Derivatives | Medium   \n",
       "71                                                                                                      Prior over functions: Gaussian process | by Jehill Parikh | Towards Data Science   \n",
       "72                                                                                                            1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium   \n",
       "73                                                                                  Simple and multiple linear regression with Python | by Amanda Iglesias Moreno | Towards Data Science   \n",
       "74                                                                                NER, SpaCy and Lasagne. One of the great things about NER is... | by Paul Ellis | The Startup | Medium   \n",
       "75                                                                                    Word2vec with PyTorch: Implementing the Original Paper | by Olga Chernytska | Towards Data Science   \n",
       "76                                                            A short introduction to StyleGAN. Generative models(GAN) have always been... | by Praveenkumar | Analytics Vidhya | Medium   \n",
       "77                                                                                       CSS Box Model and Positioning. VGG Virtual Internship Assignment. | by Chijioke Nwagwu | Medium   \n",
       "78                                                                                               Text Summarization Using Deep Neural Networks | by Shivam Duseja | Towards Data Science   \n",
       "79                                                                       Probability concepts explained: Maximum likelihood estimation | by Jonny Brooks-Bartlett | Towards Data Science   \n",
       "80                                                                                                                       Build K-Means from scratch in Python | by Rishit Dagli | Medium   \n",
       "81                                                                                                     Using ResNet for ECG time-series data | by Sanne de Roever | Towards Data Science   \n",
       "82                                                                                            Understanding UNET. How to understand U-Net in the most... | by Kirill Bondarenko | Medium   \n",
       "83                                                                                        Presenting Goibibo Insights. Its now been quite some time for... | by Goibibo Tech | Backstage   \n",
       "84                                                                                                                          Understanding LSTM and its diagrams | by Shi Yan | ML Review   \n",
       "85                                                                                                         Fast and Faster Region-based Convolutional Network | by Pavan Gurram | Medium   \n",
       "86                                                                                                   GAN 2.0: NVIDIA’s Hyperrealistic Face Generator | by Synced | SyncedReview | Medium   \n",
       "87                                                                                                     Automated Feature Engineering Tools | by Rajneesh Jha | Analytics Vidhya | Medium   \n",
       "88                                                                Clustering documents with Python. A simple example with Wikipedia... | by Dimitris Panagopoulos | Towards Data Science   \n",
       "89                                                                                                   How I got my first android job without a degree or experience | by Mo Hajr | Medium   \n",
       "90                                                                       Machine Learning —Fundamentals. Basic theory underlying the field of... | by Javaid Nabi | Towards Data Science   \n",
       "91                                                                                                      Activation Functions in Neural Networks | by SAGAR SHARMA | Towards Data Science   \n",
       "92                                                                                             Train Object Detection AI with 6 lines of code | by Moses Olafenwa | DeepQuestAI | Medium   \n",
       "93                                                                    Diving into Abstractive Text Summarization — Part 1 | by Vincenzo Santopietro | Intel Student Ambassadors | Medium   \n",
       "94                                                                         Introduction to ResNets. This Article is Based on Deep Residual... | by Connor Shorten | Towards Data Science   \n",
       "95                                                                                       NLP — Text Summarization using NLTK: TF-IDF Algorithm | by Akash Panchal | Towards Data Science   \n",
       "96                                                    Gaussian Mixture Model clustering: how to select the number of components (clusters) | by Vincenzo Lavorini | Towards Data Science   \n",
       "97                                                                                Understanding Optimization Algorithms in Machine Learning | by Supriya Secherla | Towards Data Science   \n",
       "98                       HRNet Explained: Human Pose Estimation, Semantic Segmentation and Object Detection | by Hucker Marius | Oct, 2021 | Towards Data Science | Towards Data Science   \n",
       "99                                                                                                                           No home for iPad on Apple.com | by Craig Villamor | cvil.ly   \n",
       "100                                                                         Attention — Seq2Seq Models. Sequence-to-sequence (abrv. Seq2Seq)... | by Pranay Dugar | Towards Data Science   \n",
       "101                                   Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium   \n",
       "102                                                                                        Read Text from Image with One Line of Python Code | by Dario Radečić | Towards Data Science   \n",
       "103                                                                       Interpreting recurrent neural networks on multivariate time series | by André Ferreira | Towards Data Science   \n",
       "104                                                                        How I went from zero coding skills to data scientist in 6 months | by Kate Marie Lewis | Towards Data Science   \n",
       "105                                                                                                         20 ideas for better data visualization | by Taras Bakusevych | UX Collective   \n",
       "106                                                                                  Blog 9- Information Architecture. 1. What is the purpose of metadata... | by Joshua Holmes | Medium   \n",
       "107                                                                           Understanding Dropout. One particular layers that are useful... | by Roan Gylberth | Konvergen.AI | Medium   \n",
       "108                                                                                        TokenGo запускает ICO!. Приветствую вас, друзья! TokenGo... | by TokenGo Platform_RU | Medium   \n",
       "109                                                                                             Tips to avoid the pitfall of over fitting in Linear Regression | by karthic Rao | Medium   \n",
       "110                                                                                   Step by step -Understand the architecture of Region proposal network (R-CNN) | by Pallawi | Medium   \n",
       "111                                                                                            Invest in Unchainet |Heterogeneous Cloud Computing Infrastructure | by Unchainet | Medium   \n",
       "112                                                                                                                                                  Coding is a Trap. Get Out. | TekLit   \n",
       "113                                                                             In case you missed it: My Webinar on Model-Based Machine Learning | by Daniel Emaasit | emaasit | Medium   \n",
       "114                                                                                      Instance Segmentation in Google Colab with Custom Dataset | by RomRoc | HackerNoon.com | Medium   \n",
       "115                                                             Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK. | by Javed Shaikh | Towards Data Science   \n",
       "116                                                                                       Deep Reinforcement Learning for Automated Stock Trading | by Bruce Yang | Towards Data Science   \n",
       "117                                                                              The First Inaugural Firefox Census Results | by Firefox | The Official Unofficial Firefox Blog | Medium   \n",
       "118                                                            Audio Deep Learning Made Simple: Automatic Speech Recognition (ASR), How it Works | by Ketan Doshi | Towards Data Science   \n",
       "119                       EagleView high-resolution image semantic segmentation with Mask-RCNN/DeepLabV3+ using Keras and ArcGIS Pro | by Chunguang (Wayne) Zhang | Towards Data Science   \n",
       "120                                                                                                       Everything You Need to Know about Logistic Regression | by Uday Paila | Medium   \n",
       "121                                                                Gradient descent algorithms and adaptive learning rate adjustment methods | by Manish Chablani | Towards Data Science   \n",
       "122                                                      The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English   \n",
       "123                                                                                                                   DBSCAN Parameter Estimation Using Python | by Tara Mullin | Medium   \n",
       "124                                                                       U-Net for Semantic Segmentation on Unbalanced Aerial Imagery | by Amirhossein Heydarian | Towards Data Science   \n",
       "125                                                                              Dimensionality Reduction by Stochastic Gradient Descent | by Learner Subodh | Analytics Vidhya | Medium   \n",
       "126                                                                                              How to Fine-Tune BERT Transformer with spaCy 3 | by Walid Amamou | Towards Data Science   \n",
       "127                                   Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium   \n",
       "128                                                                                                              SGD: MNIST — Putting it all together | by Becky Zhu | unpackAI | Medium   \n",
       "129                                                                                                                                   What is Transformer Network | Towards Data Science   \n",
       "130                     Simple Image Classification using Convolutional Neural Network — Deep Learning in python. | by Venkatesh Tata | Becoming Human: Artificial Intelligence Magazine   \n",
       "131                                                                                How to easily Detect Objects with Deep Learning on Raspberry Pi | by Sarthak Jain | NanoNets | Medium   \n",
       "132                                                                                                  An intuitive explanation of Beam Search | by Renu Khandelwal | Towards Data Science   \n",
       "133                                                                                    The Games That AI Won. And The Progress They Represent | by Brandon Walker | Towards Data Science   \n",
       "134                                                                              Clustering Liferay globally across data centers (GSLB) with JGroups and RELAY2 | by bitsofinfo | Medium   \n",
       "135                                                                                    Kuliah Itu Gak Penting. “Buat apa kuliah kalo kalah sukses atau... | by Andreas Yonathan | Medium   \n",
       "136                                                                              Word embeddings in 2020. Review with code examples | by Rostyslav Neskorozhenyi  | Towards Data Science   \n",
       "137                                                                                    Autoencoders — Introduction and Implementation in TF. | by Manish Chablani | Towards Data Science   \n",
       "138                                                                                                            Getting Started With Google Colab | by Anne Bonner | Towards Data Science   \n",
       "139                                                                                          Your Guide to Natural Language Processing (NLP) | by Diego Lopez Yse | Towards Data Science   \n",
       "140                                                                         PixelCNN’s Blind Spot. Limitations of the PixelCNN and how to... | by Jessica Dafflon | Towards Data Science   \n",
       "141                                                                     Simple Introduction to Convolutional Neural Networks | by Matthew Stewart, PhD Researcher | Towards Data Science   \n",
       "142                                                                                 Practical implementation of outlier detection in python | by Md Sohel Mahmood | Towards Data Science   \n",
       "143                                                               Explaining system intelligence. Empower your users, but don’t overwhelm... | by Vladimir Shapiro | SAP Design | Medium   \n",
       "144                                                                                  Topic Modeling and Latent Dirichlet Allocation (LDA) in Python | by Susan Li | Towards Data Science   \n",
       "145                                                          Step by Step Implementation of Conditional Generative Adversarial Networks | by Neeraj Varshney | Analytics Vidhya | Medium   \n",
       "146                                                                                        Multiclass Text Classification using LSTM in Pytorch | by Aakanksha NS | Towards Data Science   \n",
       "147                                                                Linear Regression using Python. Linear Regression is usually the first... | by Animesh Agarwal | Towards Data Science   \n",
       "148                                                                                       Autoencoders — Bits and Bytes of Deep Learning | by Vindula Jayawardana | Towards Data Science   \n",
       "149                                                                                Write an AI to win at Pong from scratch with Reinforcement Learning | by Dhruv Parthasarathy | Medium   \n",
       "150                                                                               Basics of Using Pre-trained GloVe Vectors in Python | by Sebastian Theiler | Analytics Vidhya | Medium   \n",
       "151                                              Pipelines & Custom Transformers in scikit-learn: The step-by-step guide (with Python code) | by Himanshu Chandra | Towards Data Science   \n",
       "152                                                                                     TF-IDF from scratch in python on a real-world dataset. | by William Scott | Towards Data Science   \n",
       "153                                                                                       Deep Latent Variable Models: Unravel Hidden Structures | by Kevin Luxem | Towards Data Science   \n",
       "154                                                                                                        Sentence correction using Deep learning techniques | by Sourav kumar | Medium   \n",
       "155                                                                                                         R — CNN Ailesi Part II: Faster R-CNN & Mask R-CNN | by Elif Meşeci | Medium   \n",
       "156                                                                           Clustering Techniques. Clustering falls under the unsupervised... | by M Bharathwaj | Towards Data Science   \n",
       "157                                                                              Introduction to Object Detection with RCNN Family Models | by Sairaj Neelam | Analytics Vidhya | Medium   \n",
       "158                                                                    LSTM by Example using Tensorflow. In Deep Learning, Recurrent Neural... | by Rowel Atienza | Towards Data Science   \n",
       "159                                                                            Illustrated Guide to LSTM’s and GRU’s: A step by step explanation | by Michael Phi | Towards Data Science   \n",
       "160                                                                                       Amazon Adds Photographic Product Search To iOS App | by IPG Media Lab | IPG Media Lab | Medium   \n",
       "161                                                                                              How to cluster images based on visual similarity | by Gabe Flomo | Towards Data Science   \n",
       "162                                                                         A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way | by Sumit Saha | Towards Data Science   \n",
       "163                                                             Solving the FrozenLake environment from OpenAI gym using Value Iteration | by Diganta Kalita | Analytics Vidhya | Medium   \n",
       "164                                                                                             Neural Networks Backpropagation Made Easy | by Lihi Gur Arie, PhD | Towards Data Science   \n",
       "165                                                                  ICML 2018: Advances in transfer, multitask, and semi-supervised learning | by Isaac Godfried | Towards Data Science   \n",
       "166                                                                                        Run StyleGAN2 ADA on an AWS Spot Instance in No Time | by Oleg Polosin | Towards Data Science   \n",
       "167                                                                                 Generating text with Recurrent Neural Networks based on the work of F. Pessoa | Towards Data Science   \n",
       "168                                                                                                       Advancements in Machine Learning Assisted Ideation. | by Adam Pickard | Medium   \n",
       "169                                                                                             기계 학습(Machine Learning, 머신 러닝)은 즐겁다! Part 5 | by Jongdae Lim | Medium   \n",
       "170                                                                              Understanding PyTorch with an example: a step-by-step tutorial | by Daniel Godoy | Towards Data Science   \n",
       "171                                                                                                RNN or Recurrent Neural Network for Noobs | by Debarko De 🦁 | HackerNoon.com | Medium   \n",
       "172                                                                                                      Optimizers in Deep Learning. What is Optimizers? | by Ayushi choudhary | Medium   \n",
       "173                                                      “Isolation Forest”: The Anomaly Detection Algorithm Any Data Scientist Should Know | by Samuele Mazzanti | Towards Data Science   \n",
       "174                                                                                  Word2Vec (Part 1). Word2Vec; the Steroids for Natural... | by Mukul Malik | HackerNoon.com | Medium   \n",
       "175                                                                               Keywords to know before you start reading papers on GANs | by Dr. Varshita Sher | Towards Data Science   \n",
       "176                                                                                                                           Bayesian Variational Autoencoders | by Rob Parkin | Medium   \n",
       "177                                                                                       關於影像辨識,所有你應該知道的深度學習模型. Computer vision object detection... | by Steven Shen | Cubo AI | Medium   \n",
       "178                                                                                              Emotional Computing. Investigating the human to computer... | by Robbie Tilton | Medium   \n",
       "179                                                                                        Computational creativity: generative creature design for concept art | by Kyle Huang | Medium   \n",
       "180                                                                                                            Learning Artistic Styles from Images | by James Lee | Nurture.AI | Medium   \n",
       "181                                                                                                A Friendly Introduction to Text Clustering | by Korbinian Koch | Towards Data Science   \n",
       "182                                                                                     Normalization vs Standardization — Quantitative analysis | by Shay Geller | Towards Data Science   \n",
       "183                                                                                                    An Overview for Text Representations in NLP | by jiawei hu | Towards Data Science   \n",
       "184                                                                                             Why is gradient descent robust to non-linearly separable data? | by Vivek Yadav | Medium   \n",
       "185                                                                                                                                               K-means Clustering Algorithm | Edureka   \n",
       "186                                                            Meta Learning — AI Generalised.. AI learning to learn, to help with... | by Snehal Reddy Koukuntla | Towards Data Science   \n",
       "187                                                                                           Gamma Function — Intuition, Derivation, and Examples | by Aerin Kim | Towards Data Science   \n",
       "188                                                                                    A Beginner’s Guide to Convolutional Neural Networks (CNNs) | by Suhyun Kim | Towards Data Science   \n",
       "189                                                                                Using Affinity Propagation to Find the Number of Clusters in a Dataset | by Aneesha Bakharia | Medium   \n",
       "190                                                                                               10 Tips for Choosing the Optimal Number of Clusters | by Matt.0 | Towards Data Science   \n",
       "191                                                                                        Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca | Towards Data Science   \n",
       "192                                                                                               Data Visualization in Python: Advanced Functionality in Seaborn | by Insight | Insight   \n",
       "193                                                                                                   Let’s talk Clustering (Unsupervised Learning) | by Kaustubh N | SomX Labs | Medium   \n",
       "194                                                                                                  I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero   \n",
       "195                                                       Image Classifier using VGG-19 Deep learning model in Google Colab Notebook. Dishes Detection | by Ravi Prakash pandey | Medium   \n",
       "196               An Analysis On How Deepmind’s Starcraft 2 AI’s Superhuman Speed is Probably a Band-Aid Fix For The Limitations of Imitation Learning | by Aleksi Pietikäinen | Medium   \n",
       "197                                                                                                    Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science   \n",
       "198                                                                 Generating Modern Art using\\nGenerative Adversarial Network(GAN) on Spell | by Anish Shrestha | Towards Data Science   \n",
       "199                                                                                                          A Brief Overview of Attention Mechanism | by Synced | SyncedReview | Medium   \n",
       "200                                                            Named Entity Recognition (NER) for CoNLL dataset with Tensorflow 2.2.0 | by Bhuvana Kundumani | Analytics Vidhya | Medium   \n",
       "201                                                                                                        Sentence correction using Deep learning techniques | by Sourav kumar | Medium   \n",
       "202                                                                Implementation of Principal Component Analysis(PCA) in K Means Clustering | by Wamika Jha | Analytics Vidhya | Medium   \n",
       "203                                                                                 AI-Class.com — A classroom with 160,000 students | by Maria Neumayer | A problem like Maria | Medium   \n",
       "204                                                                                                       Multi-Class Text Classification with LSTM | by Susan Li | Towards Data Science   \n",
       "205                                                                                        Polynomial Regression — Gradient Descent from Scratch | by Mark Garvey | Towards Data Science   \n",
       "206                                                                                         From Faces to Kitties to Apartments: GAN Fakes the World | by Synced | SyncedReview | Medium   \n",
       "207                                                                                Deep Learning Architectures That You Can Use with a Few Data | by Gorkem Polat | The Startup | Medium   \n",
       "208                                                                                                               10 rules for better dashboard design | by Taras Bakusevych | UX Planet   \n",
       "209                                                       Transfer Learning — Part — 4.0!! VGG-16 and VGG-19 | by RAVI SHEKHAR TIWARI | Becoming Human: Artificial Intelligence Magazine   \n",
       "210                                                                   Google DeepMind Releases Structure Predictions for Coronavirus Linked Proteins | by Synced | SyncedReview | Medium   \n",
       "211                                                                                                        Workflow of a Machine Learning project | by Ayush Pant | Towards Data Science   \n",
       "212                                                                               ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium   \n",
       "213                                                                                      Multi-Class Metrics Made Simple, Part II: the F1-score | by Boaz Shmueli | Towards Data Science   \n",
       "214                                                                                                  RSNA 2013 — Top 5 Tendências em TI | by Thiago Julio, MD | Saúde Digital | Medium   \n",
       "215                                                                                                   Extracting image metadata at scale | by Netflix Technology Blog | Netflix TechBlog   \n",
       "216                                                                           Machine Learning for Beginners: An Introduction to Neural Networks | by Victor Zhou | Towards Data Science   \n",
       "217                                                                         Using MaskRCNN to predict tropical fruits in custom dataset | by Bernardo Caldas | Analytics Vidhya | Medium   \n",
       "218                                                                                                       [TensorFlow 2.0] Variational Auto encoder (VAE) Part II | by A Ydobon | Medium   \n",
       "219                                                                                                     DeepMind et al Paper Trumpets Graph Networks | by Synced | SyncedReview | Medium   \n",
       "220                                                                                                 Data Science for Newbies (including me!) | by Helena Campbell | Towards Data Science   \n",
       "221                                                                                                Attacking Google Cloud Vision API with Adversarial Examples | by NN Intruder | Medium   \n",
       "222                                                                         An Intuitive Explanation of Connectionist Temporal Classification | by Harald Scheidl | Towards Data Science   \n",
       "223                                                                                                       Using Knowledge Graphs to Summarize Long Documents | by Abdarhman Taha | agolo   \n",
       "224                                                                                              Creating OpenAI Gym Environments with PyBullet (Part 1) | by Gerard Maggiolino | Medium   \n",
       "225                                                                                    Logistic Regression: A Simplified Approach Using Python | by Surya Remanan | Towards Data Science   \n",
       "226                                                                                  Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science   \n",
       "227                                                                        What is a Transformer?. An Introduction to Transformers and... | by Maxime | Inside Machine learning | Medium   \n",
       "228                                                    Quantum Chemistry Breakthrough: DeepMind Uses Neural Networks to Tackle Schrödinger Equation | by Synced | SyncedReview | Medium   \n",
       "229                                                                    Explaining K-Means Clustering. Comparing PCA and t-SNE dimensionality... | by Kamil Mysiak | Towards Data Science   \n",
       "230                                                               Everything You Need to Know About Artificial Neural Networks | by Josh | Technology, Invention, App, and More | Medium   \n",
       "231                                                                                                 Liquid Neural Networks in Computer Vision | by Jacob Solawetz | Towards Data Science   \n",
       "232                                                                                                                     Yes you should understand backprop | by Andrej Karpathy | Medium   \n",
       "233                                                                                                     New to Machine Learning? Avoid these three mistakes | by James Faghmous | Medium   \n",
       "234                                                                                    Difference between AlexNet, VGGNet, ResNet, and Inception | by Aqeel Anwar | Towards Data Science   \n",
       "235                                            A Hands-On Guide To Text Classification With Transformer Models (XLNet, BERT, XLM, RoBERTa) | by Thilina Rajapakse | Towards Data Science   \n",
       "236                                                                                                                 Demystifying Object Detection using Deep Learning | by Rafi | Medium   \n",
       "237                                                                           Paper repro: Deep Metalearning using “MAML” and “Reptile” | by Adrien Lucas Ecoffet | Towards Data Science   \n",
       "238                                                  深度學習優化器Ranger: a synergistic optimizer using RAdam (Rectified Adam), Gradient Centralization and LookAhead筆記 | by Patty Wu | Medium   \n",
       "239                                                                                            Machine Learning: Polynomial Regression with Python | by Nhan Tran | Towards Data Science   \n",
       "240                                                                                             How I struggled to Convert MBR to GPT and Installed Linux? | by thirumalaivasan | Medium   \n",
       "241                                                                                  Multi-Class Text Classification Model Comparison and Selection | by Susan Li | Towards Data Science   \n",
       "242                                                                 What Is Pre-Training in NLP? Introducing 5 Key Technologies | by dan lee | AI3 | Theory, Practice, Business | Medium   \n",
       "243                                                                                        Does your model train too slow? Alleviating Vanishing Gradient Problem | Towards Data Science   \n",
       "244                                                 Graph Neural Networks through the lens of Differential Geometry and Algebraic Topology | by Michael Bronstein | Towards Data Science   \n",
       "245                                                                                                      Anomaly detection in brightfield microscopy images | by Nurlan Kerimov | Medium   \n",
       "246                                                                                       Beam Search Decoding in CTC-trained Neural Networks | by Harald Scheidl | Towards Data Science   \n",
       "247                                                                                                  Data Scientists Will be Extinct in 10 Years | by Mikhail Mew | Towards Data Science   \n",
       "248                                                                       Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science   \n",
       "249                                                                      Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science   \n",
       "250                                                                                             The Dropout Tag I Wear. *On a personal note, before reading... | by Kerish Heik | Medium   \n",
       "251                                                                                                          Attention and its Different Forms | by Anusha Lihala | Towards Data Science   \n",
       "252                                                                                         Movix.ai — movie recommendations with Deep Learning | by Supervise.ly | Supervisely | Medium   \n",
       "253                                                              How to do Deep Learning on Graphs with Graph Convolutional Networks | by Tobias Skovgaard Jepsen | Towards Data Science   \n",
       "254                                                                          Generative AI: Visual Search as a Bridge between Fiction and Reality | by Merzmensch | Towards Data Science   \n",
       "255                                                                                                     EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNet | by Akihiro FUJII | Medium   \n",
       "256          How are Logistic Regression & Ordinary Least Squares Regression (Linear Regression) Related? Why the “Regression” in Logistic? | by Rakshith Vasudev | Towards Data Science   \n",
       "257                                                                 Meta-Learning: Learning to Learn. Although artificial intelligence and... | by Thomas HARTMANN | DataThings | Medium   \n",
       "258                                                                                  Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science   \n",
       "259                                                                                                                        ML入門(十)Gradient Descent. 簡單回顧 | by Chung-Yi | 程式設計之旅 | Medium   \n",
       "260                                                                                                        Why I dropped out of college, but you shouldn’t | by João Fernandes | Medium   \n",
       "261                                                                                   Automatic Extractive Text Summarization using TF-IDF | by ASHNA JAIN | Voice Tech Podcast | Medium   \n",
       "262                                                                                     Top JavaScript Frameworks and Tech Trends for 2021 | by Eric Elliott | JavaScript Scene | Medium   \n",
       "263                                                           Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting | by Huangwei Wieniawska | Level Up Coding   \n",
       "264                                                                                                                                  Finger Dasher | by R. E. Warner | Banapana | Medium   \n",
       "265                                                        A news-analysis NeuralNet learns from a language NeuralNet | by m.zaradzki | Becoming Human: Artificial Intelligence Magazine   \n",
       "266                                                                                        Building smart robots using AI + ROS: Part 1 | by karthic Rao | Kredo.ai Engineering | Medium   \n",
       "267                                                                                Clustering on mixed type data. A proposed approach using R | by Thomas Filaire | Towards Data Science   \n",
       "268                                                                                What is the difference between Ridge Regression, the LASSO, and ElasticNet? | by Alex Lenail | Medium   \n",
       "269                                                                             Improving neural networks by preventing co-adaptation of feature detectors | by Michael L. Peng | Medium   \n",
       "270                                                                                          Extreme Event Forecasting with LSTM Autoencoders | by Marco Cerliani | Towards Data Science   \n",
       "271                                                                               Natural Language Processing for Fuzzy String Matching with Python | by Susan Li | Towards Data Science   \n",
       "272                                                                                       SocialDefender — Social Reputation Management Platform — Aji Abraham | by Aji Abraham | Medium   \n",
       "273                                                                                 The hype on AlphaFold keeps growing with this new preprint | by LucianoSphere | Towards Data Science   \n",
       "274                                                                                        Neural Image Retrieval. Assume you have an image I and an image... | by Eitan Kosman | Medium   \n",
       "275                                                                                            Top 20 Must-Watch Artificial Intelligence movies | by Benedict Neo | Towards Data Science   \n",
       "276                                                                                      Transfer Learning in TensorFlow on the Kaggle Rainforest competition | by Luuk Derksen | Medium   \n",
       "277                                                                                                Clustering on Mixed Data Types in Python | by Ryan Kemmer | Analytics Vidhya | Medium   \n",
       "278                                                                                     Insight into Faster R-CNN for Object Detection. | by Haripriya Reddy | Analytics Vidhya | Medium   \n",
       "279                                                                                                   Intelligent Agent Based Wastewater Management System | by Masumi Mutsuda | mutsuda   \n",
       "280                                                                          Springer has released 65 Machine Learning and Data books for free | by Uri Eliabayev | Towards Data Science   \n",
       "281                                                                                                    Using LSTMs to forecast time-series | by Ravindra Kompella | Towards Data Science   \n",
       "282                                                         Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models | by Roland Hewage | Towards Data Science   \n",
       "283                                                                                             帶你認識Vector-Quantized Variational AutoEncoder - 理論篇 | by Tan | Taiwan AI Academy | Medium   \n",
       "284                                                                                    True Democratization of Analytics with Meta-Learning | by Progress | Stories by Progress | Medium   \n",
       "285                                                                                                 Machine Learning Quiz 05: Decision Tree (Part 1) | by Md Shahidullah Kawsar | Medium   \n",
       "286                                                                                                      Speeding up BERT Search in Elasticsearch | by Dmitry Kan | Towards Data Science   \n",
       "287                                                                                                                                               写在看完变形金刚II之后 | by Justin Chen | Medium   \n",
       "288                                                                                              Classes of Novels. According to Creative Writing Now, the... | by Jhen Hilario | Medium   \n",
       "289                                                                                                          Object Recognition with OpenCV on Android | by Akshika Wijesundara | Medium   \n",
       "290                                                                              SSD object detection: Single Shot MultiBox Detector for real-time processing | by Jonathan Hui | Medium   \n",
       "291                                                                               Blockchain is not only crappy technology but a bad vision for the future | by Kai Stinchcombe | Medium   \n",
       "292                                                                                                      Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science   \n",
       "293                                                                                                      Transformer-based Sentence Embeddings | by Haaya Naushan | The Startup | Medium   \n",
       "294                                                                                                                 Stash Data Center ベータ版リリース。Git を大規模に利用 | by Jerome Bouchon | Medium   \n",
       "295                                                                    CNN-LSTM-Based Models for Multiple Parallel Input and Multi-Step Forecast | by Halil Ertan | Towards Data Science   \n",
       "296                                                                                                      Sentiment analysis using RNNs(LSTM) | by Manish Chablani | Towards Data Science   \n",
       "297                                                                                                                                           Activation Functions | by Chinmay | Medium   \n",
       "298                                                                                                        Sentence correction using Deep learning techniques | by Sourav kumar | Medium   \n",
       "299                                                                                                                                  Introduction | by ProjectAGI | Project AGI | Medium   \n",
       "300                                                                              Implementing Grad-CAM in PyTorch. Recently I have come across a chapter... | by Stepan Ulyanin | Medium   \n",
       "301                                                                                                 Creating Bitcoin trading bots don’t lose money | by Adam King | Towards Data Science   \n",
       "302                                                                                                   Hi Tal,. Maybe I’m missing something here, but... | by Sachin Abeywardana | Medium   \n",
       "303                                                                             Using Word Embeddings to Identify Company Names and Stock Tickers | by Brian Ward | Towards Data Science   \n",
       "304                                                                                                 Building a Bayesian deep learning classifier | by Kyle Dorman | Towards Data Science   \n",
       "305                                      Every single Machine Learning course on the internet, ranked by your reviews | by David Venturi | We’ve moved to freeCodeCamp.org/news | Medium   \n",
       "306                                                Art & AI: The Logic Behind Deep Learning ‘Style Transfer’ | by Nick Kasten | Center for Open Source Data and AI Technologies | Medium   \n",
       "307                                                                                        How to Perform Abstractive Summarization with PEGASUS | by Jiahao Weng | Towards Data Science   \n",
       "308                                                                       text summarization: applications. this article is mainly a summarization... | by Wenchen's ai fantasy | Medium   \n",
       "309                                                                   🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning | by Thomas Wolf | HuggingFace | Medium   \n",
       "310                                                                     A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs) | by Neelabh Pant | Cube Dev | Medium   \n",
       "311                                                                               ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium   \n",
       "312                                                           Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science   \n",
       "313                                                                                Semantic Image Segmentation using Fully Convolutional Networks | by Arun Kumar | Towards Data Science   \n",
       "314                                                                                                     Building a Summarization System in Minutes | by Ceshine Lee | Veritable | Medium   \n",
       "315                                                                                                        What are adversarial examples in NLP? | by Jack Morris | Towards Data Science   \n",
       "316                                                                                                   Reducing Memory Usage in R (especially for regressions) | by William Ryan | Medium   \n",
       "317                                                                            7 Applications of Auto-Encoders every Data Scientist should know | by Satyam Kumar | Towards Data Science   \n",
       "318                                                                       Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science   \n",
       "319                                                                                   Understanding 1D and 3D Convolution Neural Network | Keras | by Shiva Verma | Towards Data Science   \n",
       "320                                                                                  When Neural Networks saw the first image of Black Hole. | by Anuj shah (Exploring Neurons) | Medium   \n",
       "321                                                                                      Weekend Diversion: The Ultimate Superhero Cake | by Ethan Siegel | Starts With A Bang! | Medium   \n",
       "322                                                                                                                    Deep Generative Models | by Prakash Pandey | Towards Data Science   \n",
       "323                                                                                                           Adversarial attacks on Explainable AI | by Hubert Baniecki | ResponsibleML   \n",
       "324                                                                Adversarial Machine Learning. A Brief Introduction for Non-Technical... | by Charles Kapelke | CLTC Bulletin | Medium   \n",
       "325                                                                               Intersection Over Union. Pada masalah deteksi objek, output yang... | by Alfi Salim | BISA.AI | Medium   \n",
       "326                                                                                                      Variational Autoencoder In Finance | by Marie Imokoyende | Towards Data Science   \n",
       "327                           Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning & Big Data | by Stefan Kojouharov | Becoming Human: Artificial Intelligence Magazine   \n",
       "328                                                                           Region of Interest Pooling. A Technique which allowed a new... | by Sambasivarao. K | Towards Data Science   \n",
       "329                                                                                                        Clustering on Kubernetes & OpenShift3 using DNS | by Jimmi Dyson | fabric8 io   \n",
       "330         Support Vector Machine: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium   \n",
       "331                                                Intro to reinforcement learning: temporal difference learning, SARSA vs. Q-learning | by Viet Hoang Tran Duong | Towards Data Science   \n",
       "332                                                                                                   Object detection and tracking in PyTorch | by Chris Fotache | Towards Data Science   \n",
       "333                                                                                                  I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero   \n",
       "334                                                                                                A detailed explanation of the Attention U-Net | by Robin Vinod | Towards Data Science   \n",
       "335                                                                                                         Overview of Conditional Random Fields | by Ravish Chawla | ML 2 Vec | Medium   \n",
       "336                                                                        The Charm of a Gritty City. Baltimore as Entrepreneurship Hub | by Frank Bonsal III | Bonsal Capital | Medium   \n",
       "337                                                                                                  Understanding Latent Space in Machine Learning | by Ekin Tiu | Towards Data Science   \n",
       "338                                                                                      Bitcoin Bonanza!. Comparing the efficacy of GRU, LSTM... | by Ryan Burke | Towards Data Science   \n",
       "339                                                                                                     The Complete Beginner’s Guide To Chatbots | by Matt Schlicht | Chatbots Magazine   \n",
       "340                                                                                                   An Introduction To Conditional GANs (CGANs) | by Manish Nayak | DataDrivenInvestor   \n",
       "341                                                                                   Perturbation Theory in Deep Neural Network (DNN) Training | by Prem Prakash | Towards Data Science   \n",
       "342                                                                        A Step by Step approach to Solve DBSCAN Algorithms by tuning its hyper parameters | by Mohantysandip | Medium   \n",
       "343                                                                                        Deep Neural Networks for Regression Problems | by Mohammed AL-Ma'amari | Towards Data Science   \n",
       "344                                                                  Machine Learning for Humans, Part 2.1: Supervised Learning | by Vishal Maini | Machine Learning for Humans | Medium   \n",
       "345                                                                         Simple SGD implementation in Python for Linear Regression on Boston Housing Data | by Nikhil Parmar | Medium   \n",
       "346                                                                           Binary Logistic Regression. An overview and implementation in R | by Akanksha Rawat | Towards Data Science   \n",
       "347                                    Intuitive guide to word embedding, RNN (SimpleRNN, LSTM) with step by step implementation in keras for spam detection | by Hemant Ranvir | Medium   \n",
       "348                                                                                                          YOLOv4. While object detection matures in the... | by Jonathan Hui | Medium   \n",
       "349                                                                                                           癌細胞生長的開關:基因啟動子(Promoter)?. 啟動子 (Promoter)... | by Geneonline-基因線上 | Medium   \n",
       "350                                                                           RNN vs GRU vs LSTM. In this post, I will make you go... | by Hemanth Pedamallu | Analytics Vidhya | Medium   \n",
       "351                                                                  Fancy and custom Neural Style Transfer filters for video conferencing | by Maximus Mutschler | Towards Data Science   \n",
       "352                                                                   3 метода детектирования объектов c Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN | by Nick Komissarenko | Medium   \n",
       "353                                                                                                         Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science   \n",
       "354                                                                                                         1. Creating a Q-A system (Introduction) | by Puneet Singh | techpsl | Medium   \n",
       "355                                                                                                  Model Agnostic Meta-Learning (MAML): An Intuitive Way | by Saket Dingliwal | Medium   \n",
       "356                                                                                                                 The Current State of Machine Intelligence | by Shivon Zilis | Medium   \n",
       "357                                                                                                      Understanding Input and Output shapes in LSTM | Keras | by Shiva Verma | Medium   \n",
       "358                                                     Keras Embedding layer and Programetic Implementation of GLOVE Pre-Trained Embeddings | by Akash Deep | Analytics Vidhya | Medium   \n",
       "359                                                                                        Understanding Vector Quantized Variational Autoencoders (VQ-VAE) | by Shashank Yadav | Medium   \n",
       "360                                                                                          What does it mean by Bidirectional LSTM? | by Jaimin Mungalpara | Analytics Vidhya | Medium   \n",
       "361                                                                                                K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science   \n",
       "362                                                                                     A gentle introduction to Deep Reinforcement Learning | by Jordi TORRES.AI | Towards Data Science   \n",
       "363                                                                         Learning to Build a Model for Sketch-to-Color Image Generation using Conditional GANs | Towards Data Science   \n",
       "364                                                                      Batch vs Mini-batch vs Stochastic Gradient Descent with Code Examples | by Matheus Jacques | DataDrivenInvestor   \n",
       "365                                                                                           Lambda Functions with Practical Examples in Python | by Susan Maina | Towards Data Science   \n",
       "366                                                                                   Performance Metrics for Classification problems in Machine Learning | by Mohammed Sunasra | Medium   \n",
       "367                                                                   Few-Shot Learning with fast.ai. In few-shot learning, we train a model... | by Igor Susmelj | Towards Data Science   \n",
       "368                       GAN — Introduction and Implementation — PART1: Implement a simple GAN in TF for MNIST handwritten digit generation | by Manish Chablani | Towards Data Science   \n",
       "369                                                                                                                                  Solving 8-Puzzle using A* Algorithm | Good Audience   \n",
       "370                                                                                                      NLP: Building Text Summarizer — Part 1 | by Ashish Singhal | DataPy.ai | Medium   \n",
       "371                                                                                      From metaphor to reality. When does artificial intelligence stop... | by Hely Marleena | Medium   \n",
       "372                                                                                                           1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium   \n",
       "373                                                                                                      Training Provably-Robust Neural Networks | by Klas Leino | Towards Data Science   \n",
       "374                                                                                              Tensorflow or PyTorch : The force is strong with which one? | by Udacity India | Medium   \n",
       "375                                                                                                             Gaussian Mixture Models vs K-Means. | by K.Kubara | Towards Data Science   \n",
       "376                                                         Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras | by Emil Lykke Jensen | Towards Data Science   \n",
       "377                                      Unsupervised Classification Project: Building a Movie Recommender with Clustering Analysis and K-Means | by Victor Roman | Towards Data Science   \n",
       "378                                                                            Causal inference (Part 2 of 3): Selecting algorithms | by Jane Huang | Data Science at Microsoft | Medium   \n",
       "379                                                                                                   Convolutional Neural Networks, Explained | by Mayank Mishra | Towards Data Science   \n",
       "380                                                                                      Adversarial Examples to Break Deep Learning Models | by Pau Labarta Bajo | Towards Data Science   \n",
       "381                                                               Understanding the Backbone of Video Classification: The I3D Architecture | by Madeline Schiappa | Towards Data Science   \n",
       "382  Random Forests Classification: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium   \n",
       "383                                          Why Transformers are Slowly Replacing CNNs in Computer Vision? | by Pranoy Radhakrishnan | Becoming Human: Artificial Intelligence Magazine   \n",
       "384                                                                                           어텐션 메커니즘과 transfomer(self-attention) | by platfarm tech team | mojitok | Medium   \n",
       "385                                                                                      Understanding the Mathematics behind Gradient Descent. | by Parul Pandey | Towards Data Science   \n",
       "386                                                                                                           Logistic Regression from scratch in Python | by Martín Pellarolo | Medium   \n",
       "387                                                                 Beginner Guide to Variational Autoencoders (VAE) with PyTorch Lightning (Part 3) | by Reo Neo | Towards Data Science   \n",
       "388                                                                                                         60 Python Projects with Source Code | by Aman Kharwal | Coders Camp | Medium   \n",
       "389                                                           The Softmax Function, Neural Net Outputs as Probabilities, and Ensemble Classifiers | by Haihan Lan | Towards Data Science   \n",
       "390                                                                        A beginner’s guide to deriving and implementing backpropagation | by Pranav Budhwant | binaryandmore | Medium   \n",
       "391                                                                                         mAP (mean Average Precision) might confuse you! | by Shivy Yohanandan | Towards Data Science   \n",
       "392                                                                                                                How to recognize fake AI-generated images | by Kyle McDonald | Medium   \n",
       "393                                                                                                       A brief introduction to artificial neural networks | by Peter Bulyaki | Medium   \n",
       "394                                                                                                BigGAN: A New State of the Art in Image Synthesis | by Synced | SyncedReview | Medium   \n",
       "395                                                                                                    A 2022-Ready Deep Learning Hardware Guide | by Nir Ben-Zvi | Towards Data Science   \n",
       "396                                                                                                                          These Bored Apes Do Not Exist: GAN to NFT Pipeline | Medium   \n",
       "397                                                                                                          Detecting Empty Parking Lots With Mask RCNN Model | by Ahmet Genç | Medium   \n",
       "398                                                                What is Online Machine Learning?. Making machines learn in real time | by Max Pagels | The Hands-on Advisors | Medium   \n",
       "399                                                                                       Image analysis intro using python & opencv | by Chris Loughnane | Product Development Notebook   \n",
       "400                                                                                  Multi Class Text Classification with LSTM using TensorFlow 2.0 | by Susan Li | Towards Data Science   \n",
       "401                                                              Using OOB Tags in AIML: Part I. Suppose you are building an Intelligent... | by Pandorabots | pandorabots-blog | Medium   \n",
       "402                                                                                                       Understanding Encoders-Decoders with Attention Based Mechanism | DataX Journal   \n",
       "403                                                  Should AI explain itself? or should we design Explainable AI so that it doesn’t have to | by Prajwal Paudyal | Towards Data Science   \n",
       "404                                                                                                           An Introduction to Perceptron Algorithm | by Yang S | Towards Data Science   \n",
       "405                                                                                              Taking Keras to the Zoo. If you follow any of the popular blogs... | by Karl N. | Gab41   \n",
       "406                                                                                         Introduction: Reinforcement Learning with OpenAI Gym | by ASHISH RANA | Towards Data Science   \n",
       "407                                                         Reinforcement Learning (Pekiştirmeli Öğrenme) — İnsan Beyniyle Aradaki Fark Kapanırken | by Volkan Levent Soylu | Medium   \n",
       "408                                                                                       Sugerencias para definir un menú de navegación | by editorCapire.info | Capire.info | Medium   \n",
       "409                                                                                                How to implement an Adam Optimizer from Scratch | by Enoch Kan | Towards Data Science   \n",
       "410                                                                   Machine Learning Algorithms For Beginners with Code Examples in Python | by Towards AI Editorial Team | Towards AI   \n",
       "411                                                                                             Gradient descent vs coordinate descent | by Francesco Gadaleta | HackerNoon.com | Medium   \n",
       "412          How I deployed my spark document classification(Logistic Regression) model/s as a standalone app for real-time prediction | by surendranath bobba | HackerNoon.com | Medium   \n",
       "413                                                                        Demonstrating Customers Segmentation with DBSCAN Clustering Using Python | by Hshan.T | MLearning.ai | Medium   \n",
       "414                                                                           NLP: Spam Detection in SMS (text) data using Deep Learning | by Sudip Shrestha, PhD | Towards Data Science   \n",
       "415                                                                           POS Tagging Using RNN. Learn how to use RNNs to tag words in... | by Tanya Dayanand | Towards Data Science   \n",
       "416                                                                         Deep Convolutional Generative Adversarial Network using PyTorch | by Renu Khandelwal | Geek Culture | Medium   \n",
       "417                                                                                             A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science   \n",
       "418                                                                                               Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3 | by Jonathan Hui | Medium   \n",
       "419                                                                             Price Prediction using Machine Learning Regression — a case study | by Arun Kumar | Towards Data Science   \n",
       "420                                                                 Embeddings in Machine Learning. Embeddings are a basic method to encode... | by Bayan Bennett | The Startup | Medium   \n",
       "421                                                                                     The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science   \n",
       "422                                                                                                                       Understanding Attention Mechanism | by Shashank Yadav | Medium   \n",
       "423                                                                                            Ensemble methods: bagging, boosting and stacking | by Joseph Rocca | Towards Data Science   \n",
       "424                                                                       How to Improve Naive Bayes?. Section 3: Tuning the Model in Python | by Kopal Jain | Analytics Vidhya | Medium   \n",
       "425                                                                                   Object detection in Deep learning (Part2) | by Amin Ag | AI3 | Theory, Practice, Business | Medium   \n",
       "426                                                                                A brief overview of R-CNN, Fast R-CNN and Faster R-CNN | by Sema Zeynep Bulut | MLearning.ai | Medium   \n",
       "427                                                                                    Evasion attacks on Machine Learning (or “Adversarial Examples”) | by ilmoi | Towards Data Science   \n",
       "428                                                                                               Fine-Tuned Named Entity Recognition with Hugging Face BERT | by Andrew Marmon | Medium   \n",
       "429                                                                                       Gradient Boosting from scratch. Simplifying a complex algorithm | by Prince Grover | ML Review   \n",
       "430                                                                                                 Simple Reinforcement Learning: Q-learning | by Andre Violante | Towards Data Science   \n",
       "431                                   Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium   \n",
       "432                                                                       Neural Networks without Backpropagation: Direct Feedback Alignment | by Rizky Luthfianto | Blog rilut | Medium   \n",
       "433                                                                              Clustering with Gaussian Mixture Model | by Azad Soni | Clustering with Gaussian Mixture Model | Medium   \n",
       "434                                                                                             Training a spaCy NER Pipeline with Prodigy | by JP Zamanillo | Analytics Vidhya | Medium   \n",
       "435                                                                                                        Solving the Multi-Armed Bandit Problem | by Anson Wong | Towards Data Science   \n",
       "436                                                                                     Single Stage Instance Segmentation — A Review | by Patrick Langechuan Liu | Towards Data Science   \n",
       "437                                                                        Difference between AutoEncoder (AE) and Variational AutoEncoder (VAE) | by Aqeel Anwar | Towards Data Science   \n",
       "438                                                                       Predict Customer Churn with R. For any service company that bills on a... | by Susan Li | Towards Data Science   \n",
       "439                                                                    Anisotropic, Dynamic, Spectral and Multiscale Filters Defined on Graphs | by Boris Knyazev | Towards Data Science   \n",
       "440                                                                                     Important Topics in Machine Learning You Need to Know | by Sabina Pokhrel | Towards Data Science   \n",
       "441                                                                                             Deriving Backpropagation with Cross-Entropy Loss | by Essam Wisam | Towards Data Science   \n",
       "442                                                                                The Ultimate Guide to Clustering Algorithms and Topic Modeling | by Zijing Zhu | Towards Data Science   \n",
       "443                                                    Text Summarization from scratch using Encoder-Decoder network with Attention in Keras | by Varun Saravanan | Towards Data Science   \n",
       "444   Linear Discriminant Analysis: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium   \n",
       "445                                                                        Why AlphaGo Zero is a Quantum Leap Forward in Deep Learning | by Carlos E. Perez | Intuition Machine | Medium   \n",
       "446                                                                                                              Segmentasi Semantik untuk Klasifikasi Citra | by Ilma Arifiany | Medium   \n",
       "447                                                                                        Beginner’s Guide to RNN & LSTMs. Let’s understand how exactly RNN and... | by Dinesh | Medium   \n",
       "448                                                                                            Puppyslugs ‘R Us: Part 1. In “Puppyslugs ‘R Us: Part 0”, I... | by Boris Anthony | Medium   \n",
       "449                                                                       Understanding Deep Self-attention Mechanism in Convolution Neural Networks | by Shuchen Du | AI Salon | Medium   \n",
       "450                                                                  Transfer learning and Image classification using Keras on Kaggle kernels. | by Rising Odegua | Towards Data Science   \n",
       "451                                                                            Understanding the StyleGAN and StyleGAN2 Architecture | by Prem Chandra Singh | Analytics Vidhya | Medium   \n",
       "452                                                                                                         mAP (mean Average Precision) for Object Detection | by Jonathan Hui | Medium   \n",
       "453                                                                                                       GUIDE: POP! Slots Casino — Level 27 & 34 ($13+) [EASY] | by EarnSkins | Medium   \n",
       "454                                                                                                                Seq2seq pay Attention to Self Attention: Part 2 | by Gene Su | Medium   \n",
       "455                                                                                  Attention for time series forecasting and classification | by Isaac Godfried | Towards Data Science   \n",
       "456                                                                           Silhouette Coefficient. This is my first medium story, so... | by Ashutosh Bhardwaj | Towards Data Science   \n",
       "457                                                                                               Clustering Algorithm for Customer Segmentation | by Destin Gong | Towards Data Science   \n",
       "458                                                                Train a neural net for semantic segmentation in 50 lines of code, with Pytorch | by Sagi eppel | Towards Data Science   \n",
       "459                                                                                      Multivariate Time Series Forecasting with Transformers | by Jake Grigsby | Towards Data Science   \n",
       "460                                                                                     BLiTZ — A Bayesian Neural Network library for PyTorch | by Piero Esposito | Towards Data Science   \n",
       "461                                                                    Neural Art Style Transfer with Keras — Theory and Implementation | by Adrian Yijie Xu | GradientCrescent | Medium   \n",
       "462                                                                                                                            What are the common word embeddings? | The Ezra Tech Blog   \n",
       "463                                                                                                           EQuake. Riley Davis and David Souther... | by The NYT Open Team | NYT Open   \n",
       "464                                                                                               GANGogh: Creating Art with GANs. Introduction: | by Kenny Jones | Towards Data Science   \n",
       "465                                                      The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English   \n",
       "466                                                                                         Tutorial on Graph Neural Networks for Computer Vision and Beyond | by Boris Knyazev | Medium   \n",
       "467                                                                                           Smartphones vs Tablets: Does size matter? | by DataCrafts @ DataWeave | DataWeave | Medium   \n",
       "468                                                                     Stochastic Gradient Descent for machine learning clearly explained | by Baptiste Monpezat | Towards Data Science   \n",
       "469                                                                                                                                  Keyword Extraction with BERT | Towards Data Science   \n",
       "470                                                                                             A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science   \n",
       "471                                                                                                    Fooling Facial Detection with Fashion | by Bruce MacDonald | Towards Data Science   \n",
       "472                                                                                       StyleGAN2. This article explores changes made in... | by Connor Shorten | Towards Data Science   \n",
       "473                                                                                                Quick Logistic Regression with TensorFlow | by Pankaj Mathur | Pankaj Mathur | Medium   \n",
       "474                                                                                                      Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science   \n",
       "475                                                                                                          Time Series of Price Anomaly Detection | by Susan Li | Towards Data Science   \n",
       "476                                                                                   A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model | by Zhi Li | Towards Data Science   \n",
       "477                                                                            The Vanishing Gradient Problem. The Problem, Its Causes, Its... | by Chi-Feng Wang | Towards Data Science   \n",
       "478                                                                                                        Regularization in Machine Learning | by Prashant Gupta | Towards Data Science   \n",
       "479                                                             GMM: Gaussian Mixture Models — How to Successfully Use It to Cluster Your Data? | by Saul Dobilas | Towards Data Science   \n",
       "480                                                                         Speeding up your code (2): vectorizing the loops with Numpy | by Vincenzo Lavorini | HackerNoon.com | Medium   \n",
       "481                                                                                        Bayesian Linear Regression in Python via PyMC3 | by Dr. Robert Kübler | Towards Data Science   \n",
       "482                                                                                                       Introduction to recommender systems | by Baptiste Rocca | Towards Data Science   \n",
       "483                                                                                           A guide to transfer learning with Keras using ResNet50 | by Kenneth Cortés Aguas | Medium   \n",
       "484                                                                                  GPT-3 Is an Amazing Research Tool. But OpenAI Isn’t Sharing the Code. | by Dave Gershgorn | OneZero   \n",
       "485                                                                                                Introduction to Machine Learning for Beginners | by Ayush Pant | Towards Data Science   \n",
       "486                                                                                                        Federated Clusters with Docker Swarm | by Jeff Nickoloff | On Docker | Medium   \n",
       "487                                                                                                 Clustering Based Unsupervised Learning | by Syed Sadat Nazrul | Towards Data Science   \n",
       "488                                                                                                                Training a Conditional DC-GAN on CIFAR-10 | by Utkarsh Desai | Medium   \n",
       "489                                                                                             The proper way to use Machine Learning metrics | by Félix Revert | Towards Data Science   \n",
       "490                                                                                                    Few-shot Object Detection in Practice | by Alexander Hirner | Moonvision | Medium   \n",
       "491                                                                                      Object detection with Tensorflow model and OpenCV | by Gabriel Cassimiro | Towards Data Science   \n",
       "492                                                                          Batch Normalization and ReLU for solving Vanishing Gradients | by Lavanya Gupta | Analytics Vidhya | Medium   \n",
       "493                                                                                                      K-Means Clustering and the Gap-Statistics | by Tim Löhr | Towards Data Science   \n",
       "494                                                            Of brains and cities; neuroscience and cultures of decision-making | by Dan Hill | Dark Matter and Trojan Horses | Medium   \n",
       "495                                                                        Redes Neurais, Perceptron Multicamadas e o Algoritmo Backpropagation | by Tiago M. Leite | Ensina.AI | Medium   \n",
       "496                                                                                                     Spam Classifier in Python from scratch | by Tejan Karmali | Towards Data Science   \n",
       "497                                                                                                                                         Preparing for Insight | by Insight | Insight   \n",
       "498                                                                                                                    GOOGLE AI CONTEST | by Aleksey Tikhonov | Altsoph’s blog | Medium   \n",
       "499                                                     🏎 Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT | by Victor Sanh | HuggingFace | Medium   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                text  \n",
       "0    Towards Data Science\\nOct 18, 2019\\nClassification and object detection are the main parts of computer vision. Classification is finding what is in an image and object detection and localisation is finding where is that object in that image. Detection is a more complex problem to solve as we need to find the coordinates of the object in an image.\\nTo Solve this problem R-CNN was introduced by Ross Girshick, Jeff Donahue, Trevor Darrell and Jitendra Malik in 2014. R-CNN stands for Regions with CNN. In R-CNN instead of running classification on huge number of regions we pass the image through selective search and select first 2000 region proposal from the result and run classification on that. In this way instead of classifying huge number of regions we need to just classify first 2000 r...  \n",
       "1    Towards Data Science\\nMar 11, 2019\\nIf you liked this post and want to learn how machine learning algorithms work, how did they arise, and where are they going, I recommend the following:\\nwww.holloway.com\\nTransformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in their language models, and also used recently by DeepMind for AlphaStar — their program to defeat a top professional Starcraft player.\\nTransformers were developed to solve the problem of sequence transduction, or neural machine translation. That means any task that transforms an input sequence to an output sequence. This includes speech recognition, text-to-speech transformation, etc..\\nFor models to perform sequence transduction, it is necessary to...  \n",
       "2    Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...  \n",
       "3    Nov 21, 2005\\nToday, we build complex software applications based on the things computers do well, such as storing and retrieving large amounts of information or rapidly performing calculations. However, humans still significantly outperform the most powerful computers at completing such simple tasks as identifying objects in photographs — something children can do even before they learn to speak.When we think of interfaces between human beings and computers, we usually assume that the human being is the one requesting that a task be completed, and the computer is completing the task and providing the results. What if this process were reversed and a computer program could ask a human being to perform a task and return the results? What if it could coordinate many human beings to perfo...  \n",
       "4    SDG Counting\\nFeb 17, 2017\\n1 . IISD provided context to news that the report of the 48th Statistical Commission (coming up March 7th-10th in New York) intends to include a draft resolution on the global indicator framework for the UN Economic and Social Council (ECOSOC) and the UN General Assembly to adopt. Last year, through the 47th Statistical Commission, the global indicator framework was agreed upon as a starting point and “taken note of by ECOSOC” in June 2016. A formal adoption would mean that methodology standards for indicator review and revision would be followed, as well as coming closer to the acceptance of all 230 indicators by all member states.\\nsdg.iisd.org\\n2. The Global Festival of Ideas for Sustainable Development is less than two weeks away, and a detailed agenda o...  \n",
       "5    Jan 4, 2016\\nIf you asked me where I would be right now a year ago, my prediction wouldn’t even come close.\\nI had the opportunity to apprentice under radio show host and business coach, Margaret Jackson. On top of business skills, the biggest lesson she taught me was about legacy.\\nWhat legacy do I want to leave behind in the world?\\nMargaret told me to highlight my top 3 items on my bucket list. I wrote crazy goals like\\nMargaret looked at the rest of my (extensive) bucket list and started laughing to herself.\\n“Tam, you know there are people in organizations devoting their lives to ONE of these goals. How the hell in the world are you going to accomplish everything?”\\nMaintaining focus was the next crucial lesson. Mozart was known for music. Michael Jordan was known for basketball. ...  \n",
       "6                                                                                                                                                                                                                  ECLaboratorio\\nDec 5, 2016\\nMachine Learning, Big Data, Deep Learning, ... ¿por qué cada día se oyen mas estos términos? y de hecho ¿qué significan? Acompáñame a descubrirlo de forma sencilla y con muchos ejemplos en el siguiente vídeo:\\n... Y la presentación llena de enlaces que te pueden ayudar a profundizar más:\\n5 \\n5 \\nTrabajamos con equipos autónomos y autosuficientes enfocados a la creación de productos útiles, sencillos y que consigan mayor satisfacción del cliente\\n28 Followers\\nData scientist\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "7    The Awl\\nFeb 22, 2012\\nby Jane Hu\\nIn the final episode of “Freaks and Geeks,” the Freaks group leader Daniel Desario accepts an invitation to play Dungeons & Dragons with the notoriously geeky A/V club. Surprised by Daniel’s warm receptivity to the game, the Geeks wonders what this means for their future status. As Bill puts it: “Does him wanting to play with us again mean he’s turning into a geek or we’re turning into cool guys?” Sam answers, “I’m going to go for us becoming cool guys.” It’s a nice ambiguous note on which to end the show.\\nOutside the universe of “Freaks and Geeks,” a similar drift has occurred. Geekiness has accrued cachet, and geeks are becoming the cool guys. In an interview about the comedy web series “Geek Therapy,” actress America Young observed: “We started ta...  \n",
       "8    Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...  \n",
       "9    Nov 12, 2015\\nas mentiras e conturbações feitas a vida do “monstro” e “mito” Lou Reed atráves de biográfias e material descártavel são absurdamentes grandes, mas de certa forma provacadas pelo mesmo, uma figura icônica e contráditoria.\\nantes da fama Lou já era conturbado, mas a primeira aparição do Velvet em uma zine desmistifica algumas das alegações tardias do cantor e guitarrista. Lou Reed cita os beatles como criativos e absolutamente magníficos, assim como os Stones. ele cita Creedence como legais a primeira ouvida mas depois absolutamente tedioso e desgastante era 1972 e Lou estava no caminho de albúns como “Transformer” que absorvia toda a atmosfera Glam da época com uma pegada Rock and Roll, e ao mesmo tempo definia uma época, a ambiguidade sexual em sua capa ...  \n",
       "10   May 5, 2014\\nUpdate: This article is part of a series. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, Part 6, Part 7 and Part 8! You can also read this article in 日本語, Português, Português (alternate), Türkçe, Français, 한국어 , العَرَبِيَّة‎‎, Español (México), Español (España), Polski, Italiano, 普通话, Русский, 한국어 , Tiếng Việt or فارسی.\\nGiant update: I’ve written a new book based on these articles! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. Check it out now!\\nHave you heard people talking about machine learning but only have a fuzzy idea of what that means? Are you tired of nodding your way through conversations with co-workers? Let’s change that!\\nThis guide is f...  \n",
       "11   Towards Data Science\\nMay 3, 2020\\nCOCO (Common Objects in Context), being one of the most popular image datasets out there, with applications like object detection, segmentation, and captioning - it is quite surprising how few comprehensive but simple, end-to-end tutorials exist. When I first started out with this dataset, I was quite lost and intimidated. I had to plough my way through so many scattered, inadequate resources on the web, multiple vague tutorials, and some experimentation to finally see light at the end of this tunnel. When I was done, I knew I had to document this journey, from start to finish. And so I did. With the hope that someday, someone out there would find these of value and not have to go through all the trouble I faced.\\nHere’s presenting you a two part seri...  \n",
       "12   Towards Data Science\\nMar 15, 2019\\nProject Description and initial assumptions:\\nAs a part of our final project for Cognitive computing, we decided to address a real life business challenge for which we chose IT Service Management. Of all the business cases, we were interested with four user cases that might befitting for our project.\\n1. In Helpdesk, almost 30–40% of incident tickets are not routed to the right team and the tickets keep roaming around and around and by the time it reaches the right team, the issue might have widespread and reached the top management inviting a lot of trouble.\\n2. Let’s say that users are having some trouble with printers. User calls help desk, he creates a ticket with IT Support, and they realize that they need to update a configuration in user’s sys...  \n",
       "13   Towards Data Science\\nNov 10, 2021\\nBack in 2018, Google developed a powerful Transformer-based machine learning model for NLP applications that outperforms previous language models in different benchmark datasets. And this model is called BERT.\\nIn this post, we’re going to use a pre-trained BERT model from Hugging Face for a text classification task. As you might already know, the main goal of the model in a text classification task is to categorize a text into one of the predefined labels or tags.\\nSpecifically, soon we’re going to use the pre-trained BERT model to classify whether the text of a news article can be categorized as sport, politics, business, entertainment, or tech category.\\nBut before we dive into the implementation, let’s talk about the concept behind BERT briefly.\\...  \n",
       "14   Insight\\nJun 30, 2016\\nWant to learn Elasticsearch and other big data tools from top data engineers in Silicon Valley or New York? The Insight Data Engineering Fellows Program is a free 7-week professional training program where you can build cutting edge big data platforms and transition to a career in data engineering at top teams like Facebook, Uber, Slack and Squarespace.\\nLearn more about the program and apply today.\\nThis post is part of a series covering the underlying architecture and prototyping examples with a popular distributed search engine, Elasticsearch. In this post, we’ll be discussing the underlying storage model and how CRUD (create, read, update and delete) operations work in Elasticsearch.\\nElasticsearch is a very popular distributed search engine used at many comp...  \n",
       "15   Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...  \n",
       "16   IoT & Data Science\\nFeb 15, 2019\\nThe article tackles smart data processing of the Internet of Things (IoT) in a predictive maintenance context and relates this to recent developments in semi-supervised learning. While written with an eye towards a non-expert audience, the article references recent scientific publications. We leave it to the curious and technically oriented reader to expand their knowledge on the ideas we have sketched out (see References). We aim to be informative and open minds to stimulating discussions on IoT and data analytics.\\nWe cover the topic of IoT Learning Algorithms and Predictive Maintenance in a series of three articles. In PART I, we present a simple case study in detail and discuss some learning algorithms related to it. In PART II, we focus on IoT dat...  \n",
       "17   Jan 10, 2018\\nI have started doing Andrew Ng’s popular machine learning course on Coursera. The first week covers a lot, at least for someone who hasn’t touched much calculus for a few years\\nThese three topics were a lot to take in. I’ll talk about each in detail, and how they all fit together, with some python code to demonstrate.\\nEdit May 4th: I published a follow up focusing on how the Cost Function works here, including an intuition, how to calculate it by hand and two different Python implementations. I can do gradient descent and then bring them together for linear regression soon.\\nFirst, the goal of most machine learning algorithms is to construct a model: a hypothesis that can be used to estimate Y based on X. The hypothesis, or model, maps inputs to outputs. So, for example...  \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law & Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "19   Analytics Vidhya\\nJul 22, 2019\\nI am fascinated by self-driving cars. The sheer complexity and mix of different computer vision techniques that go into building a self-driving car system is a dream for a data scientist like me.\\nSo, I set about trying to understand the computer vision technique behind how a self-driving car potentially detects objects. A simple object detection framework might not work because it simply detects an object and draws a fixed shape around it.\\nThat’s a risky proposition in a real-world scenario. Imagine if there’s a sharp turn in the road ahead and our system draws a rectangular box around the road. The car might not be able to understand whether to turn or go straight. That’s a potential disaster!\\nInstead, we need a technique that can detect the exact sh...  \n",
       "20   Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...  \n",
       "21   Passion for Data Science\\nApr 1, 2018\\nThe credit score is a numeric expression measuring people’s creditworthiness. The banking usually utilizes it as a method to support the decision-making about credit applications. In this blog, I will talk about how to develop a standard scorecard with Python (Pandas, Sklearn), which is the most popular and simplest form for credit scoring, to measure the creditworthiness of the customers.\\nNowadays, creditworthiness is very important for everyone since it is regarded as an indicator for how dependable an individual is. In various situations, service suppliers need to evaluate customers’ credit history first, and then decide whether they will provide the service or not. However, it is time-consuming to check the entire personal portfolios and gene...  \n",
       "22   Jun 6, 2016\\nIf you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works rather well for my use case.\\nfrom gensim.models.doc2vec import LabeledSentence\\nfrom os import listdir\\nfrom os.path import isfile, join\\nimport gensim\\nimport DocIterator as DocIt\\ndocLabels = []\\ndocLabels = [f for f in listdir(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu”) if f.endswith(‘.txt’)]\\ndata = []\\nfor doc in docLabels:\\nwith open(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu/” + doc, ‘r’) as f:\\ndata.append(f.read())\\nit = DocIt.DocIterator(data, docLabels)\\nmodel = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=3,alpha=0.04, min_alpha=0.005) # use fixed learning rate\\nmodel.build_vocab(it)\\nfor epoch in range(100):\\nprint(“Epoch “ + str...  \n",
       "23   Towards Data Science\\nDec 2, 2020\\nIn the previous chapter we built a dataloader that picks up our images and performs some transformations and augmentations so that they can be fed in batches to a neural network like the U-Net. In this part, we focus on building a U-Net from scratch with the PyTorch library. The goal is to implement the U-Net in such a way, that important model configurations such as the activation function or the depth can be passed as arguments when creating the model.\\nThe U-Net is a convolutional neural network architecture that is designed for fast and precise segmentation of images. It has performed extremely well in several challenges and to this day, it is one of the most popular end-to-end architectures in the field of semantic segmentation.\\nWe can split the...  \n",
       "24   TechnologyMadeEasy\\nJul 28, 2016\\nCNNs have wide applications in image and video recognition, recommender systems and natural language processing. In this article, the example that I will take is related to Computer Vision. However, the basic concept remains the same and can be applied to any other use-case!\\nFor a quick recap of Neural Networks, here’s a very clearly explained article series.\\nCNNs, like neural networks, are made up of neurons with learnable weights and biases. Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output. The whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs. Pretty straightforward, right?\\nSo, how are Convol...  \n",
       "25   Nov 18, 2018\\nKey takeaways — O’reilly AI London Conference, Oct 9–11, 2018\\nI had an opportunity to attend the O’reilly AI London Conference, Oct 9–11, 2018. Given our short attention span these days, let me try a more clickbait style approach for the takeaways :)\\nKey takeaways\\n1. AI Gurus are the new rock stars and there was never a better time to be in this field. There continues to be tremendous interest in Enterprise AI. This was the first...\\n1 \\n1 \\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Patents https://www.linkedinin/debmalya-biswas-397526\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n125 Followers\\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Pat...  \n",
       "26   Towards Data Science\\nOct 4, 2018\\nIn the previous post, we discussed various steps of text processing involved in Nature Language Processing (NLP) and also implemented a basic Sentiment Analyzer using some of the classical ML techniques.\\nDeep learning has demonstrated superior performance on a wide variety of tasks including NLP, Computer Vision, and Games. To explore further, we will discuss and use some of the advanced NLP techniques, based on Deep Learning, to create an improved Sentiment Classifier.\\nSentiment classification is the task of looking at a piece of text and telling if someone likes or dislikes the thing they’re talking about.\\nThe input X is a piece of text and the output Y is the sentiment which we want to predict, such as the star rating of a movie review.\\nIf we c...  \n",
       "27   Towards Data Science\\nJul 31, 2019\\nThis is the fourth part in the series on Computer vision journey. In this article we will explore Mask R-CNN to understand how instance segmentation works with Mask R-CNN and then predict the segmentation for an image with Mask R-CNN using Keras\\nPart 1- CNN, R-CNN, Fast R-CNN, Faster R-CNN\\nPart 2 — Understanding YOLO, YOLOv2, YOLO v3\\nPart 3- Object Detection with YOLOv3 using Keras\\nWhat is instance segmentation and how is different from semantic segmentation?\\nSemantic Segmentation detects all the objects present in an image at the pixel level. Outputs regions with different classes or objects\\nSemantic segmentation groups pixels in a semantically meaningful way. Pixels belonging to a person, road, building, fence, bicycle, cars or trees are grou...  \n",
       "28   Jan 19, 2013\\nKaggle announced the Traveling santa problem in the christmas season. I joined in excitedly.. but soon realized this is not an easy problem. Solving this problem would require expertise on data structures and some good familiarity with TSP problems and its many heuristic algorithms. I had neither.. I had to find a way to deal with this problem. I compenseted my lack of algorithmic expertise with common sense, logic and intuition. I finished 65th out of 356 total competitors.\\nI did some research on packaged TSP solvers and top TSP algorithms. I found concorde but I could not get it to work on my ubuntu machine. So I settled with LKH which uses Lin-Kernighan heuristic for solving TSP and related problems. I wrote scripts for file conversions and for running LKH.\\nLKH easil...  \n",
       "29   SlideMagic\\nSep 1, 2011\\nThe quarter is done, and here comes the day-long sales results presentation. Excel is pasted into PowerPoint, creating huge decks through which senior management has to sit through. Sales organizes by channel: small restaurants sales, growth; large restaurants sales, growth, supermarkets sales, growth. Marketing presents by brands: brand 1 sales, growth, brand 2 sales, growth.If you are a marketing manager, looking at the Q3 sales and growth figures of a particular brand is really interesting. All the numbers of the previous quarters are more or less in your head. For the production manager though, going through these pages is mental torture, as she does not have the historical context readily available. (Read more about the Curse of Knowledge here)The solution...  \n",
       "30   The Owl\\nMar 20, 2020\\nwith a little help from sklearn\\nMachine Learning models often fails to generalize well on data it has not been trained on. Sometimes, it fails miserably, sometimes it gives somewhat better than miserable performance. To be sure that the model can perform well on unseen data, we use a re-sampling technique, called Cross-Validation.\\nWe often follow a simple approach of splitting the data into 3 parts, namely, Train, Validation and Test sets. But this technique does not generally work well for cases when we don’t have a large datasets. When we have limited data, dividing the dataset into Train and Validation sets may casue some data points with useful information to be excluded from the training procedure, and the model fails to learn the data distrubution properl...  \n",
       "31   Aug 8, 2016\\nFor this blog post, we decided to jump on the PokémonGO hype and add a bit of science into the craze. Our goal is to give you the optimal portfolio of Pokémon to train, so you can be as effective as possible against a wide variety of opponents. As each Pokémon has its strengths and weaknesses, we created clusters of Pokémon with similar characteristics and looked at the few selected ones allowing the player to compete against as many different enemies as possible.\\nWe used the Pokémon API fan service available on the internet to find all the information about the little creatures.\\nThe data we used consists of:\\nThe data is available for 811 Pokémon. Although we have done the analysis for all the Pokémon, in this post, we focus only on the first 150 Pokémon as thos...  \n",
       "32   Towards Data Science\\nMar 16, 2021\\nOne of the most challenging tasks for machine learning models is finding the best way to to generate numeric representations for words so the model can use that information in its calculations.\\nIn computer vision tasks, the red channel in a color (RGB) image will always refer to the red channel, and the green channel to the green channel. Text, however, is heavily based on context, such that the same word can take on multiple meanings depending on its use. Pandas, for example, can refer to cute and fuzzy bears or a Python data analysis library.\\nThis is further complicated when considering sentences and paragraphs. Consider the following:\\nPandas are cute and fuzzy. They don’t use Pandas data analysis library because they are bears.\\nNow I realize t...  \n",
       "33   Towards Data Science\\nJun 2, 2021\\nEditor’s note: This episode is part of our podcast series on emerging problems in data science and machine learning, hosted by Jeremie Harris. Apart from hosting the podcast, Jeremie helps run a data science mentorship startup called SharpestMinds.\\nWhen OpenAI announced the release of their GPT-3 API last year, the tech world was shocked. Here was a language model, trained only to perform a simple autocomplete task, which turned out to be capable of language translation, coding, essay writing, question answering and many other tasks that previously would each have required purpose-built systems.\\nWhat accounted for GPT-3’s ability to solve these problems? How did it beat state-of-the-art AIs that were purpose-built to solve tasks it was never explici...  \n",
       "34   Oct 17, 2016\\nИтак, вы решили подключить свой локальный пул геймобъектов, прочли документацию на сайте, нашли необходимые методы и решили , что сейчас все заработает. Возможно в вашем случае это действительно будет так, если вы до этого не регистрировали ни одного префаба для спаунинга по сети.\\nДело в том, что в Unity при спауне геймобъекта приватным методом ClientScene.OnObjectSpawn сначала проверяется наличие объекта в списке зарегистрированных (через инспектор компоненты NetworkManager или напрямую через добавление геймобъектов в словарь NetworkManager.spawnPrefabs), и только если необходимый геймобъект не найден, то идет в работу словарь хендлеров (делегатов SpawnDelegate) для спауна, в который и записывается ваш делегат с помощью методов ClientScene.RegisterSpawnHandl...  \n",
       "35   Feb 25, 2019\\nFor the last couple of weeks, I have been experimenting with mobilenet models for object detection on Android devices. Since I took a Deep learning course in the past semester, I knew that those mobilenet models could be trained for detecting other objects as well. Moreover, available guides such as this object detection tutorial and this Android deployment tutorial rely on the older version of the Tensorflow framework — Tensorflow Mobile, which is being deprecated as of February 2019. Instead, Tensorflow Lite will be the main framework for mobile devices in the future and Lite version has moved from the contribution stage to the core of Tensorflow.\\nAdditionally, there are recent articles that manually annotate images for training purposes. However, we will implement ope...  \n",
       "36   Towards Data Science\\nNov 13, 2018\\nA decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules. Below diagram illustrate the basic flow of decision tree for decision making with labels (Rain(Yes), No Rain(No)).\\nDecision tree is one of the predictive modelling approaches used in statistics, data mining and machine learning.\\nDecision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of ...  \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law & Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "38   Towards Data Science\\nSep 30, 2018\\nIn this post I’d like to take some content from Introduction to Machine Learning with Python by Andreas C. Müller & Sarah Guido and briefly expand on one of the examples provided to showcase some of the strengths of DBSCAN clustering when k-means clustering doesn’t seem to handle the data shape well. I’m going to go right to the point, so I encourage you to read the full content of Chapter 3, starting on page 168 if you would like to expand on this topic. I’ll be quoting the book when describing the working of the algorithm.\\nThis is how k-means work in a visual representation:\\nOne issue with k-means clustering is that it assumes that all directions are equally important for each cluster. This is usually not a big problem, unless we come across wit...  \n",
       "39   Towards Data Science\\nJan 29, 2019\\nEver since the world of Machine Learning was introduced to non-linear functions that work recursively (i.e. Artificial Neural Networks), the applications of which boomed noticeably. In this context, proper training of a Neural Network is the most important aspect of making a reliable model. This training is usually associated with the term “Back-propagation”, which is highly vague to most people getting into Deep Learning. Heck, most people in the industry don’t even know how it works — they just know it does!\\nBack-propagation is the essence of neural net training. It is the practice of fine-tuning the weights of a neural net based on the error rate (i.e. loss) obtained in the previous epoch (i.e. iteration). Proper tuning of the weights ensures low...  \n",
       "40   Emergent // Future\\nJul 27, 2016\\nIssue 17 This week we review Elon Musk’s big plans for Tesla, how Google uses DeepMind to save millions of dollars, why Zuckerberg is building a fleet of internet drones, and check in on Moore’s Law death watch. Plus, projects to try at home, and our top reads from the past week.\\nNot a subscriber? Join the Emergent // Future newsletter here.\\nYou might have heard: Elon Musk outlined his masterplan for Tesla in blog post. For the past 10-years, Tesla’s vision had been to do:\\nNow, Musk is doubling-down on solar power, Tesla trucks, self-driving cars, and car-sharing — he wants your car to make you money when you aren’t using it. The company has already started developing electric and autonomous trucks and buses.\\ntl;dr “We’re not an electric car compan...  \n",
       "41   Towards Data Science\\nOct 23, 2018\\nThis article teaches you how to use transfer learning to solve image classification problems. A practical example using Keras and its pre-trained models is given for demonstration purposes.\\nDeep learning is fast becoming a key instrument in artificial intelligence applications (LeCun et al. 2015). For example, in areas such as computer vision, natural language processing, and speech recognition, deep learning has been producing remarkable results. Therefore, there is a growing interest in deep learning.\\nOne of the problems where deep learning excels is image classification (Rawat & Wang 2017). The goal in image classification is to classify a specific picture according to a set of possible categories. A classic example of image classification is th...  \n",
       "42   Oct 8, 2017\\nCode available here: https://github.com/michaelulin/pytorch-caffe2-aws-lambda\\nHaving worked with PyTorch, I love the flexibility and ease of development of the framework versus other platforms. As PyTorch is still early in its development, I was unable to find good resources on serving trained PyTorch models, so I’ve written up a method here that utilizes ONNX, Caffe2 and AWS Lambda to serve predictions from a trained PyTorch model. I hope that you find it to be useful.\\nHow to effectively deploy a trained PyTorch model\\nUsing ONNX, Facebook and Microsoft’s recently released platform for Neural Network interoperability, we can convert a model trained in PyTorch to Caffe2 and then serve predictions with that model from AWS Lambda.\\nONNX enables models trained in PyTorch to...  \n",
       "43   人機共生你我它\\nDec 20, 2018\\n「蟲苔已經撲到人家的臉上了!」 「快要滿人口啦!應該要開戰了喔,因為其實人口滿,你剛剛把人家斷炊,這邊是一個很好的時機點可以來壓制」\\n電競賽評每天在做的事就是分析許多專業玩家打game的過程,帶著觀眾理解這些專業玩家每一步背後的策略,仔細想想,這些賽評帶領觀眾理解專業玩家的方式,是不是也跟使用者透過一個解釋機制來理解黑盒子般的智慧系統類似?電競賽評是專家行為的詮釋者,從他們身上,能帶給我們什麼智慧代理系統設計的啟發?\\n來自美國Oregon State University的研究團隊發現了這個關聯,透過分析賽評們對於電競的即時評論,試圖了解:當解釋機制(賽評)在說明智慧系統運作(專業玩家動作)時,需要哪些線索來搞懂智慧系統的行為、對使用者說明時需要包含哪些資訊、以及要怎麼說出這些難懂的資訊才能幫助使用者搞懂智慧系統這個黑盒子。\\n在眾多線索中,哪些資訊才是賽評需要的呢?研究者分析賽評切換的畫面,發現遊戲賽評會不斷的蒐集玩家當下的表現、所處的環境、產能狀況或統計資料(例:擊殺比例)以及賽評不斷切換視角(例:畫面轉到不同地點、切換成不同玩家的視角)來幫助自己解釋這些玩家為什麼在此時此刻會做出特定的行為。透過分析賽評如何理解專業玩家,我們可以知道當設計解釋機制的時候,需要想辦法讓使用者需要知道系統已做、能做哪些事,就如同賽評會說出「蟲苔已經撲到人家的臉上了」或告訴觀眾「滿人口應該就可以開戰了」,藉由這些資訊來讓觀眾理解玩家做出特定行為的意圖。\\n除此之外,智慧系統的解釋機制也需要告訴使用者現在系統已經看到、聽到或取得哪些資訊,以自駕車來說,在操作面板上對駕駛顯示目前系統偵測到周圍環境哪些資訊、已經分別執行過哪些步驟,幫助駕駛理解系統做決策的過程;或是讓使用者知道智慧系統做了哪些事、能做哪些事,例如透過系統協助保安人員判斷某位...  \n",
       "44   Data Science Group, IITR\\nSep 4, 2017\\nWe all have used apps like Prisma and Lucid, but ever wondered how these things works? Like we give a photo from our camera roll and select a design to mix both the images and we get a new image which has the content of our input image and style of the design image. In the world of deep learning this is called style transfer.\\nStyle transfer is the technique of recomposing images in the style of other images. It all started when Gatys et al. published an awesome paper on how it was actually possible to transfer artistic style from one painting to another picture using convolutional neural networks..\\nHere are some examples :\\n“Neural networks are everywhere. I do not expect that they will take away the bread of artists and designers, but it took m...  \n",
       "45   ML Review\\nJun 7, 2017\\nThe article is about Manhattan LSTM (MaLSTM) — a Siamese deep network and its appliance to Kaggle’s Quora Pairs competition.I will do my best to explain the network and go through the Keras code (if you are only here for the code, scroll down :)Full code on Github\\nIn the past few years, deep learning is all the fuss in the tech industry.To keep up on things I like to get my hands dirty implementing interesting network architectures I come across in article readings.\\nFew months ago I came across a very nice article called Siamese Recurrent Architectures for Learning Sentence Similarity.It offers a pretty straightforward approach to the common problem of sentence similarity.Named MaLSTM (“Ma” for Manhattan distance), its architecture is depicted in figure 1 (dia...  \n",
       "46   Towards Data Science\\nJan 24, 2019\\nBefore building any Deep Learning model in Natural Language Processing (NLP), text embedding plays a major role. The text embedding converts text (words or sentences) into a numerical vector.\\nWhy do we convert texts into vectors?\\nA vector is an array of numbers of a particular dimension. A vector of size 5×1 contain 5 numbers and we can think of it as a point in 5D space. If there are two vectors each of dimension 5, they can be thought of two points in a 5D space. Thus we can calculate how close or distant those two vectors are, depending on the distance measure between them.\\nHence, lots of efforts in machine learning research are bring put to converting data into a vector as once data is converted into a vector, we can say two data points are si...  \n",
       "47   Towards Data Science\\nNov 13, 2017\\nBidirectional recurrent neural networks(RNN) are really just putting two independent RNNs together. The input sequence is fed in normal time order for one network, and in reverse time order for another. The outputs of the two networks are usually concatenated at each time step, though there are other options, e.g. summation.\\nThis structure allows the networks to have both backward and forward information about the sequence at every time step. The concept seems easy enough. But when it comes to actually implementing a neural network which utilizes bidirectional structure, confusion arises...\\nThe first confusion is about the way to forward the outputs of a bidirectional RNN to a dense neural network. For normal RNNs we could just forward the outputs ...  \n",
       "48   Jul 24, 2020\\nUsing the neural-net tool Artbreeder, Photoshop and historical references, I have created photoreal depictions of Roman Emperors. Scroll down to see each emperor.\\nON CREATIVE COMMONS & COPYRIGHT: Faces can be shared non-watermarked at 200 pixels max height OR 512 pixels with the digital mosaic watermark with Attribution-NonCommercial-ShareAlike. Please link back to this page. Continuation of this project depends on prints, licensing and commissions.\\n*CONCISE UPDATE (July 31st) replacing a July 27th CLARIFICATION: ‘TheApricity’, a tertiary source, has been removed entirely. I knew it to be unreliable prior to starting this project but kept here for posterity and debate. It is now clear to me they have distorted primary and secondary sources to push a pernicious white sup...  \n",
       "49   Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...  \n",
       "50   Towards Data Science\\nFeb 21, 2019\\nLogistic Regression is a popular statistical model used for binary classification, that is for predictions of the type this or that, yes or no, A or B, etc. Logistic regression can, however, be used for multiclass classification, but here we will focus on its simplest application.\\nAs an example, consider the task of predicting someone’s gender (Male/Female) based on their Weight and Height.\\nFor this, we will train a machine learning model from a data set of 10,000 samples of people’s weight and height. The data set is taken from the Conway & Myles Machine Learning for Hackers book, Chapter 2, and can it can be directly downloaded here.\\nThis is a preview of what the data looks like:\\nEach sample contains three columns: Height, Weight, and Male.\\nTh...  \n",
       "51   Aug 27, 2019\\nIt was announced by FAIR (facebook artificial intelligence research) last year that the Mask RCNN structure using the resnet50 infrastructure was successfully implemented on MS COCO and Balloon datasets and valuable resuts were obtained (see dedicated github page). In addition, the trained weights were also released for researchers and practitionars to make transfer learning to solve different problems with reasonable cost(see matterport github page).\\nIn my another article I have explaineed how to make transfer learning with such released MS COCO weights to deletect an locate weapons (see article here)\\nAt the end of this reading this article, you will see succesful object recognition and segmentation in video and images taken randomly from the outerside of the world.\\nI...  \n",
       "52   Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...  \n",
       "53   Nov 10, 2016\\nDear reader,\\nThis article has been republished at Educaora and has also been open sourced. Unfortunately TensorFlow 2.0 changed the API so it is broken for later versions. Any help to make the tutorials up to date are greatly appreciated. I also recommend you looking into PyTorch.\\nIn this tutorial I’ll explain how to build a simple working Recurrent Neural Network in TensorFlow. This is the first in a series of seven parts where various aspects and techniques of building Recurrent Neural Networks in TensorFlow are covered. A short introduction to TensorFlow is available here. For now, let’s get started with the RNN!\\nIt is short for “Recurrent Neural Network”, and is basically a neural network that can be used when your data is treated as a sequence, where the particula...  \n",
       "54   Towards Data Science\\nApr 12, 2020\\nNatural language processing (NLP) is a key component in many data science systems that must understand or reason about a text. Common use cases include text classification, question answering, paraphrasing or summarising, sentiment analysis, natural language BI, language modeling, and disambiguation.\\nNLP is essential in a growing number of AI applications. Extracting accurate information from free text is a must if you are building a chatbot, searching through a patent database, matching patients to clinical trials, grading customer service or sales calls, extracting facts from financial reports or solving for any of these 44 use cases across 17 industries.\\nText classification is one of the main tasks in modern NLP and it is the task of assigning a...  \n",
       "55   Jun 11, 2017\\nIn the last post I’ve applied DBScan to remove noises from a trajectory. However, to achieve an acceptable result from original trajectory I tried several parameters before end up witth:\\nUsually data analysis cannot afford such strategy since it would take too long to clean up big amount of data if every trajectory demands a human evaluation. The good news is that this process can be automated. Actually, the original DBScan paper from Ester et al. brings a section about determining the parameters Eps and MinPts using a heuristic approach.\\nThe basic idea is process data evaluating the k-th nearest neighbor of each point and sort them descending. Usually the result will point out a threshold value where clusters will appear on the right side of the chart while noises will...  \n",
       "56   Jun 28, 2020\\nTikTok is an application which has been used for talking materials between teens and startups for years now. Most of time we only see how it creates from a new emerging industry instead of investigating what makes the customer retention high as 39%.\\nTikTok’s Chinese version, Douyin, published a new filter in its app this week. Within 3 days, they gathered millions of posts which used this filter. The filter names as “Anime Change”. The main character is to change the video into animation.\\nIt’s not a new one to be honest, many applications have launched a similar filter before, such as B612. But the difference here is to change a video and to make the result acceptable.\\nThe technology used behind is one called Generative Adversarial Networks, AKA GAN. GAN is used for ge...  \n",
       "57   Towards Data Science\\nJul 26, 2021\\nNot only computational but also experimental biology. Thoughts on the future of data science niches in biology.\\nIn a recent story I covered the release of the academic paper describing AlphaFold’s version 2 and its source code, and I showed you how scientists around the world were starting to apply the program to their favorite proteins through Google Colab notebooks, for free and without any hardware needs. These notebooks are rapidly evolving to enable more features, allowing anybody to model not only isolated proteins but also complexes of multiple proteins, and including known structures of related proteins and multiple sequence alignments to improve the program’s results. Moreover, Deepmind and the European Bioinformatics Institute started to u...  \n",
       "58   Jun 27, 2018\\nAn app that removes and replaces in real-time the background in webcam video streams, and all from within the browser! No need for a green screen or a uniform background. This project was made during my 4 weeks at the AI Program of Insight Data Science (Palo Alto).\\nTry it here!\\nThere is a trend in AI to move from Centralized Cloud Computing to Edge Computing [1], in particular for real time services application for which Centralized Cloud Computing suffers from higher latency. Furthermore, Edge Computing AI might provide solutions for privacy conscientious consumers [2]. One tool that is likely to help this trend is TensorflowJS (TFJS), in brief Tensorflow in Javascript wrapper. TFJS enables to create AI apps, which training and prediction can be conducted on the client...  \n",
       "59   The Startup\\nJun 5, 2018\\nOh, how the headlines blared:\\n“...the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nMessaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!\\nPlus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptan...  \n",
       "60   Towards Data Science\\nJul 31, 2017\\nQuick Recap\\nLast time in our Keras/OpenAI tutorial, we discussed a very fundamental algorithm in reinforcement learning: the DQN. The Deep Q-Network is actually a fairly new advent that arrived on the seen only a couple years back, so it is quite incredible if you were able to understand and implement this algorithm having just gotten a start in the field. As with the original post, let’s take a quick moment to appreciate how incredible results we achieved are: in a continuous output space scenario and starting with absolutely no knowledge on what “winning” entails, we were able to explore our environment and “complete” the trials.\\nPut yourself in the situation of this simulation. This would essentially be like asking you to play a game, without a ...  \n",
       "61   Towards Data Science\\nJan 20, 2019\\nIn this project, we will develop and evaluate the performance and the predictive power of a model trained and tested on data collected from houses in Boston’s suburbs.\\nOnce we get a good fit, we will use this model to predict the monetary value of a house located at the Boston’s area.\\nA model like this would be very valuable for a real state agent who could make use of the information provided in a dayly basis.\\nYou can find the complete project, documentation and dataset on my GitHub page:\\nhttps://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/tree/master/projects/boston_housing\\nThe dataset used in this project comes from the UCI Machine Learning Repository. This data was collected in 1978 and each of the 506 entries represent...  \n",
       "62   Towards Data Science\\nDec 19, 2020\\nAll types of neural networks and many machine learning algorithms optimize their loss functions using gradient-based optimization algorithms. There are several such optimization algorithms, or optimizers, that exist and are used to train models - RMSprop, Stochastic Gradient Descent(SGD), Adaptive Moment Estimation(Adam) and so many more.\\nThere are two primary metrics to look at while determining the efficacy of an optimizer:\\nAdaptive algorithms like Adam have a good convergence speed, while algorithms like SGD generalize better.\\nBut recently researchers from Yale introduced a novel AdaBelief optimizer (AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients) that combines many benefits of existing optimization methods:\\nWe pro...  \n",
       "63   Towards Data Science\\nJul 6, 2021\\nMany of my articles have been focused on BERT — the model that came and dominated the world of natural language processing (NLP) and marked a new age for language models.\\nFor those of you that may not have used transformers models (eg what BERT is) before, the process looks a little like this:\\nNow, this is a great approach, but if we only ever do this, we lack the understanding behind creating our own transformers models.\\nAnd, if we cannot create our own transformer models — we must rely on there being a pre-trained model that fits our problem, this is not always the case:\\nSo in this article, we will explore the steps we must take to build our own transformer model — specifically a further developed version of BERT, called RoBERTa.\\nThere are a fe...  \n",
       "64   Towards Data Science\\nNov 17, 2018\\nFrauds in the finance field are very rare to be identified. Because of that, it can do a severe damage to the financial field. It is estimated that fraud costs at least $80 billion a year across all lines of insurance. If there is a small possibility of detecting fraudulent activities, that can do a major impact on annual losses. That is why financial companies invest in machine learning as a preemptive approach to tackling fraud.\\nThe benefits of using a machine learning approach are that,\\nThe best way to detect frauds is anomaly detection.\\nAnomaly detection is a technique to identify unusual patterns that do not conform to the expected behaviors, called outliers. It has many applications in business from fraud detection in credit card transaction...  \n",
       "65   Towards Data Science\\nSep 21, 2021\\nWhat sets artificial neural networks apart from other machine learning algorithms is how they can efficiently deal with big data and how they assume very little about your dataset.\\nYour neural network doesn’t care if your classification data isn’t linearly separable via a kernel or if the trend followed by your regression data is a roller coaster. As long that your dataset is some continuous mapping from one finite space (x) to another (y) then you can approximate that mapping to any degree of accuracy depending on your architecture. This follows from them being universal approximators as proven by the Universal Approximation Theory. The point is that back, when neural networks first showed up in the 40s, there was no fast way to make use of this as...  \n",
       "66   Heartbeat\\nMay 17, 2018\\nMany deep learning frameworks have been released over the past few years. Among them, PyTorch from Facebook AI Research is very unique and has gained widespread adoption because of its elegance, flexibility, speed, and simplicity. Most deep learning frameworks have either been too specific to application development without sufficient support for research, or too specific for research without sufficient support for application development.\\nHowever, PyTorch blurs the line between the two by providing an API that’s very friendly to application developers while at the same time providing functionalities to easily define custom layers and fully control the training process, including gradient propagation. This makes it a great fit for both developers and researche...  \n",
       "67   Clairvoyant Blog\\nMay 7, 2021\\n“If Music is a Place — then Jazz is the City, Folk is the Wilderness, Rock is the Road, Classical is a Temple.” — Vera Nazarin\\nWe’ve all used some music streaming app to listen to music. But what is the app's logic for creating a personalized playlist for us?\\nOne general example of logic is by having a Music Genre Classification System.\\nMusic genre classification forms a basic step for building a strong recommendation system.\\nThe idea behind this project is to see how to handle sound files in python, compute sound and audio features from them, run Machine Learning Algorithms on them, and see the results.\\nIn a more systematic way, the main aim is to create a machine learning model, which classifies music samples into different genres. It aims to predi...  \n",
       "68                                                                                                                                                                                                                                                      HuggingFace\\nJan 27, 2019\\nThe past year has ushered in an exciting age for Natural Language Processing using deep neural networks. Research in the field of using pre-trained models have resulted in massive leap in state-of-the-art results for many of the NLP tasks, such as text classification, natural language inference and question-answering.\\n3.3K \\n3.3K \\n30\\nStories @ Hugging Face\\n1K Followers\\nChief Architect & Technologist, AI & Machine Learning, Co-founder at utterworks\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "69   Aug 17, 2016\\nThere was news recently in bloomberg about how google was able to cut electricity usage in its datacenter by using an AI scheme made by DeepMind (of AlphaGo fame). Earlier this week, i decided to make a quick-and-dirty implemetation in python and share it here for anyone interested in a practical example of what exactly they did. First lets take a quick look at why one would want to make such a thing...\\nDatacenters (and indeed any other large scale structures that use a lot of energy) need to be carefully optimized for efficiency as even a 10% - 15% saving on the electricity bill can add up to millions of dollars a year. The biggest challenge here is that even though there are certain simple steps that anyone can take to reduce energy use (don’t use a very low server roo...  \n",
       "70   Acuity Derivatives\\nAug 1, 2014\\nInventory Aging is a rather innocuous looking member of the band of (now) seven metrics that, under the Volcker rule, banking entities with significant trading assets and liabilities are required to calculate daily and report monthly.\\nAs written, the metric description seems straightforward enough:\\nInventory Aging generally describes a schedule of the trading desk’s aggregate assets and liabilities and the amount of time that those assets and liabilities have been held. [It] should measure the age profile of the trading desk’s assets and liabilities and must include two schedules, an asset- aging schedule and a liability-aging schedule.\\nThe graphic below broadly outlines the processes of asset/liability tagging, matching, sorting and netting of trade...  \n",
       "71   Towards Data Science\\nSep 7, 2019\\nIn this post we discuss working of Gaussian process. Gaussian process fall under kernel methods, and are model free. Gaussian process are specially useful for low data regimen to “learn” complex functions. We shall review a very practical real world application (not related to deep learning or neural networks). The discussion follows from the talks of subject matter experts Prof Neil Lawrence and Prof Richard Tuner.\\nBackground reading:\\nMultivariate gaussian distribution: A Gaussian distribution can be specified using a mean (u), variance (σ2) and probability distribution function (PDF) as shown below\\nIf we have more than one independent gaussian distribution we can combine them. The combined PDF is also Gaussian i.e. a multivariate Gaussian. E.g. o...  \n",
       "72   Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is <=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...  \n",
       "73   Towards Data Science\\nJul 27, 2019\\nLinear regression is an approach to model the relationship between a single dependent variable (target variable) and one (simple regression) or more (multiple regression) independent variables. The linear regression model assumes a linear relationship between the input and output variables. If this relationship is present, we can estimate the coefficients required by the model to make predictions on new data.\\nIn this article, you will learn how to visualize and implement the linear regression algorithm from scratch in Python using multiple libraries such as Pandas, Numpy, Scikit-Learn, and Scipy. Additionally, we will measure the direction and strength of the linear relationship between two variables using the Pearson correlation coefficient as well...  \n",
       "74                  The Startup\\nFeb 2, 2021\\nOne of the great things about NER is trying to find those critters! I recently completed a project where one of the pre-requisites was to identify a location from large text fields containing randomly entered data.\\nOf course if there’s no control during the input of data then chaos reigns but we are where we are and if someone wants to put their homemade recipe for lasagne in an address field then hey it’s going to get messy but we’ll keep the lecture notes on data entry for another time and place.\\n34 \\n34 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n15 Followers\\nRandom ramblings from a sedate stroller.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "75   Towards Data Science\\nSep 29, 2021\\nWord Embeddings is the most fundamental concept in Deep Natural Language Processing. And word2vec is one of the earliest algorithms used to train word embeddings.\\nIn this post, I want to go deeper into the first paper on word2vec — Efficient Estimation of Word Representations in Vector Space (2013), which as of now has 24k citations, and this number is still growing.\\nOur plan is the following:\\nI am attaching my Github project with word2vec training. We will go through it in this post.\\nToday we are reviewing only the first paper on word2vec. However, there are several later papers, describing the evolution of word2vec:\\nI believe, if you understand the first paper, you’ll easily catch the ideas described in later papers. So let’s go!\\nDisclosure. ...  \n",
       "76            Analytics Vidhya\\nAug 1, 2021\\nGenerative models(GAN) have always been the niche and hard-to-master domain of the Deep learning space. Control over distinct features of output image has been a challenging research topic. StyleGAN is an approach that addresses this aspect. It distances itself from the conventional architectures of GAN and introduces a novel approach to generate high-resolution synthetic images along with a fair control over the distinct features...\\n5 \\n5 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n10 Followers\\nAI Enthusiast; M.Sc., University of Stuttgart, Mercedes-Benz AG\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "77   Jan 21, 2020\\nCSS Box Model and Positioning\\nVGG Virtual Internship Assignment.\\nThe CSS box model is crucial and fundamental to understand as far as layout and positioning are concerned in styling of a web page. This is so because every element in HTML generate a box around it and these boxes have properties that can be illustrated using what is popularly know as the CSS Box Model. You can view the box model from the developer tool by simply right clicking on an element on the web page then click on “inspect”.\\nOnce you are in the developer tools menu, ensure the “Elements” tab and “Styles” tab are selected (might be slightly different for other browsers). Then scroll down, you will see the box model for the element you are inspecting as shown below.\\nFrom the image above, we can see ...  \n",
       "78   Towards Data Science\\nAug 28, 2020\\nThe amount of textual data being produced every day is increasing rapidly both in terms of complexity as well as volume. Social Media, News articles, emails, text messages (the list goes on..), generate massive information and it becomes cumbersome to go through lengthy text materials (and boring too!). Thankfully with the advancements in Deep Learning, we can build models to shorten long pieces of text and produce a crisp and coherent summary to save time and understand the key points effectively.\\nWe can broadly classify text summarization into two types:\\n1. Extractive Summarization: This technique involves the extraction of important words/phrases from the input sentence. The underlying idea is to create a summary by selecting the most important ...  \n",
       "79   Towards Data Science\\nJan 3, 2018\\nIn this post I’ll explain what the maximum likelihood method for parameter estimation is and go through a simple example to demonstrate the method. Some of the content requires knowledge of fundamental probability concepts such as the definition of joint probability and independence of events. I’ve written a blog post with these prerequisites so feel free to read this if you think you need a refresher.\\nOften in machine learning we use a model to describe the process that results in the data that are observed. For example, we may use a random forest model to classify whether customers may cancel a subscription from a service (known as churn modelling) or we may use a linear model to predict the revenue that will be generated for a company depending on...  \n",
       "80   Oct 29, 2019\\nK-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity. The results of the K-means clustering algorithm are:\\nRather than defining groups before looking at the data, clustering allows you to find and analyze the groups that have formed organically. The “Choosing K” section below describes how the number of groups can be determined.\\nThis story covers:\\nThe algorithm can be used to confirm business ...  \n",
       "81   Towards Data Science\\nJun 29, 2020\\nRecurrent neural networks like plain RNN or more advanced models like LSTM and GRU used to be the goto models for deep-learning practitioners venturing into the time series domain. NLP, providing an abundance of sequence data, provided a willing subject. But transformer architectures like BERT and GPT have definitely taken over in the domain. Apart from these transformer architectures, CNN’s have also made a come-back or advance in the time-series domain. Are CNN’s good at modelling time-series?\\nHow good are CNN’s at modelling time-series?\\nTo answer this question tthis post replicates an article called “ECG Heartbeat Classification: A Deep Transferable Representation” [1] that applies ResNet, a CNN based architecture, to electrocardiogram (ECG) dat...  \n",
       "82   Jul 2, 2019\\nHow to understand U-Net in the most simple way.\\nHello everyone!\\nIn this article I want to explain in simple way the one of the most popular models structures to solve image segmentation task — UNET.\\nIf you haven’t heard about it and haven’t seen its architecture, it’s not a problem, because in this article I will start with a simple structure and at the end will be traditional UNET. Let’s start.\\nUNET model was created for medicine purpose to find tumors in lungs or brain, but nowadays it has got much wider usage field.\\nFor example your task is to find rectangles on images, no matter what color or shape they are.\\nWe have a red one and yellow one rectangles on a green background. This is an input for UNET model.\\nWe need to define positive regions on the image where we...  \n",
       "83   Backstage\\nDec 9, 2012\\nIts now been quite some time for Goibibo in business, which means that there is a huge amount of data that we have generated over this period. As a part of converting this data to information, we present to you our new initiative — Goibibo Insights.\\nAs the name suggests,Insights aims to give you interesting trends across the travel industry as seen by the large data we crunch at Goibibo. We believe this will further assist you in fine-tuning your travel plans. After all, this is your data — we have simply organised it and given it back.\\nRead on for the first series of insights with the info-graphics.\\nInsights are publicly shared on our Group portal (IbiboGroup) and also with the press.\\nOriginally published at goibibo.github.io on December 9, 2012.\\nBehind th...  \n",
       "84   ML Review\\nMar 13, 2016\\nI just want to reiterate what’s said here:\\ncolah.github.io\\nI’m not better at explaining LSTM, I want to write this down as a way to remember it myself. I think the above blog post written by Christopher Olah is the best LSTM material you would find. Please visit the original link if you want to learn LSTM. (But I did create some nice diagrams.)\\nAlthough we don’t know how brain functions yet, we have the feeling that it must have a logic unit and a memory unit. We make decisions by reasoning and by experience. So do computers, we have the logic units, CPUs and GPUs and we also have memories.\\nBut when you look at a neural network, it functions like a black box. You feed in some inputs from one side, you receive some outputs from the other side. The decision i...  \n",
       "85   Nov 27, 2019\\nObject detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.\\nThis post contains the details of Fast R-CNN and Faster R-CNN, which are the incremental improvements of R-CNN( aka “slow R-CNN”).\\nFast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks.\\nThe main contribution of Fast-R-CNN is the RoI pooling followed by a two-headed fully connected network.\\nAn input image is passed through CNN(set of convolutional and maxpooling layers)....  \n",
       "86                                                                                                                          SyncedReview\\nDec 14, 2018\\nLook at the two pictures below. Can you tell which is a photograph and which was generated by AI?\\nThe truth is... wait for for it... both images are AI-generated fakes, products of American GPU producer NVIDIA’s new...\\n632 \\n632 \\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology & Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "87   Analytics Vidhya\\nFeb 22, 2020\\nFeature Engineering is a technique to convert raw data columns to something meaningful which can help in predicting the outcomes in a machine learning task. Feature Engineering can be a very tedious and often the most time taking in machine learning life cycle.\\nBut to our rescue comes some of the cool tools which automates the whole feature engineering process and creates a large pool of features in a very short span for both classification and regression tasks.\\nWe have found following tools which automates the whole feature engineering process and creates large number of features for both relation and non-relational data. While some of them only performs feature engineering, we have some tools which also perform feature selection. Many a times these t...  \n",
       "88   Towards Data Science\\nAug 5, 2020\\nNatural Language Processing has made huge advancements in the last years. Currently, various implementations of neural networks are cutting edge and it seems that everybody talks about them. But, sometimes a simpler solution might be preferable. After all, one should try to walk before running. In this short article, I am going to demonstrate a simple method for clustering documents with Python. All code is available at GitHub (please note that it might be better to view the code in nbviewer).\\nWe are going to cluster Wikipedia articles using k-means algorithm. The steps for doing that are the following:\\n2. represent each article as a vector,\\n3. perform k-means clustering,\\n4. evaluate the result.\\nUsing the wikipedia package it is very easy to down...  \n",
       "89   Oct 7, 2016\\nIt’s a great time to work as an android developer, as Millions of android devices activated every day a huge demand for android developers is required.\\nBegging as an android developer can be extremely challenging too, so in this post, I will try to elaborate all the basic requirements and skills anyone needs to land a job as an android developer without the need of a degree or experience.\\nSo below is a list of all generalized requirements based on my little experience as an android developer and my researching for junior-level positions , the requirements will always vary from company to another and you will hardly find any two job descriptions exactly the same but these requirements will be good to start with.\\nYou might consider that this a lot of things but you can bu...  \n",
       "90   Towards Data Science\\nAug 15, 2018\\nThis article introduces the basics of machine learning theory, laying down the common concepts and techniques involved. This post is intended for the people starting with machine learning, making it easy to follow the core concepts and get comfortable with machine learning basics.\\nIn 1959, Arthur Samuel, a computer scientist who pioneered the study of artificial intelligence, described machine learning as “the study that gives computers the ability to learn without being explicitly programmed.”\\nAlan Turing’s seminal paper (Turing, 1950) introduced a benchmark standard for demonstrating machine intelligence, such that a machine has to be intelligent and responsive in a manner that cannot be differentiated from that of a human being.\\nMachine Learnin...  \n",
       "91   Towards Data Science\\nSep 6, 2017\\nIt’s just a thing function that you use to get the output of node. It is also known as Transfer Function.\\nIt is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\\nThe Activation Functions can be basically divided into 2 types-\\nFYI: The Cheat sheet is given below.\\nAs you can see the function is a line or linear. Therefore, the output of the functions will not be confined between any range.\\nEquation : f(x) = x\\nRange : (-infinity to infinity)\\nIt doesn’t help with the complexity or various parameters of usual data that is fed to the neural networks.\\nThe Nonlinear Activation Functions are the most used activation functions. Nonlinearity helps t...  \n",
       "92   DeepQuestAI\\nAug 1, 2019\\nStep-by-step tutorial on training object detection models on your custom dataset\\nObject detection is one of the most profound aspects of computer vision as it allows you to locate, identify, count and track any object-of-interest in images and videos. Object detection is used extensively in many interesting areas of work and study such as:\\nA number of pre-collected object detection datasets such as Pascal VOC, Microsoft’s COCO, Google’s Open Images are readily available along with their pre-trained models for detection and identifying only a fix set of items.\\nHowever, the challenge with using these public datasets and pre-trained models is that they do not provide a convenient way for you to easily train new object detection models to detect and identify yo...  \n",
       "93   Intel Student Ambassadors\\nFeb 14, 2019\\nText summarization is nowadays one of the most studied research topics in natural language processing (NLP) and has its applications in almost all domains of the internet, for example, e-shops, search engines and news websites that use summaries to give readers an overview of what a particular article might talk about.\\nText Summarization is a task to generate a shorter and concise version of a text while preserving the meaning of the original text.[1]\\nText summarization algorithms can be classified into two main categories:\\nExtractive text summarization algorithms are capable of extracting key sentences from a text without modifying any word [2][3]. Abstractive summarization, instead, involves a complex process understanding the language, the...  \n",
       "94   Towards Data Science\\nJan 24, 2019\\nThis Article is Based on Deep Residual Learning for Image Recognition from He et al. [2] (Microsoft Research): https://arxiv.org/pdf/1512.03385.pdf\\nIn 2012, Krizhevsky et al. [1] rolled out the red carpet for the Deep Convolutional Neural Network. This was the first time this architecture was more successful that traditional, hand-crafted feature learning on the ImageNet. Their DCNN, named AlexNet, contained 8 neural network layers, 5 convolutional and 3 fully-connected. This laid the foundational for the traditional CNN, a convolutional layer followed by an activation function followed by a max pooling operation, (sometimes the pooling operation is omitted to preserve the spatial resolution of the image).\\nMuch of the success of Deep Neural Network...  \n",
       "95   Towards Data Science\\nJun 10, 2019\\nIn the Article Text summarization in 5 steps using NLTK, we saw how we summarize the text using Word Frequency Algorithm.\\nBonus: See in Action with Streamlit App\\nNow, we’ll summarize the text using Tf-IDF Algorithm.\\nNote that, we’re implementing the actual algorithm here, not using any library to do the most of the tasks, we’re highly relying on the Math only.\\nIn a simple language, TF-IDF can be defined as follows:\\nA High weight in TF-IDF is reached by a high term frequency(in the given document) and a low document frequency of the term in the whole collection of documents.\\nTF-IDF algorithm is made of 2 algorithms multiplied together.\\nTerm frequency (TF) is how often a word appears in a document, divided by how many words there are.\\nTF(t) = (...  \n",
       "96   Towards Data Science\\nNov 21, 2018\\nIf you landed on this post, you probably already know what a Gaussian Mixture Model is, so I will avoid the general description of the this technique.\\nBut if you are not aware of the details, you can just see the GMM as a k-means which is able to form stretched clusters, like the ones you can see in Figure 2.\\nAll the code used for this post is in this notebook. In the same repository you can find the data to fully replicate the results you see plotted.\\nNow: suppose you are in the situation depicted in Figure 1, you want to discern how many clusters we have (or, if you prefer, how many gaussians components generated the data), and you don’t have information about the “ground truth”. A real case, where data do not have the nicety of behaving good as...  \n",
       "97   Towards Data Science\\nJun 18, 2021\\nMathematics behind two important optimization techniques in machine learning\\nOptimization is the process where we train the model iteratively that results in a maximum and minimum function evaluation. It is one of the most important phenomena in Machine Learning to get better results.\\nWhy do we optimize our machine learning models? We compare the results in every iteration by changing the hyperparameters in each step until we reach the optimum results. We create an accurate model with less error rate. There are different ways using which we can optimize a model. In this article, let’s discuss two important Optimization algorithms: Gradient Descent and Stochastic Gradient Descent Algorithms; how they are used in Machine Learning Models, and the math...  \n",
       "98   Towards Data Science\\nOct 6, 2021\\nOutline of HRNet explained:\\nIf you know already the basics (CNN + Areas of Application), skip down to section 3 or section 4.\\nHRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.\\nBut first, let’s understand what the fields mean and what kind of algorithm hides behind HRNet.\\nSemantic Segmentation is used to categorize structures of an image into certain classes. This is done by labeling each pixel with a certain class [3]. In the example below all pixels representing the cyclist are a class person and all pixels representing the bicycle are class ...  \n",
       "99                                                                    cvil.ly\\nFeb 24, 2010\\nHave you noticed that there’s no spot in the Apple.com navigation for the iPad? I tried navigating to iPhone, iPod+iTunes and Mac and could not find iPad in any of those locations. I wonder when they plan to address this?\\n[caption id=”” align=”aligncenter” width=”576\" caption=”No home for iPad in Apple.com IA”]\\n[/caption]\\nUpdate: Now there is a home for iPad! Note that they also separated iPod & iTunes.\\n[caption id=”” align=”aligncenter” width=”604\" caption=”Now there is a home for iPad on Aplle.com”]\\n[/caption]\\ndesign | technology | product\\n1.3K Followers\\nProduct leader, designer, tech and gadget nerd. Pragmatic optimist.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "100  Towards Data Science\\nJul 13, 2019\\nSequence-to-sequence (abrv. Seq2Seq) models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning. Google Translate started using such a model in production in late 2016. These models are explained in the two pioneering papers (Sutskever et al., 2014, Cho et al., 2014).\\nA Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.\\nIn the case of Neural Machine Translation, the input is a series of words, and the output is the translated series of words.\\nNow let's work on reducing the blackness of our black box. The model is composed of an encoder and a decoder. The encoder captures the context of ...  \n",
       "101  Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...  \n",
       "102  Towards Data Science\\nOct 28, 2019\\nDealing with images is not a trivial task. To you, as a human, it’s easy to look at something and immediately know what is it you’re looking at. But computers don’t work that way.\\nTasks that are too hard for you, like complex arithmetics, and math in general, is something that a computer chews without breaking a sweat. But here the exact opposite applies — tasks that are trivial to you, like recognizing is it cat or dog in an image are really hard for a computer. In a way, we are a perfect match. For now at least.\\nWhile image classification and tasks that involve some level of computer vision might require a good bit of code and a solid understanding, reading text from a somewhat well-formatted image turns out to be a one-liner in Python —and can b...  \n",
       "103  Towards Data Science\\nJul 31, 2019\\nIn this article, we’ll explore a state-of-the-art method of machine learning interpretability and adapt it to multivariate time series data, a use case which it wasn’t previously prepared to work on. You’ll find explanations to core concepts, on what they are and how they work, followed by examples. We’ll also address the main ideas behind the proposed solution, as well as a suggested visualization of instance importance.\\nIt’s not just hype anymore, machine learning is becoming an important part of our lives. Sure, there aren’t any sentient machines nor Scarlett Johansson ear lovers (shoutout to Her) out there, but the evolution of these algorithms is undeniable. They can ride cars, assist in medical prognosis, predict stock, play videogames at a pr...  \n",
       "104  Towards Data Science\\nJan 24, 2020\\nI had just walked away from 8 years of study and hard work with no plan. You might be wondering why someone would do that. My boss was crushing my spirit and knew that I needed to make a change.\\nMy boyfriend suggested becoming a data scientist. I said ‘you're crazy!’ I didn’t know the first thing about programming. Surely he was overestimating what I was capable of. Imposter syndrome strikes again.\\nAbout two weeks later my friend Anna suggested the exact same thing, I thought about it some more and began to entertain the idea. Why not? I decided to become a beginner again and reinvent myself as a data scientist.\\nI wanted to learn at my own pace so I decided to take online courses. I figured that with a PhD in Neuroscience I probably had enough for...  \n",
       "105  UX Collective\\nAug 17, 2021\\nApplications we design are becoming increasingly data-driven. The need for quality data visualization is high as ever. Confusing and misleading graphics are all around us, but we can change this by following these simple rules.\\nChoosing the wrong chart type, or defaulting to the most common type of data visualization could confuse users or lead to data misinterpretation. The same data set can be represented in many ways, depending on what users would like to see. Always start with a review of your data set and user interview.\\nYou can learn more on how to pick the right representation for your data, and how to design effective dashboards in my article about Dashboard design.\\nWhen using horizontal bars, plot negatives values on the left side and positive o...  \n",
       "106  Oct 18, 2015\\n1. What is the purpose of metadata? What are the categories of metadata?\\nMetadata provides definitions about the data they are attached to. It can include descriptive information about the context, quality, condition and characteristics.\\nMetadata is broken into three categories; structural (describes information about the document), descriptive (enables the document to be identified) and administrative (identifies the relationship of the document to the business context).\\n2. What is a controlled vocabulary? How is a controlled vocabulary beneficial to a web site and/or organisation?\\nA controlled vocabulary is a list of equivalent terms in the form of a synonym ring or a list of preferred terms in the form of an authority file.\\nThis is beneficial as it helps categoris...  \n",
       "107                                                                                                                        Konvergen.AI\\nJul 21, 2019\\nOne particular layer that is useful, yet mysterious when training neural networks is Dropout. Dropout is created as a regularization technique, that we can use to reduce the model capacity so that our model can achieve lower generalization error. The intuition is easy, we didn’t use all neurons but only turn on some neuron in each training iteration with probability p. But how does dropout works, and is it the same as the implementation?\\n105 \\n105 \\n2\\nThe sharing platform of Konvergen.ai. Visit our homepage at https://konvergen.ai\\n171 Followers\\nCofounder of Konvergen.AI\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "108  Feb 26, 2018\\nПриветствую вас, друзья! TokenGo запускает ICO!\\nМы долго шли к этому дню, к этому волнующему событию. До момента запуска ICO платформы TokenGo остались считанные часы.\\nВ первую очередь я хочу сказать спасибо всем тем, кто сегодня с нами! С кем-то мы знакомы уже несколько месяцев, успели пообщаться, обсудить будущее и подружиться, кто-то присоединяется только сейчас, изучает White Paper, читает темы на форумах, задает вопросы в Telegram-чате. И это очень здорово, что наше сообщество постоянно растет, укрепляется, и каждый участник вносит свой вклад в строительство экосистемы TokenGo. Отдельно хочу поздравить инвесторов, записавшихся в White List. Уверен, что полученный вами уникальный бонус вас обязательно порадует!\\nА в TokenGo все продолжает идти по плану. Совсем ...  \n",
       "109                                                                                                                                                                          Jan 10, 2016\\nTips to avoid the pitfall of over fitting in Linear Regression\\n8. The choice of the model has to be based on the observation from training error and test error . Also its tricky to make choice of right features to come to make build the model for your predictions.\\n1 \\n1 \\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n743 Followers\\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "110  Sep 5, 2020\\nThis blog is written to explain the evolution of object detection models in simple words and self-explanatory diagrams. This blog can be helpful to every individual who is entering into the field of computer vision and data science or has taken up a project which requires solving an object detection problem.\\nWe all must have heard about Faster R-CNN and there are high chances that you found this blog when you searched for the keyword “Faster R-CNN” as it has been among the state of arts used in many fields since January 2016.\\nA strong object detection architecture like Faster RCNN is built upon the successful research like R-CNN and Fast R-CNN. To honestly enjoy working, troubleshooting and pursuing the dream of creating your own model which can one day be called a state...  \n",
       "111  Aug 28, 2018\\nUnchainet is aiming to provide a decentralized cloud platform connecting providers with spare computing resources and clients who need them. Research shows 30% of servers in private data centers consume energy but are not being used. We are working to provide easy-to-install software for companies with private data centers, hosting companies and individuals so they can easily connect to the Unchainet network and start earning money on a transparent and efficient marketplace. Unchainet clients will include existing partners and all other cloud users. Our platform’s important differentiation from competing decentralized cloud platforms is familiar open source technology and bridging interfaces which completely removes friction associated with staff training and allows easy ...  \n",
       "112                                                                                        TekLit\\nJul 10, 2021\\nThe looming threat to the average programmer.\\nLet’s face it. Unless you are talented enough for Google to hire you, you are probably limited to developing APIs, websites, or customizing an ERP-like business system.\\nIf toiling day after day, adding mundane features to boring systems isn’t enough for you, you have the added task of keeping up with the frameworks and tools that will evolve with...\\n8.8K \\n8.8K \\n295\\nWe’re software developers, for better or for worse. Friendlier than your average StackOverflow moderator, but we probably won’t fix your code.\\n1.9K Followers\\nSoftware Developer | Writer for TekLit\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "113  emaasit\\nAug 3, 2016\\nIn case you missed my free webinar on “Model-Based Machine Learning”, here is the recording.\\nApologies for the poor quality of the video. Domino Data Lab’s webinar platform suffered a service degradation while recording the event. The webinar slides may be found below.\\n[slideshare id=64647075&doc=3rdpresentationpaperreview-160803065711]\\nIf you have any questions, please do not hesitate to contact me. Finally, I would like to thank Daniel Enthoven and Daniel Chalef from Domino Data Lab for setting up this webinar.\\nEmaasit’s personal blog about R, Bayesian Machine Learning, Big Data, Bayesian Nonparametrics, & Probabilistic Programming\\n252 Followers\\nFounder at @SparkIQ_Labs, PhD Student in Urban Mobility, Bayesian Machine Learning Research Scientist, Organizer...  \n",
       "114  HackerNoon.com\\nSep 18, 2018\\nThis article proposes an easy and free solution to train a Tensorflow model for instance segmentation in Google Colab notebook, with a custom dataset.\\nPrevious article was about Object Detection in Google Colab with Custom Dataset, where I trained a model to infer bounding box of my dog in pictures. The protagonist of my article is again my dog: in this case we take a step forward, we identify not only the bounding box, we make even pixel wise classification.\\nCompared to previous article, we hold the same characteristics:\\nThese features allow anybody following this tutorial to create an instance segmentation model, and test it in Google Colab or export the model to run in a local machine.\\nSource code of this article, including the sample dataset, is av...  \n",
       "115  Towards Data Science\\nJul 23, 2017\\nLatest Update:I have uploaded the complete code (Python and Jupyter notebook) on GitHub: https://github.com/javedsha/text-classification\\nDocument/Text classification is one of the important and typical task in supervised machine learning (ML). Assigning categories to documents, which can be a web page, library book, media articles, gallery etc. has many applications like e.g. spam filtering, email routing, sentiment analysis etc. In this article, I would like to demonstrate how we can do text classification using python, scikit-learn and little bit of NLTK.\\nDisclaimer: I am new to machine learning and also to blogging (First). So, if there are any mistakes, please do let me know. All feedback appreciated.\\nLet’s divide the classification problem in...  \n",
       "116  Towards Data Science\\nAug 25, 2020\\nNote from Towards Data Science’s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author’s contribution. You should not rely on an author’s works without seeking professional advice. See our Reader Terms for details.\\nThis blog is based on our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, presented at ICAIF 2020: ACM International Conference on AI in Finance.\\nOur codes are available on Github.\\ngithub.com\\nOur paper is available on SSRN.\\npapers.ssrn.com\\nIf you want to cite our paper, the reference format is as follows:\\nHongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated S...  \n",
       "117  The Official Unofficial Firefox Blog\\nNov 10, 2016\\nWe did a bit of informal censusing last month to get to know our users in the best way possible: anonymously and collectively. You might have seen the survey, which we shared through email, our about:home page, and social media. You might have also noticed it came from our Bureau of Censusing (not an official team here), Department of Whimsy (also not an official department, but you better believe we’re doing some introspection now as to why not). It was totally voluntary and, like everything we do, about openness and transparency.\\nSo in that spirit, let’s look at the results! You can find the full report here, if you’re into that sort of thing. There were 44 questions and a ton of interesting ways to slice the data, so for the sake ...  \n",
       "118  Towards Data Science\\nMar 25, 2021\\nOver the last few years, Voice Assistants have become ubiquitous with the popularity of Google Home, Amazon Echo, Siri, Cortana, and others. These are the most well-known examples of Automatic Speech Recognition (ASR). This class of applications starts with a clip of spoken audio in some language and extracts the words that were spoken, as text. For this reason, they are also known as Speech-to-Text algorithms.\\nOf course, applications like Siri and the others mentioned above, go further. Not only do they extract the text but they also interpret and understand the semantic meaning of what was spoken, so that they can respond with answers, or take actions based on the user's commands.\\nIn this article, I will focus on the core capability of Speech-to-...  \n",
       "119  Towards Data Science\\nDec 10, 2019\\nComputer vision in Machine Learning provides enormous opportunities for GIS. Its tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions.[1][2][3][4] In the last several years, computer vision is increasingly shifting from traditional statistical methods to the state-of-art deep learning neural network techniques.\\nIn this blog, I will share several empirical practices using Keras and ESRI ArcGIS Pro tools with deep learning and transfer learning techniques to build a building footprint image segmentation network model from a super-high-resolution 3-inch of EagleView (Pi...  \n",
       "120  Feb 6, 2020\\nIn this article, I will discuss all cases of Logistic Regression that are useful while applying.\\nLet’s take x as an input feature vector, and y is a class (-1 or +1), then the probability of class given input vector represented by the below formula.\\nand log loss is\\nLoss with regularization for optimization is\\nN is the number of data points we have, C is hyperparameter to control regularization. Above I added l2 regularization notation. x_i is the data points features and y_i(+1 or -1) is the label we have for x_i. This formulation works only for Binary classification.\\nAlso, we can represent the Loss function as below, and that works for multiclass formulation as well.\\nLet’s take we have K classes and N number of data points. Now the Log loss function is represented a...  \n",
       "121  Towards Data Science\\nJul 14, 2017\\nHere is a quick concise summary for reference. For more detailed explanation please read: http://ruder.io/optimizing-gradient-descent/\\nVanilla gradient descent, aka batch gradient descent, computes the gradient of the cost function w.r.t. to the parameters θ for the entire training dataset.\\nStochastic gradient descent (SGD) in contrast performs a parameter update for each training example x(i) and label y(i)\\nMini-batch gradient descent finally takes the best of both worlds and performs an update for every mini-batch of n training examples.\\nVanilla mini-batch gradient descent, however, does not guarantee good convergence, but offers a few challenges that need to be addressed:\\nSGD has trouble navigating ravines, i.e. areas where the surface curves...  \n",
       "122  Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...  \n",
       "123  Jul 10, 2020\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is an unsupervised machine learning technique used to identify clusters of varying shape in a data set (Ester et al. 1996). Another post I wrote goes into what DBSCAN is and when to use it. You can find it here. This post will focus on estimating DBSCAN’s two parameters:\\nThere is no automatic way to determine the MinPts value for DBSCAN. Ultimately, the MinPts value should be set using domain knowledge and familiarity with the data set. From some research I’ve done, here are a few rules of thumb for selecting the MinPts value:\\nAfter you select your MinPts value, you can move on to determining ε. One technique to automatically determine the optimal ε value is described in this paper. This technique calc...  \n",
       "124  Towards Data Science\\nOct 3, 2021\\nIn this article, we review the problem of semantic segmentation on unbalanced binary masks. Focal loss and mIoU are introduced as loss functions to tune the network parameters. Finally, we train the U-Net implemented in PyTorch to perform semantic segmentation on aerial images. The training codes and PyTorch implementations are available through Github.\\nThe dataset used here is “Semantic segmentation of aerial imagery” which contains 72 satellite images of Dubai, the UAE, and is segmented into 6 classes. The classes include water, land, road, building, vegetation, and unlabeled.\\nU-Net is a convolutional neural network that originally was presented for biomedical image segmentation at the Computer Science Department of the University of Freiburg. It ...  \n",
       "125  Analytics Vidhya\\nAug 27, 2020\\nThis post demonstrates the use of Stochastic Gradient Descent for Dimensionality Reduction.\\nWhat is Dimensionality Reduction?\\nDimensionality reduction is the process of reducing a potentially large set of features F to a smaller set of features F’ to be considered in a given machine learning or statistics problem.\\nIn an unsupervised setting, dimensionality reduction is often used for exploratory data analysis, for example to visualize the distribution of high dimensional data in human-digestible two or three dimensions. In a supervised setting, the main use is to reduce the number of parameters a learning machine has to determine. In other words: The goal of dimensionality reduction is to overcome the curse of dimensionality.\\nA straightforward approa...  \n",
       "126  Towards Data Science\\nFeb 28, 2021\\nSince the seminal paper “Attention is all you need” of Vaswani et al, Transformer models have become by far the state of the art in NLP technology. With applications ranging from NER, Text Classification, Question Answering or text generation, the applications of this amazing technology are limitless.\\nMore specifically, BERT — which stands for Bidirectional Encoder Representations from Transformers— leverages the transformer architecture in a novel way. For example, BERT analyses both sides of the sentence with a randomly masked word to make a prediction. In addition to predicting the masked token, BERT predicts the sequence of the sentences by adding a classification token [CLS] at the beginning of the first sentence and tries to predict if the sec...  \n",
       "127  Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...  \n",
       "128  unpackAI\\nJun 6, 2021\\nThere are 7 steps to train/get a model in deep learning like this chart:\\nWe now put it with the SGD together and look at them step by step:\\nStep 1: Initialize\\nIn this step, we initialize our parameters with random values and tell PyTorch that we want to track their gradients:\\nWe will do the following things in this step:\\nStep 2: Predict\\nIn this step,we will calculate the predictions to see how close our predictions to our targets. The code will like this\\npreds = f(time, params)\\nStep 3: Calculate the Loss\\nIn this step, can change the weight by a little in the direction of the slope, calculate the loss and adjustment again, and repeat this a few times. We will get to the lowest point on the curve. We can use “mse”or “l1”to calculate.\\n“mse”stands for *mean...  \n",
       "129  Towards Data Science\\nApr 24, 2020\\nThe Transformer Neural Network is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease. It was proposed in the paper “Attention Is All You Need” 2017 [1]. It is the current state-of-the-art technique in the field of NLP.\\nBefore directly jumping to Transformer, I will take some time to explain the reason why we use it and from where it comes into the picture. (If you want to skip this part then directly go to the Transformer topic, but I suggest you read it sequentially for better understanding).\\nSo, the story starts with RNN (Recurrent Neural Networks).\\nWhat is RNN? How is it different from simple ANN? What is the major difference?\\nRNNs are the Feed Forward Neural Networks that are ro...  \n",
       "130  Becoming Human: Artificial Intelligence Magazine\\nDec 13, 2017\\nIn this article we will be solving an image classification problem, where our goal will be to tell which class the input image belongs to. The way we are going to achieve it is by training an artificial neural network on few thousand images of cats and dogs and make the NN(Neural Network) learn to predict which class the image belongs to, next time it sees an image having a cat or dog in it.\\nThe key thing to understand while following this article is that the model we are building now can be trained on any type of class you want, i am using cat and dog only as a simple example for making you understand how convolutional neural networks work. For example, if there are any doctors reading this, after completing this article...  \n",
       "131  NanoNets\\nMar 20, 2018\\nDisclaimer: I’m building nanonets.com to help build ML with less data and no hardware\\nIf you’re impatient scroll to the bottom of the post for the Github Repos\\nThe raspberry pi is a neat piece of hardware that has captured the hearts of a generation with ~15M devices sold, with hackers building even cooler projects on it. Given the popularity of Deep Learning and the Raspberry Pi Camera we thought it would be nice if we could detect any object using Deep Learning on the Pi.\\nNow you will be able to detect a photobomber in your selfie, someone entering Harambe’s cage, where someone kept the Sriracha or an Amazon delivery guy entering your house.\\n20M years of evolution have made human vision fairly evolved. The human brain has 30% of it’s Neurons work on proces...  \n",
       "132  Towards Data Science\\nFeb 2, 2020\\nIn this article, we will learn:\\nmedium.com\\ntowardsdatascience.com\\nIn this article, you will get a detailed explanation of how neural machine translation developed using sequence to sequence algorithm to find the most relevant words in sentences for a target language.\\nWhat is Beam search?\\nTo understand the Beam search, we will use the neural machine translation use case of sequence to sequence.\\nThe sequence to sequence model uses an encoder and decoder framework with Long Short Term Memory(LSTM) or Gated Recurrent Unit(GRU) as the basic blocks.\\nEncoder maps a source sequence encodes the source information and passes it to the decoder. The decoder takes the encoded data from the encoder as an input along with the start-of-string <START> token as ...  \n",
       "133  Towards Data Science\\nMar 15, 2020\\nSome tasks that AI does are actually not impressive. Think about your camera recognizing and auto-focusing on faces in pictures. That technology has been around since 2001, and it doesn’t tend to excite people. Why not? Well, because you can do that too, you can focus your eyes on someone’s face very easily. In fact, it’s so easy you don’t even know how you do it. If AI can do it too, then who cares how it works? Though we may not explicitly understand how this AI works, its underlying mechanisms don’t do anything we can’t. At least, this is what I think most people are thinking.\\nGames are just the opposite. Rather than games being an innate ability we have (like focusing your vision), you have an understanding of how and why you make decisions with...  \n",
       "134  May 21, 2014\\nRecently I’ve have been looking into options to solve the problem of GSLB’ing (global server load balancing) a Liferay Portal instance.\\nThis article is a work in progress... and a long one. Jan Eerdekens states it correctly in his article, “Configuring a Liferay cluster is part experience and part black magic” .... however doing it across data-centers however is like wielding black magic across N black holes....\\nFootnotes for this article are here: https://bitsofinfo.wordpress.com/2014/05/21/liferay-clustering-internals/\\nThe objective is a typical one.\\nHopefully this article will help others out there, point them in a new direction and give them some ideas on how to put something like this together.\\nI’d like to note that this is not necessarily the ideal way to do th...  \n",
       "135  May 2, 2017\\n“Buat apa kuliah kalo kalah sukses atau gaji aja kalah gede dari lulusan SMA/SMK?”\\nSerius, pasti banyak orang yang pernah terlintas pikiran brilian seperti diatas. Bahkan bisa jadi kamu yang membaca ini adalah satunya bukan? Tenang saja, kamu tidak sendirian karena saya juga pernah berpikir seperti itu kok hehehe :D\\nYa, tidak bisa dipungkiri karena kita sering melihat contoh orang-orang terkenal yang sukses padahal mereka OD (baca: Out Dewe, kalau DO kan Drop Out, jelek kesannya ditendang, sementara OD gak perlu nunggu ditendang udah keluar-keluar sendiri hehehe :p) atau bahkan sekolah pun gak tamat. Contohnya Brad Pitt, Oprah Winfrey, Lady Gaga, John Lennon, Eminem. Nama-nama itu pasti sudah tidak asing lagi kan?\\nMungkin ada yang berpikir orang yang OD maupun DO tidak ...  \n",
       "136  Towards Data Science\\nJul 24, 2020\\nIn this article we will study word embeddings — digital representation of words suitable for processing by machine learning algorithms.\\nOriginally I created this article as a general overview and compilation of current approaches to word embedding in 2020, which our AI Labs team could use from time to time as a quick refresher. I hope that my article will be useful to a wider circle of data scientists and developers. Each word embedding method in the article has a (very) short description, links for further study, and code examples in Python. All code is packed as Google Colab Notebook. So let’s begin.\\nAccording to Wikipedia, Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language pro...  \n",
       "137  Towards Data Science\\nJun 26, 2017\\nAutoencoders (AE) are a family of neural networks for which the input is the same as the output (they implement a identity function). They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.\\nA really popular use for autoencoders is to apply them to images. The trick is to replace fully connected layers by convolutional layers. These, along with pooling layers, convert the input from wide and thin (let’s say 100 x 100 px with 3 channels — RGB) to narrow and thick. This helps the network extract visual features from the images, and therefore obtain a much more accurate latent space representation. The reconstruction process uses upsampling and convolutions.\\nThe resulting netwo...  \n",
       "138  Towards Data Science\\nJan 1, 2019\\nYou know it’s out there. You know there’s free GPU somewhere, hanging like a fat, juicy, ripe blackberry on a branch just slightly out of reach.\\nBeautiful lightning-fast speed waiting just for you.\\nWondering how on earth to get it to work? You’re in the right place!\\nFor anyone who doesn’t already know, Google has done the coolest thing ever by providing a free cloud service based on Jupyter Notebooks that supports free GPU. Not only is this a great tool for improving your coding skills, but it also allows absolutely anyone to develop deep learning applications using popular libraries such as PyTorch, TensorFlow, Keras, and OpenCV.\\nColab provides GPU and it’s totally free. Seriously!\\nThere are, of course, limits. (Nitty gritty details are availabl...  \n",
       "139  Towards Data Science\\nJan 15, 2019\\nEverything we express (either verbally or in written) carries huge amounts of information. The topic we choose, our tone, our selection of words, everything adds some type of information that can be interpreted and value extracted from it. In theory, we can understand and even predict human behaviour using that information.\\nBut there is a problem: one person may generate hundreds or thousands of words in a declaration, each sentence with its corresponding complexity. If you want to scale and analyze several hundreds, thousands or millions of people or declarations in a given geography, then the situation is unmanageable.\\nData generated from conversations, declarations or even tweets are examples of unstructured data. Unstructured data doesn’t fit n...  \n",
       "140  Towards Data Science\\nSep 8, 2021\\nWritten by Walter Hugo Lopez Pinaya, Pedro F. da Costa, and Jessica Dafflon\\nHi everybody! Today, we will continue the series about autoregressive models and we will focus on one of the biggest limitations of PixelCNNs (i.e., blind spots) and how to improve to fix it.\\nSummary\\nFor each topic, the code is availiable in this repository.\\nIn the previous two posts, we introduced generative models, the concept behind PixelCNNs, and looked at how a coloured PixelCNN works. Recall that PixelCNNs are a type of generative models that learn the probability distribution of pixels, that means that the intensity of future pixels will be determined by previous pixels. In this blogpost series we implemented two PixelCNNs and noticed that the performance was not st...  \n",
       "141  Towards Data Science\\nFeb 26, 2019\\nIn this article, I will explain the concept of convolution neural networks (CNN’s) using many swan pictures and will make the case of using CNN’s over regular multilayer perceptron neural networks for processing images.\\nImage Analysis\\nLet us assume that we want to create a neural network model that is capable of recognizing swans in images. The swan has certain characteristics that can be used to help determine whether a swan is present or not, such as its long neck, its white color, etc.\\nFor some images, it may be more difficult to determine whether a swan is present, consider the following image.\\nThe features are still present in the above image, but it is more difficult for us to pick out these characteristic features. Let us consider some mor...  \n",
       "142  Towards Data Science\\nDec 26, 2020\\nOutliers, one of the buzzwords in the manufacturing industry, has driven engineers and scientists to develop newer algorithms as well as robust techniques for continuous quality improvement. If the data include even if one outlier, it has the potential to dramatically skew the calculated parameters. Therefore, it is of utmost importance to analyze the data without those deviant points. It is also important to understand which of the data points are considered as outliers. Extreme data points do not always necessarily mean those are outliers.\\nIn this article, I will discuss the algorithm and the python implementation for three different outlier detection techniques. Those are Interquartile (IQR) method, Hampel method and DBSCAN clustering method.\\nIn...  \n",
       "143  SAP Design\\nApr 11, 2018\\nThis blog belongs to the SAP Design series about intelligent system design. You might also be interested in our previous post, 5 Challenges to Your Machine Learning Project.\\nOne of the guiding design principles for intelligent systems is to empower end users. If we want people to trust machines, we must share information about the underlying models and the reasoning behind the results of algorithms. This is even more vital for business applications, when users are held accountable for every decision they make.\\nIt’s widely accepted that intelligent systems must come with a certain level of transparency. There’s even a new term for it: explainable AI. But, that’s just the beginning. As designers, we need to ask ourselves how explainable AI is tied to user inte...  \n",
       "144  Towards Data Science\\nMay 31, 2018\\nTopic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.\\nHere we are going to apply LDA to a set of documents and split them into topics. Let’s get started!\\nThe data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from Kaggle.\\nTake a peek of the data.\\n1048575\\nWe will perform the following steps:\\nLoading gensim and nltk libraries\\n[nltk_data] Downloading package wordnet to[nltk_data]...  \n",
       "145  Analytics Vidhya\\nJun 7, 2020\\nGenerative Adversarial Networks (GANs) have had a lot of success since they were introduced in 2014 by Ian Goodfellow. For somebody starting out in Machine Learning, the intricate Mathematics and the complex-looking architecture of GANs seems daunting. So, let’s demystify GANs/C-GANs and implement a simple application with PyTorch. This article is self-contained and is targeted for beginner to intermediate level Machine Learning enthusiasts.\\n159 \\n159 \\n2\\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n105 Followers\\nPh.D. student in Natural Language Processing (https://nrjvarshney.github.io)\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nT...  \n",
       "146  Towards Data Science\\nApr 7, 2020\\nHuman language is filled with ambiguity, many-a-times the same phrase can have multiple interpretations based on the context and can even appear confusing to humans. Such challenges make natural language processing an interesting but hard problem to solve. However, we’ve seen a lot of advancement in NLP in the past couple of years and it’s quite fascinating to explore the various techniques being used. This article aims to cover one such technique in deep learning using Pytorch: Long Short Term Memory (LSTM) models.\\nHere’s a link to the notebook consisting of all the code I’ve used for this article: https://jovian.ml/aakanksha-ns/lstm-multiclass-text-classification\\nIf you’re new to NLP or need an in-depth read on preprocessing and word embeddings, y...  \n",
       "147  Towards Data Science\\nOct 5, 2018\\nLinear Regression is usually the first machine learning algorithm that every data scientist comes across. It is a simple model but everyone needs to master it as it lays the foundation for other machine learning algorithms.\\nWhere can Linear Regression be used? It is a very powerful technique and can be used to understand the factors that influence profitability. It can be used to forecast sales in the coming months by analyzing the sales data for previous months. It can also be used to gain various insights about customer behaviour. By the end of the blog we will build a model which looks like the below picture i.e, determine a line which best fits the data.\\nThis is the first blog of the machine learning series that I am going to cover. One can get ...  \n",
       "148  Towards Data Science\\nAug 4, 2017\\nOne way to think of what deep learning does is as “A to B mappings,” says Andrew Ng, chief scientist at Baidu Research. “You can input an audio clip and output the transcript. That’s speech recognition.” As long as you have data to train the software, the possibilities are endless, he maintains. “You can input email, and the output could be: Is this spam or not?” Input loan applications, he says, and the output might be the likelihood a customer will repay it. Input usage patterns on a fleet of cars and the output could advise where to send a car next.\\nRather making the facts complicated by having complex definitions, think of deep learning as a subset of a subset. Artificial Intelligence encircles a wide range of technologies and techniques that ena...  \n",
       "149  Sep 25, 2016\\nThere’s a huge difference between reading about Reinforcement Learning and actually implementing it.\\nIn this post, you’ll implement a Neural Network for Reinforcement Learning and see it learn more and more as it finally becomes good enough to beat the computer in Pong! You can play around with other such Atari games at the OpenAI Gym.\\nBy the end of this post, you’ll be able to do the following:\\nThe code and the idea are all tightly based on Andrej Karpathy’s blog post. The code in me_pong.py is intended to be a simpler to follow version of pong.py which was written by Dr. Karpathy.\\nTo follow along, you’ll need to know the following:\\nIf you want a deeper dive into the material at hand, read the blog post on which all of this is based. This post is meant to be a simpl...  \n",
       "150  Analytics Vidhya\\nSep 7, 2019\\nThis article will cover: * Downloading and loading the pre-trained vectors * Finding similar vectors to a given vector * “Math with words” * Visualizing the vectors\\nFurther reading resources, including the original GloVe paper, are available at the end.\\nGlobal Vectors for Word Representation, or GloVe, is an “unsupervised learning algorithm for obtaining vector representations for words.” Simply put, GloVe allows us to take a corpus of text, and intuitively transform each word in that corpus into a position in a high-dimensional space. This means that similar words will be placed together.\\nIf you would like a detailed explanation of how GloVe works, linked articles are available at the end.\\nHead over to https://nlp.stanford.edu/projects/glove/.Then un...  \n",
       "151  Towards Data Science\\nMay 6, 2020\\nThis article will cover:\\nThere’s a video walkthrough of the code at the end for those who prefer the format. I personally like written tutorials, but I’ve had requests for video versions too in the past, so there it is.\\nSince you are here, there’s a very good chance you already know Pipelines make your life easy by pre-processing the data. I heard that too and tried to implement one in my code.\\nA shout-out to the few great tutorials I could find on the topic! I recommend you certainly browse through them, before or after the current article :\\ni. https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65ii. https://machinelearningmastery.com/how-to-transform-target-variables-for-regression-with-scikit-learniii...  \n",
       "152  Towards Data Science\\nFeb 15, 2019\\nTF-IDF stands for “Term Frequency — Inverse Document Frequency”. This is a technique to quantify words in a set of documents. We generally compute a score for each word to signify its importance in the document and corpus. This method is a widely used technique in Information Retrieval and Text Mining.\\nIf I give you a sentence for example “This building is so tall”. It's easy for us to understand the sentence as we know the semantics of the words and the sentence. But how can any program (eg: python) interpret this sentence? It is easier for any programming language to understand textual data in the form of numerical value. So, for this reason, we need to vectorize all of the text so that it is better represented.\\nBy vectorizing the documents we ca...  \n",
       "153  Towards Data Science\\nJul 31, 2019\\nUnderstanding the underlying structure of real-world data is one of the most compelling quests in machine learning. But with the advent of deep generative models researcher and practitioners have a powerful method to unravel it.\\nReal-world data is often complex and high-dimensional. Traditional approaches of data analysis are in most cases ineffective and can only model a very simple data distribution. Nowadays, we can use machine learning models to directly learn the structure of our data. The most common approach in machine learning is supervised learning, where we ask the model to learn a mapping from an input to an output variable, e.g. an image x to a label y. However, labelled data is expensive and prone to errors or biases by the human annota...  \n",
       "154  Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...  \n",
       "155  Aug 19, 2021\\nMerhaba, R-CNN Ailesi: Part I’ de CNN , R- CNN ve Fast R-CNN’den bahsetmiştim. Bu yazıda ise Faster R-CNN ile Mask R-CNN’in gelişimini, avantajlarını ve dezavantajlarını inceleyeceğiz.\\nBir önceki yazımda bahsettiğim R-CNN ve Fast R-CNN, bölge tekliflerini bulmak için seçici arama kullanır. Seçici arama, ağın performansını etkileyen yavaş ve zaman alıcı bir işlemdir. Bunun üzerine Shaoqing Ren ve ark. seçici arama algoritmasını ortadan kaldıran ve ağın bölge tekliflerini öğrenmesini sağlayan bir nesne algılama algoritması geliştirdi. Faster R-CNN’de bölge tekliflerini belirlemek için özellik haritası üzerinde Seçici Arama algoritması kullanmak yerine Bölge Teklif Ağı (RPN — Region Proposal Network) kullanılır.\\nFaster R-CNN’de izlenen adımlar:\\n...  \n",
       "156  Towards Data Science\\nSep 22, 2020\\nClustering falls under the unsupervised learning technique. In this technique, the data is not labelled and there is no defined dependant variable. This type of learning is usually done to identify patterns in the data and/or to group similar data.\\nIn this post, a detailed explanation on the type of clustering techniques and a code walk-through is provided.\\nClustering is a method of grouping of similar objects. The objective of clustering is to create homogeneous groups out of heterogeneous observations. The assumption is that the data comes from multiple population, for example, there could be people from different walks of life requesting loan from a bank for different purposes. If the person is a student, he/she could ask for an education loan, ...  \n",
       "157  Analytics Vidhya\\nAug 28, 2021\\nIn this post, you will discover a gentle introduction to the problem of object detection and state-of-the-art deep learning models designed to address it.\\nAfter reading this post, you will know:\\nLet’s get started.\\nThis article is divided into three parts; they are:\\n· Input: An image with a single object, such as a photograph.\\n· Output: A class label (e.g. one or more integers that are mapped to class labels).\\n2. Object Localization: Locate the objects in an image and output their location with a bounding box.\\n· Input: An image with one or more objects, such as a photograph.\\n· Output: One or more bounding boxes (e.g. defined by a point, width, and height).\\n3. Object Detection: Locate the objects with a bounding box and types or classes of the loc...  \n",
       "158  Towards Data Science\\nMar 17, 2017\\nIn Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class of RNN that has found practical applications is Long Short-Term Memory (LSTM) because it is robust against the problems of long-term dependency. There is no shortage of articles and references explaining LSTM. Two recommended references are:\\nChapter 10 of Deep Learning Book by Goodfellow et. al.\\nUnderstanding LSTM Networks by Chris Olah\\nThere is also no shortage of good libraries to build machine learning applications based on LSTM. In GitHub, Google’s Tensorflow has now over 50,000 stars at the time of this writing suggesting a strong popularity among machine learning practitioners.\\nWhat seems to be lacking is a...  \n",
       "159  Towards Data Science\\nSep 24, 2018\\nHi and welcome to an Illustrated Guide to Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU). I’m Michael, and I’m a Machine Learning Engineer in the AI voice assistant space.\\nIn this post, we’ll start with the intuition behind LSTM ’s and GRU’s. Then I’ll explain the internal mechanisms that allow LSTM’s and GRU’s to perform so well. If you want to understand what’s happening under the hood for these two networks, then this post is for you.\\nYou can also watch the video version of this post on youtube if you prefer.\\nRecurrent Neural Networks suffer from short-term memory. If a sequence is long enough, they’ll have a hard time carrying information from earlier time steps to later ones. So if you are trying to process a paragraph of text ...  \n",
       "160  IPG Media Lab\\nFeb 7, 2014\\nAmazon is raising the stakes of showrooming for retailers once again, folding its “Flow” technology, previously found in a standalone app released by its subsidiary, A9, into its main shopping app for iOS. “Flow” is visual product search, allowing users to photograph an object and see details about it on Amazon, which is even simpler than the previous norm of barcode recognition. Amazon’s competitive pricing is its main advantage in comparison to retailers, and by more effectively using other retailers as showrooms for the products it sells, it has the potential to further extend its dominance in more consumer categories.\\nThe media futures agency of IPG Mediabrands\\n1.99K Followers\\nKeeping brands ahead of the digital curve. An @IPGMediabrands company.\\nHel...  \n",
       "161  Towards Data Science\\nSep 29, 2020\\nIn this tutorial, I'm going to walk you through using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.\\nThe pre-trained model that will be used in this tutorial is the VGG16 convolutional neural network (CNN), which is considered to be state of the art for image recognition tasks. We are going to be using this model as a feature extractor only, meaning that we will remove the final (prediction) layer so that we can obtain a feature vector.\\nThis implementation will use the flowers dataset from Kaggle which you can download here. The dataset contains 210 images of 10 different species of flowers that will be downloaded as png files.\\nBefore we get started, we need...  \n",
       "162  Towards Data Science\\nDec 15, 2018\\nArtificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.\\nThe agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image & Video recognition, Image Analysis & Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutiona...  \n",
       "163  Analytics Vidhya\\nNov 28, 2019\\nSo I was trying to learn about Reinforcement Learning, and then I came across this thing called ‘Value Iteration’. I really couldn’t wrap my head around Value Iteration. It was very difficult for me to understand how it worked and how it could help an agent to find the optimal policy. Then I got an idea.\\nWhat better way to understand “Value Iteration” than to use it to solve some game or environment. Thus I began my journey to find some game easy enough problem to solve. And then I stumbled upon this fairy from OpenAI.\\nLet me explain the game/environment first.\\nThere are 64 states in the game. The agent starts from S (S for Start) and our goal is to get to G (G for Goal). So just go. Nope. Its a slippery surface. The F’s and the H’s in between are pre...  \n",
       "164  Towards Data Science\\nMay 8, 2021\\nUnderstanding the mathematic operands behind Neural Networks (NNs) is highly important for the data scientist capabilities, in designing an efficient deep model. In this article, the high-level calculus of a fully connected NN will be demonstrated, with focus on the backward propagation step. The article is oriented to people with basic knowledge of NNs, that seek to dive deeper into the NNs structure.\\nThe objective of the training process is to find the weights (W) and biases (b) that minimize the error. It is done by the gradient descent algorithm. To begin with, the weights are randomly initialized, and an iterative process of a subtle weights change is performed until convergence.\\nEach iteration begins with a forward pass, that outputs the curre...  \n",
       "165  Towards Data Science\\nAug 8, 2018\\nThe International Conference on Machine Learning took place last July in Stockholm. Altogether it showcased many interesting trends and directions in machine learning. Since, ICML was such a huge conference I will focus my attention on a few (of the many) interesting strands going on at the conference.\\nSpecifically, this year’s ICML split the oral talks into several different “tracks/sessions.” I was happy to see three of theses sessions focused on “transfer and multitask learning” as this has long been an area of interest of mine. Additionally, a large number of posters dealt with theses concepts as well as several orals from other tracks.\\nLack of large amounts of clean labeled data remains a barrier to the potential impact of deep learning. For ma...  \n",
       "166  Towards Data Science\\nNov 1, 2020\\nRecently NVIDIA published a paper called “Training Generative Adversarial Networks with Limited Data” and released the code. They proposed an adaptive discriminator augmentation (ADA) mechanism that stabilizes StyleGAN2 training and achieves significantly better results on small datasets.\\nIn this post, we’ll show how to quickly run this code on an AWS Spot instance.\\n“A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly.”\\n— Spot Instances, AWS Documentation\\nTo launch a Spot instance and run a Docker container with the environment, we will be using Spotty. Spotty is an open-...  \n",
       "167  Towards Data Science\\nApr 19, 2021\\nSequences of discrete tokens can be found in many applications, namely words in a text, notes in a musical composition, pixels in an image, actions in a reinforcement learning agent, etc [1]. These sequences often show a strong correlation between consecutive or nearby tokens. The correlations on words in a sentence or characters in words express the underlying semantics and language characteristics. The next token in the sequence x_n can be modeled as:\\nwhere x_i represents the ith token in the sequence. In Natural Language Processing (NLP), these are defined as language models. Usually, each token stands for a separate word or n-gram. The output generated is a probability distribution from which we can sample to generate the next token in the seque...  \n",
       "168                                                                                                                                                          Jun 23, 2020\\nThe most common debate around Artificial Intelligence and Machine Learning is “Will AI Take Your Job — or Make It Better?.” If most people had a choice, they would probably choose the latter. With any of these new technologies, it can be challenging to distinguish the hype from the headline. On one end, you have big tech companies and startups promising to fix problems ranging from detecting cancer to...\\n140 \\n140 \\n1\\nArt Director adampickard.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n13 Followers\\nArt Director adampickard.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "169  Feb 24, 2017\\n딥러닝(Deep Learning)과 시퀀스(Sequence)의 마법을 사용한 언어 번역(Language Translation)\\n우리는 모두 마법처럼 100 가지 다른 언어를 즉시 번역 할 수 있는 웹 사이트 인 구글 번역(Google Translate)을 알고 있고 사랑합니다. 심지어 휴대 전화나 스마트 워치에서도 사용할 수 있습니다:\\n구글 번역에 사용된 기술을 기계 번역(Machine Translation)이라고 합니다. 다른 방법으로는 절대 불가능했던 전세계 사람들의 의사 소통을 가능하게 함으로써 세상을 변화시켰습니다.\\n그런데, 사실 고등학생들이... 음... 지난 15 년간 스페인어 숙제를 하기위해 구글 번역의 도움을 받아 왔다는 것을 모두 알고 있습니다. 그렇다면 이건 오래된 뉴스가 아닌가요?\\n지난 2 년 동안, 딥러닝(deep learning)은 기계 번역에 대하...  \n",
       "170  Towards Data Science\\nMay 7, 2019\\nUpdate (May 18th, 2021): Today I’ve finished my book: Deep Learning with PyTorch Step-by-Step: A Beginner’s Guide.\\nUpdate (February 23rd, 2022): The paperback edition is available now (in three volumes). For more details, please check pytorchstepbystep.com.\\nPyTorch is the fastest growing Deep Learning framework and it is also used by Fast.ai in its MOOC, Deep Learning for Coders and its library.\\nPyTorch is also very pythonic, meaning, it feels more natural to use it if you already are a Python developer.\\nBesides, using PyTorch may even improve your health, according to Andrej Karpathy :-)\\nThere are many many PyTorch tutorials around and its documentation is quite complete and extensive. So, why should you keep reading this step-by-step tutorial?\\...  \n",
       "171  HackerNoon.com\\nJun 19, 2018\\nWhat is a Recurrent Neural Network or RNN, how it works, where it can be used? This article tries to answer the above questions. It also shows a demo implementation of a RNN used for a specific purpose, but you would be able to generalise it for your needs.\\nKnowhow. Python, CNN knowledge is required. CNN is required to compare why and where RNN performs better than CNN? No need to understand the math. If you want to check then go back to my earlier article to check what is a CNN.\\nWe will begin with the word use of the word “Recurrent”. Why is it called Recurrent? In english the word recurrent means:\\noccurring often or repeatedly\\nIn the case of this type of Neural Network it’s called Recurrent since it does the same operation over and over on sets of se...  \n",
       "172  Apr 5, 2021\\nWhat is Optimizers?\\nOptimizers are algorithms used to reduce the loss function and update the weights in backpropagation.\\nHere is the formula used by all the optimizers for updating the weights with a certain value of the learning rate.\\nThis is the most common optimizer used in neural networks. The weights are updated when the whole dataset gradient is calculated, If there is a huge amount of data weights updation takes more time and required huge amount of RAM size memory which will slow down the process and computationally expensive.\\nThere is also a saddle point problem. This is a point where the gradient is zero but is not an optimal point.\\nIn some cases, problems like Vanishing Gradient or Exploding Gradient may also occur due to incorrect parameter initialization...  \n",
       "173  Towards Data Science\\nJul 4, 2021\\n“Isolation Forest” is a brilliant algorithm for anomaly detection born in 2009 (here is the original paper). It has since become very popular: it is also implemented in Scikit-learn (see the documentation).\\nIn this article, we will appreciate the beauty in the intuition behind this algorithm and understand how exactly it works under the hood, with the aid of some examples.\\nAnomaly (or outlier) detection is the task of identifying data points that are “very strange” compared to the majority of observations.\\nThis is useful in a range of applications, from fault detection to discovery of financial frauds, from finding health issues to identifying unsatisfied customers. Moreover, it can also be beneficial for machine learning pipelines, since it has be...  \n",
       "174  HackerNoon.com\\nOct 15, 2016\\nWord2Vec; the Steroids for Natural Language Processing\\nLet’s start with the Basics.\\nQ) What are word vectors?\\nAns) Representation of words with numbers.\\nQ) Why Word Vectors?\\nAns) I’ll sum it up with three main reasons:\\n1. Computer cannot do computations on strings.\\n2. Strings don’t hold much explicit information themselves.\\n3. Words Vectors are usually dense vector representations.\\nQ) So what is Explicit information?\\nAns) Yes, the word itself doesn’t say much about what it represents in real life. Example:\\nThe string “cat” just tells us it has three alphabets “c”, ”a” and “t”.\\nIt has no information about the animal it represents or the count or the context in which it is being used.\\nQ) Dense Vector Representation?\\nAns) Short answer (for now),...  \n",
       "175  Towards Data Science\\nMar 22, 2021\\nThere is no denying the fact that GANs are awesome! If you don’t know what they are, check out this article where I explain GANs from scratch to a 5-year old and how to implement GANs in Pytorch! In a nutshell, GANs belong to a category of generative models that let us generate incredibly realistic synthetic data, with the same qualities as that of the underlying training data. That means if you feed the model images of a few bedroom decors, after few hours of training it can generate never-seen-before brand-new ideas for your interior design.\\nOver the past few weeks, I have probably read a dozen papers on GANs (and its variants) and tinkered around with their code on custom images (courtesy open-source Github repos). While most of these papers are ...  \n",
       "176                                                                                                                                                                                                                   Oct 5, 2017\\nThe main motivation for this post was that I wanted to get more experience with Bayesian types of Variational Autoencoders (VAEs) using Tensorflow.\\nAutoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we’ll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed...\\n248 \\n248 \\n1\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "177  Cubo AI\\nFeb 4, 2018\\nComputer vision object detection models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO\\n這篇是簡介一些用來辨識影像中物體的 AI 模型。\\n在前面有提到,透過 CNN 模型,你可以輸入一張圖片,得到該圖片屬於哪種類別的結果,這過程我們把他稱作分類 (Classification)。\\n但在真實世界的應用情境通常要從一張圖片中辨識所有出現的物體, 並且標示出位置來 (標出位置稱之為 Object Localization)。你一定在網路上看過類似底下的影片,這段影片可以看出中國閉路攝影機(CCTV)發展的概況,不只是可以框出影像中每個物件,辨別物件種類,偵測出移動物體的動量,甚至是人臉辨識,實現楚門世界的惡夢。要做到這就需要靠深度學習中的 Object Detection 演算法,這也是最近幾年來深度學習最蓬勃發展的一塊領域。\\n基本的想法是,既然 CNN 對於物體的分類又快又好,那我們可不可以拿 CNN 來掃描並辨識圖片中的任何物體? 答案當然是 — 可以。\\n最簡單的作法就是用 Sliding Windows 的概念,也就是用一個固定大小的框框,逐一的掃過整張圖片,每次框出來的圖像丟到 CNN 中去判斷類別。由於物體的大小是不可預知的,所以還要用不同大小的框框去偵測。但是 Sliding Window 是非常暴力的作法,對單一影像我們需要掃描非常多次,每掃一次都需要算一次 CNN,這將會耗費大量的運算資源,而且速度慢,根本無法拿來應用!\\n所以後來就有人提出了 R-CNN (Regions with CNN)\\n與其用 Sliding Window 的方式掃過一輪,R-CNN 的作法是預先篩選出約 2000 個可能的區域,再將...  \n",
       "178  Apr 26, 2012\\nInvestigating the human to computer relationship through reverse engineering the Turing test\\nHumans are getting closer to creating a computer with the ability to feel and think. Although the processes of the human brain are at large unknown, computer scientists have been working to simulate the human capacity to feel and understand emotions. This paper explores what it means to live in an age where computers can have emotional depth and what this means for the future of human to computer interactions. In an experiment between a human and a human disguised as a computer, the Turing test is reverse engineered in order to understand the role computers will play as they become more adept to the processes of the human mind. Implications for this study are discussed and the di...  \n",
       "179  Oct 9, 2020\\nAbstract\\nWith the ever-powerful deep learning algorithm, computer graphics have been pushed to a new level. The generative adversarial network (GAN) can now generate almost any type of photo-realistic images with the proper size of datasets. However, most of the GAN use cases have been limited to the pursue of lifelike graphics. In this article, I prose a new framework “MonsterGAN,” combining machine learning, design, and psychology. MonsterGAN is a prototype of a generative design system (DRCI), which reduces the cognitive burden of creation and makes creativity scalable, for concept artists.\\nWhat happens if computer vision passes the Turing test? Where and how can we use it? As a designer, I’m fascinated by these questions because we designers are the graphic wizards w...  \n",
       "180  Nurture.AI\\nFeb 2, 2018\\nIt’s currently an arms race in the tech scene right now with Deep Learning and Artificial Intelligence already the next industry-grade buzzword. Everyone’s looking to make the next big commercial success with a successful and innovative application of Artificial Intelligence.\\nOne such breakthrough is the use of deep learning neural networks to mathematically separate the content and style of images. What naturally entails is the idea of taking the content of one image and the style of another, and merging them both into one image. This idea was successfully implemented in 2015 by Gatys. et al in their paper “A Neural Algorithm of Artistic Style”.\\nSince then, there have been many insights and improvements of the base idea. Modern iterations of the algorithm ar...  \n",
       "181  Towards Data Science\\nMar 26, 2020\\nThe topics covered in this article include k-means, brown clustering, tf-idf, topic models and latent Dirichlet allocation (also known as LDA).\\nClustering is one of the biggest topics in data science, so big that you will easily find tons of books discussing every last bit of it. The subtopic of text clustering is no exception. This article can therefore not deliver an exhaustive overview, but it covers the main aspects. This being said, let us start by getting on common ground what clustering is and what it isn’t.\\nYou just scrolled by clusters!\\nIn fact, clusters are nothing more than groups that contain similar objects. Clustering is the process used for separating the objects into these groups.\\nObjects inside of a cluster should be as similar a...  \n",
       "182  Towards Data Science\\nApr 4, 2019\\nEvery ML practitioner knows that feature scaling is an important issue (read more here).\\nThe two most discussed scaling methods are Normalization and Standardization. Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\\nIn this blog, I conducted a few experiments and hope to answer questions like:\\nI’ll analyze the empirical results of applying different scaling methods on features in multiple experiments settings.\\nFirst, I was trying to understand what is the difference between Normalization and Standardization.So, I encountered this excellent blog by Sebastian Raschka that supplies a mathematical background that sat...  \n",
       "183  Towards Data Science\\nMar 4, 2020\\nWriting is always a good choice when it comes to clarifying one’s understandings of a given topic. By putting thoughts on papers, ideas will be clarified and confusions exposed. Though it might not be the most comfortable thing to do it’s indeed an efficient way to learn and improve.\\nIf you ever find yourself having a hard time explaining something to a friend, something you’ve been studying for a while but somehow still didn’t manage to portray the subject clearly and intuitively, you should try writing it down.\\nIn this article, I attempt to summarize some of the ideas for text representations in NLP, aiming to build a foundation for future complex concepts to come and hoping to contribute my granito de arena to your learning as well.\\nThe above di...  \n",
       "184  Nov 8, 2016\\nClarification: Gradient descent by itself is NOT robust to non-linearly separable data. However, when used with appropriate nonlinear activation functions it is.\\nThe reason is due to the kernel trick. In kernel trick, we apply a nonlinear transform on the data, so the resulting data set is linearly separable. This is illustrated below. Consider task of classifying blue and red points, they are not linearly separable. But what if we transform this data by adding a third variable (z = x2+y2), wecan draw a plane between blue and red points, and separate the two set of points. This is precisely what neural networks also do.\\nNeural networks’ learning can be viewed as a 2 part process where they learn some nonlinear transform of the data, and how to separate data based on this...  \n",
       "185  Edureka\\nFeb 10, 2017\\nThe majority of retail business holders find it hard to recognize customer needs. The reason why Data-driven companies such as Netflix, Walmart, Target, etc. are doing so well is that they have an army of Certified Data Analysts that grow their business by using the right tools to create personalized marketing strategies. We do understand that not all customers are alike and have the same taste. So, this leads to the challenge of marketing the right product to the right customer. An offer or product which might entice a particular customer segment may not be very helpful to other segments. So, you can apply the k-means clustering algorithm to segment your entire customer audience into groups with similar traits and preferences based on various metrics (such as th...  \n",
       "186  Towards Data Science\\nJun 8, 2019\\nDeep Learning has shown immense success in various fields and is continuing to spread its wings. But one of the major issues with training any traditional neural network model is the requirement of colossal amounts of data, and using this data to perform many iterative updates across many labeled examples.\\nLet’s take a look at a classic example of cats vs dogs classification. Although over the last two decades, we have made our models better and better to increase the accuracy, but the fundamental problem mentioned above still persists. We still need loads of labelled dogs and cats to get a decent accuracy.\\nHow do humans classify them with much lesser examples. Lets say all of a sudden you are shown two new animals, which are as visually distinguish...  \n",
       "187  Towards Data Science\\nNov 23, 2019\\nWhy should I care?\\nMany probability distributions are defined by using the gamma function — such as Gamma distribution, Beta distribution, Dirichlet distribution, Chi-squared distribution, and Student’s t-distribution, etc.For data scientists, machine learning engineers, researchers, the Gamma function is probably one of the most widely used functions because it is employed in many distributions. These distributions are then used for Bayesian inference, stochastic processes (such as queueing models), generative statistical models (such as Latent Dirichlet Allocation), and variational inference. Therefore, if you understand the Gamma function well, you will have a better understanding of a lot of applications in which it appears!\\nBecause we want to ...  \n",
       "188  Towards Data Science\\nFeb 15, 2019\\nA convolution is how the input is modified by a filter. In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge. Each time a match is found, it is mapped out onto an output image.\\nFor example, there is a picture of Eileen Collins and the matrix above the red arrow is used as a convolution to detect dark edges. As a result, we see an image where only dark edges are emphasized.\\nNote that an image is 2 dimensional with width and height. If the image is colored, it is considered to have one more dimension for RGB color. Fo...  \n",
       "189  Jan 11, 2016\\nClustering and dimension reduction algorithms help you to explore a dataset. Clustering and dimension reduction are unsupervised learning algorithms i.e., they don’t need labelled data to build a model. k-means is a popular clustering algorithm — you specify the the number of clusters (k) and it then finds the best cluster for each data instance. Choosing a good initial value for the number of clusters (k) can be problematic as k can be anything between 1 and the number of data instances. Finding the number of clusters is an active research field and techniques do exist (such as the Silhouette coefficient) but have varying success as the dimensionality of the data increases. I’m not going to go into any of these other techniques to find k in this blog post. Instead I’m go...  \n",
       "190  Towards Data Science\\nJan 27, 2019\\nClustering is one of the most common unsupervised machine learning problems. Similarity between observations is defined using some inter-observation distance measures or correlation-based distance measures.\\nThere are 5 classes of clustering methods:\\n+ Hierarchical Clustering+ Partitioning Methods (k-means, PAM, CLARA)+ Density-Based Clustering+ Model-based Clustering+ Fuzzy Clustering\\nMy desire to write this post came mainly from reading about the clustree package, the dendextend documentation, and the Practical Guide to Cluster Analysis in R book written by Alboukadel Kassambara author of the factoextra package.\\nI will be using a lesser known data set from the cluster package: all.mammals.milk.1956, one which I haven’t looked at before.\\nThis sm...  \n",
       "191  Towards Data Science\\nJan 7, 2019\\nThis post was co-written with Baptiste Rocca.\\nYann LeCun described it as “the most interesting idea in the last 10 years in Machine Learning”. Of course, such a compliment coming from such a prominent researcher in the deep learning area is always a great advertisement for the subject we are talking about! And, indeed, Generative Adversarial Networks (GANs for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article Generative Adversarial Nets.\\nSo what are Generative Adversarial Networks ? What makes them so “interesting” ? In this post, we will see that adversarial training is an enlightening idea, beautiful by its simplicity, that represents a real conceptual progress for Machine Learning...  \n",
       "192  Insight\\nNov 13, 2015\\nSlater Stich is an Insight alum and was previously a Staff Data Scientist at Square. He is currently a Vice President at Valor Equity Partners.\\nSeaborn is a Python data visualization library with an emphasis on statistical plots. The library is an excellent resource for common regression and distribution plots, but where Seaborn really shines is in its ability to visualize many different features at once.\\nIn this post, we’ll cover three of Seaborn’s most useful functions: factorplot, pairplot, and jointgrid. Going a step further, we'll show how we can get even more mileage out of these functions by stepping up to their even-more-powerful forms: FacetGrid, PairGrid, and JointGrid.\\nTo showcase Seaborn, we’ll use the UCI “Auto MPG” data set. We did a bit of prepr...  \n",
       "193  SomX Labs\\nSep 2, 2016\\nSimple Definition:\\nA collection of similar objects to each other.\\nSlightly Complex Definition:\\nA connected component of a level set of the probability density function of underlying (and unknown) distribution from which our data samples are drawn.\\nYou are posed with a problem to solve, what you have is a large amount of data represented in lot of dimensions. The data can not be read or understood by looking at it raw by a human.\\nEven before you start defining your problem (hypothesis), you need to understand the data, perform an EDA on it. There are multiple ways to do it.\\nA. Perform Clustering\\nPerfect! Clustering is a good way of identifying interesting parts of data by grouping it.\\nClustering is a process of grouping a sample of data into smaller simil...  \n",
       "194                                                                                                                                                                                                      OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder & CEO of Gado Images. I write, speak & consult about tech, food, privacy, AI & photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "195  Aug 23, 2020\\nA simple Image classifier model to demonstrate the usage of VGG-19Deep Learning Model to predict input image. This model is developed in python programming and executed on a Colab notebook. At the end of this article you will learn how to develop a simple image classifier application that uses Pytorch Python based Deep Learning library to predict an image.\\nAt the end of this article you will learn:\\nVGG-19 is a variant of VGG model which in short consists of 19 layers (16 convolution layers, 3 Fully connected layer, 5 MaxPool layers and 1 SoftMax layer). There are other variants of VGG like VGG11, VGG16 and others.\\nAlexNet came out in 2012 and it improved on the traditional Convolutional neural networks, So we can understand VGG as a successor of the AlexNet.\\nVGG means...  \n",
       "196  Jan 27, 2019\\nAs all you have probably heard by now, an AI called AlphaStar developed by Google Deepmind has recently beaten human professionals in the real-time strategy game Starcraft 2. This is an unprecedented feat in the field of AI. However, I do have some constructive criticism about the way they did it.\\nI will try to make a convincing argument for the following:\\nFirst of all, I want to clarify that I am a layman. I’ve been following AI development and the Starcraft 2 scene for years but I do not claim to be an expert in either topic. If you notice any misconceptions in what I’m about to write please do point them out. I’m only a fanboy and all of this is incredibly fascinating to me. This essay will contain a lot of speculation and I admit that I can’t prove all of my core cl...  \n",
       "197  Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...  \n",
       "198  Towards Data Science\\nNov 13, 2019\\nYou need to have a good understanding of:\\nAnd some basic knowledge of:\\nImage data used in this project has been collected from WikiArts.org.\\nIn this tutorial, we are going to look at the step by step process to create a Generative Adversarial Network to generate Modern Art and write a code for that using Python and Keras together.\\nAfter that, for training the model, we are going to use a powerful GPU Instance of Spell platform. Everything will be explained along the way and links will be provided for further readings.\\nLet’s get started!\\nBefore getting started, let’s look at our image dataset.\\nWikiArt has a huge collection of modern art with various different styles. For our particular project, we are going to use images of Cubism Style.\\nYou c...  \n",
       "199  SyncedReview\\nSep 25, 2017\\nAttention is simply a vector, often the outputs of dense layer using softmax function.\\nBefore Attention mechanism, translation relies on reading a complete sentence and compress all information into a fixed-length vector, as you can image, a sentence with hundreds of words represented by several words will surely lead to information loss, inadequate translation, etc.\\nHowever, attention partially fixes this problem. It allows machine translator to look over all the information the original sentence holds, then generate the proper word according to current word it works on and the context. It can even allow translator to zoom in or out (focus on local or global features).\\nAttention is not mysterious or complex. It is just an interface formulated by paramete...  \n",
       "200  Analytics Vidhya\\nAug 22, 2020\\nThis blog details the steps for Named Entity Recognition (NER) tagging of sentences (CoNLL-2003 dataset ) using Tensorflow2.2.0\\nCoNLL-2003 dataset includes 1,393 English and 909 German news articles. We will be looking at the English data. The CoNLL-2003 data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of t...  \n",
       "201  Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...  \n",
       "202  Analytics Vidhya\\nFeb 19, 2021\\nPrerequisites\\nThis article assumes that you are familiar with the basic theory behind PCA, K Means Algorithm and know Python programming language.\\nK Means clustering is one of the simplest yet efficient unsupervised algorithms. First let us have a brief description of what this algorithm does.\\nK Means Algorithm Suppose we have a dataset with two features x1 and x2. This is unlabelled data and our objective is to find K number of groups or “clusters” which are similar to each other. Suppose our training set looks like this :-\\nWe can clearly see there are two clusters, let us name them cluster 0 and cluster 1. Each cluster is associated with a centroid which is unique to each cluster. This algorithm iterates until the centroids do not change its positi...  \n",
       "203  A problem like Maria\\nOct 23, 2011\\nAI Class is a great experiment by two professors at the Stanford University: Sebastian Thrun and Peter Norvig. The course is being held as an actual course at Stanford University plus an online course for about 160,000 enrolled students. People in the advanced track have to do homework and write exams, people in the basic track just have to watch the lectures. Currently I’m in the advanced track, although I might switch to the basic track due to time problems (having a full time job + working on a private application + a University course is a bit too much). At the end of the course you’ll get a certificate, sadly not from Stanford but still. Pretty cool having done a course at Stanford... kind of.\\nI think it’s a great experience to attend a course ...  \n",
       "204  Towards Data Science\\nApr 10, 2019\\nAutomatic text classification or document classification can be done in many different ways in machine learning as we have seen before.\\nThis article aims to provide an example of how a Recurrent Neural Network (RNN) using the Long Short Term Memory (LSTM) architecture can be implemented using Keras. We will use the same data source as we did Multi-Class Text Classification with Scikit-Lean, the Consumer Complaints data set that originated from data.gov.\\nWe will use a smaller data set, you can also find the data on Kaggle. In the task, given a consumer complaint narrative, the model attempts to predict which product the complaint is about. This is a multi-class text classification problem. Let’s roll!\\nAfter first glance of the labels, we realized t...  \n",
       "205  Towards Data Science\\nJan 18, 2021\\nGradient descent is an important algorithm to understand, as it underpins many of the more advanced algorithms used in Machine Learning and Deep Learning. Getting to grips with the inner workings of gradient descent will therefore be of great benefit to anyone who plans on exploring ML algorithms further.\\nThe best way to learn is by doing, so in this article I will be walking through the steps of how the gradient descent process works, without using ML libraries such as scikit-learn for example. In day-to-day work, it is of course quicker and neater to make use of such libraries, but regarding the learning process I have found the exercise of implementing by hand to be invaluable for this particular algorithm.\\nThe goal of gradient descent is to min...  \n",
       "206  SyncedReview\\nFeb 27, 2019\\nWith just a mouse click, you can delight in mega-litters of adorable kitties, admire countless fresh anime characters, or stare into the twinkling eyes of all sorts of beautiful people. The only catch is that they’re all fake. As Synced previously reported, these hyperrealistic images now flooding the Internet come from US chip giant NVIDIA’s StyleGAN, a generative adversarial network based face generator that performs so well that most people can’t distinguish its creations from photos of real people.\\nSoon after StyleGAN was open-sourced earlier this month, Uber software engineer Philip Wang used the tool to create “This Person Does Not Exist,” a website which generates a new hyperrealistic fake human face every time it’s refreshed. The site quickly went v...  \n",
       "207                                                                                       The Startup\\nJun 26, 2020\\nConventional CNNs (AlexNet, VGG, GoogLeNet, ResNet, DenseNet ...) have good performances when there are many samples for each class in the dataset. Unfortunately, they generally do not work well when you have a small dataset. However, there are many real-life scenarios where it is challenging to gather data for your classes. For example, in face identification systems, there are...\\n373 \\n373 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n77 Followers\\nDeep learning researcher. PhD candidate at @METU. https://www.linkedin.com/in/gorkempolat/\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "208  UX Planet\\nJul 17, 2018\\nDashboard design is a frequent request these days. Businesses dream about a simple view that presents all information, shows trends and risky areas, updates users on what happened — a view that will guide them into a bright financial future.\\nFor me, a dashboard — is an at a glance preview of the most crucial information for the user at the moment he is looking at it, and an easy way to navigate directly to various areas of the application that require users attention. The term “dashboard” is a metaphor for a car dashboard, sometimes also called the cockpit area, usually near the front of an aircraft or spacecraft, from which a pilot controls the aircraft.\\nWorking on enterprise projects for years, I have designed countless dashboards. And every new one is the ...  \n",
       "209  Becoming Human: Artificial Intelligence Magazine\\nOct 1, 2021\\nIn Part 3 of the Transfer Learning series we have discussed the datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch. In this, article we will discuss theoretically about the VGG-16 and VGG-19 and in article 4.2 and 4.3 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:\\nbecominghuman.ai\\nFor the repository and document please follow below two mentioned links:\\nKeras:\\nkeras.io\\nPyTorch:\\npytorch.org\\nAlexNet came out in 2012 and it improved on the...  \n",
       "210  SyncedReview\\nMar 5, 2020\\nThis is an updated version.\\nIn a bid to help the global research community better understand the coronavirus, DeepMind today released the structure predictions for six proteins associated with SARS-CoV-2, the virus that causes COVID-19, using the most up-to-date version of their AlphaFold system.\\nAs the world struggles with the COVID-19 outbreak, one research team after another in the global scientific community has stepped up to offer expertise, tools and possible solutions. In the early stages of the outbreak front-line labs open-sourced genomes of the virus which enabled other researchers to rapidly develop tests around the pathogen. Other labs modelled the coronavirus infection peak or produced molecular structures to develop drug compounds and treatmen...  \n",
       "211  Towards Data Science\\nJan 11, 2019\\nIn this blog, we will discuss the workflow of a Machine learning project this includes all the steps required to build the proper machine learning project from scratch.\\nWe will also go over data pre-processing, data cleaning, feature exploration and feature engineering and show the impact that it has on Machine Learning Model Performance. We will also cover a couple of the pre-modelling steps that can help to improve the model performance.\\nPython Libraries that would be need to achieve the task: 1. Numpy 2. Pandas 3. Sci-kit Learn 4. Matplotlib\\nWe can define the machine learning workflow in 3 stages.\\nOkay but first let’s start from the basics\\nThe machine learning model is nothing but a piece of code; an engineer or data scientist makes it smart ...  \n",
       "212  May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...  \n",
       "213  Towards Data Science\\nJul 3, 2019\\nIn Part I of Multi-Class Metrics Made Simple, I explained precision and recall, and how to calculate them for a multi-class classifier. In this post I’ll explain another popular performance measure, the F1-score, or rather F1-scores, as there are at least 3 variants. I’ll explain why F1-scores are used, and how to calculate them in a multi-class setting.\\nBut first, a BIG FAT WARNING: F1-scores are widely used as a metric, but are often the wrong way to compare classifiers. You will often spot them in academic papers where researchers use a higher F1-score as “proof” that their model is better than a model with a lower score. However, a higher F1-score does not necessarily mean a better classifier. Use with care, and take F1 scores with a grain of sal...  \n",
       "214  Saúde Digital\\nJan 10, 2014\\nMuitas novidades foram apresentadas durante o congresso em Chicago. Muita inovação entre as aulas e sessões. Apresentações científicas com novas aplicações de conhecidas tecnologias e alguns novos protótipos. Diante de tanto conteúdo, seis dias passam rápido para quem gosta de tecnologia. Tentei elencar as cinco coisas mais bacanas que vi em termos de inovação e TI:\\n1. PACS 3.0\\nTermo repetido em inúmeras palestras. Ficou nítido que estamos diante de uma nova geração de PACS. Ferramentas de manipulação de imagens e workflow (manejo de worklists, aplicativos de laudo automatizados e reconhecimento de voz) já são considerados standart, e anualmente melhorados. As próximas versões de PACS, algumas já lançadas durante a feira, deverã...  \n",
       "215  Netflix TechBlog\\nMar 21, 2016\\nWe have a collection of nearly two million images that play very prominent roles in helping members pick what to watch. This blog describes how we use computer vision algorithms to address the challenges of focal point, text placement and image clustering at a large scale.\\nAll images have a region that is the most interesting (e.g. a character’s face, sharpest region, etc.) part of the image. In order to effectively render an image on a variety of canvases like a phone screen or TV, it is often required to display only the interesting region of the image and dynamically crop the rest of an image depending on the available real-estate and desired user experience. The goal of the focal point algorithm is to use a series of signals to identify the most int...  \n",
       "216  Towards Data Science\\nMar 5, 2019\\nHere’s something that might surprise you: neural networks aren’t that complicated! The term “neural network” gets used as a buzzword a lot, but in reality they’re often much simpler than people imagine.\\nThis post is intended for complete beginners and assumes ZERO prior knowledge of machine learning. We’ll understand how neural networks work while implementing one from scratch in Python.\\nLet’s get started!\\nNote: I recommend reading this post on victorzhou.com — much of the formatting in this post looks better there.\\nFirst, we have to talk about neurons, the basic unit of a neural network. A neuron takes inputs, does some math with them, and produces one output. Here’s what a 2-input neuron looks like:\\n3 things are happening here. First, each inpu...  \n",
       "217  Analytics Vidhya\\nJan 26, 2020\\nApplication to predict fruits using Mask_RCNN on custom dataset, this is a easy tutorial to how create a object detection application for a custom dataset, as a sample we are using a dataset of tropical fruits in this case only ( Oranges and Pineapple).\\nsource code in github : https://github.com/bernardcaldas/object-detection-custom-maskrcnn\\nin recent years we can see a lot applications in our life including, autonomous cars, facial detections app, education, military, finance etc.\\nInstance segmentation it's a task to identifying objects , detecting and delineating each distinct object of interest appearing in an image.\\nFollow the post created for Waleed Abdulla explaining how works Mask R-CNN one of the most used algorithm for image segmentation and...  \n",
       "218                                                                                                                                                                                                                                                                                                                                                                                                                                                   Nov 17, 2019\\nwww.tensorflow.org\\nLet’s get started!\\nIn the previous posting, we have finished two things, first, loading the dependent libraries to our workspace,\\n54 \\n54 \\n1\\nYdobon is nobody.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n85 Followers\\nYdobon is nobody.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "219  SyncedReview\\nJun 15, 2018\\nThe paper Relational inductive biases, deep learning, and graph networks, published last week on arXiv by researchers from DeepMind, Google Brain, MIT and University of Edinburgh, has stimulated discussion in the artificial intelligence community. The paper introduces a new machine learning framework called Graph Networks, which some believe promises huge potential for approaching the holy grail of artificial general intelligence.\\nDue to the development of big data and increasingly powerful computational resources over the past few years, modern AI technology — primarily deep learning — has show its prowess and even outsmarted humans in tasks such as image recognition and speech detection. However, AI remains challenged by tasks that involve complicated lea...  \n",
       "220  Towards Data Science\\nSep 15, 2015\\nData Science for Newbies (including me!)\\nI’ve studied math, I’ve studied computer science, and of course I’ve focused on machine learning algorithms. But I’m still new to the field of data science. I don’t know yet how or whether I can make an impact. But if I explain what it is, then people will know what I can do, what I could learn to do, and most importantly, what they can ask me to do. Here’s the primer.\\nThere are several types of machine learning algorithms, but my focus is on finding patterns in data. Those patterns could be entirely numerical, they could be graphical, or they could even be written out in words. Humans are very good at finding patterns, even going too far sometimes and making stereotypes. We’re at a point where many people j...  \n",
       "221  May 11, 2018\\nAdversarial attacks have been a concerning topic in the field of deep learning research in recent years. We’ve long since known that deep neural networks don’t generate perfect classification boundaries (this article in 2013. .. Yes, 2013 is a long time ago in fields related to deep learning.). Researchers have found numerous ways to generate adversarial examples to cause models to make mistakes (see e.g. this review paper and reference therein). This is obviously dangerous in commercial applications such as self-driving cars, automated robots, and other audio/visual recognition tasks. The vulnerability to adversarial examples is one of the major risks for applying deep neural networks in safety-critical scenarios.\\nBefore we go into our implementation, we need to categor...  \n",
       "222  Towards Data Science\\nJun 10, 2018\\nIf you want a computer to recognize text, neural networks (NN) are a good choice as they outperform all other approaches at the moment. The NN for such use-cases usually consists of convolutional layers (CNN) to extract a sequence of features and recurrent layers (RNN) to propagate information through this sequence. It outputs character-scores for each sequence-element, which simply is represented by a matrix. Now, there are two things we want to do with this matrix:\\nBoth tasks are achieved by the CTC operation. An overview of the handwriting recognition system is shown in Fig. 1.\\nLet’s have a closer look at the CTC operation and discuss how it works without hiding the clever ideas it is based on behind complicated formulas. At the end, I will poin...  \n",
       "223  agolo\\nApr 19, 2021\\nAutomatic text summarization is the task of automatically identifying the salient topics/key-phrases in a document(s) and then either generates or extracts a summary.\\nCurrently, most state-of-the-art summarizers are focused on single, short document summarization. Recent progress in summarization, mostly transformers-based, struggles with long inputs due to the architecture limitations, which have led many researchers to explore using new ideas like the longformer to overcome this issue. However, the final summaries are 5–10 sentences long that lacks coherence, and don’t give enough info about the original document. And of course, such methods can’t handle even tougher situations where the input is more than one long document. Similar observations could be found w...  \n",
       "224  Oct 22, 2019\\nThis guide assumes rudimentary knowledge of reinforcement learning and the structure of OpenAI Gym environments, along with proficiency in Python.\\nMany of the standard environments for evaluating continuous control reinforcement learning algorithms are built on the MuJoCo physics engine, a paid and licensed software. Bullet Physics provides a free and open source alternative to physics simulation with OpenAI Gym offering a set of environments built upon it. PyBullet is a library designed to provide Python bindings to the lower level C-API of Bullet. We will use PyBullet to design our own OpenAI Gym environments.\\nThis post will be the first of a two part series.\\nWe’ll go through building an environment step by step with enough explanations for you to learn how to indepe...  \n",
       "225  Towards Data Science\\nSep 17, 2018\\nIn Logistic Regression, we wish to model a dependent variable(Y) in terms of one or more independent variables(X). It is a method for classification. This algorithm is used for the dependent variable that is Categorical. Y is modeled using a function that gives output between 0 and 1 for all values of X. In Logistic Regression, the Sigmoid (aka Logistic) Function is used.\\nAfter we train a logistic regression model on some training data, we will evaluate the performance of the model on some test data. For this, we use the Confusion Matrix. A Confusion Matrix is a table that is often used to describe the performance of the classification model on a set of test data for which the true values are already known. Given below is a Confusion Matrix.\\nHere, ...  \n",
       "226  Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...  \n",
       "227  Inside Machine learning\\nJan 4, 2019\\nNew deep learning models are introduced at an increasing rate and sometimes it’s hard to keep track of all the novelties. That said, one particular neural network model has proven to be especially effective for common natural language processing tasks. The model is called a Transformer and it makes use of several methods and mechanisms that I’ll introduce here. The papers I refer to in the post offer a more detailed and quantitative description.\\nThe paper ‘Attention Is All You Need’ describes transformers and what is called a sequence-to-sequence architecture. Sequence-to-Sequence (or Seq2Seq) is a neural net that transforms a given sequence of elements, such as the sequence of words in a sentence, into another sequence. (Well, this might not surp...  \n",
       "228  SyncedReview\\nSep 18, 2019\\nWave function represents the quantum state of an atom, including the position and movement states of the nucleus and electrons. For decades researchers have struggled to determine the exact wave function when analyzing a normal chemical molecule system, which has its nuclear position fixed and electrons spinning. Fixing wave function has proven problematic even with help from the Schrödinger equation.\\nPrevious research in this field used a Slater-Jastrow Ansatz application of quantum Monte Carlo (QMC) methods, which takes a linear combination of Slater determinants and adds the Jastrow multiplicative term to capture the close-range correlations.\\nNow, a group of DeepMind researchers have brought QMC to a higher level with the Fermionic Neural Network — or ...  \n",
       "229  Towards Data Science\\nJul 13, 2020\\nToday’s data comes in all shapes and sizes. NLP data encompasses the written word, time-series data tracks sequential data movement over time (ie. stocks), structured data which allows computers to learn by example, and unclassified data allows the computer to apply structure. Whichever dataset you possess, you can be sure there is an algorithm ready to decipher its secrets. In this article, we want to cover a clustering algorithm named KMeans which attempts to uncover hidden subgroups hiding in your dataset. Furthermore, we will examine what effects dimension reduction has on the quality of the clusters obtained from KMeans.\\nIn our example, we will be examining a human resources dataset consisting of 15,000 individual employees. The dataset contain...  \n",
       "230  Technology, Invention, App, and More\\nDec 28, 2015\\nThe year 2015 was a monumental year in the field of artificial intelligence. Not only are computers learning more and learning faster, but we’re learning more about how to improve their systems. Everything is starting to align, and because of it we’re seeing strides we’ve never thought possible until now. We have programs that can tell stories about pictures. We have cars that are driving themselves. We even have programs that create art. If you want to read more about advancements in 2015, read this article. Here at Josh.ai, with AI technology becoming the core of just about everything we do, we think it’s important to understand some of the common terminology and to get a rough idea of how it all works.\\nA lot of the advances in art...  \n",
       "231  Towards Data Science\\nFeb 12, 2021\\nExcitement is building in the artificial intelligence community around MIT’s recent release of liquid neural networks. The breakthroughs that Hasani and team have made are incredible.\\nLet’s dive in.\\nArtificial intelligence research and applications involve the construction and training of deep neural networks. Until liquid neural networks, all deep learning systems have shared the same vulnerability — namely, that they learn a fixed mapping from input data to output prediction based on the training data that they are shown, making them brittle to the shifting environment around them. Furthermore, most deep learning models are context independent. For example, when applying an object detection model or a classification model to a video, the video wi...  \n",
       "232  Dec 19, 2016\\nWhen we offered CS231n (Deep Learning class) at Stanford, we intentionally designed the programming assignments to include explicit calculations involved in backpropagation on the lowest level. The students had to implement the forward and the backward pass of each layer in raw numpy. Inevitably, some students complained on the class message boards:\\n“Why do we have to write the backward pass when frameworks in the real world, such as TensorFlow, compute them for you automatically?”\\nThis is seemingly a perfectly sensible appeal - if you’re never going to write backward passes once the class is over, why practice writing them? Are we just torturing the students for our own amusement? Some easy answers could make arguments along the lines of “it’s worth knowing what’s unde...  \n",
       "233                                                      Nov 7, 2013\\nMachine learning (ML) is one of the hottest fields in data science. As soon as ML entered the mainstream through Amazon, Netflix, and Facebook people have been giddy about what they can learn from their data. However, modern machine learning (i.e. not the theoretical statistical learning that emerged in the...\\n275 \\n275 \\n2\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n548 Followers\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "234  Towards Data Science\\nJun 7, 2019\\nIn this tutorial, I will quickly go through the details of four of the famous CNN architectures and how they differ from each other by explaining their W3H (When, Why, What, and How)\\nWhen?\\nWhy? AlexNet was born out of the need to improve the results of the ImageNet challenge. This was one of the first Deep convolutional networks to achieve considerable accuracy on the 2012 ImageNet LSVRC-2012 challenge with an accuracy of 84.7% as compared to the second-best with an accuracy of 73.8%. The idea of spatial correlation in an image frame was explored using convolutional layers and receptive fields.\\nWhat? The network consists of 5 Convolutional (CONV) layers and 3 Fully Connected (FC) layers. The activation used is the Rectified Linear Unit (ReLU). The ...  \n",
       "235  Towards Data Science\\nSep 3, 2019\\nPlease consider using the Simple Transformers library as it is easy to use, feature-packed, and regularly updated. The article still stands as a reference to BERT models and is likely to be helpful with understanding how BERT works. However, Simple Transformers offers a lot more features, much more straightforward tuning options, all the while being quick and easy to use! The links below should help you get started quickly.\\nThe Pytorch-Transformers (now Transformers) library has moved on quite a bit since this article was written. I recommend using SimpleTransformers as it is kept up to date with the Transformers library and is significantly more user-friendly. While the ideas and concepts in this article still stand, the code and the Github repo are...  \n",
       "236  Dec 28, 2019\\nObject detection has been quite a center of attraction nowadays because of its wide range of applications and advancements in Deep Learning technology. Object Detection is a subdomain of image processing and computer vision that deals with identifying and localizing objects in videos or digital images. The credit for the evolution of object detection goes to the breakthrough in deep learning classification algorithms called CNN- Convolutional Neural Network and Graphic Processing Units that have shown great leads in the development of real-world solutions for computer vision problems like autonomous driving car, face detection and recognition, people detection, and tracking, video surveillance, security system design, etc.\\nObject detection can be done either using machin...  \n",
       "237  Towards Data Science\\nApr 2, 2018\\nIn this post I reproduce two recent papers in the field of metalearning: MAML and the similar Reptile. The full notebook for this reproduction can be found here.\\nThe goal of both of these papers is to solve the K-shot learning problem. In K-shot learning, we need to train a neural network to generalize based on a very small number of examples (often on the order of 10 or so) instead of the often thousands of examples we see in datasets like ImageNet.\\nHowever, in preparation for K-shot learning, you are allowed to train on many similar K-shot problems to learn the best way to generalize based on only K examples.\\nThis is learning to learn or metalearning. We have already seen metalearning in my post on “Learning to Learn by Gradient Descent by Gradie...  \n",
       "238  Nov 20, 2020\\n今年人工智慧年會中,偶然聽到講師呼籲大家,都2020了,不要再用Adam了,請改用Ranger,因此著手來寫一篇Ranger的筆記。\\n今年有兩篇優化器相關的論文被提出,分別是LookAhead和RAdam,這兩種方法用不同角度對深度學習的優化做改進,後來研究員 Less Wright將兩個方法整合成一個新的優化器:Ranger,得到了更好的成果。\\n廢話不多說,先上PyTorch實現的GitHub:https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\\n要了解RAdam 和 LookAhead 是如何互補的,需要先分別討論他們的概念。\\n全名是Rectified Adam,白話地說,就是自動熱身(warmup)版的Adam。\\n概念\\nAdam是一種常用的自適應學習率 (adptive learning rate) 優化器,但類方法在訓練的初期,adptive learning rate的變異非常大,然後在少量的數據進行過度跳躍,下了錯誤決策,就容易收斂在local minimum。\\n為了解決這個問題,RAdam根據adaptive rate的變異程度去修正learning rate,讓Adam可以自動熱身,不需再手動調整,也避免模型收斂在local minimum。\\n概念是這樣:有個熱身用的開關,閥值為rho,這個rho代表adpative learning rate分配的自由度:\\n優點\\n如此的做法,讓RAdam在享有Adam快速收斂優勢的同時,又達到跟SGD差不多好的收斂結果。RAdam詳細概念可以參考我寫的另一篇文章:https://is.gd/2yxrE7。\\n2020由深度學習教父Geoffrey Hinton團隊發表的論文,LookAhead基於損失空...  \n",
       "239  Towards Data Science\\nMar 20, 2019\\nAbbreviations using in this post:\\nIn my previous post, we discussed about Linear Regression. Let’s take a look back. Linear Regression is applied for the data set that their values are linear as below example:\\nAnd real life is not that simple, especially when you observe from many different companies in different industries. Salary of 1 YE teacher is different from 1 YE engineer; even 1 YE civil engineer is different from mechanical engineer; and if you compare 2 mechanical engineers from 2 different companies, their salary mostly different as well. So how can we predict the salary of a candidate?\\nToday, we will use another data set to represent the Polynomial shape.\\nTo get an overview of the increment of salary, let’s visualize the data set into...  \n",
       "240  Apr 22, 2019\\nI was supposed to Install Linux in my PC which is having a storage of 500GB with Windows in it ,So as a regular Linux installation procedure I unallocated 60GB and started to install the linux OS during the installation I found something fishy ,The Unallocated space was not showing up as a free space to install the Operating System ,I was like What the heck is this as usual Searched this issue in the Internet and discussed it with my techie friends all they told is “YOU HAVE TO CONVERT GPT TO MBR” and they suggested me some tools too like MINITOOL PARTITION WIZARD,ES PARTITION MASTER but everything ended up in Popping up for PREMIUM ACCESS to perform the particular action .It again started to irritate me a lot , I restarted my Computer several times again and again and en...  \n",
       "241  Towards Data Science\\nSep 25, 2018\\nWhen working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier. The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\\nThis is what we are going to do today: use everything that we have presented about text classification in the previous articles (and more) and comparing between the tex...  \n",
       "242                                                                                                                                                                                                                                       AI3 | Theory, Practice, Business\\nFeb 24, 2020\\nWelcome back to my blog for engineers who want to learn AI!\\nStarting with this post, we’ll be launching into a new series of articles on pre-training in NLP. Today, we’ll begin by forming a big picture.\\n394 \\n394 \\nThe AI revolution is here! Navigate the ever changing industry with our thoughtfully written articles whether your a researcher, engineer, or entrepreneur\\n298 Followers\\nNLP Engineer, Google Developer Expert, AI Specialist in Yodo1\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "243  Towards Data Science\\nMar 11, 2021\\nYou must definitely have encountered the problem when training a model is getting slower for a very Deep Neural Network. This phenomenon happens prominently during the backpropagation training (using Gradient Descent) of the DNNs, wherein, each parameter’s gradient error is propagated along its way to the lower layers of the network. Why? This usually happens because gradients usually get smaller and smaller. As a result, the lower layers weights never change and training never converges to the good solution.\\nThis post categorically discuss about the ways to alleviate the Vanishing Gradient (or the Exploding Gradient) problem while training the DNNs\\nThere are various ways to overcome this challenge —\\nLet’s look into all these in detail...\\nWe know...  \n",
       "244  Towards Data Science\\nNov 18, 2021\\n“Symmetry, as wide or as narrow as you may define its meaning, is one idea by which man through the ages has tried to comprehend and create order, beauty, and perfection.”\\nThis somewhat poetic description by Hermann Weyl [1] underlines the cornerstone role of symmetry in science. Felix Klein’s 1872 “Erlangen Programme” [2] characterised geometries through symmetry groups. Not only was this a breakthrough in mathematics, unifying the “zoo of geometries,” but also led to the development of modern physical theories that can be entirely derived from the first principles of symmetry [3]. Similar principles have emerged in machine learning under the umbrella of Geometric Deep Learning, a general blueprint for deriving the majority of popular neural networ...  \n",
       "245  Jun 14, 2020\\nDisclaimer: This project was developed by Kaspar Hollo and Nurlan Kerimov for the Neural Networks course at the University of Tartu. The data and the code used in this project are not public and, in this blog-post only a few examples from the dataset will be shown. The data was provided by PerkinElmer.\\nNowadays, microscopy images are often used for doing medical diagnosis. For example, in this paper, a deep learning model was developed to count mitotic cells to help diagnose breast cancer. There is a problem though — the captured microscopy images may contain some so-called anomalies which can be considered as noise. It is found that the cell count and position predictions (cell segmentation) are performing badly in areas with anomalies. In our project, we tried to predi...  \n",
       "246  Towards Data Science\\nJul 10, 2018\\nNeural networks (NN) consisting of convolutional NN layers and recurrent NN layers combined with a final connectionist temporal classification (CTC) layer are a good choice for (handwritten) text recognition.\\nThe output of the NN is a matrix containing character-probabilities for each time-step (horizontal position), an example is shown in Fig 1. This matrix must be decoded to get the final text. One algorithm to achieve this is beam search decoding which can easily integrate a character-level language model.\\nWe will start our discussion with a recap of CTC and best path decoding. Then we will discuss the building blocks (basic algorithm, CTC scoring, language model) of the CTC beam search decoding algorithm. Finally, I will point you to a Python i...  \n",
       "247  Towards Data Science\\nMay 10, 2021\\nAs advances in AI continue to progress in leaps and bounds, accessibility to data science at a base level has become increasingly democratized. Traditional entry barriers to the field such as a lack of data and computing power have been swept aside with a continuous supply of new data startups popping up(some offering access for as little as a cup of coffee a day) and all powerful cloud computing removing the need for expensive onsite hardware. Rounding out the trinity of prerequisites, is the skill and know-how to implement, which has arguably become the most ubiquitous aspect of data science. One does not need to look far to find online tutorials touting taglines like “implement X model in seconds” , “apply Z method to your data in just a few lines...  \n",
       "248  Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...  \n",
       "249  Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...  \n",
       "250  Jan 8, 2016\\n*On a personal note, before reading this article take a deep breath and relax yourself. In this article, you will neither hear any neighbor’s aunties gossiping ills about you nor see your parents hesitations when you say something cause you are wearing a dropout tag that isn’t sugar coated. This is an article on the bright side of the moon about how I get the inspiration to ultimately drop out.\\nThis moment in my life about a year ago I got the ultimate boredom to drop out of my class to do something of my own that I am really passionate about. Everyone in the class was doing the same thing, solving Irodov’s problems where the task itself would be a terror for every country’s layman and more importantly, till now I don’t find any usefulness of that things beside teaching t...  \n",
       "251  Towards Data Science\\nMar 29, 2019\\nI assume you are already familiar with Recurrent Neural Networks (including the seq2seq encoder-decoder architecture).\\nIn the encoder-decoder architecture, the complete sequence of information must be captured by a single vector. This poses problems in holding on to information at the beginning of the sequence and encoding long-range dependencies.\\nThe core idea of attention is to focus on the most relevant parts of the input sequence for each output. By providing a direct path to the inputs, attention also helps to alleviate the vanishing gradient problem.\\nAssume you have a sequential decoder, but in addition to the previous cell’s output and hidden state, you also feed in a context vector c.\\nWhere c is a weighted sum of the encoder hidden states...  \n",
       "252  Supervisely\\nMay 2, 2017\\n“What movie should i watch this evening?” — have you ever had to answer this question at least once when you came home from work? As for us — yes, and more than once. Here we will say a few words about what we’ve been working on for the past six months: an interactive movie recommender system Movix.ai. The system is based on Deep Learning and it adapts to the user preferences in real time. As big movie fans we felt the need for such a service, and we believe that it will be useful for every movie lover.\\nAt Deep Systems we are engaged in creating solutions and products based on machine learning and Deep Learning. Among our projects: developing a “mind” for self-driving car prototype and automatic defects detection for roads and airport runways. The important p...  \n",
       "253  Towards Data Science\\nSep 18, 2018\\nMachine learning on graphs is a difficult task due to the highly complex, but also informative graph structure. This post is the first in a series on how to do deep learning on graphs with Graph Convolutional Networks (GCNs), a powerful type of neural network designed to work directly on graphs and leverage their structural information. The posts in the series are:\\nIn this post, I will give an introduction to GCNs and illustrate how information is propagated through the hidden layers of a GCN using coding examples. We’ll see how the GCN aggregates information from the previous layers and how this mechanism produces useful feature representations of nodes in graphs.\\nGCNs are a very powerful neural network architecture for machine learning on graphs....  \n",
       "254  Towards Data Science\\nFeb 8, 2021\\nFirst, tell me, please, what is fiction and what is reality — in the context of Generative Adversarial Networks?\\nWe’ve seen a lot of things, which hadn’t existed before its AI-driven creation. Sure, the GAN-generated images in This Person Does Not Exist or This Artwork Does Not Exist have no direct reference in the material world — they are products of knowledge and AI models training. But being transported into our world, they might get their own story, specific meaning, and particular use, leaving the Latent Space and become more real than fiction.\\nIndeed, you can use them for making movies; you also can generate fraud and fakes. AI is not to blame for misuse, but us, humans. You cannot fix society by breaking technology.\\nNevertheless, in Digital...  \n",
       "255  Feb 2, 2020\\nこの記事は、EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNetを提案した2020/1/17投稿の論文””Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network [1]の解説記事です。\\nこの記事では以下のこと説明します。\\nこの論文のサマリは以下のような感じです。\\n既存のあらゆるテクニックを組み合わせて、EfficientNet B6+AutoAugと同等程度の精度で5倍早いネットワークを構築した研究。著者たちがいうにはAugMix等の最新のものはここでは使ってないので、まだ精度があがる可能性があるとのこと。\\nここでは、Assemble-ResNetのベースライン比較となっているEfficientNet+AutoAugmentの解説をします。EfficientNetは2019年に発表された既存のネットワークより大幅に軽くて高精度なネットワークです。AutoAugmentは2018年に発表された論文で、最適なデータ拡張を自動で探索する研究です。どちらも画像認識では頻繁にベースラインとして登場する強力な手法です。\\nEfficientNet[2]は2019/5/28に投稿された論文で、それまでの既存のネットワークより高速で高精度なネットワークです。論文の内容をまとめると下記のような感じです。今まで成されていなかった解像度・深さ・チャネル数を同時に最適化することによって、高速かつ高精度なネットワークを構築。式3におけるφ=1にしてMnasNetの探索空間でαβγを最適化(B0)、後にφを変...  \n",
       "256  Towards Data Science\\nJun 5, 2018\\nIf you are like me bothered by “regression” in “logistic regression” which realistically should be called “logistic classification”, considering it does classification, I have an answer for your botheration!\\nLogistic regression is useful for situations where there could be an ability to predict the presence or absence of a characteristic or outcome, based on values of a set of predictor variables. It is similar to a linear regression model but is suited to models where the dependent variable is dichotomous. It’s coefficients can be used to estimate odd ratios for each of the independent variables in the model. It is applicable to a broader range of research situations than discriminant analysis. Logistic Regression on the other hand is used to ascert...  \n",
       "257  DataThings\\nFeb 6, 2019\\nAlthough artificial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. Meta-learning aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning algorithm.\\nArtificial intelligence and machine learning are currently extremely fashionable. In recent years, this technology has left the ...  \n",
       "258  Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...  \n",
       "259  程式設計之旅\\nSep 22, 2019\\n簡單回顧\\n在ML入門(五)Linear Regression有介紹什麼是Gradient Descent,就是對loss function做偏微分(切線斜率)就是找極大極小值的概念,找一組參數讓loss function越小越好。在ML入門(五)Linear Regression,我們要更新的是w, b,在這邊用一個theta表示。\\nGradient Descent如何運行\\n這邊可以搭配公式一起看,紅色箭頭就是loss function的gradient方向,當乘上learning rate後再乘上負號(改變方向)就會變成藍色箭頭,一直重複這樣的動作,這就是Gradient Descent的運行模式。\\nLearning Rate對 Loss Function的影響\\n調整learning rate的方法\\n既然learning rate有時候不是太大不然就是太小,是不是有什麼方法可以來讓機器自己調整。當一開始起始點離最低點還很遠的時候,learning rate可以大一點;當越來越接近最低點時,learning rate要小一點,這樣才能收斂在最低點附近。下面那張圖所示,假設定義learning rate是每次跟著更新次數做調整,也就是說你的更新次數越多,learning rate會跟次數的開根號成反比,learning rate會越小。那有人就覺得說可以根據不同參數調整不同的learning rate,以下會列出幾種方法:\\n現在對於每一個參數w都要給一個不同的η,就是每次更新的η就是等於前一次的η再除以σ^t,而 σ^t則代表的是第 t 次以前的所有梯度更新值之平方和開根號(root mean square),而ε只是為了不讓分母為0而加上去的值。\\n下面圖中的式子可以清楚看出,分子的部分(紅色框框)顯示,當g...  \n",
       "260  Oct 26, 2015\\nThis article’s title is even a surprise to me. This is not something that I expected to write and you’re probably wondering what happened to all that advice about “you grow your wings on your way down”. I know, but this is the kind of theme that creates a lot of fuss by itself and a lot of irresponsible advice is given.\\nHere I will clarify my position on pursuing an academic career and how is the life of a college drop out.\\nI’ve always been a decent student, I always knew that I could be one of the top students in the class, but I never felt like going after that status. Video games always seemed more interesting than boring themes with zero practical implication. So school never presented itself as a challenge when it came to studying. Even in college I pass at every s...  \n",
       "261  Voice Tech Podcast\\nApr 1, 2019\\nIn the recent years, information grows rapidly along with the development of social media. With the increasing amount of information, it takes more effort and time to review the entire text document and understand its contents. One possible solution to the above problem is to read the summary of the document. The summary will not only retain the essence of the document, but will also save a lot of time and effort. An effective summary of the document will concise and fluent while preserving key information and overall meaning.\\nThere are two major text summarization approaches, abstractive and extractive summarization. The approach of Abstractive summarization selects words on the basis of semantic understanding, and even includes those words which do n...  \n",
       "262  JavaScript Scene\\nDec 31, 2020\\nHappy New Year! It’s time to review the big trends in JavaScript and technology in 2020 and consider our momentum going into 2021.\\nOur aim is to highlight the learning topics and technologies with the highest potential job ROI. This is not about which ones are best, but which ones have the most potential to land you (or keep you in) a great job in 2021. We’ll also look at some larger tech trends towards the end.\\nJavaScript still reigns supreme on GitHub and Stack Overflow. Tip #1: Learn JavaScript, and in particular, learn functional programming in JavaScript. Most of JavaScript’s top frameworks, including React, Redux, Lodash, and Ramda, are grounded in functional programming concepts.\\nTypeScript jumped past PHP, and C# into 4th place, behind only Ja...  \n",
       "263  Level Up Coding\\nJun 25, 2020\\nDo you want to try some other methods to solve your forecasting problem rather than traditional regression? There are many neural network architectures, which are frequently applied in NLP field, can be used for time series as well. In this article, we are going to build two Seq2Seq Models in Keras, the simple Seq2Seq LSTM Model, and the Seq2Seq LSTM Model with Luong Attention, and compare their forecasting accuracy.\\nFirst of all, let’s create some time series data.\\nWe’ve just created two sequences, x1 and x2, by combining sin waves, trend, and random noise. Next we will preprocess x1 and x2.\\nSince the sequence length is n_ = 1000, the first 800 data points will be used as our train data, while the rest will be used as our test data.\\nIt is not a must ...  \n",
       "264                                                                                                                                                Banapana\\nJan 4, 2008\\nDasher is a novel piece of software that lets you point at what you want to write. Honestly, it’s kind of difficult to describe without [seeing the demonstration](http://www.youtube.com/watch?v=0d6yIquOKQ0). It’s very novel and makes novel use of some simple AI. I wonder if Apple would ever integrate this in to the iPhone? And it would seem to be of great use were it to be integrated into eye tracking software.\\nOur Minds on Media\\n86 Followers\\nWriter of story, poetry and code. Currently attempting to illustrate one Ism a day — https://ismisms.tumblr.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "265  Becoming Human: Artificial Intelligence Magazine\\nMar 28, 2017\\nPython notebook, using Keras library, available on this GitHub repo.\\nA common way to solve a complex computing task is to chain together specialized components. In data-science this is the pipeline approach. Each component mostly treats the other components as I/O black-boxes. As developers we potentially have the full picture but the system does not.\\nWith Neural Network what happens between I and O is often too interesting to be ignored. One Neural Network can leverage the way another Neural Network processes its inputs.\\nIn this post I discuss the following scenario :\\nTo “understand” english is necessary to analyse news. Thus during training a standalone ’N’ NeuralNet would learn about the semantics of english as a by...  \n",
       "266  Kredo.ai Engineering\\nDec 8, 2017\\nMotivation for writing blog series on AI + Robotic Operating Systems:\\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\\nROS is used to create application for a physical robot without depending on the actual machine, thus saving cost and time. These applications can be transferred onto the physical robot without modifications.\\nThe decision making capability of the robots can be aided with AI. The cases where the robot agent has to learn optimal strategies in high dimensional state space often means that it is impractical to generate sufficient...  \n",
       "267  Towards Data Science\\nJul 16, 2018\\nClustering unsupervised data is not an easy task. Indeed, data crunching and exploration is in such a context often driven by domain knowledge, if not pure intuition, and made difficult as there is no way to measure the accuracy of the resulting segmentation (as opposed to supervised learning).\\nIn addition, introductory courses to unsupervised learning quite often discuss ideal use cases, such as k-means tutorials, which only apply to numerical features.\\nHowever, real business situations often deviate from these ideal use cases, and need to analyze datasets made of mixed-type data, where numeric (the difference between two values is meaningful), nominal (categorical, not ordered) or ordinal (categorical, ordered) features coexist.\\nIn this post, I’...  \n",
       "268  Jul 31, 2017\\nThis article is about different ways of regularizing regressions. In the context of classification, we might use logistic regression but these ideas apply just as well to any kind of regression or GLM.\\nWith binary logistic regression, the goal is to find a way to separate your two classes. There are a number of ways of visualizing this.\\nNo matter which of these you choose to think of, we can agree logistic regression defines a decision rule\\nh(x|theta) = sigmoid(x dot theta + b)\\nand seeks a theta which minimizes some objective function, usually\\nloss(theta)= ∑ y*log(h(x|theta)) + (1−y)log(1−h(x|theta))\\nwhich is obfuscated by a couple clever tricks. It is derived from the intuitive objective function:\\nloss(theta)= ∑ (y - h(x|theta))\\ni.e. the number of misclassified x...  \n",
       "269  May 7, 2018\\nThis blog post aims to provide readers some insights on deep neural networks and intuition about dropout technique.\\nDeep neural networks are models composed of multiple layers of simple, non-linear neurons. With composition of enough neurons, the model can learn extremely complex functions that can accurately perform complicated tasks that are impossibly difficult to hard code, such as image classification, translation, speech recognition, etc. The key aspect of deep neural networks is that they are able to automatically learn data representation needed for features detection or classification without any a priori knowledge1.\\nFor example, VGG16 (shown below) is a convolutional neural network that is trained on ImageNet Large Scale Visual Recognition Competition (ILSVRC) ...  \n",
       "270  Towards Data Science\\nMay 22, 2019\\nDealing with extreme event prediction is a frequent nightmare for every Data Scientist. Looking around I found very interesting resources that deal with this problem. Personally, I literally fall in love with the approach released by Uber Researchers. In their papers (two versions are available here and here) they developed an ML solution for daily future prediction of traveler demand. Their methodology stole my attention for its geniality, good explanation, and easy implementation. So my purpose is to reproduce their discovery in pythonic language. I’m very satisfied with this challenge and in the end, I improved my knowledge of regression forecasting.\\nThe most important takeaways from this post can be summarized as:\\nBut Keep Kalm and let’s procee...  \n",
       "271  Towards Data Science\\nOct 12, 2018\\nIn computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\\nFuzzy string search can be used in various applications, such as:\\nSpeaking of dedupe, it may not as easy as it sounds, in particular if you have hundred thousands of records. Even Expedia does not make it 100% right:\\nThis post will explain what fuzzy string matching is together with its use cases and give examples using Python’s Fuzzywuzzy library.\\nEach hotel has its own nomenclature to name its rooms, the sam...  \n",
       "272  Jan 11, 2013\\nSocial media can be hard to control. From small and medium-sized businesses lacking additional manpower to large companies requiring a method for scheduling numerous team members, we decided to create a tool that will add additional value to social media efforts.\\nSocial Defender provides real-time social media monitoring, insights and gives the ability to accurately moderate social media efforts and understand customer sentiment.\\nBy using the tool, businesses can manage multiple social media networks including Facebook, Twitter, Tumblr, YouTube, G+, blogs and forums using just one login. This social media management tool gives businesses the ability to analyze what is being said online about a brand, service, industry, and competitors. Analytics provided by Social Defen...  \n",
       "273  Towards Data Science\\nAug 18, 2021\\nI am sure you read about AlphaFold in late 2020 when it “won” the CASP14 “contest” on modeling protein structures, and in July 2021 when the peer-reviewed paper and AI model were released. If not, or if you want to refresh what protein structures are, why biologists prayed for decades for programs to accurately predict them, and how AlphaFold works and performs, then check this story and this one, then come back here.\\nThis new story brings you the latest news, based on a just-published preprint.\\nTable of contents\\nThis story is based on a preprint just posted in the bioRxiv that formally describes a tool dubbed ColabFold under the moto Making protein folding accessible to all (which I would have rather phrased Making modern protein structure modeli...  \n",
       "274  Jul 4, 2020\\nAssume you have an image I and an image database X containing thousands of other images. You want to find a subset S⊆X containing images that are most similar to I. This is a task called image retrieval. However, before solving this, you may ask yourself, what is the meaning of similar images? Is it based on the colors in the images? Or maybe the content? In the second case, two images containing dogs could be considered similar regardless of their breed, which obviously may have different colors. In this post, I will describe a simple implementation of this. The implementation is based on neural networks and is done by comparing the similarity between the embeddings of the two images.\\nGiven a query image I, I extract the features using VGG-19 and use the output of the fi...  \n",
       "275  Towards Data Science\\nApr 9, 2020\\nMovies are more than just blockbusters hit with explosions and superpowers, it’s the main idea behind the movie that changes people and injects a notion in the viewer’s head.\\nTo illustrate, the movie Joker wasn’t a hero vs villain film, fighting with superpowers and wreaking havoc on New York City. It portrayed how there is a distinct chasm between the rich and the poor, the lucky and the unlucky, and how mental illness can distort a person’s morality and value system.\\nSo, movies are more than just an activity for enjoyment and amusement, it plays an imperative role in shaping our view on the world and communal consciousness.\\nIn short, movies educate people and spread ideas in ways a paperback book early does today.\\nOne reason for the effectivenes...  \n",
       "276  Jul 31, 2017\\nWhen I first noticed the Kaggle competition: “Planet: Understanding the Amazon from space” I was immediately thinking of trying out Transfer Learning using a pre-trained model. I had never really played with Transfer Learning before so I thought this would be a good one to try it out on. Transfer Learning is described by Wikipedia as:\\n“a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem”\\nwhere in this case the ‘relatedness’ of the problem is that both the Kaggle competition and the pre-trained model(s) are addressing computer vision problems. For more information on Transfer Learning there is a good resource from Stanfords CS class and a fun blog by Sebastian Ruder.\\...  \n",
       "277  Analytics Vidhya\\nJan 25, 2021\\nDuring my first ever data science internship, I was given a seemingly simple task to find clusters within a dataset. Given my basic knowledge of clustering algorithms like K-Means, DBSCAN, and GMM I thought that I could easily get this task done. However, as I took a closer look into the dataset, I realized the data contained a mixture of categorical and continuous data, and many common methods of clustering I knew would not easily work.\\nCategorical data consists of multiple discrete categories that commonly do not have any clear order or relationship to each-other. This data might look like “Android” or “iOS”.\\nContinuous data consists of real numbers that can take any value. This data might look like “3.14159” or “43\".\\nMany datasets contain a mixture...  \n",
       "278                                                                                                                       Analytics Vidhya\\nJan 23, 2020\\nFaster R-CNN is an object detection architecture presented by Ross Girshick, Shaoqing Ren, Kaiming He and Jian Sun in 2015, and is one of the famous object detection architectures that uses convolution neural networks.It detects and classifies objects in an image as shown below:\\nBefore diving into Faster R-CNN let’s learn about R-CNN, Fast R-CNN and RPN which are the building blocks...\\n303 \\n303 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n24 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "279  mutsuda\\nMar 22, 2012\\nFa dos anys, a l’assignatura d’AIA (Aplicacions de la Intel·ligència Artificial), ens van fer implementar un sistema intel·ligent que dominaria tot el procés de depuració d’aigua de Catalunya. Les diferents plantes havien de ser intel·ligents i tenir suficient coneixement del seu entorn com per decidir, entre elles, de quina manera actuar en cas de detecció d’un contaminant, pluja torrencial, etc. Elles soles decidien mitjançant diverses polítiques què fer en cadascuna de les situacions per tal de resoldre els problemes.\\nLes plantes entre si es comunicaven mitjançant missatges en format d’ontologia, que ve a ser una representació lògica del context en què s’està treballant. En aquest cas l’ontologia contenia informació sobre els tòxics, l’aigua, ai...  \n",
       "280  Towards Data Science\\nApr 26, 2020\\nHundreds of books are now free to download\\nSpringer has released hundreds of free books on a wide range of topics to the general public. The list, which includes 408 books in total, covers a wide range of scientific and technological topics. In order to save you some time, I have created one list of all the books (65 in number) that are relevant to the data and Machine Learning field.\\nAmong the books, you will find those dealing with the mathematical side of the domain (Algebra, Statistics, and more), along with more advanced books on Deep Learning and other advanced topics. You also could find some good books in various programming languages such as Python, R, and MATLAB, etc.\\nIf you are looking for more recommended books about Machine Learning a...  \n",
       "281  Towards Data Science\\nJan 17, 2018\\nThere are several time-series forecasting techniques like auto regression (AR) models, moving average (MA) models, Holt-winters, ARIMA etc., to name a few. So, what is the need for yet another model like LSTM-RNN to forecast time-series? This is quite a valid question to begin with and here are the reasons that I could come up with (respond below if you are aware of more, I will be curious to know)—\\nOn the other hand, there are the usual downsides that one needs to be careful about, while using LSTM’s (or any DNN architectures for that matter) — requirement of lots of data, multiple hyper-parameters to be tuned etc., I also came across few articles that mentioned that LSTM’s are not supposedly good at auto regression type of series. So take this wit...  \n",
       "282  Towards Data Science\\nMay 12, 2020\\nKeras provides a set of deep learning models that are made available alongside pre-trained weights on ImageNet dataset. These models can be used for prediction, feature extraction, and fine-tuning. Here I’m going to discuss how to extract features, visualize filters and feature maps for the pretrained models VGG16 and VGG19 for a given image.\\nHere we first import the VGG16 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG16 model. The numpy module is imported for array-processing. Then the VGG16 model is loaded with the pretrained weights for the imagenet dataset. VGG16 model is a series of convolutional layers followed ...  \n",
       "283  Taiwan AI Academy\\nApr 28, 2020\\n說到近年來最火紅以深度學習為主的生成模型,大家必定會想到生成對抗網路(Generative Adversarial Network, GAN),然而在GAN(2014)還沒被提出來之前,有另外一個同樣屬於生成模型的Variational AutoEnoder (VAE)常被大家所使用,很可惜的是當時GAN在許多任務上所產生的圖片清晰度較高,因此VAE類型的模型相對而言就勢弱了一些(當然GAN在訓練的特性上有一些難以克服的問題至今也尚未完全解決)。\\n故事總不會就這樣結束,2017年DeepMind在NIPS研討會上提出了Vector-Quantized Variational AutoEncoder模型,雖然在效果上仍然是先與VAE做比較,但VQ-VAE提出的概念讓它擁有比其它生成模型更獨特的地方,甚至在後續2019年6月提出的VQ-VAE2甚至宣稱在生成1024*1024的高解析度人臉時與當時效果最佳的BigGAN可作比擬。如果你開始對VQ-VAE感到好奇,就跟著我們一起看下去吧。\\n註1:如果你對Variational AutoEncoder甚至是AutoEncoder的概念還沒那麼熟的話,可以參考此篇AutoEncoder介紹、此篇VAE介紹、或是尋找其他資源唷。\\n我們可以這樣解讀AutoEncoder家族在做的事情,Encoder試圖找出輸入圖片x在潛在空間上的表徵(representation),在大多數的狀況中,大家使用連續型的分布去模擬z的樣貌(e.g. AE將輸入x投影至潛在空間的一個點;VAE則改為使用高斯分布模擬輸入x在潛在空間的樣貌),然而VQVAE的作者提到離散的潛在表徵在很多情境上也許才是比較適合的,例如語言概念,因此VQ-VAE主要的突破就是試圖讓Encoder產出離散的...  \n",
       "284  Stories by Progress\\nAug 14, 2017\\nThe democratization of analytics has become a popular term, and a quick Google search will generate results that explore the necessity of empowering more people with analytics and the rise of citizen data scientists. The ability to easily make better use of your (constantly growing) pool of data is a critical driver of business success, but many of the existing solutions that claim to democratize analytics only do so within severe limits. If you have a complex business scenario and are looking to get revolutionary insights using them, it’s easy to come away disappointed.\\nHowever, the democratization of analytics isn’t just a buzzword that refers to a narrow approach. It’s possible to do so much more. Let’s quickly review the current state of the mark...  \n",
       "285  Jun 1, 2021\\nLet’s check your basic knowledge of Decision Tree. Here are 10 multiple-choice questions for you and there’s no time limit. Have fun!\\nQuestion 1: Decision trees are also known as CART. What is CART?(A) Classification and Regression Trees(B) Customer Analysis and Research Tool(C) Communication Access Real-time Translation(D) Computerized Automatic Rating Technique\\nQuestion 2: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees implicitly perform variable screening or feature selection(B) Can handle both numerical and categorical data(C) Can handle multi-output problems.(D) All of the above\\nQuestion 3: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees require relatively less effort from users for ...  \n",
       "286  Towards Data Science\\nMar 15, 2021\\nIn two previous blog posts on my journey with BERT: Neural Search with BERT and Solr and Fun with Apache Lucene and BERT I’ve taken you through the practice of what it takes to enable semantic search powered by BERT in Solr (in fact, you can plug in any other dense embeddings method, other than BERT, as long as it outputs a float vector; a binary vector can also work). While it feels cool and modern to empower your search experience with a tech like BERT, making it performant is still important for productization. You want your search engine operations team to be happy in a real industrial setting. And you want your users to enjoy your search solution.\\nDevops cares about disk sizes, RAM and CPU consumption a lot. In some companies, they also care ab...  \n",
       "287  Jun 29, 2009\\n变形金刚II(Transformers:ROF)这样一部电影,从我从电影院看完他的第一部就开始期待了,昨天终于有幸去电影院看了。画面很,庞大,震撼说不上,可能在1的时候已经给我震完了吧。影院的效果就是好,所以看这个电影确实是一种享受的。当然就我个人看来他想超越1或者是原版动漫是没有多大可能了。我不是一个喜欢搞剧透的人,所以我非常不想说剧情。\\n只说一下对于剧情的感受:1. 剧情太商业化,变形金刚这么强大的战斗力和防御力,我不知道拿着枪的人类可以对他们造成什么样的威胁呢?美国大兵们与变形金刚们短兵相接,难道是为了方便狂派们刷数据么?2. 由于是美国电影,所以一定要展现美国军备的强大,所以战舰上的秘密武器可以KO看上去甚是强大的纸老虎 — — 狂派合体机器人;3. 主角一定得是人类,为了烘托人类主角的伟大性,不惜牺牲同样伟大但没有他伟大的各位领袖同志,主角由于起点比较低,所以随便摸一下某个能量体就可以吸收里面的精髓;4. 赶新潮,年轻人做网站办公司、经济危机,再在电影里融入一点青春元素,把学生宿舍比喻为霍格沃茨,可惜这方面的篇幅太短,如果开发一下说不定会为本集贫乏的剧情添加一点色彩;5. 冷兵器,变形金刚们之间的斗争,如果想要解决对方,就必须使用冷兵器或者蛮力,这方面是我所欣赏的,我可不希望擎天柱、威震天是被一把麦林爆头干掉的;6. HappyEnding,每一部想拍续集的电影都有那么一个HappyEnding,狂派还会回来的誓言也是必需的~\\n综上所述,这的确是一部好电影,看的时候请放松您的大脑,因为没什么可以让你去思考的。\\nBTW:搬到cosbeta的主机以后速度很快,很快,我非常欣慰。\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Follower...  \n",
       "288  Oct 31, 2015\\nAccording to Creative Writing Now, the publishing world tends to classify Fiction as either Commercial (built to make money), or Literary (a work of art). There are no further explanations why art cannot also make money, but things just doesn’t work that way. Observe how Commercial Fiction and Literary Fiction are handled as separate categories. Commercial Fiction is divided into several genres. This kind of classification can help readers to determine what kind of novel do they like to read. Each genre also has its own rubric. Literary fiction has been generally chunked all together in bookstores as “General Fiction”. Because the precedence of literary authors is to produce works of art, while selling books is only a second thought. Literary authors are less likely to th...  \n",
       "289  Dec 20, 2016\\nThis article is for a person who has some knowledge on Android and OpenCV. We will look at how to use the OpenCV library to recognize objects on Android using feature extraction.\\nI am using Android Studio and you can follow this link to download and install Android studio and SDK tools but if you are a die hard eclipse fan you also can follow this tutorial( no hard feelings ;) )\\n2. Setting up OpenCV library inside Android Studio\\nYou have to download and import OpenCV library to android studio and there is a stackoverflow answer which you can follow to setup everything. If you are using Eclipse use this link.\\nNow you are ready to mingle with me ;). The algorithm we are going to use is ORB(Oriented FAST and Rotated BRIEF). As an OpenCV enthusiast, the most important thi...  \n",
       "290  Mar 14, 2018\\nSSD is designed for object detection in real-time. Faster R-CNN uses a region proposal network to create boundary boxes and utilizes those boxes to classify objects. While it is considered the start-of-the-art in accuracy, the whole process runs at 7 frames per second. Far below what real-time processing needs. SSD speeds up the process by eliminating the need for the region proposal network. To recover the drop in accuracy, SSD applies a few improvements including multi-scale features and default boxes. These improvements allow SSD to match the Faster R-CNN’s accuracy using lower resolution images, which further pushes the speed higher. According to the following comparison, it achieves the real-time processing speed and even beats the accuracy of the Faster R-CNN. (Accu...  \n",
       "291  Apr 5, 2018\\nBlockchain is not only crappy technology but a bad vision for the future. Its failure to achieve adoption to date is because systems built on trust, norms, and institutions inherently function better than the type of no-need-for-trusted-parties systems blockchain envisions. That’s permanent: no matter how much blockchain improves it is still headed in the wrong direction.\\nThis December I wrote a widely-circulated article on the inapplicability of blockchain to any actual problem. People objected mostly not to the technology argument, but rather hoped that decentralization could produce integrity.\\nLet’s start with this: Venmo is a free service to transfer dollars, and bitcoin transfers are not free. Yet after I wrote an article last December saying bitcoin had no use, som...  \n",
       "292  Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...  \n",
       "293                                                                                                                                                                                                                                                                                                                                                 The Startup\\nDec 22, 2020\\nNatural language processing (NLP) is a diverse field; the approaches and techniques are as varied...\\n172 \\n172 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n637 Followers\\nResearch Consultant and Data Scientist. Enthusiastic about machine learning, social justice, video games and philosophy.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "294  Sep 16, 2014\\nこれまで Stash は常に、最高のスピードと安全性を実現する Git リポジトリ管理ツール製品となってきました。そして今回、最高の拡張性も提供します。Stash Data Center のリリースの発表です (本日、ベータ版リリース)! このクラスタリング搭載の Stash Data Center デプロイメント オプションは、エンタープライズの大規模システムでのニーズを満たすことを目的としています。\\n今すぐベータ版トライアル\\nStash Data Center はアクティブ/アクティブ クラスタリングを提供し、ユーザーは途切れることなく確実に Git リポジトリにアクセスできます。 Data Center は負荷バランシング技術と冗長化技術を使い、ハードウェア障害による予期せぬシステムのダウンタイムのリスクを軽減します。データベースクラスタリングと共有ファイルシステムの業界標準技術を組み合わせ、Stash は単一障害点を排除します。Stash Data Center の初期設定プロセスの中で、クラスタリングは簡単に設定できますので、チームはすぐに立ち上げ稼働することができます。さらに、稼働規模を拡張するためのノードの追加や削除にダウンタイムは不要ですので、開発チームやビルドプロセスを妨害することはありません。\\n組織内で Git ベースのソリューションを利用するチームが増えるにつれ、開発者とビルドサーバーからのトラフィック量が急速に増加し、リソースを圧迫することがあります。Stash Data Center は、負荷継続時やピーク負荷時に、より高いアプリケーションスループットに対応でき、ユーザーやビルドの追加...  \n",
       "295  Towards Data Science\\nNov 17, 2021\\nTime series forecasting is a very popular field of machine learning. The reason behind this is the widespread usage of time series in daily life in almost every domain. Going into details for time series forecasting, we encounter lots of different kinds of sub-fields and approaches. In this writing, I will focus on a specific subdomain that is performing multi-step forecasts by receiving multiple parallel time series, and also mention basic key points that should be taken into consideration in time series forecasting. Note that forecasting models differ from predictive models at various points.\\nLet's think about lots of network devices spread over a large geography, and traffic flows through these devices continuously. Another example might be about...  \n",
       "296  Towards Data Science\\nJun 21, 2017\\nHere we use the example of reviews to predict sentiment (even though it can be applied more generically to other domains for example sentiment analysis for tweets, comments, customer feedback, etc). Whole idea here is that movie reviews are made of sequence of words and order of words encode lot of information that is useful to predict sentiment. Step 1 is to map words to word embeddings (see post 1 and 2 for more context on word embeddings). Step 2 is the RNN that receives a sequence of vectors as input and considers the order of the vectors to generate prediction.\\nThe architecture for this network is shown below.\\nHere, we’ll pass in words to an embedding layer. You can actually train up an embedding with word2vec and use it here. But it’s good en...  \n",
       "297  Aug 15, 2021\\nWhat are Activation Functions? Why are they used? why are there so many types? Does one works better than other?\\nFirstly, lets recap. A deep layer neural network as seen below receives the input and makes the decision based on its weights and biases which are learned during its backpropagation. As the Hidden layers increases , the decision making becomes more complex and sometimes leads to taking noise into consideration. When output is produced , mot all the neurons in the layers have equal say/contribution, and its because of the weights and bias updated during backpropagation. Done.\\nThen were is Activation function used? And Why?\\nSo basically, Activation functions decide whether the particular neuron or node to be fired /activated or not.\\nAs said, Activation functi...  \n",
       "298  Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...  \n",
       "299  Project AGI\\nApr 7, 2014\\nby David Rawlinson and Gideon Kowadlo\\nThis blog will be written by several people. Other contributors are welcome — send us an email to introduce yourself!\\nThe content will be a series of short articles about a set of common architectures for artificial general intelligence (AGI). Specifically, we will look at the commonalities in Deep Belief Networks and Numenta’s Memory Prediction Framework (MPF). MPF is these days better known by its concrete implementations CLA (Cortical Learning Algorithm) and HTM (Hierarchical Temporal Memory). For an introduction to Deep Belief Networks, read one of the papers by Hinton et al.\\nThis blog will typically use the term MPF to collectively describe all the current implementations — CLA, HTM, NUPIC etc. We see MPF as an int...  \n",
       "300  Feb 22, 2019\\nRecently I have come across a chapter in François Chollet’s “Deep Learning With Python” book, describing the implementation of Class Activation Mapping for the VGG16 network. He implemented the algorithm using Keras as he is the creator of the library. Hence, my instinct was to re-implement the CAM algorithm using PyTorch.\\nGrad-CAM\\nThe algorithm itself comes from this paper. It was a great addition to the computer vision analysis tools for a single primary reason. It provides us with a way to look into what particular parts of the image influenced the whole model’s decision for a specifically assigned label. It is particularly useful in analyzing wrongly classified samples. The Grad-CAM algorithm is very intuitive and reasonably simple to implement.\\nThe intuition behi...  \n",
       "301  Towards Data Science\\nApr 27, 2019\\nIn this article we are going to create deep reinforcement learning agents that learn to make money trading Bitcoin. In this tutorial we will be using OpenAI’s gym and the PPO agent from the stable-baselines library, a fork of OpenAI’s baselines library.\\nThe purpose of this series of articles is to experiment with state-of-the-art deep reinforcement learning technologies to see if we can create profitable Bitcoin trading bots. It seems to be the status quo to quickly shut down any attempts to create reinforcement learning algorithms, as it is “the wrong way to go about building a trading algorithm”. However, recent advances in the field have shown that RL agents are often capable of learning much more than supervised learning agents within the same p...  \n",
       "302  Dec 22, 2016\\nTal Perry\\nHi Tal,\\nMaybe I’m missing something here, but 1. I don’t think your first layer is a embedding layer but a dense layer. You are converting 4000 NUMBERS into 300 by multiplying by a matrix. Embedding layer is when you have categorical variables mapped to vectors, which doesn’t seem to be what’s happening. Unless you are using the name of the stock.\\n2. You mentioned that your output is 5 minute data, but your input is daily data. This is a bit confusing since the time intervals of the input and output have to be the same? If you are getting 5 minute stock data, where do you download them from (I haven’t been able to find anything of the sort).\\nCheers\\n11 \\n11 \\nPhD in Machine Learning | Founder of DeepSchool.io\\nLove podcasts or audiobooks? Learn on the go wit...  \n",
       "303  Towards Data Science\\nJul 13, 2021\\nProject Goal: Using word embeddings identify company names and stock tickers from natural text.\\nAssumption: Stock tickers and company names are used in similar context in natural text such as a Reddit post or a tweet.\\nUnder this assumption, word embeddings should be a good fit for identifying these target words as word embeddings are trained by the context in which words are found.\\nIn this post, I will skip describing what word embeddings are and how the Word2Vec algorithm works. I have written a much more detailed paper on the same project which can be found here. In this paper, I explain the details of what word embeddings are as well as how the Word2Vec Algorithm works. I also detail sentiment analysis via Naive Bayes. In this post, I will just...  \n",
       "304  Towards Data Science\\nJul 17, 2017\\nIn this blog post, I am going to teach you how to train a Bayesian deep learning classifier using Keras and tensorflow. Before diving into the specific training example, I will cover a few important high level concepts:\\nI will then cover two techniques for including uncertainty in a deep learning model and will go over a specific example using Keras to train fully connected layers over a frozen ResNet50 encoder on the cifar10 dataset. With this example, I will also discuss methods of exploring the uncertainty predictions of a Bayesian deep learning classifier and provide suggestions for improving the model in the future.\\nThis post is based on material from two blog posts (here and here) and a white paper on Bayesian deep learning from the Universit...  \n",
       "305  We’ve moved to freeCodeCamp.org/news\\nMay 3, 2017\\nA year and a half ago, I dropped out of one of the best computer science programs in Canada. I started creating my own data science master’s program using online resources. I realized that I could learn everything I needed through edX, Coursera, and Udacity instead. And I could learn it faster, more efficiently, and for a fraction of the cost.\\nI’m almost finished now. I’ve taken many data science-related courses and audited portions of many more. I know the options out there, and what skills are needed for learners preparing for a data analyst or data scientist role. So I started creating a review-driven guide that recommends the best courses for each subject within data science.\\nFor the first guide in the series, I recommended a few...  \n",
       "306  Center for Open Source Data and AI Technologies\\nFeb 21, 2019\\nWhen humans and machines collaborate, we can produce things neither would create on their own. The intersection of art and AI is an area that I find really exciting, but with all the business impact AI can have, I personally feel it doesn’t always get enough attention. In this spirit, I recently set out on a personal quest to learn more about PyTorch, the machine learning library that’s been creating a lot of buzz since its 1.0 release late last year, and I was pleasantly surprised by what I found.\\nFor me, PyTorch turned out to be more than just an interesting alternative to TensorFlow, with dynamic graphs and an imperative coding style. One of the examples from their official docs inspired me to track down some academic p...  \n",
       "307  Towards Data Science\\nFeb 4, 2021\\nNote: For those of you who prefer watching videos, please feel free to play above video on the same content.\\nGiven long documents to read, our natural preference is to not read, or at least, to scan just the main points. So having a summary would always be great to save us time ⏳ and brain processing power.\\nHowever, auto-summarization used to be an impossible task. Specifically, abstractive summarization is very challenging. Differing from extractive summarization (which extracts important sentences from a document and combines them to form a “summary”), abstractive summarization involves paraphrasing words and hence, is more difficult but can potentially give a more coherent and polished summary.\\nIt was not until the development of techniques like...  \n",
       "308                                                                                                        May 25, 2017\\nthis article is mainly a summarization of Yasemin Altun’s presentation in May 2014 on how google applies text summarization.\\ntext summarization is highly related to google knowledge graph project:\\nentities description within red circle use text summarization from wiki to give a one sentence description of the entity.\\n7 \\n7 \\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n83 Followers\\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "309  HuggingFace\\nMay 9, 2019\\nA few years ago, creating a chatbot -as limited as they were back then- could take months 🗓, from designing the rules to actually writing thousands of answers to cover some of the conversation topics.\\nWith the recent progress in deep-learning for NLP, we can now get rid of this petty work and build much more powerful conversational AI 🌟 in just a matter of hours 🍃 as you will see in this tutorial.\\nWe’ve set up a demo running the pretrained model we’ll build together in this tutorial at convai.huggingface.co. Be sure to check it out! 🎮\\nHere is what we will learn and play with today:\\nTogether with this post, we released a clean and commented code base with a pretrained model! Check the Github repo here ✈️\\nThe story of this post began a few months ago in Mon...  \n",
       "310  Cube Dev\\nSep 7, 2017\\nThe Statsbot team has already published the article about using time series analysis for anomaly detection. Today, we’d like to discuss time series prediction with a long short-term memory model (LSTMs). We asked a data scientist, Neelabh Pant, to tell you about his experience of forecasting exchange rates using recurrent neural networks.\\nAs an Indian guy living in the US, I have a constant flow of money from home to me and vice versa. If the USD is stronger in the market, then the Indian rupee (INR) goes down, hence, a person from India buys a dollar for more rupees. If the dollar is weaker, you spend less rupees to buy the same dollar.\\nIf one can predict how much a dollar will cost tomorrow, then this can guide one’s decision making and can be very important ...  \n",
       "311  May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...  \n",
       "312  Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...  \n",
       "313  Towards Data Science\\nMay 10, 2020\\nHumans have the innate ability to identify the objects that they see in the world around them. The visual cortex present in our brain can distinguish between a cat and a dog effortlessly in almost no time. This is true not only with cats and dogs but with almost all the objects that we see. But a computer is not as smart as a human brain to be able to this on its own. Over the past few decades, Deep Learning researchers have tried to bridge this gap between human brain and computer through a special type of artificial neural networks called Convolutional Neural Networks(CNNs).\\nAfter a lot of research to study mammalian brains, researchers found that specific parts of the brain get activated to specific type of stimulus. For example, some parts in th...  \n",
       "314  Veritable\\nNov 1, 2018\\n(This is sort of a sequel or an update to “Building a Translation System in Minutes” published a year ago. This time we use a publicly available dataset, a different NLP task, and some task-specific evaluation metrics)\\nSummarization is the task of producing a shorter version of one or several documents that preserves most of the input’s meaning. [1]\\nThe text summarization task is mostly solved using variants of the seq2seq structure [2] these days. The seq2seq structure is much more complicated than the usual RNN models, and that makes implementing the model from scratch a rather daunting task. Luckily, OpenNMT project [3] provides ready-to-use implementations of seq2seq models that are close to state-of-the-art. We can use it as a starting point.\\nIn this pos...  \n",
       "315  Towards Data Science\\nAug 28, 2020\\nThis article talks about the concept of adversarial examples as applied to NLP (natural language processing). The terminology can be confusing at times, so we’ll begin with an overview of the language used to talk about adversarial examples and adversarial attacks. Then, we’ll talk about TextAttack, our open-source Python library for adversarial examples, data augmentation, and adversarial training in NLP that’s changing the way people research the robustness of NLP models. We’ll conclude with some thoughts on the future of this area of research.\\nAn adversarial example is an input designed to fool a machine learning model [1]. An adversarial example crafted as a change to a benign input is known as an adversarial perturbation. ‘Adversarial perturbat...  \n",
       "316  Jun 28, 2016\\nR uses a ton of memory. Here are ways to make it use a little less. Definitely not an expert, this is largely a resource/reference for myself, but thought it might be useful for others as well.\\nThe best introduction to how R uses memory is likely this guide, by Hadley Wickham.\\nGarbage collector: gc()\\nMy impression is that this function used to be more useful. R uses it to release memory it isn’t using, but will usually run it automatically. So you shouldn’t have to call it explicitly. However, if you want to see when this is happening, use gcinfo(TRUE) — you probably won’t want to leave this on all the time, it will get annoying. But, it can be very useful for finding the peak memory used by a function.\\nObject size: object.size()\\nTo find the size of a given R object,...  \n",
       "317  Towards Data Science\\nDec 20, 2021\\nAuto-Encoders are a popular type of unsupervised artificial neural network that takes un-labeled data and learns efficient codings about the structure of the data that can be used for another context. Auto-Encoders approximates the function that maps the data from full input space to lower dimension coordinates and further approximates to the same dimension of input space with minimum loss.\\nFor classification or regression tasks, auto-encoders can be used to extract features from the raw data to improve the robustness of the model. There are various other applications of an Auto-Encoder network, that can be used for some other context. We will 7 of such applications of auto-encoder in this article:\\nBefore diving into the applications of AutoEncoder...  \n",
       "318  Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...  \n",
       "319  Towards Data Science\\nSep 20, 2019\\nWhen we say Convolution Neural Network (CNN), generally we refer to a 2 dimensional CNN which is used for image classification. But there are two other types of Convolution Neural Networks used in the real world, which are 1 dimensional and 3-dimensional CNNs. In this guide, we are going to cover 1D and 3D CNNs and their applications in the real world. I am assuming you are already familiar with the concept of Convolutions Networks in general.\\nThis is the standard Convolution Neural Network which was first introduced in Lenet-5 architecture. Conv2D is generally used on Image data. It is called 2 dimensional CNN because the kernel slides along 2 dimensions on the data as shown in the following image.\\nThe whole advantage of using CNN is that it can e...  \n",
       "320  Apr 19, 2019\\nOn April 10th, scientists and engineers from Event Horizon Telescope team achieved a remarkable breakthrough in quest to understand the cosmos by unveiling the first image of black hole. This furthers strengthens Einstein theory of general relativity — “ massive objects cause a distortion in space-time, which is felt as gravity”.\\nWell I am not a physicist or astronomer to comprehend and explain in detail about this but like me there are millions and millions of people who despite being in different fields are fascinated by cosmos and specially black hole. The first image of black hole has send wave of excitement all over the world. I am a Deep learning engineer who mainly works with convolution neural network and I wanted to see what AI algorithms thinks about the black ...  \n",
       "321  Starts With A Bang!\\nAug 30, 2015\\nThanks to 3D printing, creativity and a lot of effort, this DIY Optimus Prime cake is unlike any other.\\n“When he came home, I could see a change. He was quieter and he was a man and a hero to me. I watched him and listened to him. I’d never had an opportunity to do a superhero, and when that came, [that voice] just came right out of me and I sounded like Optimus.” -Peter Cullen, on his brother\\nBeing a hero is something we all dream about in our own way. On our birthdays, everyone deserves to live out that fantasy, if only for a day. Have a listen to Tracy Chapman’s reflective and provocative song, Change,\\nwhile you consider the ultimate in “changing” superheros: Optimus Prime.\\nUnlike the flashy Decepticons, who transformed from robots into fighter...  \n",
       "322  Towards Data Science\\nJan 31, 2018\\nA Generative Model is a powerful way of learning any kind of data distribution using unsupervised learning and it has achieved tremendous success in just few years. All types of generative models aim at learning the true data distribution of the training set so as to generate new data points with some variations. But it is not always possible to learn the exact distribution of our data either implicitly or explicitly and so we try to model a distribution which is as similar as possible to the true data distribution. For this, we can leverage the power of neural networks to learn a function which can approximate the model distribution to the true distribution.\\nTwo of the most commonly used and efficient approaches are Variational Autoencoders (VAE) a...  \n",
       "323  ResponsibleML\\nJan 23, 2021\\nAre explainability methods black-box themselves?\\nThere are various adversarial attacks on machine learning models; hence, ways of defending, e.g. by using Explainable AI methods. Nowadays, attacks on model explanations come to light, so does the defense to such adversary. Here, we introduce fundamental concepts related to the domain. A further reference list is available at https://github.com/hbaniecki/adversarial-explainable-ai.\\nWhen considering an explanation as a function of model and data, there is a possibility to change one of these variables to achieve a different result.\\nThe first concept is to manipulate model explanations via data change. Dombrowski et al. [2019] showcase that perturbed images produce arbitrarily made visual explanations (e.g. ...  \n",
       "324  CLTC Bulletin\\nDec 3, 2019\\nA Brief Introduction for Non-Technical Audiences\\nRecent years have seen a rapid increase in the use of machine learning, through which computers can be programmed to identify patterns in information and make increasingly accurate predictions over time. Machine learning is a key enabling technology behind artificial intelligence (AI), and is used for such valuable applications as email spam filters and malware detection, as well as more complex technologies like speech recognition, facial recognition, robotics, and self-driving cars.\\nWhile machine learning models have many potential benefits, they may be vulnerable to manipulation. Cybersecurity researchers refer to this risk as “adversarial machine learning,” as AI systems can be deceived (by attackers or ...  \n",
       "325  BISA.AI\\nMar 25, 2020\\nPada masalah deteksi objek, output yang dihasilkan berupa bounding box (kotak pembatas) hasil prediksi sistem terhadap objek yang telah ditentukan. Bounding box ini merepresentasikan posisi objek dalam sebuah gambar. Untuk mengevaluasi model deteksi objek yang telah kita latih terdapat beberapa cara, salah satu caranya adalah dengan menggunakan metode Intersection Over Union (IOU). IOU memanfaatkan bounding box yang terdapat pada gambar.\\nIntersection Over Union (IOU) adalah nilai berdasarkan statistik kesamaan dan keragaman set sampel yang tujuannya untuk mengevaluasi area tumpang tindih (area yang beririsan) antara dua bounding box, yaitu bounding box hasil prediksi dan bounding box ground truth (kebenaran). Jadi, syarat untuk menerapkan IOU adalah mempunyai ke...  \n",
       "326  Towards Data Science\\nApr 15, 2019\\nThis article explores the use of a variational autoencoder to reduce the dimensions of financial time series with Keras and Python. We will further detect similarities between financial instruments in different markets and will use the results obtained to construct a custom index.\\nDisclaimer: The research presented in this article comes from our Winter 2019 Term Project for the Deep Learning course at the University of Toronto School of Continuing Studies. It was done in collaboration with Humberto Ribeiro de Souza. The concepts and ideas are our own. We are in no way representing our current or previous employers.\\nIn this section, we will discuss:\\nCreating The Geometric Moving Average Dataset\\nIn order to compare time series of various price rang...  \n",
       "327  Becoming Human: Artificial Intelligence Magazine\\nJul 9, 2017\\nOver the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.\\nThis is the most complete list and the Big-O is at the very end, enjoy...\\n>>> Update: We have recently redesigned these cheat sheets into a Super High Definition PDF. Check them out below:\\nbecominghuman.ai\\nchatbotslife.com\\naijobsboard.com\\nThis machine learning cheat sheet will help you find the right estimator for the job which is the most difficult part. The flowchart will help you che...  \n",
       "328  Towards Data Science\\nApr 22, 2019\\nThe major hurdle for going from image classification to object detection is fixed size input requirement to the network because of existing fully connected layers. In object detection, each proposal will be of a different shape. So there is a need for converting all the proposals to fixed shape as required by fully connected layers. ROI Pooling is exactly doing this.\\nRegion of Interest (ROI) pooling is used for utilising single feature map for all the proposals generated by RPN in a single pass. ROI pooling solves the problem of fixed image size requirement for object detection network.\\nROI pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of...  \n",
       "329  fabric8 io\\nApr 17, 2015\\nOne of the big promises of Kubernetes & OpenShift is really easy management of your containerised applications. For standalone or load-balanced stateless applications, Kubernetes works brilliantly, but one thing that I had a bit of trouble figuring out was how do perform cluster discovery for my applications? Say one of my applications needs to know about at least one other node (seed node) that it should join a cluster with.\\nThere is an example in the Kubernetes repo for Cassandra that requests existing service endpoints from the Kubernetes API server & use those as the seed servers. You can see the code for it here. That works great for a cluster that allows unauthenticated/unauthorized access to the API server, but hopefully most people are going to lock d...  \n",
       "330  Aug 17, 2016\\nI release MATLAB, R and Python codes of Support Vector Machine (SVM). They are very easy to use. You prepare data set, and just run the code! Then, SVM and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/XdZSo Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/OyXVZ Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/AtOvT Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofb...  \n",
       "331  Towards Data Science\\nFeb 23, 2021\\nReinforcement learning (RL) is surely a rising field, with the huge influence from the performance of AlphaZero (the best chess engine as of now). RL is a subfield of machine learning that teaches agents to perform in an environment to maximize rewards overtime.\\nAmong RL’s model-free methods is temporal difference (TD) learning, with SARSA and Q-learning (QL) being two of the most used algorithms. I chose to explore SARSA and QL to highlight a subtle difference between on-policy learning and off-learning, which we will discuss later in the post.\\nThis post assumes you have basic knowledge of the agent, environment, action, and rewards within RL's scope. A brief introduction can be found here.\\nThe outline of this post include:\\nWe will compare these...  \n",
       "332  Towards Data Science\\nDec 10, 2018\\nIn my previous story, I went over how to train an image classifier in PyTorch, with your own images, and then use it for image recognition. Now I’ll show you how to use a pre-trained classifier to detect multiple objects in an image, and later track them across a video.\\nWhat’s the difference between image classification (recognition) and object detection? In classification, you identify what’s the main object in the image and the entire image is classified by a single class. In detection, multiple objects are identified in the image, classified, and a location is also determined (as a bounding box).\\nThere are several algorithms for object detection, with YOLO and SSD among the most popular. For this story, I’ll use YOLOv3. I won’t get into the tech...  \n",
       "333                                                                                                                                                                                                      OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder & CEO of Gado Images. I write, speak & consult about tech, food, privacy, AI & photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "334  Towards Data Science\\nMay 1, 2020\\nIn this story, I explain the Attention U-Net from Attention U-Net:Learning Where to Look for the Pancreas written by Oktay et. al. The paper was written in 2018 and proposed a novel attention gate (AG) mechanism that allows the U-Net to focus on target structures of varying size and shape.\\nAttention, in the context of image segmentation, is a way to highlight only the relevant activations during training. This reduces the computational resources wasted on irrelevant activations, providing the network with better generalisation power. Essentially, the network can pay “attention” to certain parts of the image.\\na. Hard Attention\\nAttention comes in two forms, hard and soft. Hard attention works on the basis of highlighting relevant regions by cropping ...  \n",
       "335  ML 2 Vec\\nAug 7, 2017\\nConditional Random Fields are a discriminative model, used for predicting sequences. They use contextual information from previous labels, thus increasing the amount of information the model has to make a good prediction. In this post, I will go over some topics that will introduce CRFs. I will go over:\\nMachine Learning models have two common categorizations, Generative and Discriminative. Conditional Random Fields are a type of Discriminative classifier, and as such, they model the decision boundary between the different classes. Generative models, on the other hand, model how the data was generated, which after having learnt, can be used to make classifications. As a simple example, Naive Bayes, a very simple and popular probabilistic classifier, is a Generati...  \n",
       "336  Bonsal Capital\\nJan 25, 2014\\nSome people ask me Why Baltimore? Couldn’t you do what you do from anywhere in the U.S.? Isn’t this the place where the acclaimed HBO series The Wire was filmed? Has Baltimore ever been on a tech entrepreneur-friendly list? Aren’t there more voluminous entrepreneurial hubs? While the concise response is pegged to an authentic and ever-congealing entrepreneurial ecosystem more focused on the act of doing (the scoreboard) than a Top Ten List, the more interesting answer is found in an array of professional and personal attributes. Let me paint a picture as to why Baltimore is a great city to build a business, a career, a life.\\nBaltimore has a nearly three hundred year history of resilience and determination. What many do not grasp is that Baltimore is a top...  \n",
       "337  Towards Data Science\\nFeb 4, 2020\\nIf I have to describe latent space in one sentence, it simply means a representation of compressed data.\\nImagine a large dataset of handwritten digits (0–9) like the one shown above. Handwritten images of the same number (i.e. images that are 3’s) are the most similar to each other compared to other images of different numbers (i.e. 3s vs. 7s). But can we train an algorithm to recognize these similarities? How?\\nIf you have trained a model to classify digits, then you have also trained the model to learn the ‘structural similarities’ between images. In fact, this is how the model is able to classify digits in the first place- by learning the features of each digit.\\nIf it seems that this process is ‘hidden’ from you, it’s because it is. Latent, by de...  \n",
       "338  Towards Data Science\\nJan 25, 2021\\nI have been following crypto prices for several years now. I am fascinated with the evolution of the blockchain and its implications. I’ve chuckled more than once at the idea of digital currency. Not that it’s new, but I was born in the 80’s when we had to fill out a paper and speak with a human if we wanted to withdraw actual paper money...Remember paper money?\\nIn any case, today I want to share one of my recent projects with you. I will be comparing three models to determine their efficacy at predicting the price of Bitcoin, the King of Crypto. For this project, I used gated recurrent units (GRU), long short term memory units (LSTM), and bidirectional LSTM units (BiLSTM). First, let’s take a quick dive into the workings of these mysterious predict...  \n",
       "339  Chatbots Magazine\\nApr 20, 2016\\nWhat are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?\\nThese are the questions we’re going to answer for you right now.\\nReady? Let’s do this.\\n(Do you work in ecommerce? Stop reading and click here, we made something for you.)\\n(p.s. here is where I believe the future of bots is headed, you will probably disagree with me at first.)\\n(p.p.s. My newest guide about conversational commerce is up, I think you’ll find it super interesting.)\\n“~90% of our time on mobile is spent on email and messaging platforms. I would love to back teams that build stuff for places where the consumers hang out!” — Niko Bonatsos, Managing Director at General Catalyst\\nA chatbot is a s...  \n",
       "340  DataDrivenInvestor\\nMay 9, 2019\\nConditional GANs (CGANs) are an extension of the GANs model. You can read about a variant of GANs called DCGANs in my previous post here. CGANs are allowed to generate images that have certain conditions or attributes.\\nLike DCGANs, Conditional GANs also has two components.\\nwww.datadriveninvestor.com\\nConditional GANs (CGANs): The Generator and Discriminator both receive some additional conditioning input information. This could be the class of the current image or some other property.\\nFor example, if we train a DCGANs to generate new MNIST images, There is no control over which specific digits will be produced by the Generator. There is no mechanism for how to request a particular digit from the Generator. This problem can be addressed by a variation...  \n",
       "341  Towards Data Science\\nMar 23, 2020\\nVanishing Gradient, Saddle Point, Adversarial Training\\nPrerequisite- this post assumes the reader has an introductory-level understanding of neural network architectures, and have trained some form of deep networks, during which might have faced some issues related to training or robustness of a model.\\nA small perturbation or nudge in various parameters/components associated with training such as gradients, weights, inputs etc. can affect DNN training in overcoming some of the issues one might bump into, for example, vanishing gradient problem, saddle point trap, or creating a robust model to avoid malicious attacks through adversarial training etc.\\nTypically, perturbation theory is the study of a small change in a system which can be as a result ...  \n",
       "342  Mar 12, 2020\\nDBSCAN is a clustering method that is used in machine learning to separate clusters of high density from clusters of low density region. Its a very efficient clustering algorithm as it used to segregate the data points with high density observations vs data points of low density observations in form of various clusters.It can sort the data into various shapes of clusters as well. Major challenge of using DBSCAN algorithm is to find right set hyper parameters(eps and min_samples values) to fit in to the algorithm for getting accurate result.\\nLet’s look at a Spatial data of two dimensional coordinates (x,y) using we need to find out various possible star coagulation or dense clusters from this data.\\nRead the input data using Pandas dataframe.\\nAn initial plotting of the d...  \n",
       "343  Towards Data Science\\nSep 29, 2018\\nNeural networks are well known for classification problems, for example, they are used in handwritten digits classification, but the question is will it be fruitful if we used them for regression problems?\\nIn this article I will use a deep neural network to predict house pricing using a dataset from Kaggle .\\nYou can download the dataset from Here\\nI highly recommend you to try running the code using my notebook on Google colab [Here]\\n1- Process the dataset2- Make the deep neural network3- Train the DNN4- Test the DNN5- Compare the result from the DNN to another ML algorithm\\nFirst of all, we will import the needed dependencies :\\nWe will not go deep in processing the dataset, all we want to do is getting the dataset ready to be fed into our models...  \n",
       "344  Machine Learning for Humans\\nAug 19, 2017\\nHow much money will we make by spending more dollars on digital advertising? Will this loan applicant pay back the loan or not? What’s going to happen to the stock market tomorrow?\\nIn supervised learning problems, we start with a data set containing training examples with associated correct labels. For example, when learning to classify handwritten digits, a supervised learning algorithm takes thousands of pictures of handwritten digits along with labels containing the correct number each image represents. The algorithm will then learn the relationship between the images and their associated numbers, and apply that learned relationship to classify completely new images (without labels) that the machine hasn’t seen before. This is how you’re a...  \n",
       "345  Dec 11, 2019\\nHello Folks, in this article we will build our own Stochastic Gradient Descent (SGD) from scratch in Python and then we will use it for Linear Regression on Boston Housing Dataset. Just after a short recap of SGD, we will start building our own custom SGD.\\nTo keep the concept simple and easy to understand, we will touch the math calculations in an extremely simple step by step manner with its Python Code.\\nThen in the end we will combine all the code to solve the Linear Regression on Boston Housing Dataset.\\nWikipedia says: “ Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties. ”\\nLet’s begin, the Linear Regression optimization problem is to optimize or MINimize the SQUARED ERROR as shown below.\\nBut...  \n",
       "346  Towards Data Science\\nOct 31, 2017\\nHave you ever come across a situation where you want to predict a binary outcome like:\\nA very simple Machine Learning algorithm which will come to your rescue is Logistic Regression.\\nLogistic Regression is a classification algorithm which is used when we want to predict a categorical variable (Yes/No, Pass/Fail) based on a set of independent variable(s).\\nIn the Logistic Regression model, the log of odds of the dependent variable is modeled as a linear combination of the independent variables.\\nLet’s get more clarity on Binary Logistic Regression using a practical example in R.\\nConsider a situation where you are interested in classifying an individual as diabetic or non-diabetic based on features like glucose concentration, blood pressure, age etc...  \n",
       "347                                                                                                                                                                                                                                                                                       Jun 20, 2019\\nThis tutorial will guide you through the implementation and intuitive grasp on what is actually happening underneath the RNN networks.\\nThere has been extensive writing on this subject but I could not find a single source where the complete walk through of word...\\n68 \\n68 \\n2\\nSoftware Design and Product Management\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n14 Followers\\nSoftware Design and Product Management\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "348  May 4, 2020\\nEven object detection starts maturing in the last few years, the competition remains fierce. As shown below, YOLOv4 claims to have state-of-the-art accuracy while maintains a high processing frame rate. It achieves an accuracy of 43.5% AP (65.7% AP50) for the MS COCO with an approximately 65 FPS inference speed on Tesla V100. In object detection, high accuracy is not the only holy grail anymore. We want the model to run smoothly in the edge devices. How to process input video in real-time with low-cost hardware becomes important also.\\nThe fun part of reading the YOLOv4 development is what new technologies have been evaluated, modified, and integrated into YOLOv4. And it also makes changes to make the detector more suitable for training on a single GPU.\\nImprovements can b...  \n",
       "349  May 19, 2016\\n啟動子 (Promoter) 在人體遺傳基因扮演著重要角色,宛如人體一個開關,可以決定基因的活動,並控制細胞開始生產人體所需的蛋白質。當啟動子發生突變時,將可能導致基因表現的調節障礙。近期國際學者在癌細胞基因組的研究中發現,基因啟動子中的 DNA 突變數量增加,是因結合 DNA 控制基因表現的某些蛋白質,阻止人體的一個細胞修復系統去修復損傷的 DNA。啟動子突變的多寡與 DNA 修復系統相互作用,引發癌細胞生長有了重要的發現。\\n皮膚癌啟動子的突變密度特別高\\n2016 年 4 月發表在《Nature》的研究指出,科學家們分析來自 14 種癌症類型、1,161 個腫瘤的 2000 多萬 DNA 突變。他們發現在許多癌症類型,尤其是皮膚癌中,基因啟動子的基因組區域內突變數量特別高。研究進一步探究發現,人體控制基因表達的一些蛋白質,降低人體細胞修復系統的功能發揮,導致無法正常修復受損的 DNA,這個系統被稱為核苷酸切除修復 (NER, Nucleotide Excision-Repair)。NER 是唯一能修復紫外線造成的 DNA 損傷的系統,不僅如此,它還能處理抽煙誘導的遺傳損傷。\\n(上圖為DNA修復示意圖)\\n延伸閱讀:腫瘤的轉移與「偽轉移」 基因定序分析癌細胞親緣\\nDNA 修復如何參與癌細胞生長\\n西班牙研究團隊人員利用來自人類黑色素瘤樣本的全基因組序列分析調控區域的突變,並進一步分析核苷酸切除修復 (NER) 活性位點。結果發現,NER 功能的下降可導致一些轉錄因子位點的突變率增高。除此,在肺癌樣本中,他們也證實一些轉錄因子結合位點的突變率增高,尤其是與抽煙相關的突變。另一研究中,研究人員則分析多個癌症類型調控元件的突變。結果發現預測轉錄因子將結合的位置,即調控區域的核心,比側翼序列的突變率高達 5 倍。\\n總結,這項研究提示,在...  \n",
       "350  Analytics Vidhya\\nNov 14, 2020\\nIn this post, I will make you go through the theory of RNN, GRU and LSTM first and then I will show you how to implement and use them with code.\\nThere are already many posts on these topics out there. But in this post, I wanted to provide a much better understanding and comparison with help of code.\\nLet’s start with RNN!\\nRecurrent Neural Networks (RNN) are designed to work with sequential data. Sequential data(can be time-series) can be in form of text, audio, video etc.\\nRNN uses the previous information in the sequence to produce the current output. To understand this better I’m taking an example sentence.\\n“My class is the best class.”\\nAt the time(T0 ), the first step is to feed the word “My” into the network. the RNN produces an output.\\nAt the t...  \n",
       "351  Towards Data Science\\nJun 27, 2021\\nMy open-source GitHub script provides AI-based filters which apply a rather new technology called Artistic Neural Style Transfer to the input stream of your physical webcam device. In contrast to traditional filters, these AI-based filters are feature-aware. Depending on what kind of features are apparent in the video, the AI adapts the output. In addition, these kinds of filters can be learned from any real-world image. Since the provided filters are directly applied on the webcam video stream, they can be used in all types of video conferencing tools, such as Zoom, Skype, Discord, MS-Teams....\\nIn detail, my script sets up a virtual webcam device that applies Artistic Neural Style Transfer to the input stream of the physical webcam device. This new...  \n",
       "352  Jul 24, 2020\\nПроблема классификации объекта на изображении уже решена — сверточные нейронные сети (Convolutional Neural Networks, CNN) уже неплохо справляются с определением кошек или собак. Но если на изображении много объектов, которые нужно найти, задача сразу усложняется. На смену обычным сверточным нейросетям пришли более сложные модели. В этой статье рассмотрим 3 популярных способа детектирования изображений методами Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN.\\nРаспознавание образов — это общий термин, описывающий круг задач компьютерного зрения, которые решают проблему обнаружения объектов на изображении или видеокадрах. К ним относятся классификация изображения, локализация объектов, детектирование объектов и сегментация. Проведем между ними грань:\\nКлассификация и...  \n",
       "353  Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...  \n",
       "354  techpsl\\nNov 11, 2013\\nWikipedia says, “Question Answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.”As I have taken the course of “Information Retrieval” this fall at UB, my final project is decided to be a Q-A system. Well we (me and my 3 group partners) have not decided much on features, which can make our project stand out, but for now we would like to start with a small goal. Somehow index the infobox of Wikipedia, and try to query it using natural language. My initial research suggests that IBM has already created something similar but on a very large scale, and they call it Watson.As we d...  \n",
       "355  Jan 22, 2020\\nThere has been a great advancement in the research in the area of meta-learning in recent years. And so has been an expansion in the available literature and blog posts.\\nModel Agnostic Meta-Learning (MAML) lies at the heart of the developments in the area. There have been many excellent blog-posts explaining meta-learning in general (here and here) and MAML in particular (here and here). The heavy terms and complex equations make the algorithm to look like a big shot rocket science. However, through this blog, I want to provide intuitive reasoning behind the algorithm that can be easy to understand for a person who has no idea about meta-learning. All one needs to know is the basic idea all machine learning researchers have been following from its inception: “Throw all y...  \n",
       "356  Dec 10, 2014\\n(The 2016 Machine Intelligence landscape and post can be found here)\\nI spent the last three months learning about every artificial intelligence, machine learning, or data related startup I could find — my current list has 2,529 of them to be exact. Yes, I should find better things to do with my evenings and weekends but until then...\\nWhy do this?\\nA few years ago, investors and startups were chasing “big data” (I helped put together a landscape on that industry). Now we’re seeing a similar explosion of companies calling themselves artificial intelligence, machine learning, or somesuch — collectively I call these “machine intelligence” (I’ll get into the definitions in a second). Our fund, Bloomberg Beta, which is focused on the future of work, has been investing in thes...  \n",
       "357                                                                                                                                 Jan 14, 2019\\nEven if we understand LSTMs theoretically, still many of us are confused about its input and output shapes while fitting the data to the network. This guide will help you understand the Input and Output shapes of the LSTM.\\nLet’s first understand the Input and its shape in LSTM Keras. The input data to LSTM looks like the following diagram.\\n1.95K \\n1.95K \\n17\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n918 Followers\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "358                                                                                                                  Analytics Vidhya\\nAug 23, 2020\\nKeras Embedding layer is first of Input layer for the neural networks. After the conversion of our raw input data in the token and padded sequence, now its time to feed the prepared input to the neural networks. In our previous two post we had covered step by step conversion of words into token and padded sequence, so i highly recommend to just...\\n53 \\n53 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n28 Followers\\nData scientist, (NLP, CV,ML,DL) Expert 007011\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "359  Sep 1, 2019\\nFrom my most recent escapade into the deep learning literature I present to you this paper by Oord et. al. which presents the idea of using discrete latent embeddings for variational auto encoders. The proposed model is called Vector Quantized Variational Autoencoders (VQ-VAE). I really liked the idea and the results that came with it but found surprisingly few resources to develop an understanding. Here’s an attempt to help other who might venture into this domain after me.\\nLike numerous other people Variational Autoencoders (VAEs) are my choice of generative models. Unlike GANs they are easier to train and reason about (No offence intended dear GANs). Going forward I assume you have some understanding of VAEs. If you don’t I suggest going through this post, I found it t...  \n",
       "360  Analytics Vidhya\\nFeb 9, 2021\\nThis has turn the old approach by giving an input from both the direction and by this it can remember the long sequences.\\nIn my previous article we discussed about RNN, LSTM and GRU. Now, there are certain limitations are still persist with LSTM because it is not able to remember the context for a longer period of time.\\nYou can see in this LSTM architecture that information is still have to pass from longer path. LSTM and GRU are introduced to overcome the problem of vanishing gradient and sequential data memory but the architecture of both are having multiple sequential path. Thus, vanishing gradient problem is still persist. Also, LSTM and GRU can remember sequences of 10s and 100s but not 1000s or more.\\nBidirectional Network\\nNow, when we are dealin...  \n",
       "361  Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...  \n",
       "362  Towards Data Science\\nMay 15, 2020\\nThis is the first post of the series “Deep Reinforcement Learning Explained”; an introductory series that gradually and with a practical approach introduces the reader to the basic concepts and methods used in modern Deep Reinforcement Learning.\\nSpanish version of this publication:\\nmedium.com\\nDeep Reinforcement Learning (DRL), a very fast-moving field, is the combination of Reinforcement Learning and Deep Learning. It is also the most trending type of Machine Learning because it can solve a wide range of complex decision-making tasks that were previously out of reach for a machine to solve real-world problems with human-like intelligence.\\nToday I’m starting a series about Deep Reinforcement Learning that will bring the topic closer to the reader....  \n",
       "363  Towards Data Science\\nJun 23, 2020\\nThis article is a part of the Gans-Series published by me on TowardsDataScience Publication on Medium. If you do not know what GANs are or if you have an idea about it but wish to quickly go over it again, I highly recommend you read the previous article which is just a 7 minutes long read and provides a simple understanding of GANs for people who are new to this amazing domain of Deep Learning.\\nAs you can tell from the gif shown above, this article is going to be all about learning how to create a Conditional GAN to predict colorful images from the given black and white sketch inputs without knowing the actual ground truth.\\nSketch to Color Image generation is an image-to-image translation model using Conditional Generative Adversarial Networks as ...  \n",
       "364  DataDrivenInvestor\\nMay 5, 2020\\nOne of the main questions that arise when studying Machine Learning and Deep Learning is the several types of Gradient Descent. Should I use Batch Gradient Descent? Mini-batch Gradient Descent or Stochastic Gradient Descent? In this post, we are going to understand the difference between those concepts and take a look at code implementations from Gradient Descent, to clarify these methods.\\nEdit: Updated version here.\\nAt this point, we know that our matrix of weights W and our vector of bias b are the core values of our Neural Networks (NN) (Check the Deep Learning Basics post). We can make an analogy with these concepts with the memory in which a NN stores patterns, and it is through tuning these parameters that we teach a NN. The acting of tuning is ...  \n",
       "365  Towards Data Science\\nJun 17, 2021\\nWhen I first came across lambda functions in python, I was very much intimidated and thought they were for advanced Pythonistas. Beginner python tutorials applaud the language for its readable syntax, but lambdas sure didn’t seem user-friendly.\\nHowever, once I understood the general syntax and examined some simple use cases, using them was less scary.\\nSimply put, a lambda function is just like any normal python function, except that it has no name when defining it, and it is contained in one line of code.\\nA lambda function evaluates an expression for a given argument. You give the function a value (argument) and then provide the operation (expression). The keyword lambda must come first. A full colon (:) separates the argument and the expression.\\...  \n",
       "366  Nov 11, 2017\\n“Numbers have an important story to tell. They rely on you to give them a voice.” — Stephen Few\\nAfter doing the usual Feature Engineering, Selection, and of course, implementing a model and getting some output in forms of a probability or a class, the next step is to find out how effective is the model based on some metric using test datasets. Different performance metrics are used to evaluate different Machine Learning Algorithms. For now, we will be focusing on the ones used for Classification problems. We can use classification performance metrics such as Log-Loss, Accuracy, AUC(Area under Curve) etc. Another example of metric for evaluation of machine learning algorithms is precision, recall, which can be used for sorting algorithms primarily used by search engines.\\...  \n",
       "367  Towards Data Science\\nAug 27, 2020\\nLately, posts and tutorials about new deep learning architectures and training strategies have dominated the community. However, one very interesting research area, namely few-shot learning, is not getting the attention it deserves. If we want widespread adoption of ML we need to find ways to train them efficiently, with little data and code. In this tutorial, we will go through a Google Colab Notebook to train an image classification model using only 5 labeled samples per class. Using only 5 exemplary samples is also called 5-shot learning.\\nDon’t forget to check out our Google Colab Notebook for the full code of this tutorial!\\nJupyter Notebook (Google Colab)The full code of this tutorial will be provided as a notebook. Jupyter Notebooks are python...  \n",
       "368  Towards Data Science\\nJun 27, 2017\\nThe idea behind GANs is that you have two networks, a generator GG and a discriminator DD, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it’s received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistinguishable from real data to the discriminator.\\nThis is equilibrium state and expectation is discriminator is emitting a probability of 0.5 for both real and fake data.\\nThe general structure of a ...  \n",
       "369  Good Audience\\nSep 15, 2018\\nSolving the sliding puzzle using a basic AI algorithm.\\nN-Puzzle or sliding puzzle is a popular puzzle that consists of N tiles where N can be 8, 15, 24, and so on. In our example N = 8. The puzzle is divided into sqrt(N+1) rows and sqrt(N+1) columns. Eg. 15-Puzzle will have 4 rows and 4 columns and an 8-Puzzle will have 3 rows and 3 columns. The puzzle consists of N tiles and one empty space where the tiles can be moved. Start and Goal configurations (also called state) of the puzzle are provided. The puzzle can be solved by moving the tiles one by one in the single empty space and thus achieving the Goal configuration.\\nThe tiles in the initial(start) state can be moved in the empty space in a particular order and thus achieve the goal state.\\nNote: There...  \n",
       "370                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            DataPy.ai\\nNov 18, 2019\\n105 \\n105 \\n3\\nSchool for Data Science\\n98 Followers\\nTrying to become ( .* ?) | MSc @ University of Twente | ML-NLP-Big Data-DL | tencsor.github.io | theguywithblacktie.github.io\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "371  Jul 19, 2014\\n“A mind is like a computer program that is executed in our brain” says the computer metaphor of the mind. It was developed in the 1950s. It basically compares the human mind to a computer program, suggesting that computers and our brain function on the same principles.\\nIn the philosophy of artificial intelligence (AI), the brain is perceived as a similar information processing machine as a digital computer.\\nThere is no doubt that some of our thinking processes, such as mental calculation and logical reasoning, are algorithmic. The digital computer functions with binary computer language where the symbols ‘1’ and ‘0’ represent the state of circuit’s gate. This means that an electrical impulse either goes through (state ‘1’) or does not (state ‘0’). It is similar to the f...  \n",
       "372  Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is <=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...  \n",
       "373  Towards Data Science\\nNov 13, 2021\\nOver the last several years, deep networks have extensively been shown to be vulnerable to attackers that can cause the network to make perplexing mistakes, simply by feeding maliciously-perturbed inputs to the network. Clearly, this raises concrete safety concerns for neural networks deployed in the wild, especially in safety-critical settings, e.g., in autonomous vehicles. In turn, this has motivated a volume of work on practical defenses, ranging from attack detection strategies to modified training routines that aim to produce networks that are difficult — or impossible — to attack. In this article, we’ll take a look at an elegant and effective defense I designed with my colleagues at CMU (appearing in ICML 2021) that modifies the architecture of...  \n",
       "374  Apr 24, 2018\\nBy — Yashwardhan Jain\\nSo, since you’re reading this article, I’m going to assume you have started your deep learning journey and have been playing around for a while with artificial neural nets. Or maybe, you’re just thinking of starting. Whichever case it be, you find yourself in a bit of a dilemma. You have read about various deep learning frameworks and libraries and maybe two really stand out. The two most popular deep learning libraries: Tensorflow and PyTorch. And you can’t quite figure out what exactly is the difference. Fret not! I’m here to add one more article to the unending repository of the Internet. And maybe, help you get some clarity. Also, I’m going to make it easier and quicker for you, and give you just five points. Five points of comparison, no more. ...  \n",
       "375  Towards Data Science\\nOct 8, 2020\\nK-Means and Gaussian Mixtures (GMs) are both clustering models. Many data scientist, however, tend to choose a more popular K-Means algorithm. Even if GMs can prove superior in certain clustering problems.\\nIn this article, we will see that both models offer a different performance in terms of speed and robustness. We will also see that it is possible to use K-Means as an initializer for GMs which tends to boost the performance of the clustering model.\\nFirst, let’s review the theoretical part of these algorithms. It will help us to understand their behaviour later in the article.\\nK-Means is a popular non-probabilistic clustering algorithm. The goal of the algorithm is to minimize the distortion measure J. We achieve that by the following iterative p...  \n",
       "376  Towards Data Science\\nAug 25, 2020\\nThe internet is full of text classification articles, most of which are BoW-models combined with some kind of ML-model typically solving a binary text classification problem. With the rise of NLP, and in particular BERT (take a look here, if you are not familiar with BERT) and other multilingual transformer based models, more and more text classification problems can now be solved.\\nHowever, when it comes to solving a multi-label, multi-class text classification problem using Huggingface Transformers, BERT, and Tensorflow Keras, the number of articles are indeed very limited and I for one, haven’t found any... Yet!\\nTherefore, with the help and inspiration of a great deal of blog posts, tutorials and GitHub code snippets all relating to either BERT, ...  \n",
       "377  Towards Data Science\\nMar 19, 2019\\nThe goal of this project is to find out similarities within groups of people in order to build a movie recommending system for users. We are going to analyze a dataset from Netflix database to explore the characteristics that people share in movies’ taste, based on how they rate them.\\nData will come from the MovieLens user rating dataset.\\nThis dataset has two files, we will import both and work with both of them.\\nWe will want to find out how the structure of the dataset works and how many records do we have in each of these tables.\\nWe will start by considering a subset of users and discovering what are their favourite genre. We will do this by defining a function that will calculate each user’s average rating for all science fiction and romance m...  \n",
       "378  Data Science at Microsoft\\nNov 5, 2020\\nBy Jane Huang, Daniel Yehdego, and Siddharth Kumar\\nThis is the second article of a series focusing on causal inference methods and applications. In Part 1, we discussed when and why causal models can help with different business problems. We also provided fundamentals for causal inference analysis and compared a few popular Python packages for causal analysis. In this article, we dive into details of various causal inference estimation methods and discuss algorithm selection for your own problem settings. Causal inference can be used on top of A/B tests in multiple ways to extract insights, but this article focuses mainly on estimation methods under unconfoundedness or on quasi-experimental bases when a randomized control trial (RCT) is not feas...  \n",
       "379  Towards Data Science\\nAug 26, 2020\\nA Convolutional Neural Network, also known as CNN or ConvNet, is a class of neural networks that specializes in processing data that has a grid-like topology, such as an image. A digital image is a binary representation of visual data. It contains a series of pixels arranged in a grid-like fashion that contains pixel values to denote how bright and what color each pixel should be.\\nThe human brain processes a huge amount of information the second we see an image. Each neuron works in its own receptive field and is connected to other neurons in a way that they cover the entire visual field. Just as each neuron responds to stimuli only in the restricted region of the visual field called the receptive field in the biological vision system, each neuron i...  \n",
       "380  Towards Data Science\\nNov 16, 2021\\nDo you think it is impossible to fool the vision system of a self-driving Tesla car?\\nOr that machine learning models used in malware detection software are too good to be evaded by hackers?\\nOr that face recognition systems in airports are bulletproof?\\nLike any of us machine learning enthusiasts, you might fall into the trap of thinking that deep models used out there are perfect.\\nWell, you are WRONG.\\nThere are easy ways to build adversarial examples that can fool any deep learning model and create security issues. In this post, we will cover the following:\\nLet’s start!\\nIn the last 10 years, deep learning models have left the academic kindergarten, become big boys, and transformed many industries. This is especially true for computer vision mod...  \n",
       "381  Towards Data Science\\nJun 7, 2020\\nOne of the distinctive differences between information in a single image and information in a video is the temporal element. This has led to improvements of deep learning model architectures to incorporate 3D processing in order to additionally process temporal information. This article summarizes the architectural changes from images to video through the I3D model.\\nThe I3D model was presented by researchers from DeepMind and the University of Oxford in a paper called “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” [1]. The paper compares previous approaches to the problem of action detection in videos while additionally presenting a new architecture, the focus here. Their approach starts with a 2D architecture and inflates all ...  \n",
       "382  Aug 23, 2016\\nI release MATLAB, R and Python codes of Random Forests Classification (RFC). They are very easy to use. You prepare data set, and just run the code! Then, RFC and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/RciDk Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/gdJgy Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/nDrmZ Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://un...  \n",
       "383  Becoming Human: Artificial Intelligence Magazine\\nAug 31, 2021\\nBefore getting into Transformers, let’s understand why researchers were interested in building something like Transformers inspite of having MLPs , CNNs and RNNs.\\nEveryone wants a universal model to solve different tasks with accuracy and speed. Just like MLPs which are universal function approximators, Transformer models are universal approximators of sequence-to-sequence functions.\\nTransformers use the concept of Attention mechanism. Let’s look what is attention and briefly go through self attention mechanisms.\\nAttention mechanism enhances the important parts of the input data and fades out the rest. Take the example of you captioning an image. You will have to focus on the relevant part of the image to generate meani...  \n",
       "384  mojitok\\nMar 10, 2019\\n어텐션 메커니즘은 자연어 기계 번역을 위한 Seq2Seq 모델에 처음 도입되었습니다. 어텐션 메커니즘은 NLP 태스크 뿐만 아니라, 도메인에 관계 없이 다양하게 쓰이고 있습니다. 현재의 SOTA NLP모델들은 대부분 어텐션 메커니즘을 적용하고 있으니 최근 논문을 이해함에 있어 이해하고 넘어가야 하는 부분입니다.\\n코드는 이곳(https://github.com/graykode/nlp-tutorial)을 참고해주세요 .\\n1. Seq2Seq (링크)2. Seq2Seq with Attention (링크)3. Bi-LSTM with Attention (링크)4. Transformer (링크)\\nSeq2Seq 모델은 대중적이므로 가볍게 짚고만 넘어가겠습니다. Seq2Seq 모델에 대한 자세한 설명들은 ratsgo님의 블로그를 참조하면 볼 수 있습니다. 더불어 자세한 내용은 원작 논문인 Neural Machine Translation by Jointly Learn...  \n",
       "385  Towards Data Science\\nMar 18, 2019\\n“Premature optimization is the root of all evil.” ― Donald Ervin Knuth\\nAgile is a pretty well-known term in the software development process. The basic idea behind it is simple: build something quickly, ➡️ get it out there, ➡️ get some feedback ➡️ make changes depending upon the feedback ➡️ repeat the process. The goal is to get the product near the user and guide you with feedback to obtain the best possible product with the least error. Also, the steps taken for improvement need to be small and should constantly involve the user. In a way, an Agile software development process involves rapid iterations. The idea of — start with a solution as soon as possible, measure and iterate as frequently as possible, is Gradient descent under the hood.\\nGradi...  \n",
       "386  Feb 23, 2018\\nWhile Python’s scikit-learn library provides the easy-to-use and efficient LogisticRegression class, the objective of this post is to create an own implementation using NumPy. Implementing basic models is a great idea to improve your comprehension about how they work.\\nWe will use the well known Iris data set. It contains 3 classes of 50 instances each, where each class refers to a type of iris plant. To simplify things, we take just the first two feature columns. Also, the two non-linearly separable classes are labeled with the same category, ending up with a binary classification problem.\\nGiven a set of inputs X, we want to assign them to one of two possible categories (0 or 1). Logistic regression models the probability that each input belongs to a particular category...  \n",
       "387  Towards Data Science\\nJun 10, 2021\\nThis blog post is part of a mini-series that talks about the different aspects of building a PyTorch Deep Learning project using Variational Autoencoders.\\nPart 1: Mathematical Foundations and ImplementationPart 2: Supercharge with PyTorch LightningPart 3: Convolutional VAE, Inheritance and Unit TestingPart 4: Streamlit Web App and Deployment\\nIn this section, we will look at how we can use the code we wrote in the previous section and use it to build a convolutional VAE. This VAE would be better at identifying important features in the images and thus generate even better images.\\nThe best part is that this new model can be built with minimal additional code thanks to PyTorch modules and class inheritance.\\nConvolution is an operation commonly used ...  \n",
       "388  Coders Camp\\nJan 14, 2021\\nPython has been in the top 10 popular programming languages for a long time, as the community of Python programmers has grown a lot due to its easy syntax and library support. In this article, I will introduce you to 60 amazing Python projects with source code solved and explained for free.\\nIf you’re a newbie to Python where you’ve just learned lists, tuples, dictionaries, and some basic Python modules like the random module, here are some Python projects with source code for beginners for you:\\nIf you have learned the fundamental Python libraries and some of the external libraries, you should now know how to install external libraries and work with them. So if you are at that level now, you can work on all the advanced Python projects with source code menti...  \n",
       "389  Towards Data Science\\nNov 13, 2017\\nIn this article, we’ll look at:\\nLinks to my other articles:\\nIn many cases when using neural network models such as regular deep feedforward nets and convolutional nets for classification tasks over some set of class labels, one wonders whether it is possible to interpret the output, for example y = [0.02, 0, 0.005, 0.975], as the probability of some input being in a class equal to the respective component values yi in the output vector. Skipping straight to the long answer: no, unless you have a softmax layer as your output layer and train the net with the cross-entropy loss function. This point is important because it is sometimes omitted in online sources and even in some textbooks regarding classification with neural networks. We’ll take a look ...  \n",
       "390  binaryandmore\\nJul 16, 2018\\nThis article is divided into two sections:1. Derivation — In this section, we will be deriving all the required formulae for performing backpropagation. I strongly recommend that you derive the equations on paper as you read through the article.2. Implementation — In this part, we will use the derived formulae to implement backpropagation from scratch. We will be solving a binary classification problem in python using numpy.\\nDisclaimerThis article assumes a basic understanding of neural networks and how they work. If you are not familiar with neural networks, or think your concepts are a little rusty, you may want to review chapter 1 of the amazing book, Neural Networks and Deep Learning, by Michael Nielsen, or if you prefer video lectures, you might want ...  \n",
       "391  Towards Data Science\\nJun 9, 2020\\nOne can be forgiven for taking mAP (mean average precision) to literally mean the average of precisions. Nevertheless, you couldn’t be further from the truth!\\nLet me explain.\\nIn computer vision, mAP is a popular evaluation metric used for object detection (i.e. localisation and classification). Localization determines the location of an instance (e.g. bounding box coordinates) and classification tells you what it is (e.g. a dog or cat).\\nMany object detection algorithms, such as Faster R-CNN, MobileNet SSD, and YOLO, use mAP to evaluate their models for publishing their research.\\nYou might ask, if it’s such a popular metric, why is it still confusing?\\nFair enough!\\nmAP stands for Mean Average Precision (as you might already have guessed looking at...  \n",
       "392  Dec 5, 2018\\nIn 2014 machine learning researcher Ian Goodfellow introduced the idea of generative adversarial networks or GANs. “Generative” because they output things like images rather than predictions about input (like “hotdog or not”); “adversarial networks” because they use two neural networks competing with each other in a “cat-and-mouse game”, like a cashier and a counterfeiter: one trying to fool the other into thinking it can generate real examples, the other trying to distinguish real from fake.\\nThe first GAN images were easy for humans to identify. Consider these faces from 2014.\\nBut the latest examples of GAN-generated faces, published in October 2017, are more difficult to identify.\\nHere are some things you can look for when trying to recognize an image produced by a GA...  \n",
       "393  Nov 2, 2012\\nThis post will try to give you a brief introduction to artificial neural networks or at least to some types of them. I will skip the introduction to biological neural networks as I am neither a biologist nor a doctor, I prefer not to write about what I do not fully understand.\\nOverview of artificial neural networks and supervised learning\\nI think it is very important to note that artificial neural networks are neither magical AI circuits nor oracles with the ability of predicting stock market movements. You can save one as a file on the disk and you can name it skynet if you like but it will not get more intelligent from that. In reality they are simply mathematical tools that can come very handy in solving certain problems (and can prove to be completely useless for oth...  \n",
       "394  SyncedReview\\nOct 2, 2018\\n“Best GAN samples ever yet? Very impressive ICLR submission! BigGAN improves Inception Scores by >100.”\\nThe above Tweet is from renowned Google DeepMind research scientist Oriol Vinyals. It was retweeted last week by Google Brain researcher and “Father of Generative Adversarial Networks” Ian Goodfellow, and picked up momentum and praise from AI researchers on social media.\\n402 \\n402 \\n5\\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology & Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\...  \n",
       "395  Towards Data Science\\nNov 15, 2020\\nThis is as up to date as: 3/1/2022\\nThis is a vastly revised version of the older version you all know and love.Almost every part of this guide has been thoroughly rewritten. The original guide has been getting updated over the course of 6 years, so I decided it’s time to basically (almost) write it from scratch.This time I tried to make this a bit more thorough and general. I’ll keep updating this, but I also want to make sure my readers can understand the topic even if I stop doing so one day.\\nSo, you’ve decided you want to purchase a machine dedicated to training machine learning models. Or, rather, you work in an organization where the buzzwords of this guide are constantly thrown around and you simply want to know a bit more about what they mea...  \n",
       "396  Dec 6, 2021\\nTL;DR — I complain about NFTs, then attempt to train both a GAN and super-resolution model to generate Bored Apes that do not exist. You can check out all the generated images on thisboredapedoesnotexist.nathancooperjones.com.\\nFriday, November 12th, 2021 started out as a normal day for me. Before starting my day at work, I decided to open Twitter to see if I missed anything since the night before.\\nThen, it happened. I saw this Tweet:\\nSay what you will about how Jimmy Fallon tells and reacts to jokes, but if this was a joke, I did not understand it. An animated monkey dressed in a sailor cap? I soon learned that this wasn’t just any animated ape, but one of exactly 10,000 unique images produced in a collection called Bored Ape Yacht Club. After ten minutes down a Twitter...  \n",
       "397                                                                                                                                                                                                                                               Dec 20, 2019\\nNowadays, there are big problems about parking areas. The large number of vehicles in the cities and the scarcity of parking spaces lead to parking problems in the cities. The biggest solution that can be brought to this problem is to provide people with the information whether the parking spaces are automatically empty or full. Using a mask...\\n17 \\n17 \\n1\\nSoftware Engineer\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n49 Followers\\nSoftware Engineer\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "398  The Hands-on Advisors\\nApr 20, 2018\\nDuring the start of my career, I was fortunate enough to work on a subfield of machine learning known as online learning (also known as incremental or out-of-core learning). Compared to “traditional” ML solutions, online learning is a fundamentally different approach, one that embraces the fact that learning environments can (and do) change from second to second. It’s tricky to get right, but when applied correctly, the results you can achieve with online learning are nothing short of remarkable. In this post, I’ll give a quick introduction to the technique.\\nUpdate 27/09/2019: lots of people have asked if there exist any purpose-built incremental learning libraries. Yes! Vowpal Wabbit is extremely powerful, and has been around for quite a while. Fo...  \n",
       "399  Product Development Notebook\\nOct 26, 2015\\nIt’s been a while since I first wrote about how useful computer vision can be in product development, and I recently put together a quick demo for other engineers at my new gig (@ Continuum) that is cleaner and more thorough than previous versions (plus it uses the cv2 library instead of the deprecated cv library I used before).\\n(and of course it’s written in python)\\n...\\n...\\n...\\nImage analysis is hugely powerful, particularly in the context of product development. Most of the challenges in computer vision (and AI in general) comes from trying to process unstructured and/or uncontrolled information.\\nFortunately, we product development engineers spend a bunch of time setting up experiments in the lab. In those cases we have much more cont...  \n",
       "400  Towards Data Science\\nDec 8, 2019\\nA lot of innovations on NLP have been how to add context into word vectors. One of the common ways of doing it is using Recurrent Neural Networks. The following are the concepts of Recurrent Neural Networks:\\nThe above is the architecture of Recurrent Neural Networks.\\nAssuming we are solving document classification problem for a news article data set.\\nTherefore, we generally do not use vanilla RNNs, and we use Long Short Term Memory instead. LSTM is a type of RNNs that can solve this long term dependency problem.\\nIn our document classification for news article example, we have this many-to- one relationship. The input are sequences of words, output is one single class or label.\\nNow we are going to solve a BBC news document classification problem w...  \n",
       "401  pandorabots-blog\\nOct 9, 2014\\nSuppose you are building an Intelligent Virtual Agent or Virtual Personal Assistant (VPA) that uses a Pandorabot as the natural language processing engine. You might want this VPA to be able to perform tasks such as sending a text message, adding an event to a calendar, or even just initiating a phone call. OOB tags allow you to do just that!\\nOOB stands for “out of band,” which is an engineering term used to refer to activity performed on a separate, hidden channel. For a Pandorabot VPA, this translates to activities which fall outside of the scope of an ordinary conversation, such as placing a phone call, checking dynamic information like the weather, or searching wikipedia for the answer to some question. The task is executed, but does not necessarily ...  \n",
       "402  DataX Journal\\nFeb 1, 2021\\nHow attention-based mechanism completely transformed the working of neural machine translations while exploring contextual relations in sequences!\\nWhen it comes to applying deep learning principles to natural language processing, contextual information weighs in a lot! In the past few years, it has been shown that various improvement in existing neural network architectures concerned with NLP has shown an amazing performance in extracting featured information from textual data and performing various operations for a day to day life. One of the models which we will be discussing in this article is encoder-decoder architecture along with the attention model.\\nThe encoder-decoder architecture for recurrent neural networks is actually proving to be powerful for...  \n",
       "403  Towards Data Science\\nMar 4, 2019\\nIn this article, I’ll go over:\\nThis article got longer that what I originally intended, so for the busy souls, here is a synopsis.\\nExplanations for AI behavior that are generated Ad-hoc or post-hoc are more like justifications and may not be capture the truth of the decision process. If trust and accountability is needed, that has to be taken into account early on in the design process. Explainable AI (XAI )is NOT an AI that can explain itself, it is a design decision by developers. It is AI that is transparent enough so that the explanations that are needed are part of the design process.\\nNow, the full story.\\nA self driving car knocked down and killed a pedestrian in Tempe, AZ in 2018. Issues like who is to blame (accountability), who to prevent ...  \n",
       "404  Towards Data Science\\nJun 19, 2019\\nThis blog will cover following questions and topics\\n1. What is Perceptron?\\n2. Stochastic Gradient Descent for Perceptron\\n3. Implementation in Python\\n1. What is Perceptron?\\nPerceptron set the foundations for Neural Network models in 1980s. The algorithm was developed by Frank Rosenblatt and was encapsulated in the paper “Principles of Neuro-dynamics: Perceptrons and the Theory of Brain Mechanisms” published in 1962. At that time, Rosenblatt’s work was criticized by Marvin Minksy and Seymour Papert, arguing that neural networks were flawed and could only solve linear separation problem. However, such limitation only occurs in the single layer neural network.\\nPerceptron can be used to solve two-class classification problem. The generalized form of...  \n",
       "405  Gab41\\nDec 13, 2015\\nIf you follow any of the popular blogs like Google’s research, FastML, Smola’s Adventures in Data Land, or one of the indie-pop ones like Edwin Chen’s blog, you’ve probably also used ModelZoo. Actually, if you’re like our boss, you affectionately call it “The Zoo”. (Actually x 2, if you have interesting blogs that you read, feel free to let us know!)\\nUnfortunately, ModelZoo is only supported in Caffe. Fortunately, we’ve taken a look at the difference between the kernels in Keras, Theano, and Caffe for you, and after reading this blog, you’ll be able to load models from ModelZoo into any of your favorite Python tools.\\nWhy this post? Why not just download our Github code?\\nIn short, it’s better you figure out how these things work before you use them. That way, you...  \n",
       "406  Towards Data Science\\nSep 21, 2018\\nUnderstand the basic goto concepts to get a quick start on reinforcement learning and learn to test your algorithms with OpenAI gym to achieve research centric reproducible results.\\nThis article first walks you through the basics of reinforcement learning, its current advancements and a somewhat detailed practical use-case of autonomous driving. After that we get dirty with code and learn about OpenAI Gym, a tool often used by researchers for standardization and benchmarking results. When the coding section comes please open your terminal and get ready for some hands on.A time saver tip: You can directly skip to ‘Conceptual Understanding’ section if you want to skip basics and only want try out Open AI gym directly.\\nMainly three categories of learn...  \n",
       "407  Nov 23, 2017\\nHatırlarsınız, önce 1997’de DeepMind’ın bilgisayarı Deep Blue Kasparov’u satrançta yenmişti. Bir sonraki adımdaysa AlphaGo önce dünya Go şampiyonu Ke Jie’yi, sonrasında da bir üst model AlphaGo Zero en iyi Go oyuncularından biri sayılan Lee Sedol’u 2016’da 3 kez yendi. Şimdi yeni adımın StarCraft olacağı söyleniyor; ki bilen bilir StarCraft koordinasyon, hızlı karar alma, dikkat olarak epey zorlayıcı bir oyundur. AlphaGo bütün bunları Reinforcement Learning (Pekiştirmeli Öğrenme) ile yaptı.\\nPekiştirmeli Öğrenme, Makine Öğrenmesi’nin alt kollarından biri. Makine Öğrenmesi’nde genellikle Markov Karar Süreci adı verilen bir model kullanılıyor. Bu model yapay zekânın önceden bilgilendirilmesine ve yönlendirilmesine dayalı. Kesin bir neden sonuç ili...  \n",
       "408  Capire.info\\nJun 18, 2008\\nEscribe Jorge Garrido G.\\nAlgunas sugerencias sobre cómo construir un menú que entregue orientación y control al usuario, sin perder claridad en su forma de presentarse.¿Qué es un menú? ¿Qué representa? ¿Qué comunica? ¿Para qué sirve? ¿Todo sitio web o aplicación debe tener un menú?\\nLas respuestas no son tan sencillas ni están tan claras; mucho menos se puede considerar este como un tema superado. No lo creo por lo que percibo cuando navego, periódicamente. Veo menús poco cuidados, incomprendidos, mal diseñados, desenfocados.\\nHay muchos otros recursos, fuera de los menús de navegación, para destacar los contenidos más importantes: Accesos directos con características gráficas sobresalientes, listados de hotlinks, nubes de tags y un largo ...  \n",
       "409  Towards Data Science\\nNov 6, 2020\\nIt’s not as hard as you think!\\nTl;dr if you want to skip the tutorial. Here is the notebook I created.\\nAdam is algorithm the optimizes stochastic objective functions based on adaptive estimates of moments. The update rule of Adam is a combination of momentum and the RMSProp optimizer.\\nThe rules are simple. Code Adam from scratch without the help of any external ML libraries such as PyTorch, Keras, Chainer or Tensorflow. Only libraries we are allowed to use arenumpy and math .\\n(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ\\nThe easiest way to learn how Adam’s works is to watch Andrew Ng’s video. Alternatively, you can read Adam’s original paper to get a better understanding of the motivation and intuition behind it.\\nTwo values that Adam depend on are ...  \n",
       "410  Towards AI\\nJun 3, 2020\\nAuthor(s): Pratik Shukla, Roberto Iriondo, Sherwin Chen\\nLast updated April 14, 2021\\nmembers.towardsai.net\\nMachine learning (ML) is rapidly changing the world, from diverse types of applications and research pursued in industry and academia. Machine learning is affecting every part of our daily lives. From voice assistants using NLP and machine learning to make appointments, check our calendar, and play music, to programmatic advertisements — that are so accurate that they can predict what we will need before we even think of it.\\nMore often than not, the complexity of the scientific field of machine learning can be overwhelming, making keeping up with “what is important” a very challenging task. However, to make sure that we provide a learning path to those ...  \n",
       "411  HackerNoon.com\\nMay 31, 2014\\nWhen it comes to function minimization, it’s time to open a book of optimization and linear algebra. I am currently working on variable selection and lasso-based solutions in genetics. What lasso does is basically minimizing the loss function and an penalty in order to set to zero some regression coefficients and select only those covariates that are really associated with the response. Pheew, the shortest summary of lasso ever!\\nWe all know that, provided the function to be minimized is convex, a good direction to follow, in order to find a local minimum, is towards the negative gradient of the function. Now, my question is how good or bad is following the negative gradient with respect to a coordinate descent approach that loops across all dimensions and...  \n",
       "412  HackerNoon.com\\nOct 4, 2016\\nTLDR — Use pipelines to save TF-IDF model generated from the training set, and SVM model for prediction. So essentially save two models, one for feature extraction and transformation of input, the other for prediction.\\nOne of the big challenges when you develop a text classification model, the trained model which you get is not enough for prediction if your plan was to train offline and deploy only the model for prediction in some cases. Especially in the case where we are extracting features from the training set using `Hashing Trick` and to normalise the importance of a feature/term to the document using `Inverse Document Frequency`, the most frequent terms in documents actually have lesser importance to the whole corpus. This is all commonly labelled ac...  \n",
       "413                                                                                                                                                                                                                                                                                                                                                                                                                                   MLearning.ai\\nMar 4, 2021\\n4 \\n4 \\nData Scientists must think like an artist when finding a solution when creating a piece of code. ⚪️ Artists enjoy working on interesting problems, even if there is no obvious answer ⚪️ linktr.ee/mlearning 🔵 Follow to join our 18K+ Unique DAILY Readers 🟠\\n36 Followers\\nData.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "414  Towards Data Science\\nJul 27, 2020\\nToday, internet and social media have become the fastest and easiest ways to get information. In this age, reviews, opinions, feedbacks, messages and recommendations have become significant source of information. Thanks to advancement in technologies, we are now able to extract meaningful information from such data using various Natural Language Processing (NLP) techniques. NLP , a branch of Artificial Intelligence (AI), makes use of computers and human natural language to output valuable information. NLP is commonly used in text classification task such as spam detection and sentiment analysis, text generation, language translations and document classification.\\nThe purpose of this article is to understand how we can use TensorFlow2 to build SMS spa...  \n",
       "415  Towards Data Science\\nSep 3, 2020\\nThe classical way of doing POS tagging is using some variant of Hidden Markov Model. Here we'll see how we could do that using Recurrent neural networks. The original RNN architecture has some variants too. It has a novel RNN architecture — the Bidirectional RNN which is capable of reading sequences in the ‘reverse order’ as well and has proven to boost performance significantly.\\nThen two important cutting-edge variants of the RNN which have made it possible to train large networks on real datasets. Although RNNs are capable of solving a variety of sequence problems, their architecture itself is their biggest enemy due to the problems of exploding and vanishing gradients that occur during the training of RNNs. This problem is solved by two popular ga...  \n",
       "416                                                                                                                                                                                                                                            Geek Culture\\nMay 6, 2021\\nThis post will learn to create a DCGAN using PyTorch on the MNIST dataset.\\nA basic understanding of CNN\\nA sample implementation using CNN\\nUnderstanding Deep Convolutional GAN\\nGANs were invented by Ian Goodfellow in 2014 and first described in the paper Generative...\\n3 \\n3 \\n1\\nA new tech publication by Start it up (https://medium.com/swlh).\\n3.7K Followers\\nLoves learning, sharing, and discovering myself. Passionate about Machine Learning and Deep Learning\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "417  Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...  \n",
       "418  Mar 18, 2018\\nYou only look once (YOLO) is an object detection system targeted for real-time processing. We will introduce YOLO, YOLOv2 and YOLO9000 in this article. For those only interested in YOLOv3, please forward to the bottom of the article. Here is the accuracy and speed comparison provided by the YOLO web site.\\nA demonstration from the YOLOv2.\\nLet’s start with our own testing image below.\\nThe objects detected by YOLO:\\nGrid cell\\nFor our discussion, we crop our original photo. YOLO divides the input image into an S×S grid. Each grid cell predicts only one object. For example, the yellow grid cell below tries to predict the “person” object whose center (the blue dot) falls inside the grid cell.\\nEach grid cell predicts a fixed number of boundary boxes. In this example, the ye...  \n",
       "419  Towards Data Science\\nMar 30, 2020\\nThis article is a detailed account of my approach to solving a regression problem, which is also a popular Kaggle competition. Hope you find it useful and enjoy reading it :)\\nArtificial Intelligence is an integral part of all major e-commerce companies today. With the evolution of the information industry and extensive research in the field of AI in the past two decades, businesses have started to explore the ways to automate various activities using state of the art Machine Learning algorithms and Deep Neural Networks. Many IT giants and start-ups have already taken a big leap in this field and have dedicated teams and resources for research and development of cutting edge AI applications. Online retail platforms today are extensively driven by AI-...  \n",
       "420                                                                                                  The Startup\\nAug 13, 2020\\nI first came across the concept of embeddings while developing the RNN typing practice app.\\nEven though I am just beginning to understand the range of uses for embeddings, I thought it would be useful to write down some of the basics.\\nFirst, let’s look at what I knew before embeddings, one-hot vectors.\\n52 \\n52 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n13 Followers\\nMy goal is to serve humanity and to bring happiness to others. I want to understand the problems around us and help find solutions. https://www.bayanbennett.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "421  Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...  \n",
       "422  Feb 5, 2019\\nAttention mechanism for sequence modelling was first introduced in the paper: Neural Machine Translation by jointly learning to align and translate, Bengio et. al. ICLR 2015. Even though the paper itself mentions the word “attention” scarcely (3 times total in 2 consecutive lines!!) the term has caught on. A lot of prominent work that came later on uses the same naming convention (Well, I for one think it’s more of a “soft memory” rather than “attention”).\\nThis post focuses on Bengio et. al. 2015 and tries to give a step by step explanation of the (attention) model explained in their paper. Probably it’s just me but the explanation given in the paper and the diagrams that came with it left a lot to the imagination. This post tries to make understanding their great work a ...  \n",
       "423  Towards Data Science\\nApr 23, 2019\\nThis post was co-written with Baptiste Rocca.\\n“Unity is strength”. This old saying expresses pretty well the underlying idea that rules the very powerful “ensemble methods” in machine learning. Roughly, ensemble learning methods, that often trust the top rankings of many machine learning competitions (including Kaggle’s competitions), are based on the hypothesis that combining multiple models together can often produce a much more powerful model.\\nThe purpose of this post is to introduce various notions of ensemble learning. We will give the reader some necessary keys to well understand and use related methods and be able to design adapted solutions when needed. We will discuss some well known notions such as boostrapping, bagging, random forest, bo...  \n",
       "424  Analytics Vidhya\\nApr 2, 2021\\nReference How to Implement Naive Bayes? Section 2: Building the Model in Python, prior to continuing...\\n[10] Define Grid Search Parameters\\nWhy this step: To set the selected parameters used to find the optimal combination. By referencing the sklearn.naive_bayes.GaussianNB documentation, you can find a completed list of parameters with descriptions that can be used in grid search functionalities.\\n[11] Hyperparameter Tune using Training Data\\nNote: Total number of fits is 1000 since the cv is defined as 10 and there are 100 candidates (var_smoothing has 100 defined parameters). Therefore, the calculation for a total number of fits → 10 x [100] = 1000.\\nWhy this step: To find an optimal combination of hyperparameters that minimizes a predefined loss funct...  \n",
       "425  AI3 | Theory, Practice, Business\\nSep 22, 2019\\nR-CNN & Fast R-CNN\\nFollowing part1, an object-detection-algorithm has to draw up to several bounding boxes representing different objects of interest within the image and you would not know how many beforehand.\\nA direct approach (brut force) to solve this issue would be to take different regions of interest from the image and use a CNN to classify the presence of the object within that region. The problem here, the objects of interest might have different spatial locations within the image and different aspect ratios. Hence, you would have to select a huge number of regions and this could computationally hard (increasingly hard). Therefore, algorithms like R-CNN, YOLO, etc have been developed to find these occurrences and find them fast...  \n",
       "426  MLearning.ai\\nMay 6, 2021\\nR-CNN architecture is used to detect the classes of objects in the images and the bounding boxes of these objects. RCNN architecture has been developed since classification cannot be made for more than one object with CNN in visuals containing more than one object.\\nThe general working principle of R-CNN takes place in two steps. First, the features where the object can be found in the visual are determined with selective search, then after the regions are determined, each region is given as an input to a CNN model and the prediction process is performed for classes and bounding boxes.\\nSelective Search:\\nIt is used to determine the regions on the image that should be captured. Small areas are determined first. Then, similar regions are combined to create lar...  \n",
       "427  Towards Data Science\\nJul 14, 2019\\nMachine learning is exciting. However, just like any new technology or invention, not only does ML enable new amazing capabilities — but also, unfortunately, new vulnerabilities.\\nPreviously I’ve discussed how to think about these vulnerabilities in a structured way (or how to develop a “threat model” for your ML). This time I’d like to dive deep into how your ML system can be exploited during inference time through what is known as an evasion attack.\\nWith no time to waste, let’s get started.\\nAn evasion attack happens when the network is fed an “adversarial example” — a carefully perturbed input that looks and feels exactly the same as its untampered copy to a human — but that completely throws off the classifier.\\nDespite all the hype around adver...  \n",
       "428  Aug 5, 2021\\nIn many organizations, there is a unique vocabulary that maps names to known entities within that domain. At the United Nations, for instance, we have many specific entities which it is useful to identify in documents, including specific named committees and assemblies, important topics like the Sustainable Development Goals (SGDs), and many different countries and cultural groups that must be identified correctly. Exhaustively naming each and every important topic that may appear in a document, however, is not reasonable considering the shear number that may be important, especially considering the context of a document or sentence in which this entity is present. Instead, we want to be able to automatically identify and predict named entities using Named Entity Recogniti...  \n",
       "429  ML Review\\nDec 9, 2017\\nSimplifying a complex algorithm\\nAlthough most of the Kaggle competition winners use stack/ensemble of various models, one particular model that is part of most of the ensembles is some variant of Gradient Boosting (GBM) algorithm. Take for an example the winner of latest Kaggle competition: Michael Jahrer’s solution with representation learning in Safe Driver Prediction. His solution was a blend of 6 models. 1 LightGBM (a variant of GBM) and 5 Neural Nets. Although his success is attributed to the semi-supervised learning that he used for the structured data, but gradient boosting model has done the useful part too.\\nEven though GBM is being used widely, many practitioners still treat it as complex black-box algorithm and just run the models using pre-built lib...  \n",
       "430  Towards Data Science\\nMar 18, 2019\\nOne of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it seemed to make sense. In this quick post I’ll discuss q-learning and provide the basic background to understanding the algorithm.\\nQ-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It’s considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn’t needed. More specifically, q-learning seeks to learn a policy that maximizes the total reward.\\nThe ‘q’ in q-learning stands for quali...  \n",
       "431  Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...  \n",
       "432  Blog rilut\\nJan 3, 2017\\nHere’s a quick summary on Arild Nøkland’s 2016 paper “Direct Feedback Alignment” which is not only written clearly but also interesting. Both Lillicrap et al. (2016) and Nøkland (2016) were able to train a Neural Network (NN) without Backpropagation.\\nFirst, create a simple NN like this:\\nwith cross-entropy as its loss function.\\nSo here is our implementation so far:\\nTo train a NN, we have to get the loss function derivative w.r.t to softmax function. Let’s take a look at Equation 5 from Nøkland’s paper.\\nwhich simply corresponds to:\\nI am sorry as I am not going to explain the Calculus behind this. Should you refer to Sadowski’s Notes on Backpropagation if you want the explanation.\\nThis is our implementation of Backpropagation:\\nWhere d1, d2, and ewill be us...  \n",
       "433  Clustering with Gaussian Mixture Model\\nDec 5, 2017\\nOne of the popular problems in unsupervised learning is clustering. Clustering is the assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense.\\nAs in above diagram the result of clustering is colouring of the squares into three clusters.\\nOne of the basic approach to solve cluster analysis problem is K-means. K-means algorithm partitioned the data into K clusters .\\nK means:\\nIn general, suppose we have n data points, that have to be partitioned in K clusters. The goal is to assign a cluster to each data point. K-means is a clustering method that aims to find the K positions of the clusters that minimize the distance(for example Euclidian distance) from the...  \n",
       "434  Analytics Vidhya\\nApr 26, 2021\\nThe success of a custom Named Entity Recognition (NER) model is dependent on the quality of data passed to it. However, supplying a model with sufficient examples of training data is typically a time-consuming and exhaustive process. Using Prodigy, the task of labeling your data for building a custom NER pipeline to a spaCy model is much quicker and simpler.\\nAccording to the official Prodigy site:\\nProdigy is a modern annotation tool for creating training and evaluation data for machine learning models. You can also use Prodigy to help you inspect and clean your data, do error analysis and develop rule-based systems to use in combination with your statistical models.\\nProdigy makes it easy to label your data to use in model training. For this overview, ...  \n",
       "435  Towards Data Science\\nSep 25, 2017\\nThe multi-armed bandit problem is a classic reinforcement learning example where we are given a slot machine with n arms (bandits) with each arm having its own rigged probability distribution of success. Pulling any one of the arms gives you a stochastic reward of either R=+1 for success, or R=0 for failure. Our objective is to pull the arms one-by-one in sequence such that we maximize our total reward collected in the long run.\\nThe non-triviality of the multi-armed bandit problem lies in the fact that we (the agent) cannot access the true bandit probability distributions — all learning is carried out via the means of trial-and-error and value estimation. So the question is:\\nHow can we design a systematic strategy that adapts to these stochastic re...  \n",
       "436  Towards Data Science\\nApr 28, 2020\\nUpdate:\\nInstance segmentation is a challenging computer vision task that requires the prediction of object instances and their per-pixel segmentation mask. This makes it a hybrid of semantic segmentation and object detection.\\nEver since Mask R-CNN was invented, the state-of-the-art method for instance segmentation has largely been Mask RCNN and its variants (PANet, Mask Score RCNN, etc). It adopts the detect-then-segment approach, first perform object detection to extract bounding boxes around each object instances, and then perform binary segmentation inside each bounding box to separate the foreground (object) and the background.\\nThere are some other instance segmentation methods other than the top-down approach of detect-then-segment (or segmen...  \n",
       "437  Towards Data Science\\nNov 3, 2021\\nThe ability to simplify means to eliminate the unnecessary so that the necessary may speak — Hans Hofmann\\nData compression is an essential phase in training a network. The idea is to compress the data so that the same amount of information can be represented by fewer bits. This also helps with the problem of the curse of dimensionality. A dataset with many attributes is different to train with because it tends to overfit the model. Hence dimensionality reduction techniques need to be applied before the dataset can be used for training.\\nThis is where the Autoencoder (AE) and Variational Autoencoder (VAE) come into play. They are end-to-end networks that are used to compress the input data. Both Autoencoder and Variational Autoencoder are used to tran...  \n",
       "438  Towards Data Science\\nNov 16, 2017\\nFor any service company that bills on a recurring basis, a key variable is the rate of churn. Harvard Business Review, March 2016\\nFor just about any growing company in this “as-a-service” world, two of the most important metrics are customer churn and lifetime value. Entrepreneur, February 2016\\nCustomer churn occurs when customers or subscribers stop doing business with a company or service, also known as customer attrition. It is also referred as loss of clients or customers. One industry in which churn rates are particularly useful is the telecommunications industry, because most customers have multiple options from which to choose within a geographic location.\\nSimilar concept with predicting employee turnover, we are going to predict customer c...  \n",
       "439  Towards Data Science\\nAug 12, 2019\\nI’m presenting an overview of important Graph Neural Network works, by distilling key ideas and explaining simple intuition behind milestone methods using Python and PyTorch. This post continues the first part of my tutorial.\\nIn the “Graph of Graph Neural Network (GNN) and related works” above, I added papers on graphs that I have come across in the last year. In this graph, a directed edge between two works denotes that one paper is based on the other (while not necessary citing it) and a color of the work denotes:\\nNote, that some other important works and edges are not shown to avoid further clutter, and only a tiny fraction of works, highlighted in bold boxes, will be covered in this post. Disclaimer: I still found room to squeeze our own recent...  \n",
       "440  Towards Data Science\\nSep 4, 2019\\nMachine learning is a hot topic right now and everyone is trying to get their hands on any information they can get about the topic. With the amount of information that is out there about machine learning, one can get overwhelmed. In this post, I have listed some of the most important topics in machine learning that you need to know, along with some resources which can help you in further reading about the topics which you are interested to know in-depth.\\nAI is a branch of computer science that aims to create intelligent machines that mimic human behaviour such as knowledge, reasoning, problem-solving, perception, learning, planning, ability to manipulate and move objects\\nAI is an area of computer science that emphasizes the creation of intelligent ...  \n",
       "441  Towards Data Science\\nOct 2, 2021\\nThere is a myriad of loss functions that you can choose for your neural network. The choice of loss function is imperative for the network’s performance because eventually the parameters in the network are going to be set such that the loss is minimized.\\nCross-Entropy loss is a popular choice if the problem at hand is a classification problem, and in and of itself it can be classified into either categorical cross-entropy or multi-class cross-entropy (with binary cross-entropy being a special case of the former.) In case you’re scratching your head about how different are these, I’ll try to introduce each before delving into the derivation.\\nLet’s start with categorical cross-entropy. For this loss function our y’s are one-hot encoded to denote the c...  \n",
       "442  Towards Data Science\\nJul 23, 2021\\nClustering is one of the most used unsupervised machine learning algorithms. You can think of clustering as putting unorganized data points into different categories so that you can learn more about the structures of your data. Clustering has a variety of applications in extracting information from data without labels. For example, companies cluster customers based on their characteristics, like purchasing behaviors, to make better market campaigns, to set pricing strategies to make more profit, etc. Clustering algorithms are also widely used in natural language processing (NLP) to extract information from unstructured textual data, and topic modeling is one example.\\nThe series of articles aims to provide readers with a thorough view of two common b...  \n",
       "443  Towards Data Science\\nJun 14, 2020\\nDuring our school days, most of us would have encountered the reading comprehension section of our English paper. We would be given a paragraph or Essay based on which we need to answer several questions.\\nHow do we as humans approach this task at hand? We go through the entire text, make sense of the context in which the question is asked and then we write answers. Is there a way we can use AI and deep learning techniques to mimic this behavior of us?\\nAutomatic text summarization is a common problem in machine learning and natural language processing (NLP). There are two approaches to this problem.\\n2. Abstractive Summarization-Abstractive text summarization, on the other hand, is a technique in which the summary is generated by generating novel se...  \n",
       "444  Aug 26, 2016\\nI release MATLAB, R and Python codes of Linear Discriminant Analysis (LDA). They are very easy to use. You prepare data set, and just run the code! Then, LDA and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/uVtRo Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/bZPL Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/JHFt Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univp...  \n",
       "445  Intuition Machine\\nOct 22, 2017\\nSelf-play is Automated Knowledge Creation\\nThe 1983 movie “War Games” has a memorable climax where the supercomputer known as WOPR (War Operation Plan Response) is asked to train on itself to discover the concept of an un-winnable game. The character played by Mathew Broderick asks “Is there any way that it can play itself?”\\n34 years later, DeepMind has shown how this is exactly done in real life! The solution is the same, set the number of players to zero (i.e. zero humans).\\nThere is plenty to digest about this latest breakthrough in Deep Learning technology. DeepMind authors use the term “self-play reinforcement learning”. As I remarked in the piece about “Tribes of AI”, DeepMind is particularly fond of their Reinforcement Learning (RL) approach. De...  \n",
       "446  Sep 3, 2018\\nSegmentasi citra merupakan bagian dari proses pengolahan citra. Segmentasi citra (image segmentation) mempunyai arti membagi suatu citra menjadi wilayah-wilayah yang homogen berdasarkan kriteria keserupaan tertentu antara suatu piksel dengan piksel — piksel tetangganya, kemudian hasil dari proses segmentasi ini akan digunakan untuk proses tingkat tinggi lebih lanjut yang dapat dilakukan terhadap suatu citra, misalnya proses klasifikasi citra dan proses identifikasi objek.\\nSegmentasi semantik adalah proses klasifikasi setiap piksel dari sebuah citra sebagai sebuah label kelas untuk memahami citra dalam tingkat per piksel. Label kelas yang yang dimaksud adalah kelas objek, seperti rumah, buku, manusia, dan lain-lain.\\nSelain mengenali dan membedakan pengendara dan motor, se...  \n",
       "447  Dec 5, 2019\\nWhat is RNN?\\nRecurrent Neural Network is basically a generalization of feed-forward neural network that has an internal memory. RNNs are a special kind of neural networks that are designed to effectively deal with sequential data. This kind of data includes time series (a list of values of some parameters over a certain period of time) text documents, which can be seen as a sequence of words, or audio, which can be seen as a sequence of sound frequencies over time.RNN is recurrent in nature as it performs the same function for every input of data while the output of the current input depends on the past one computation. For making a decision, it considers the current input and the output that it has learned from the previous input.\\nCells that are a function of inputs fro...  \n",
       "448  Aug 5, 2015\\nIn “Puppyslugs ‘R Us: Part 0”, I started out quite cheekily on a topic I hope to explore here in a bit more serious detail.\\nI am going to start with the recent Google “DeepDream” release and the so-called Puppyslug images you’ve likely encountered, explaining roughly what those are and how they come to be. I will connect that to AI and algorithms in general and then move specifically to how they already appear in your everyday mobile experience. From there we can paint a picture of what’s in store for us, and why I say... the Puppyslugs are Us. I’ll conclude by setting up Part 2, and how all of this lands squarely in the lap of Design to deal with.\\nPuppyslugs. Quick background:\\nAbout two months ago (early June 2015), Google Researchers start showing off some algorithmic...  \n",
       "449                                                                                                                                                                                                                                                                                                                                                                                                   AI Salon\\nJan 8, 2020\\nConvolution neural networks (CNN) are broadly used in deep learning and computer vision algorithms. Even though many CNN-based algorithms meet industry standards and can be embedded in commercial products...\\n422 \\n422 \\n1\\nA tea drinking place to talk about AI\\n198 Followers\\nMachine learning engineer based in Tokyo\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "450  Towards Data Science\\nNov 2, 2018\\nIn my last post, we trained a convnet to differentiate dogs from cats. We trained the convnet from scratch and got an accuracy of about 80%. Not bad for a model trained on very little dataset (4000 images).\\nBut in real world/production scenarios, our model is actually under-performing.\\nAlthough we suggested tuning some hyperparameters — epochs, learning rates, input size, network depth, backpropagation algorithms e.t.c — to see if we could increase our accuracy.\\nWell, I did try...\\nAnd truth is, after tuning, re-tuning, not-tuning , my accuracy wouldn’t go above 90% and at a point It was useless.\\nOf course having more data would have helped our model; But remember we’re working with a small dataset, a common problem in the field of deep learning.\\...  \n",
       "451  Analytics Vidhya\\nFeb 12, 2021\\nThe article contains the introduction of StyleGAN and StyleGAN2 architecture which will give you an idea. It may help you to start with StyleGAN. You will find some metric or the operations name which you don’t know, to gain a deep understanding of StyleGAN and StyleGAN2 you can go through the paper whose link is provided in the resources section.\\nLet’s start with the StyleGAN and then we move towards StyleGAN 2.\\nThe major changes they have done in the Generator part of the “Progressive Growing of GANs” architecture. Below you can see both the traditional and the style-based generator (new one or StyleGAN network) network.\\nIn the traditional network, latent vectors directly pass into the block just after the normalization whereas in the StyleGAN netwo...  \n",
       "452  Mar 7, 2018\\nAP (Average precision) is a popular metric in measuring the accuracy of object detectors like Faster R-CNN, SSD, etc. Average precision computes the average precision value for recall value over 0 to 1. It sounds complicated but actually pretty simple as we illustrate it with an example. But before that, we will do a quick recap on precision, recall, and IoU first.\\nPrecision & recall\\nPrecision measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\\nRecall measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions.\\nHere are their mathematical definitions:\\nFor example, in the testing for cancer:\\nIoU (Intersection over union)\\nIoU measures the overlap between ...  \n",
       "453  Jul 8, 2020\\nGuide made for EarnSkins users, by JaxStart the offer now at www.earnskins.gg to earn some side money!Use referral code ‘wolf’ to get yourself a free 50 points to start with.\\nUPDATE: The offer is currently to finish Level 34, this strategy still works, tested and confirmed, however it takes a bit longer now.\\nVideo Guide: https://youtu.be/AIEBGMRPe7I\\nThe POP! Slots offer is a casino/slots based app offer that exists for both iOS and Android phones. The offer required me to reach level 27 in the app, which was easily obtainable and you can automate it really easy making the time spent actually doing anything is extremely low.\\nThere’s three different types of this offer that I’m aware of. One requires you to reach level 27, one level 26 while the last one requires you to ...  \n",
       "454  Oct 3, 2018\\nPart 1 https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-1-d332e85e9aad\\nChinese Version https://medium.com/%40bgg/seq2seq-pay-attention-to-self-attention-part-2-%E4%B8%AD%E6%96%87%E7%89%88-ef2ddf8597a4\\nWe have talked about Seq2seq and Attention model in the first part. In this part, I will be focusing on Self attention, proposed by Google in the paper “Attention is all you need”. Self attention is the concept of “The transformer”model, which outperforms the attention model in various tasks. Two main concepts of the “transformer” model are “self attention” and “multi-head”.\\nThe biggest advantage comes from how The Transformer lends itself to parallelization and self attention.\\nHope you enjoy it.\\nI will use the figure in part 1 as a quick overview. We...  \n",
       "455  Towards Data Science\\nApr 10, 2019\\nTransformers (specifically self-attention) have powered significant recent progress in NLP. They have enabled models like BERT, GPT-2, and XLNet to form powerful language models that can be used to generate text, translate text, answer questions, classify documents, summarize text, and much more. With their recent success in NLP one would expect widespread adaptation to problems like time series forecasting and classification. After all, both involve processing sequential data. However, to this point research on their adaptation to time series problems has remained limited. Moreover, while some results are promising, others remain more mixed. In this article, I will review current literature on applying transformers as well as attention more broadly ...  \n",
       "456  Towards Data Science\\nMay 26, 2020\\nAfter learning and applying several supervised ML algorithms like least square regression, logistic regression, SVM, decision tree etc. most of us try to have some hands-on unsupervised learning by implementing some clustering techniques like K-Means, DBSCAN or HDBSCAN.\\nWe usually start with K-Means clustering. After going through several tutorials and Medium stories you will be able to implement k-means clustering easily. But as you implement it, a question starts to bug your mind: how can we measure its goodness of fit? Supervised algorithms have lots of metrics to check their goodness of fit like accuracy, r-square value, sensitivity, specificity etc. but what can we calculate to measure the accuracy or goodness of our clustering technique? The a...  \n",
       "457  Towards Data Science\\nJul 4, 2021\\nIn a business context: Clustering algorithm is a technique that assists customer segmentation which is a process of classifying similar customers into the same segment. Clustering algorithm helps to better understand customers, in terms of both static demographics and dynamic behaviors. Customer with comparable characteristics often interact with the business similarly, thus business can benefit from this technique by creating tailored marketing strategy for each segment.\\nIn a data science context: Clustering algorithm is an unsupervised machine learning algorithm that discovers groups of data points that are closely related. The fundamental difference between supervised and unsupervised algorithm is that:\\nAfter giving an overview of what is cluster...  \n",
       "458  Towards Data Science\\nDec 3, 2021\\nHow to train a neural net for semantic segmentation in less than 50 lines of code (40 if you exclude imports). The goal here is to give the fastest simplest overview of how to train semantic segmentation neural net in PyTorch using the built-in Torchvision neural nets (DeepLabV3).\\nCode is available: https://github.com/sagieppel/Train-Semantic-Segmentation-Net-with-Pytorch-In-50-Lines-Of-Code\\nThe goal is semantic segmentation is to take images and identify regions belonging to specific classes. This is done by processing the image through a convolution neural network that outputs a map with a class per pixel. The classes are given as a set of numbers. For example, in this case, we will use the LabPics V1 dataset with three classes (shown in the figur...  \n",
       "459  Towards Data Science\\nOct 28, 2021\\nMany real-world applications of Machine Learning involve making predictions about the outcomes of a group of related variables based on historical context. We might want to forecast the traffic conditions on connected roads, the weather at nearby locations, or the demand for similar products. By modeling multiple time series together, we hope that changes in one variable may reveal key information about the behavior of related variables. Multivariate Time Series Forecasting (TSF) datasets have two axes of difficulty: we need to learn temporal relationships to understand how values change over time and spatial relationships to know how variables impact one another.\\nPopular statistical approaches to TSF can struggle to interpret long context sequences...  \n",
       "460  Towards Data Science\\nApr 4, 2020\\nThis is a post on the usage of a library for Deep Bayesian Learning. If you are new to the theme, you may want to seek one of the many posts on medium about it or just the documentation section on Bayesian DL of our lib repo.\\nAs there is a rising need for gathering uncertainty over neural network predictions, using Bayesian Neural Network layers became one of the most intuitive approaches — and that can be confirmed by the trend of Bayesian Networks as a study field on Deep Learning.\\nIt occurs that, despite the trend of PyTorch as a main Deep Learning framework (for research, at least), no library lets the user introduce Bayesian Neural Network layers intro their models with as ease as they can do it with nn.Linear and nn.Conv2d, for example.\\nLogic...  \n",
       "461  GradientCrescent\\nFeb 4, 2019\\nIntroduction\\nOver the past five years, neural networks have received attention through AI-generated art pieces, whether these be paintings, poetry, or music. During October of last year, an AI-generated art piece sold for over $400,000 at an auction at Christie’s, sparking debate and discussion over the intrinsic value and nature of art generated by machines.\\nWhile most of these mentioned art pieces were original pieces generated through Generative Adversarial Networks (GAN’s, which we will discuss in a future tutorial), apps such as PRISMA have been receiving attention for being able to apply the styles of famous paintings to one’s own photos. The concept, known as neural style transfer (henceforth NST), was first introduced in a paper by Leon Gatys et...  \n",
       "462  The Ezra Tech Blog\\nMar 4, 2021\\nEmbeddings are an important component of natural language processing pipelines. They refer to the vector representation of textual data. You can think of embeddings as a transformation from human-readable text to computer-readable numbers or vectors as seen in Fig. 1. These embeddings can be used in any machine learning task that takes text as the input, e.g. question answering, classification, text generation.\\nDifferent embedding techniques vary in their complexity and capabilities. For instance, the most simple form of word embeddings can be represented with one-hot encodings where each word in the corpus of size V is mapped to a unique index in a vector of the same size. This gives us a vector of all zeros except for one element that indicates the w...  \n",
       "463  NYT Open\\nSep 30, 2013\\nBy RILEY DAVIS and DAVID SOUTHER\\nRiley Davis and David Souther collaborated on EQuake, a 3D earthquake visualizer they developed in about a day. They discuss their motivations and approach in this piece.\\nWe were inspired by this xkcd comic imagining a situation in which tweets about an earthquake spread faster than the earthquake’s seismic waves.\\nWe both like to make complex scientific information more accessible by tying it to scales that people already understand. We thought it would be interesting to plot waves from real earthquakes onto a globe to show how fast the waves actually travel through the crust. This tool could easily be used to map out tweets (or any other geographic data) when other earthquakes occurred. To implement this, we were able to use ...  \n",
       "464  Towards Data Science\\nJun 18, 2017\\nIntroduction:\\nThe work here presented is the result of a semester long independent research performed by Kenny Jones and Derrick Bonafilia (both Williams College 2017) under the guidance of Professor Andrea Danyluk. The code associated with this project can be found at https://github.com/rkjones4/GANGogh. Kenny and Derrick are both heading to Facebook next year as Software Engineers and hope to continue studying GANs in whatever capacity is available to them.\\nBackground:\\nGenerative Adversarial Networks (GANS) were introduced by Ian Goodfellow et. al. in a 2014 paper. GANs address the lack of relative success of deep generative models compared to deep discriminative models. The authors cite the intractable nature of the maximum likelihood estimatio...  \n",
       "465  Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...  \n",
       "466  Aug 4, 2019\\nI’m answering questions that AI/ML/CV people not familiar with graphs or graph neural networks typically ask. I provide PyTorch examples to clarify the idea behind this relatively new and exciting kind of model.\\nThe questions addressed in this part of my tutorial are:\\nTo answer them, I’ll provide motivating examples, papers and Python code making it a tutorial on Graph Neural Networks (GNNs). Some basic knowledge of machine learning and computer vision is expected, however, I’ll provide some background and intuitive explanation as we go.\\nFirst of all, let’s briefly recall what is a graph? A graph G is a set of nodes (vertices) connected by directed/undirected edges. Nodes and edges typically come from some expert knowledge or intuition about the problem. So, it can be a...  \n",
       "467  DataWeave\\nAug 4, 2015\\nWe have seen a steady increase in the number of smartphones and tablets since the last five years. Looking at the number of smartphones, tablets and now wearables ( smart watches and fitbits ) that are being launched in the mobiles market, we can truly call this ‘The Mobile Age’.\\nWe, at DataWeave, deal with millions of data points related to products which vary from electronics to apparel. One of the main challenges we encounter while dealing with this data is the amount of noise and variation present for the same products across different stores.\\nOne particular problem we have been facing recently is detecting whether a particular product is a mobile phone (smartphone) or a tablet. If it is mentioned explicitly somewhere in the product information or metadata...  \n",
       "468  Towards Data Science\\nJun 1, 2020\\nAs you may know, supervised machine learning consists in finding a function, called a decision function, that best models the relation between input/output pairs of data. In order to find this function, we have to formulate this learning problem into an optimization problem.\\nLet’s consider the following task: finding the best linear function that maps the input space, the variable X to the output space, the variable Y.\\nAs we try to model the relation between X and Y by a linear function, the set of functions that the learning algorithm is allowed to select is the following :\\nThe term b is the intercept, also called bias in machine learning. This set of functions is our hypothesis space.But how do we choose the values for the parameters a,b and how ...  \n",
       "469  Towards Data Science\\nOct 29, 2020\\nWhen we want to understand key information from specific documents, we typically turn towards keyword extraction. Keyword extraction is the automated process of extracting the words and phrases that are most relevant to an input text.\\nWith methods such as Rake and YAKE! we already have easy-to-use packages that can be used to extract keywords and keyphrases. However, these models typically work based on the statistical properties of a text and not so much on semantic similarity.\\nIn comes BERT. BERT is a bi-directional transformer model that allows us to transform phrases and documents to vectors that capture their meaning.\\nWhat if we were to use BERT instead of statistical models?\\nAlthough there are many great papers and solutions out there that ...  \n",
       "470  Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...  \n",
       "471  Towards Data Science\\nJun 4, 2019\\nUsage of facial recognition is on the rise. With the recent debates over the ethics of facial recognition potential adversarial attacks against facial detection have been on my mind. Facial recognition is being used everywhere from airports to social media. It seems to be near impossible to opt-out of having your face scanned.\\nAn ideal attack on facial detection would be an article of clothing that looks inconspicuous to the uninformed. With inspiration from the Hyperface project I decided to research and implement a wearable adversarial example. In this article I’ll detail the process of creating an adversarial image to fool a selected type of facial detection and how I implemented a practical example on a face mask.\\nThe first thing it’s important ...  \n",
       "472  Towards Data Science\\nDec 17, 2019\\nThe first version of the StyleGAN architecture yielded incredibly impressive results on the facial image dataset known as Flicker-Faces-HQ (FFHQ). The most impressive characteristic of these results, compared to early iterations of GANs such as Conditional GANs or DCGANs, is the high resolution (10242) of the generated images. In addition to resolution, GANs are compared along dimensions such as the diversity of images generated (avoiding mode collapse) and a suite of quantitative metrics comparing real and generated images such as FID, Inception Score, and Precision and Recall.\\nFrechet Inception Distance (FID) is one of the most common automated metrics used to evaluate images sampled from generative models. This metric is based on comparing activa...  \n",
       "473  Pankaj Mathur\\nApr 1, 2016\\nHere is a simple logistic regression model built with TensorFlow. We are using MNIST Image example data set which is provided by default with Tensorflow package.\\nHere are the hyperparameters we choose to run initial model:\\nWe achieved impressive 90.8% accuracy in 20 epochs with a learning rate of 0.01 by running simple logistic regression model build with Tensorflow on MNIST dataset.\\nI am using Conda to install TensorFlow. You might already have a TensorFlow environment, but please check below to make sure you have all the necessary packages. If you have never used Conda environments before, please go through my other tutorial What is Anaconda and Why should I bother about it?\\nAssuming you have conda install on your machine, please run the following comm...  \n",
       "474  Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...  \n",
       "475  Towards Data Science\\nJan 23, 2019\\nAlso known as outlier detection, anomaly detection is a data mining process used to determine types of anomalies found in a data set and to determine details about their occurrences. Automatic anomaly detection is critical in today’s world where the sheer volume of data makes it impossible to tag outliers manually. Auto anomaly detection has a wide range of applications such as fraud detection, system health monitoring, fault detection, and event detection systems in sensor networks, and so on.\\nBut I would like to apply anomaly detection to hotel room prices. The reason is somewhat selfish.\\nHave you had experience that, lets say, you travel to a certain destination for business regularly and you always stay at the same hotel. While most of the time...  \n",
       "476  Towards Data Science\\nMay 30, 2019\\nWord embedding is one of the most important techniques in natural language processing(NLP), where words are mapped to vectors of real numbers. Word embedding is capable of capturing the meaning of a word in a document, semantic and syntactic similarity, relation with other words. It also has been widely used for recommender systems and text classification. This tutorial will show a brief introduction of genism word2vec model with an example of generating word embedding for the vehicle make model.\\nWord2vec is one of the most popular technique to learn word embeddings using a two-layer neural network. Its input is a text corpus and its output is a set of vectors. Word embedding via word2vec can make natural language computer-readable, then further imp...  \n",
       "477  Towards Data Science\\nJan 8, 2019\\nAs more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\\nCertain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.\\nAs an example, Image 1 is the sigmoid function and its derivative. Note how when the inputs of the sigmoid function becomes larger or smaller (when |x| becomes bigger), the derivative becomes close to zero.\\nFor shallow network with only a few layers that use these activations, this isn’t a big problem. However, when more ...  \n",
       "478  Towards Data Science\\nNov 15, 2017\\nOne of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don’t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.\\nThe concept of balancing bias and variance, is helpful in understanding the phenomenon of overfitting.\\nmedium.com\\nOne of the ways of avoiding overfitting is using cross validation, that helps in estimating the error over test set, and in deciding what parameters work best for your model.\\nmedium.com\\nThis arti...  \n",
       "479  Towards Data Science\\nMay 23, 2021\\nThis article is part of the series that explains how different Machine Learning algorithms work and provides you a range of Python examples to help you get started with your own Data Science project.\\nWhile it is not always possible to categorize every algorithm perfectly, it is still beneficial to try and do so. The below interactive chart is my attempt to help you see the broader universe of Machine Learning.\\nMake sure to click👇 on different categories to enlarge and reveal more.\\nNote, in many cases, the same algorithm can be used to solve multiple types of problems. E.g., one can use Neural Networks for classification, regression, and as part of the reinforcement learning.\\nIf you enjoy Data Science and Machine Learning, please subscribe to get ...  \n",
       "480  HackerNoon.com\\nAug 18, 2017\\nFrom this series:\\nIn the previous post I described the working environment and the basic code for clusterize points in the Poincaré ball space. Here I will improve that code transforming two loops to matrix operations.\\nI ended that post with a very promising plot about the speed improvement on a element-wise product of two vectors. So let’s detail it.\\nSuppose we have two arrays:\\nand we want to obtain as result an array where the elements are the element-wise multiplication of them:\\nWe can do it in two ways: with a loop over the elements, or with a vectorized operation. Now: what happens in terms of execution time? I did this calculations with arrays of different dimensions, ranging from 100.000 to 10.000.000.\\nIn the right plot you see the execution ...  \n",
       "481  Towards Data Science\\nDec 30, 2020\\nIn this article, we will see how to conduct Bayesian linear regression with PyMC3. If you got here without knowing what Bayes or PyMC3 is, don’t worry! You can use my articles as a primer\\nYou can view Bayesian linear regression as a more verbose version of standard linear regression. Linear regression gives you single values, for the model parameters as well as the predictions. Bayesian linear regression, in turn, gives you distributions.\\nWe will see what this exactly means in a second. Let us quickly introduce a simple dataset to be able to compare both linear regression approaches.\\nWe have done it all several times: Grabbing a dataset containing features and continuous labels, then shoving a line through the data, and call it a day. As a running...  \n",
       "482  Towards Data Science\\nJun 2, 2019\\nThis post was co-written with Joseph Rocca.\\nDuring the last few decades, with the rise of Youtube, Amazon, Netflix and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\\nIn a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy or anything else depending on industries).\\nRecommender systems are really critical in some industries as they can generate a huge amount of income wh...  \n",
       "483  Jul 4, 2020\\nIn this blog post we will provide a guide through for transfer learning with the main aspects to take into account in the process, some tips and an example implementation in Keras using ResNet50 as the trained model. The task is to transfer the learning of a ResNet50 trained with Imagenet to a model that identify images from CIFAR-10 dataset. Several methods were tested to achieve a greater accuracy which we provide to show the variety of options for a training. However with the final model of this blog we get an accuracy of 94% on test set.\\nLearning something new takes time and practice but we find it easy to do similar tasks. This is thanks to human association involved in learning. We have the capability to identify patterns from previous knowledge an apply it into new...  \n",
       "484                                                                                                                                                                                                                                                     OneZero\\nAug 20, 2020\\nFor years, A.I. research lab OpenAI has been chasing the dream of an algorithm that can write like a human.\\nIts latest iteration on that concept, a language-generation algorithm called GPT-3...\\n532 \\n532 \\n4\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n19.1K Followers\\nSenior Writer at OneZero covering surveillance, facial recognition, DIY tech, and artificial intelligence. Previously: Qz, PopSci, and NYTimes.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "485  Towards Data Science\\nJan 7, 2019\\nWe have seen Machine Learning as a buzzword for the past few years, the reason for this might be the high amount of data production by applications, the increase of computation power in the past few years and the development of better algorithms.\\nMachine Learning is used anywhere from automating mundane tasks to offering intelligent insights, industries in every sector try to benefit from it. You may already be using a device that utilizes it. For example, a wearable fitness tracker like Fitbit, or an intelligent home assistant like Google Home. But there are much more examples of ML in use.\\nIt was in the 1940s when the first manually operated computer system, ENIAC (Electronic Numerical Integrator and Computer), was invented. At that time the word ...  \n",
       "486  On Docker\\nMar 30, 2016\\nTL;DR Federated clustering overview with a focus on Swarm. Includes architecture diagrams and tools for building an experiment in AWS. Swarm’s API is a great building block that helps you create much more sophisticated deployment architectures or scale/diversify underlying infrastructure. Whale-Mullet is a Swarm fork I built to make the whole thing work.\\nDocker Swarm provides an abstraction that allows a user to treat a cluster like a single node. That is the case as long as the Swarm API is mostly compatible with the Docker API. This begs the question, “If I can treat a Swarm like a single machine can I create a Swarm of Swarm clusters?” This is called cluster federation. This article describes what how I tried to build a federated Swarm cluster, what problem...  \n",
       "487  Towards Data Science\\nApr 3, 2018\\nUnsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from “unlabeled” data (a classification or categorization is not included in the observations). Common scenarios for using unsupervised learning algorithms include:- Data Exploration- Outlier Detection- Pattern Recognition\\nWhile there is an exhaustive list of clustering algorithms available (whether you use R or Python’s Scikit-Learn), I will attempt to cover the basic concepts.\\nThe most common and simplest clustering algorithm out there is the K-Means clustering. This algorithms involve you telling the algorithms how many possible cluster (or K) there are in the dataset. The algorithm then iteratively moves the k-centers and selects the d...  \n",
       "488  Jun 8, 2018\\nAfter some promising results and tons of learning (summarized in my previous post) with a basic DC-GAN on CIFAR-10 data, I wanted to play some more with GANs. One issue with a traditional DC-GAN was that the data is expected to have similar properties in order for the training to converge properly. For instance, in case of CIFAR-10, training the DC-GAN on images of a single class was much easier and more likely to produce sharp images than training on all 10 classes. In that post on GAN learnings, I had casually mentioned Conditional GANs as an improvement over traditional GANs when the training data might come from different classes. This post describes how to setup a Conditional DC-GAN to generate images from all the classes of CIFAR-10 data.\\nGenerative Adversarial Netw...  \n",
       "489  Towards Data Science\\nSep 10, 2019\\nNote I focus on binary classification problems in this article, but the approach would be similar with multi classification and regression problems.\\nTry to convince someone that your ML model is accurate and should be trusted because it has a LogLoss of 0.34. Non data scientists will surely gawk at you while data scientists will ask for a lot more information.\\nAs a data scientist, you know it’s hard to make it clear (particularly to non data scientists) why your model should be trusted because you cannot easily translate complex measures of accuracy into tangible elements. And that’s 100% legitimate, models should be understood by everyone, at least their accuracy.\\nOn top of it, if your approach is scientifically correct, your model should have at...  \n",
       "490  Moonvision\\nApr 12, 2019\\nObject detection is vital to automate manual tasks, such as checking the completeness of objects and the exact types of its parts. In contrast to segmentation, objects are located and classified as discrete instances. This is achieved by decoding regression and activation maps after a cascade of convolutions. You can read more about state-of-the art in object detection in this survey.\\nHowever, contemporary issues in object detection are often studied in isolation. In production use cases though, multiple constraints must be solved at once. In this post, we describe the combination of techniques that we’ve developed over time that meet many of these constraints.\\nAs with any machine learning task, the amount of training data is limited. As we will review below...  \n",
       "491  Towards Data Science\\nJul 15, 2021\\nIn this article, I’m going to demonstrate how to use a trained model to detect objects in images and videos using two of the best libraries for this kind of problem. For the detection, we need a model capable of predicting multiple classes in an image and returning the location of those objects so that we can place boxes on the image.\\nWe are going to use a model from the Tensorflow Hub library, which has multiple ready to deploy models trained in all kinds of datasets and to solve all kinds of problems. For our use, I filtered models trained for object detection tasks and models in the TFLite format. This format is usually used for IoT applications, for its small size and faster performance than bigger models. I choose this format because I intend t...  \n",
       "492  Analytics Vidhya\\nApr 26, 2021\\nA logical and sequential roadmap to understanding the advanced concepts in training deep neural networks.\\nWe will break our discussion into 4 logical parts that build upon each other. For the best reading experience, please go through them sequentially:\\n1. What is Vanishing Gradient? Why is it a problem? Why does it happen?2. What is Batch Normalization? How does it help in Vanishing Gradient?3. How does ReLU help in Vanishing Gradient?4. Batch Normalization for Internal Covariate Shift\\nFirst, let’s understand what vanishing means:\\nVanishing means that it goes towards 0 but will never really be 0.\\nVanishing gradient refers to the fact that in deep neural networks, the backpropagated error signal (gradient) typically decreases exponentially as a func...  \n",
       "493  Towards Data Science\\nOct 22, 2020\\nThere is a lot of code going on under the hood. That’s why I provide my Github repository at the end of this post and I show just a little code of the K-Means.\\nClustering is an important technique in Pattern Analysis to identify distinct groups in data. Due to data being mostly more than three-dimensional, we perform dimensionality reduction methods like PCA or Laplacian Eigenmaps before applying a clustering technique. The data is then available in 2D or 3D and this allows us to visualize the found clusters very nicely to humans. Even though this is a basic workflow, it is not always the case.\\nData is also often unlabeled. This means you have no clear definition of what you want to find within this data. That’s why clustering is a good data explor...  \n",
       "494                                                                                                                                                                                                                                                                                     Dark Matter and Trojan Horses\\nDec 21, 2011\\nA chilly December night in 2011. I had been invited to take part in an evening event called the North House Salon, one of a series of salons...\\nArticles, cases and considerations regarding strategic design practice and thinking.\\n21K Followers\\nDesigner, urbanist, etc. Director of Strategic Design at Vinnova, Swedish govt. Prof. AHO Oslo, Visiting Prof. UCL Bartlett IIPP, Design Academy Eindhoven, RMIT\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n  \n",
       "495  Ensina.AI\\nMay 10, 2018\\nVocê já se perguntou como funcionam os sistemas de reconhecimento de imagem? Como um aplicativo do seu celular faz para detectar rostos, ou um teclado inteligente sugere a próxima palavra? As chamadas Redes Neurais tem sido amplamente usadas para tarefas como essas, mas mostraram-se úteis também em outras áreas, como aproximação de funções, previsão de séries temporais e processamento de linguagem natural.\\nNeste artigo, explico como funciona um tipo básico de Rede Neural, o Perceptron Multicamadas, e um fascinante algoritmo responsável pelo aprendizado da rede, o backpropagation. Tal modelo de rede serviu de base para os modelos mais complexos hoje existentes, como as Redes Convolucionais, que são o estado da arte para classificação de imagens...  \n",
       "496  Towards Data Science\\nAug 2, 2017\\nWe all face the problem of spams in our inboxes. Let’s build a spam classifier program in python which can tell whether a given message is spam or not! We can do this by using a simple, yet powerful theorem from probability theory called Baye’s Theorem. It is mathematically expressed as\\nWe have a message m = (w1, w2, . . . . , wn), where (w1, w2, . . . . , wn) is a set of unique words contained in the message. We need to find\\nIf we assume that occurrence of a word are independent of all other words, we can simplify the above expression to\\nIn order to classify we have to determine which is greater\\nWe are going to make use of NLTK for processing the messages, WordCloud and matplotlib for visualization and pandas for loading data, NumPy for generatin...  \n",
       "497  Insight\\nApr 16, 2014\\nJohn Joo is an Insight alumnus from the August 2013 session with a PhD in applied physics from Harvard. He recently joined Insight as a Program Director in January, leading the most recent cohort of Fellows in their transition from academia to industry.\\nWhen I was first considering making the transition from applied physics to data science, I had a lot of questions. What skills did I need to develop to get started in data science? What courses should I take? Did I need to know how to program and code? What languages? How much statistics did I need to know? The list goes on. Now that I’ve spent a few months as a Program Director here at Insight, I think it’s time I shared with you the tools and tips that got me, and nearly 100 other Insight Fellows, started on ou...  \n",
       "498  Altsoph’s blog\\nSep 16, 2010\\nВчера узнал, что сейчас идет Google AI Contest.\\nВ двух словах, задача состоит в написании логики бота, играющего в некоторый аналог игры Galcon — космической стратегии, основанной на разделении ресурсов. Прием ботов на конкурс идет до 27 ноября, а потом их будут стравливать и выявлять победителя. Языки доступны из списка C++, C#, Java, Python.\\nБыло бы времени побольше, я бы, наверное, поучавствовал.\\nВспоминаются стародавние времена, когда мы еще в школе рубились в RobotBattle, а потом на первом курсе с группой сотоварищей писали интерпретатор RedCode на придуманной нами модели тороидальной памяти (ToroWars).\\nRandom notes on people and machines\\n274 Followers\\nhttp://altsoph.com, Senior Data Analyst, Researcher.\\nHelp\\nStatus\\nWriters\\nBlog\\nCar...  \n",
       "499  HuggingFace\\nAug 28, 2019\\n2019, October 3rd — Update: We are releasing our NeurIPS 2019 workshop paper describing our approach on DistilBERT with improved results: 97% of BERT’s performance on GLUE (the results in the paper superseed the results presented here). The approach is slightly different from the one explained in this present blog post so this blog post should be a good entry point to the paper! We applied the same method to GPT2 and are releasing DistilGPT2! Training code and pre-trained weights for DistilBERT and DistilGPT2 are available here. 🤗\\nIn the last 18 months, transfer learning from large-scale language models has significantly improved upon the state-of-the-art on pretty much every Natural Language Processing task.\\nUsually based on the Transformer architecture of...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/content/drive/MyDrive/kaggle/articles/articles_test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7RbrbpnlWiz",
    "outputId": "d66289b2-d1ef-4e7b-f5f6-36c3f65a798c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claps']\n",
      "   claps\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n"
     ]
    }
   ],
   "source": [
    "test['claps'] = predictor.predict(test[['author','reading_time','title','text']])\n",
    "test['claps'] = test['claps'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00BF3jDwljip"
   },
   "outputs": [],
   "source": [
    "test[['id','claps']].to_csv('/content/drive/MyDrive/kaggle/articles/submissions4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yx-k2zPfltQD",
    "outputId": "fa452d4e-6a32-4046-bbe4-f19e0bd9e8bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0d6176f6-824c-47eb-ac24-f77b65c2b1c4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>claps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3756</td>\n",
       "      <td>Rohit Thakur</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/step-by-step-r-cnn-implementation-from-scratch-in-python-e97101ccde55?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Step-by-Step R-CNN Implementation From Scratch In Python | by Rohit Thakur | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 18, 2019\\nClassification and object detection are the main parts of computer vision. Classification is finding what is in an image and object detection and localisation is finding where is that object in that image. Detection is a more complex problem to solve as we need to find the coordinates of the object in an image.\\nTo Solve this problem R-CNN was introduced by Ross Girshick, Jeff Donahue, Trevor Darrell and Jitendra Malik in 2014. R-CNN stands for Regions with CNN. In R-CNN instead of running classification on huge number of regions we pass the image through selective search and select first 2000 region proposal from the result and run classification on that. In this way instead of classifying huge number of regions we need to just classify first 2000 r...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3757</td>\n",
       "      <td>Giuliano Giacaglia</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/transformers-141e32e69591?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How Transformers Work. Transformers are a type of neural... | by Giuliano Giacaglia | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 11, 2019\\nIf you liked this post and want to learn how machine learning algorithms work, how did they arise, and where are they going, I recommend the following:\\nwww.holloway.com\\nTransformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in their language models, and also used recently by DeepMind for AlphaStar — their program to defeat a top professional Starcraft player.\\nTransformers were developed to solve the problem of sequence transduction, or neural machine translation. That means any task that transforms an input sequence to an output sequence. This includes speech recognition, text-to-speech transformation, etc..\\nFor models to perform sequence transduction, it is necessary to...</td>\n",
       "      <td>3952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3758</td>\n",
       "      <td>Darshan Adakane</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3759</td>\n",
       "      <td>Sachin Palewar</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@palewar/amazons-artificial-artificial-intelligence-a5d89253184e?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Amazon’s Artificial Artificial Intelligence | by Sachin Palewar | Medium</td>\n",
       "      <td>Nov 21, 2005\\nToday, we build complex software applications based on the things computers do well, such as storing and retrieving large amounts of information or rapidly performing calculations. However, humans still significantly outperform the most powerful computers at completing such simple tasks as identifying objects in photographs — something children can do even before they learn to speak.When we think of interfaces between human beings and computers, we usually assume that the human being is the one requesting that a task be completed, and the computer is completing the task and providing the results. What if this process were reversed and a computer program could ask a human being to perform a task and return the results? What if it could coordinate many human beings to perfo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3760</td>\n",
       "      <td>SDGCounting</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/sdg-counting/this-week-in-the-sdgs-february-17-2017-d88bc4d62dac?source=tag_archive---------0-----------------------</td>\n",
       "      <td>This week in the #SDGs- February 17, 2017 | by SDGCounting | SDG Counting | Medium</td>\n",
       "      <td>SDG Counting\\nFeb 17, 2017\\n1 . IISD provided context to news that the report of the 48th Statistical Commission (coming up March 7th-10th in New York) intends to include a draft resolution on the global indicator framework for the UN Economic and Social Council (ECOSOC) and the UN General Assembly to adopt. Last year, through the 47th Statistical Commission, the global indicator framework was agreed upon as a starting point and “taken note of by ECOSOC” in June 2016. A formal adoption would mean that methodology standards for indicator review and revision would be followed, as well as coming closer to the acceptance of all 230 indicators by all member states.\\nsdg.iisd.org\\n2. The Global Festival of Ideas for Sustainable Development is less than two weeks away, and a detailed agenda o...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3761</td>\n",
       "      <td>Tam Pham</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@mrtampham/my-unconventional-year-after-dropping-out-of-college-befb536852dc?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Views From A College Dropout’s Unconventional Life — Year 2 | by Tam Pham | Medium</td>\n",
       "      <td>Jan 4, 2016\\nIf you asked me where I would be right now a year ago, my prediction wouldn’t even come close.\\nI had the opportunity to apprentice under radio show host and business coach, Margaret Jackson. On top of business skills, the biggest lesson she taught me was about legacy.\\nWhat legacy do I want to leave behind in the world?\\nMargaret told me to highlight my top 3 items on my bucket list. I wrote crazy goals like\\nMargaret looked at the rest of my (extensive) bucket list and started laughing to herself.\\n“Tam, you know there are people in organizations devoting their lives to ONE of these goals. How the hell in the world are you going to accomplish everything?”\\nMaintaining focus was the next crucial lesson. Mozart was known for music. Michael Jordan was known for basketball. ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3762</td>\n",
       "      <td>Virginia Peón</td>\n",
       "      <td>1</td>\n",
       "      <td>https://lab.elconfidencial.com/introducci%C3%B3n-a-machine-learning-e3caed58e37a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Introducción a Machine Learning. Machine Learning, Big Data, Deep... | by Virginia Peón | ECLaboratorio</td>\n",
       "      <td>ECLaboratorio\\nDec 5, 2016\\nMachine Learning, Big Data, Deep Learning, ... ¿por qué cada día se oyen mas estos términos? y de hecho ¿qué significan? Acompáñame a descubrirlo de forma sencilla y con muchos ejemplos en el siguiente vídeo:\\n... Y la presentación llena de enlaces que te pueden ayudar a profundizar más:\\n5 \\n5 \\nTrabajamos con equipos autónomos y autosuficientes enfocados a la creación de productos útiles, sencillos y que consigan mayor satisfacción del cliente\\n28 Followers\\nData scientist\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3763</td>\n",
       "      <td>The Awl</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/the-awl/when-exactly-did-it-get-cool-to-be-a-geek-44d360e98ba5?source=tag_archive---------0-----------------------</td>\n",
       "      <td>When Exactly Did It Get Cool To Be A Geek? | by The Awl | The Awl | Medium</td>\n",
       "      <td>The Awl\\nFeb 22, 2012\\nby Jane Hu\\nIn the final episode of “Freaks and Geeks,” the Freaks group leader Daniel Desario accepts an invitation to play Dungeons &amp; Dragons with the notoriously geeky A/V club. Surprised by Daniel’s warm receptivity to the game, the Geeks wonders what this means for their future status. As Bill puts it: “Does him wanting to play with us again mean he’s turning into a geek or we’re turning into cool guys?” Sam answers, “I’m going to go for us becoming cool guys.” It’s a nice ambiguous note on which to end the show.\\nOutside the universe of “Freaks and Geeks,” a similar drift has occurred. Geekiness has accrued cachet, and geeks are becoming the cool guys. In an interview about the comedy web series “Geek Therapy,” actress America Young observed: “We started ta...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3764</td>\n",
       "      <td>Ekta Sharma</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------7-----------------------</td>\n",
       "      <td>K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3765</td>\n",
       "      <td>Igor de Sousa</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@igordesousa/lou-reed-entre-transformer-e-berlin-o-mito-3c5ff2c36f59?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Lou Reed: Entre “Transformer” e “Berlin” o mito. | by Igor de Sousa | Medium</td>\n",
       "      <td>Nov 12, 2015\\nas mentiras e conturbações feitas a vida do “monstro” e “mito” Lou Reed atráves de biográfias e material descártavel são absurdamentes grandes, mas de certa forma provacadas pelo mesmo, uma figura icônica e contráditoria.\\nantes da fama Lou já era conturbado, mas a primeira aparição do Velvet em uma zine desmistifica algumas das alegações tardias do cantor e guitarrista. Lou Reed cita os beatles como criativos e absolutamente magníficos, assim como os Stones. ele cita Creedence como legais a primeira ouvida mas depois absolutamente tedioso e desgastante era 1972 e Lou estava no caminho de albúns como “Transformer” que absorvia toda a atmosfera Glam da época com uma pegada Rock and Roll, e ao mesmo tempo definia uma época, a ambiguidade sexual em sua capa ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3766</td>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Machine Learning is Fun!. The world’s easiest introduction to... | by Adam Geitgey | Medium</td>\n",
       "      <td>May 5, 2014\\nUpdate: This article is part of a series. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, Part 6, Part 7 and Part 8! You can also read this article in 日本語, Português, Português (alternate), Türkçe, Français, 한국어 , العَرَبِيَّة‎‎, Español (México), Español (España), Polski, Italiano, 普通话, Русский, 한국어 , Tiếng Việt or فارسی.\\nGiant update: I’ve written a new book based on these articles! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. Check it out now!\\nHave you heard people talking about machine learning but only have a fuzzy idea of what that means? Are you tired of nodding your way through conversations with co-workers? Let’s change that!\\nThis guide is f...</td>\n",
       "      <td>80816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3767</td>\n",
       "      <td>Viraf</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Master the COCO Dataset for Semantic Image Segmentation — Part 1 of 2 | by Viraf | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 3, 2020\\nCOCO (Common Objects in Context), being one of the most popular image datasets out there, with applications like object detection, segmentation, and captioning - it is quite surprising how few comprehensive but simple, end-to-end tutorials exist. When I first started out with this dataset, I was quite lost and intimidated. I had to plough my way through so many scattered, inadequate resources on the web, multiple vague tutorials, and some experimentation to finally see light at the end of this tunnel. When I was done, I knew I had to document this journey, from start to finish. And so I did. With the hope that someday, someone out there would find these of value and not have to go through all the trouble I faced.\\nHere’s presenting you a two part seri...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3768</td>\n",
       "      <td>Pankaj Kishore</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/it-support-ticket-classification-and-deployment-using-machine-learning-and-aws-lambda-8ef8b82643b6?source=tag_archive---------2-----------------------</td>\n",
       "      <td>IT Support Ticket Classification and Deployment using Machine Learning and AWS Lambda | by Pankaj Kishore | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 15, 2019\\nProject Description and initial assumptions:\\nAs a part of our final project for Cognitive computing, we decided to address a real life business challenge for which we chose IT Service Management. Of all the business cases, we were interested with four user cases that might befitting for our project.\\n1. In Helpdesk, almost 30–40% of incident tickets are not routed to the right team and the tickets keep roaming around and around and by the time it reaches the right team, the issue might have widespread and reached the top management inviting a lot of trouble.\\n2. Let’s say that users are having some trouble with printers. User calls help desk, he creates a ticket with IT Support, and they realize that they need to update a configuration in user’s sys...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3769</td>\n",
       "      <td>Ruben Winastwan</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Text Classification with BERT in PyTorch | by Ruben Winastwan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 10, 2021\\nBack in 2018, Google developed a powerful Transformer-based machine learning model for NLP applications that outperforms previous language models in different benchmark datasets. And this model is called BERT.\\nIn this post, we’re going to use a pre-trained BERT model from Hugging Face for a text classification task. As you might already know, the main goal of the model in a text classification task is to categorize a text into one of the predefined labels or tags.\\nSpecifically, soon we’re going to use the pre-trained BERT model to classify whether the text of a news article can be categorized as sport, politics, business, entertainment, or tech category.\\nBut before we dive into the implementation, let’s talk about the concept behind BERT briefly.\\...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3770</td>\n",
       "      <td>Ronak Nathani</td>\n",
       "      <td>9</td>\n",
       "      <td>https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Anatomy of an Elasticsearch Cluster: Part I | by Ronak Nathani | Insight</td>\n",
       "      <td>Insight\\nJun 30, 2016\\nWant to learn Elasticsearch and other big data tools from top data engineers in Silicon Valley or New York? The Insight Data Engineering Fellows Program is a free 7-week professional training program where you can build cutting edge big data platforms and transition to a career in data engineering at top teams like Facebook, Uber, Slack and Squarespace.\\nLearn more about the program and apply today.\\nThis post is part of a series covering the underlying architecture and prototyping examples with a popular distributed search engine, Elasticsearch. In this post, we’ll be discussing the underlying storage model and how CRUD (create, read, update and delete) operations work in Elasticsearch.\\nElasticsearch is a very popular distributed search engine used at many comp...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3771</td>\n",
       "      <td>George Seif</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...</td>\n",
       "      <td>38267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3772</td>\n",
       "      <td>Record Evolution</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/iot-and-cloud/iot-learning-algorithms-and-predictive-maintenance-3-few-shot-learning-95154b606197?source=tag_archive---------6-----------------------</td>\n",
       "      <td>IoT Learning Algorithms and Predictive Maintenance — Part III: Few-shot Learning | by Record Evolution | IoT &amp; Data Science | Medium</td>\n",
       "      <td>IoT &amp; Data Science\\nFeb 15, 2019\\nThe article tackles smart data processing of the Internet of Things (IoT) in a predictive maintenance context and relates this to recent developments in semi-supervised learning. While written with an eye towards a non-expert audience, the article references recent scientific publications. We leave it to the curious and technically oriented reader to expand their knowledge on the ideas we have sketched out (see References). We aim to be informative and open minds to stimulating discussions on IoT and data analytics.\\nWe cover the topic of IoT Learning Algorithms and Predictive Maintenance in a series of three articles. In PART I, we present a simple case study in detail and discuss some learning algorithms related to it. In PART II, we focus on IoT dat...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3773</td>\n",
       "      <td>Lachlan Miller</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Machine Learning week 1: Cost Function, Gradient Descent and Univariate Linear Regression | by Lachlan Miller | Medium</td>\n",
       "      <td>Jan 10, 2018\\nI have started doing Andrew Ng’s popular machine learning course on Coursera. The first week covers a lot, at least for someone who hasn’t touched much calculus for a few years\\nThese three topics were a lot to take in. I’ll talk about each in detail, and how they all fit together, with some python code to demonstrate.\\nEdit May 4th: I published a follow up focusing on how the Cost Function works here, including an intuition, how to calculate it by hand and two different Python implementations. I can do gradient descent and then bring them together for linear regression soon.\\nFirst, the goal of most machine learning algorithms is to construct a model: a hypothesis that can be used to estimate Y based on X. The hypothesis, or model, maps inputs to outputs. So, for example...</td>\n",
       "      <td>5277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3774</td>\n",
       "      <td>Julia Powles</td>\n",
       "      <td>8</td>\n",
       "      <td>https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------7-----------------------</td>\n",
       "      <td>DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero</td>\n",
       "      <td>OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law &amp; Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3775</td>\n",
       "      <td>Pulkit Sharma</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/analytics-vidhya/computer-vision-tutorial-implementing-mask-r-cnn-for-image-segmentation-with-python-code-fe34da5b99cd?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Computer Vision Tutorial: Implementing Mask R-CNN for Image Segmentation (with Python Code) | by Pulkit Sharma | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJul 22, 2019\\nI am fascinated by self-driving cars. The sheer complexity and mix of different computer vision techniques that go into building a self-driving car system is a dream for a data scientist like me.\\nSo, I set about trying to understand the computer vision technique behind how a self-driving car potentially detects objects. A simple object detection framework might not work because it simply detects an object and draws a fixed shape around it.\\nThat’s a risky proposition in a real-world scenario. Imagine if there’s a sharp turn in the road ahead and our system draws a rectangular box around the road. The car might not be able to understand whether to turn or go straight. That’s a potential disaster!\\nInstead, we need a technique that can detect the exact sh...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3776</td>\n",
       "      <td>Ryan Kwok</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3777</td>\n",
       "      <td>Hongri Jia</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/henry-jia/how-to-score-your-credit-1c08dd73e2ed?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Credit Scoring with Machine Learning | by Hongri Jia | Passion for Data Science | Medium</td>\n",
       "      <td>Passion for Data Science\\nApr 1, 2018\\nThe credit score is a numeric expression measuring people’s creditworthiness. The banking usually utilizes it as a method to support the decision-making about credit applications. In this blog, I will talk about how to develop a standard scorecard with Python (Pandas, Sklearn), which is the most popular and simplest form for credit scoring, to measure the creditworthiness of the customers.\\nNowadays, creditworthiness is very important for everyone since it is regarded as an indicator for how dependable an individual is. In various situations, service suppliers need to evaluate customers’ credit history first, and then decide whether they will provide the service or not. However, it is time-consuming to check the entire personal portfolios and gene...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3778</td>\n",
       "      <td>Justin Davies</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@justindavies/from-gensim-models-doc2vec-import-labeledsentence-9b631f9f567f?source=tag_archive---------5-----------------------</td>\n",
       "      <td>If you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works... | by Justin Davies | Medium</td>\n",
       "      <td>Jun 6, 2016\\nIf you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works rather well for my use case.\\nfrom gensim.models.doc2vec import LabeledSentence\\nfrom os import listdir\\nfrom os.path import isfile, join\\nimport gensim\\nimport DocIterator as DocIt\\ndocLabels = []\\ndocLabels = [f for f in listdir(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu”) if f.endswith(‘.txt’)]\\ndata = []\\nfor doc in docLabels:\\nwith open(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu/” + doc, ‘r’) as f:\\ndata.append(f.read())\\nit = DocIt.DocIterator(data, docLabels)\\nmodel = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=3,alpha=0.04, min_alpha=0.005) # use fixed learning rate\\nmodel.build_vocab(it)\\nfor epoch in range(100):\\nprint(“Epoch “ + str...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3779</td>\n",
       "      <td>Johannes Schmidt</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Creating and training a U-Net model with PyTorch for 2D &amp; 3D semantic segmentation: Model building [2/4] | by Johannes Schmidt | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 2, 2020\\nIn the previous chapter we built a dataloader that picks up our images and performs some transformations and augmentations so that they can be fed in batches to a neural network like the U-Net. In this part, we focus on building a U-Net from scratch with the PyTorch library. The goal is to implement the U-Net in such a way, that important model configurations such as the activation function or the depth can be passed as arguments when creating the model.\\nThe U-Net is a convolutional neural network architecture that is designed for fast and precise segmentation of images. It has performed extremely well in several challenges and to this day, it is one of the most popular end-to-end architectures in the field of semantic segmentation.\\nWe can split the...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3780</td>\n",
       "      <td>Harsh Pokharna</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8?source=tag_archive---------9-----------------------</td>\n",
       "      <td>The best explanation of Convolutional Neural Networks on the Internet! | by Harsh Pokharna | TechnologyMadeEasy | Medium</td>\n",
       "      <td>TechnologyMadeEasy\\nJul 28, 2016\\nCNNs have wide applications in image and video recognition, recommender systems and natural language processing. In this article, the example that I will take is related to Computer Vision. However, the basic concept remains the same and can be applied to any other use-case!\\nFor a quick recap of Neural Networks, here’s a very clearly explained article series.\\nCNNs, like neural networks, are made up of neurons with learnable weights and biases. Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output. The whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs. Pretty straightforward, right?\\nSo, how are Convol...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3781</td>\n",
       "      <td>Debmalya Biswas</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/@debmalyabiswas/i-had-an-opportunity-to-attend-the-oreilly-ai-london-conference-oct-9-11-2018-bf304ad69fd8?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Key takeaways — O’reilly AI London Conference, Oct 9–11, 2018 | by Debmalya Biswas | Medium</td>\n",
       "      <td>Nov 18, 2018\\nKey takeaways — O’reilly AI London Conference, Oct 9–11, 2018\\nI had an opportunity to attend the O’reilly AI London Conference, Oct 9–11, 2018. Given our short attention span these days, let me try a more clickbait style approach for the takeaways :)\\nKey takeaways\\n1. AI Gurus are the new rock stars and there was never a better time to be in this field. There continues to be tremendous interest in Enterprise AI. This was the first...\\n1 \\n1 \\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Patents https://www.linkedinin/debmalya-biswas-397526\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n125 Followers\\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Pat...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3782</td>\n",
       "      <td>Javaid Nabi</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Machine Learning — Word Embedding &amp; Sentiment Classification using Keras | by Javaid Nabi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 4, 2018\\nIn the previous post, we discussed various steps of text processing involved in Nature Language Processing (NLP) and also implemented a basic Sentiment Analyzer using some of the classical ML techniques.\\nDeep learning has demonstrated superior performance on a wide variety of tasks including NLP, Computer Vision, and Games. To explore further, we will discuss and use some of the advanced NLP techniques, based on Deep Learning, to create an improved Sentiment Classifier.\\nSentiment classification is the task of looking at a piece of text and telling if someone likes or dislikes the thing they’re talking about.\\nThe input X is a piece of text and the output Y is the sentiment which we want to predict, such as the star rating of a movie review.\\nIf we c...</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3783</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Computer Vision: Instance Segmentation with Mask R-CNN | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nThis is the fourth part in the series on Computer vision journey. In this article we will explore Mask R-CNN to understand how instance segmentation works with Mask R-CNN and then predict the segmentation for an image with Mask R-CNN using Keras\\nPart 1- CNN, R-CNN, Fast R-CNN, Faster R-CNN\\nPart 2 — Understanding YOLO, YOLOv2, YOLO v3\\nPart 3- Object Detection with YOLOv3 using Keras\\nWhat is instance segmentation and how is different from semantic segmentation?\\nSemantic Segmentation detects all the objects present in an image at the pixel level. Outputs regions with different classes or objects\\nSemantic segmentation groups pixels in a semantically meaningful way. Pixels belonging to a person, road, building, fence, bicycle, cars or trees are grou...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3784</td>\n",
       "      <td>Hrishikesh Huilgolkar</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@hrishikeshio/traveling-santa-problem-an-incompetent-algorists-attempt-49ad9d26b26?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Traveling santa Problem — An incompetent algorist’s attempt | by Hrishikesh Huilgolkar | Medium</td>\n",
       "      <td>Jan 19, 2013\\nKaggle announced the Traveling santa problem in the christmas season. I joined in excitedly.. but soon realized this is not an easy problem. Solving this problem would require expertise on data structures and some good familiarity with TSP problems and its many heuristic algorithms. I had neither.. I had to find a way to deal with this problem. I compenseted my lack of algorithmic expertise with common sense, logic and intuition. I finished 65th out of 356 total competitors.\\nI did some research on packaged TSP solvers and top TSP algorithms. I found concorde but I could not get it to work on my ubuntu machine. So I settled with LKH which uses Lin-Kernighan heuristic for solving TSP and related problems. I wrote scripts for file conversions and for running LKH.\\nLKH easil...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3785</td>\n",
       "      <td>Jan Schultink</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/slidemagic/data-without-context-is-meaningless-and-boring-c4a9944959a8?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Data without context is meaningless (and boring) | by Jan Schultink | SlideMagic | Medium</td>\n",
       "      <td>SlideMagic\\nSep 1, 2011\\nThe quarter is done, and here comes the day-long sales results presentation. Excel is pasted into PowerPoint, creating huge decks through which senior management has to sit through. Sales organizes by channel: small restaurants sales, growth; large restaurants sales, growth, supermarkets sales, growth. Marketing presents by brands: brand 1 sales, growth, brand 2 sales, growth.If you are a marketing manager, looking at the Q3 sales and growth figures of a particular brand is really interesting. All the numbers of the previous quarters are more or less in your head. For the production manager though, going through these pages is mental torture, as she does not have the historical context readily available. (Read more about the Curse of Knowledge here)The solution...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3786</td>\n",
       "      <td>Siladittya Manna</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538?source=tag_archive---------4-----------------------</td>\n",
       "      <td>K-Fold Cross Validation for Deep Learning Models using Keras | by Siladittya Manna | The Owl | Medium</td>\n",
       "      <td>The Owl\\nMar 20, 2020\\nwith a little help from sklearn\\nMachine Learning models often fails to generalize well on data it has not been trained on. Sometimes, it fails miserably, sometimes it gives somewhat better than miserable performance. To be sure that the model can perform well on unseen data, we use a re-sampling technique, called Cross-Validation.\\nWe often follow a simple approach of splitting the data into 3 parts, namely, Train, Validation and Test sets. But this technique does not generally work well for cases when we don’t have a large datasets. When we have limited data, dividing the dataset into Train and Validation sets may casue some data points with useful information to be excluded from the training procedure, and the model fails to learn the data distrubution properl...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3787</td>\n",
       "      <td>Knoyd</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@Knoyd/gotta-catch-them-all-but-which-one-first-7d808378de72?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Gotta catch them all, but which one first? | by Knoyd | Medium</td>\n",
       "      <td>Aug 8, 2016\\nFor this blog post, we decided to jump on the PokémonGO hype and add a bit of science into the craze. Our goal is to give you the optimal portfolio of Pokémon to train, so you can be as effective as possible against a wide variety of opponents. As each Pokémon has its strengths and weaknesses, we created clusters of Pokémon with similar characteristics and looked at the few selected ones allowing the player to compete against as many different enemies as possible.\\nWe used the Pokémon API fan service available on the internet to find all the information about the little creatures.\\nThe data we used consists of:\\nThe data is available for 811 Pokémon. Although we have done the analysis for all the Pokémon, in this post, we focus only on the first 150 Pokémon as thos...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3788</td>\n",
       "      <td>Ryan Burke</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/glove-elmo-bert-9dbbc9226934?source=tag_archive---------6-----------------------</td>\n",
       "      <td>GloVe, ELMo &amp; BERT. A guide to state-of-the-art text... | by Ryan Burke | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 16, 2021\\nOne of the most challenging tasks for machine learning models is finding the best way to to generate numeric representations for words so the model can use that information in its calculations.\\nIn computer vision tasks, the red channel in a color (RGB) image will always refer to the red channel, and the green channel to the green channel. Text, however, is heavily based on context, such that the same word can take on multiple meanings depending on its use. Pandas, for example, can refer to cute and fuzzy bears or a Python data analysis library.\\nThis is further complicated when considering sentences and paragraphs. Consider the following:\\nPandas are cute and fuzzy. They don’t use Pandas data analysis library because they are bears.\\nNow I realize t...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3789</td>\n",
       "      <td>Jeremie Harris</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/ai-safety-and-the-scaling-hypothesis-76bfee57f924?source=tag_archive---------8-----------------------</td>\n",
       "      <td>AI Safety and the Scaling Hypothesis | by Jeremie Harris | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 2, 2021\\nEditor’s note: This episode is part of our podcast series on emerging problems in data science and machine learning, hosted by Jeremie Harris. Apart from hosting the podcast, Jeremie helps run a data science mentorship startup called SharpestMinds.\\nWhen OpenAI announced the release of their GPT-3 API last year, the tech world was shocked. Here was a language model, trained only to perform a simple autocomplete task, which turned out to be capable of language translation, coding, essay writing, question answering and many other tasks that previously would each have required purpose-built systems.\\nWhat accounted for GPT-3’s ability to solve these problems? How did it beat state-of-the-art AIs that were purpose-built to solve tasks it was never explici...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3790</td>\n",
       "      <td>Pavel Shestakov</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@am1goo/%D0%BF%D0%BE%D0%B4%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D0%B5-%D0%BA%D0%B0%D0%BC%D0%BD%D0%B8-unet-%D0%B2-unity-5-8e78a0e673b8?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Подводные камни UNet в Unity 5. или то, что не описано в документации | by Pavel Shestakov | Medium</td>\n",
       "      <td>Oct 17, 2016\\nИтак, вы решили подключить свой локальный пул геймобъектов, прочли документацию на сайте, нашли необходимые методы и решили , что сейчас все заработает. Возможно в вашем случае это действительно будет так, если вы до этого не регистрировали ни одного префаба для спаунинга по сети.\\nДело в том, что в Unity при спауне геймобъекта приватным методом ClientScene.OnObjectSpawn сначала проверяется наличие объекта в списке зарегистрированных (через инспектор компоненты NetworkManager или напрямую через добавление геймобъектов в словарь NetworkManager.spawnPrefabs), и только если необходимый геймобъект не найден, то идет в работу словарь хендлеров (делегатов SpawnDelegate) для спауна, в который и записывается ваш делегат с помощью методов ClientScene.RegisterSpawnHandl...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3791</td>\n",
       "      <td>Saidakbar P</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@saidakbarp/real-time-face-recognition-tflite-3fb818ac039a?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Real-time face recognition: training and deploying on Android using Tensorflow lite — transfer learning | by Saidakbar P | Medium</td>\n",
       "      <td>Feb 25, 2019\\nFor the last couple of weeks, I have been experimenting with mobilenet models for object detection on Android devices. Since I took a Deep learning course in the past semester, I knew that those mobilenet models could be trained for detecting other objects as well. Moreover, available guides such as this object detection tutorial and this Android deployment tutorial rely on the older version of the Tensorflow framework — Tensorflow Mobile, which is being deprecated as of February 2019. Instead, Tensorflow Lite will be the main framework for mobile devices in the future and Lite version has moved from the contribution stage to the core of Tensorflow.\\nAdditionally, there are recent articles that manually annotate images for training purposes. However, we will implement ope...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3792</td>\n",
       "      <td>Prince Yadav</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/decision-tree-in-machine-learning-e380942a4c96?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Decision Tree in Machine Learning | by Prince Yadav | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2018\\nA decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules. Below diagram illustrate the basic flow of decision tree for decision making with labels (Rain(Yes), No Rain(No)).\\nDecision tree is one of the predictive modelling approaches used in statistics, data mining and machine learning.\\nDecision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3793</td>\n",
       "      <td>Julia Powles</td>\n",
       "      <td>8</td>\n",
       "      <td>https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------1-----------------------</td>\n",
       "      <td>DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero</td>\n",
       "      <td>OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law &amp; Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3794</td>\n",
       "      <td>Gabriel Pierobon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/dbscan-clustering-for-data-shapes-k-means-cant-handle-well-in-python-6be89af4e6ea?source=tag_archive---------0-----------------------</td>\n",
       "      <td>DBSCAN clustering for data shapes k-means can’t handle well (in Python) | by Gabriel Pierobon | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 30, 2018\\nIn this post I’d like to take some content from Introduction to Machine Learning with Python by Andreas C. Müller &amp; Sarah Guido and briefly expand on one of the examples provided to showcase some of the strengths of DBSCAN clustering when k-means clustering doesn’t seem to handle the data shape well. I’m going to go right to the point, so I encourage you to read the full content of Chapter 3, starting on page 168 if you would like to expand on this topic. I’ll be quoting the book when describing the working of the algorithm.\\nThis is how k-means work in a visual representation:\\nOne issue with k-means clustering is that it assumes that all directions are equally important for each cluster. This is usually not a big problem, unless we come across wit...</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3795</td>\n",
       "      <td>Anas Al-Masri</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/how-does-back-propagation-in-artificial-neural-networks-work-c7cad873ea7?source=tag_archive---------4-----------------------</td>\n",
       "      <td>How Does Back-Propagation in Artificial Neural Networks Work? | by Anas Al-Masri | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 29, 2019\\nEver since the world of Machine Learning was introduced to non-linear functions that work recursively (i.e. Artificial Neural Networks), the applications of which boomed noticeably. In this context, proper training of a Neural Network is the most important aspect of making a reliable model. This training is usually associated with the term “Back-propagation”, which is highly vague to most people getting into Deep Learning. Heck, most people in the industry don’t even know how it works — they just know it does!\\nBack-propagation is the essence of neural net training. It is the practice of fine-tuning the weights of a neural net based on the error rate (i.e. loss) obtained in the previous epoch (i.e. iteration). Proper tuning of the weights ensures low...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3796</td>\n",
       "      <td>Matt Kiser</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/emergent-future/teslas-big-plans-deepmind-pays-for-itself-internet-drones-and-moore-s-law-54e6bd8e2750?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Tesla’s Big Plans, DeepMind Pays For Itself, Internet Drones, and Moore’s Law | by Matt Kiser | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nJul 27, 2016\\nIssue 17 This week we review Elon Musk’s big plans for Tesla, how Google uses DeepMind to save millions of dollars, why Zuckerberg is building a fleet of internet drones, and check in on Moore’s Law death watch. Plus, projects to try at home, and our top reads from the past week.\\nNot a subscriber? Join the Emergent // Future newsletter here.\\nYou might have heard: Elon Musk outlined his masterplan for Tesla in blog post. For the past 10-years, Tesla’s vision had been to do:\\nNow, Musk is doubling-down on solar power, Tesla trucks, self-driving cars, and car-sharing — he wants your car to make you money when you aren’t using it. The company has already started developing electric and autonomous trucks and buses.\\ntl;dr “We’re not an electric car compan...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3797</td>\n",
       "      <td>Pedro Marcelino</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Transfer learning from pre-trained models | by Pedro Marcelino | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 23, 2018\\nThis article teaches you how to use transfer learning to solve image classification problems. A practical example using Keras and its pre-trained models is given for demonstration purposes.\\nDeep learning is fast becoming a key instrument in artificial intelligence applications (LeCun et al. 2015). For example, in areas such as computer vision, natural language processing, and speech recognition, deep learning has been producing remarkable results. Therefore, there is a growing interest in deep learning.\\nOne of the problems where deep learning excels is image classification (Rawat &amp; Wang 2017). The goal in image classification is to classify a specific picture according to a set of possible categories. A classic example of image classification is th...</td>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3798</td>\n",
       "      <td>michaelulin</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@michaelulin/serving-pytorch-models-on-aws-lambda-with-caffe2-onnx-7b096806cfac?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Serving PyTorch Models on AWS Lambda with Caffe2 &amp; ONNX | by michaelulin | Medium</td>\n",
       "      <td>Oct 8, 2017\\nCode available here: https://github.com/michaelulin/pytorch-caffe2-aws-lambda\\nHaving worked with PyTorch, I love the flexibility and ease of development of the framework versus other platforms. As PyTorch is still early in its development, I was unable to find good resources on serving trained PyTorch models, so I’ve written up a method here that utilizes ONNX, Caffe2 and AWS Lambda to serve predictions from a trained PyTorch model. I hope that you find it to be useful.\\nHow to effectively deploy a trained PyTorch model\\nUsing ONNX, Facebook and Microsoft’s recently released platform for Neural Network interoperability, we can convert a model trained in PyTorch to Caffe2 and then serve predictions with that model from AWS Lambda.\\nONNX enables models trained in PyTorch to...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3799</td>\n",
       "      <td>Chi-Lan Yang | 楊期蘭</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/%E4%BA%BA%E6%A9%9F%E5%85%B1%E7%94%9F%E4%BD%A0%E6%88%91%E5%AE%83/explainable-ai-for-intelligent-systems-part2-be9296529582?source=tag_archive---------5-----------------------</td>\n",
       "      <td>[談理解] 電競賽評也能告訴我們如何設計智慧系統的解釋機制?. 「蟲苔已經撲到人家的臉上了!」... | by Chi-Lan Yang | 楊期蘭 | 人機共生你我它 | Medium</td>\n",
       "      <td>人機共生你我它\\nDec 20, 2018\\n「蟲苔已經撲到人家的臉上了!」 「快要滿人口啦!應該要開戰了喔,因為其實人口滿,你剛剛把人家斷炊,這邊是一個很好的時機點可以來壓制」\\n電競賽評每天在做的事就是分析許多專業玩家打game的過程,帶著觀眾理解這些專業玩家每一步背後的策略,仔細想想,這些賽評帶領觀眾理解專業玩家的方式,是不是也跟使用者透過一個解釋機制來理解黑盒子般的智慧系統類似?電競賽評是專家行為的詮釋者,從他們身上,能帶給我們什麼智慧代理系統設計的啟發?\\n來自美國Oregon State University的研究團隊發現了這個關聯,透過分析賽評們對於電競的即時評論,試圖了解:當解釋機制(賽評)在說明智慧系統運作(專業玩家動作)時,需要哪些線索來搞懂智慧系統的行為、對使用者說明時需要包含哪些資訊、以及要怎麼說出這些難懂的資訊才能幫助使用者搞懂智慧系統這個黑盒子。\\n在眾多線索中,哪些資訊才是賽評需要的呢?研究者分析賽評切換的畫面,發現遊戲賽評會不斷的蒐集玩家當下的表現、所處的環境、產能狀況或統計資料(例:擊殺比例)以及賽評不斷切換視角(例:畫面轉到不同地點、切換成不同玩家的視角)來幫助自己解釋這些玩家為什麼在此時此刻會做出特定的行為。透過分析賽評如何理解專業玩家,我們可以知道當設計解釋機制的時候,需要想辦法讓使用者需要知道系統已做、能做哪些事,就如同賽評會說出「蟲苔已經撲到人家的臉上了」或告訴觀眾「滿人口應該就可以開戰了」,藉由這些資訊來讓觀眾理解玩家做出特定行為的意圖。\\n除此之外,智慧系統的解釋機制也需要告訴使用者現在系統已經看到、聽到或取得哪些資訊,以自駕車來說,在操作面板上對駕駛顯示目前系統偵測到周圍環境哪些資訊、已經分別執行過哪些步驟,幫助駕駛理解系統做決策的過程;或是讓使用者知道智慧系統做了哪些事、能做哪些事,例如透過系統協助保安人員判斷某位...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3800</td>\n",
       "      <td>Manjeet Singh</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/data-science-group-iitr/artistic-style-transfer-with-convolutional-neural-network-7ce2476039fd?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Artistic Style Transfer with Convolutional Neural Network | by Manjeet Singh | Data Science Group, IITR | Medium</td>\n",
       "      <td>Data Science Group, IITR\\nSep 4, 2017\\nWe all have used apps like Prisma and Lucid, but ever wondered how these things works? Like we give a photo from our camera roll and select a design to mix both the images and we get a new image which has the content of our input image and style of the design image. In the world of deep learning this is called style transfer.\\nStyle transfer is the technique of recomposing images in the style of other images. It all started when Gatys et al. published an awesome paper on how it was actually possible to transfer artistic style from one painting to another picture using convolutional neural networks..\\nHere are some examples :\\n“Neural networks are everywhere. I do not expect that they will take away the bread of artists and designers, but it took m...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3801</td>\n",
       "      <td>Elior Cohen</td>\n",
       "      <td>9</td>\n",
       "      <td>https://blog.mlreview.com/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07?source=tag_archive---------5-----------------------</td>\n",
       "      <td>How to predict Quora Question Pairs using Siamese Manhattan LSTM | by Elior Cohen | ML Review</td>\n",
       "      <td>ML Review\\nJun 7, 2017\\nThe article is about Manhattan LSTM (MaLSTM) — a Siamese deep network and its appliance to Kaggle’s Quora Pairs competition.I will do my best to explain the network and go through the Keras code (if you are only here for the code, scroll down :)Full code on Github\\nIn the past few years, deep learning is all the fuss in the tech industry.To keep up on things I like to get my hands dirty implementing interesting network architectures I come across in article readings.\\nFew months ago I came across a very nice article called Siamese Recurrent Architectures for Learning Sentence Similarity.It offers a pretty straightforward approach to the common problem of sentence similarity.Named MaLSTM (“Ma” for Manhattan distance), its architecture is depicted in figure 1 (dia...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3802</td>\n",
       "      <td>Sambit Mahapatra</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Use-cases of Google’s Universal Sentence Encoder in Production | by Sambit Mahapatra | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 24, 2019\\nBefore building any Deep Learning model in Natural Language Processing (NLP), text embedding plays a major role. The text embedding converts text (words or sentences) into a numerical vector.\\nWhy do we convert texts into vectors?\\nA vector is an array of numbers of a particular dimension. A vector of size 5×1 contain 5 numbers and we can think of it as a point in 5D space. If there are two vectors each of dimension 5, they can be thought of two points in a 5D space. Thus we can calculate how close or distant those two vectors are, depending on the distance measure between them.\\nHence, lots of efforts in machine learning research are bring put to converting data into a vector as once data is converted into a vector, we can say two data points are si...</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3803</td>\n",
       "      <td>Ceshine Lee</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Understanding Bidirectional RNN in PyTorch | by Ceshine Lee | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2017\\nBidirectional recurrent neural networks(RNN) are really just putting two independent RNNs together. The input sequence is fed in normal time order for one network, and in reverse time order for another. The outputs of the two networks are usually concatenated at each time step, though there are other options, e.g. summation.\\nThis structure allows the networks to have both backward and forward information about the sequence at every time step. The concept seems easy enough. But when it comes to actually implementing a neural network which utilizes bidirectional structure, confusion arises...\\nThe first confusion is about the way to forward the outputs of a bidirectional RNN to a dense neural network. For normal RNNs we could just forward the outputs ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3804</td>\n",
       "      <td>Daniel Voshart</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@voshart/appearance-of-the-principate-pt-ii-3df539f18fe5?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Appearance of The Principate [Pt. II] | by Daniel Voshart | Medium</td>\n",
       "      <td>Jul 24, 2020\\nUsing the neural-net tool Artbreeder, Photoshop and historical references, I have created photoreal depictions of Roman Emperors. Scroll down to see each emperor.\\nON CREATIVE COMMONS &amp; COPYRIGHT: Faces can be shared non-watermarked at 200 pixels max height OR 512 pixels with the digital mosaic watermark with Attribution-NonCommercial-ShareAlike. Please link back to this page. Continuation of this project depends on prints, licensing and commissions.\\n*CONCISE UPDATE (July 31st) replacing a July 27th CLARIFICATION: ‘TheApricity’, a tertiary source, has been removed entirely. I knew it to be unreliable prior to starting this project but kept here for posterity and debate. It is now clear to me they have distorted primary and secondary sources to push a pernicious white sup...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3805</td>\n",
       "      <td>Chandra Churh Chatterjee</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3806</td>\n",
       "      <td>Gustavo Chávez</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/understanding-logistic-regression-step-by-step-704a78be7e0a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Understanding Logistic Regression step by step | by Gustavo Chávez | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 21, 2019\\nLogistic Regression is a popular statistical model used for binary classification, that is for predictions of the type this or that, yes or no, A or B, etc. Logistic regression can, however, be used for multiclass classification, but here we will focus on its simplest application.\\nAs an example, consider the task of predicting someone’s gender (Male/Female) based on their Weight and Height.\\nFor this, we will train a machine learning model from a data set of 10,000 samples of people’s weight and height. The data set is taken from the Conway &amp; Myles Machine Learning for Hackers book, Chapter 2, and can it can be directly downloaded here.\\nThis is a preview of what the data looks like:\\nEach sample contains three columns: Height, Weight, and Male.\\nTh...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3807</td>\n",
       "      <td>Apdullah Yayik</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@apdullahyayik/mask-rcnn-object-recognition-and-segmentation-with-colab-application-cd0b5e490130?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Object Detection &amp; Segmentation with Python | by Apdullah Yayik | Medium</td>\n",
       "      <td>Aug 27, 2019\\nIt was announced by FAIR (facebook artificial intelligence research) last year that the Mask RCNN structure using the resnet50 infrastructure was successfully implemented on MS COCO and Balloon datasets and valuable resuts were obtained (see dedicated github page). In addition, the trained weights were also released for researchers and practitionars to make transfer learning to solve different problems with reasonable cost(see matterport github page).\\nIn my another article I have explaineed how to make transfer learning with such released MS COCO weights to deletect an locate weapons (see article here)\\nAt the end of this reading this article, you will see succesful object recognition and segmentation in video and images taken randomly from the outerside of the world.\\nI...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3808</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3809</td>\n",
       "      <td>Erik Hallström</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767?source=tag_archive---------1-----------------------</td>\n",
       "      <td>How to build a Recurrent Neural Network in TensorFlow (1/7) | by Erik Hallström | Medium</td>\n",
       "      <td>Nov 10, 2016\\nDear reader,\\nThis article has been republished at Educaora and has also been open sourced. Unfortunately TensorFlow 2.0 changed the API so it is broken for later versions. Any help to make the tutorials up to date are greatly appreciated. I also recommend you looking into PyTorch.\\nIn this tutorial I’ll explain how to build a simple working Recurrent Neural Network in TensorFlow. This is the first in a series of seven parts where various aspects and techniques of building Recurrent Neural Networks in TensorFlow are covered. A short introduction to TensorFlow is available here. For now, let’s get started with the RNN!\\nIt is short for “Recurrent Neural Network”, and is basically a neural network that can be used when your data is treated as a sequence, where the particula...</td>\n",
       "      <td>7023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3810</td>\n",
       "      <td>Veysel Kocaman</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Text Classification in Spark NLP with Bert and Universal Sentence Encoders | by Veysel Kocaman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 12, 2020\\nNatural language processing (NLP) is a key component in many data science systems that must understand or reason about a text. Common use cases include text classification, question answering, paraphrasing or summarising, sentiment analysis, natural language BI, language modeling, and disambiguation.\\nNLP is essential in a growing number of AI applications. Extracting accurate information from free text is a must if you are building a chatbot, searching through a patent database, matching patients to clinical trials, grading customer service or sales calls, extracting facts from financial reports or solving for any of these 44 use cases across 17 industries.\\nText classification is one of the main tasks in modern NLP and it is the task of assigning a...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3811</td>\n",
       "      <td>Marcio Geovani Jasinski</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@marciogj/dbscan-on-trajectories-determining-eps-and-minpts-ba3aa7c4ed7c?source=tag_archive---------2-----------------------</td>\n",
       "      <td>DBScan on trajectories — Determining Eps and MinPts | by Marcio Geovani Jasinski | Medium</td>\n",
       "      <td>Jun 11, 2017\\nIn the last post I’ve applied DBScan to remove noises from a trajectory. However, to achieve an acceptable result from original trajectory I tried several parameters before end up witth:\\nUsually data analysis cannot afford such strategy since it would take too long to clean up big amount of data if every trajectory demands a human evaluation. The good news is that this process can be automated. Actually, the original DBScan paper from Ester et al. brings a section about determining the parameters Eps and MinPts using a heuristic approach.\\nThe basic idea is process data evaluating the k-th nearest neighbor of each point and sort them descending. Usually the result will point out a threshold value where clusters will appear on the right side of the chart while noises will...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3812</td>\n",
       "      <td>Vicente Luego</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@vicenteluego/tiktoks-new-feature-anime-filter-got-million-posts-in-3-days-c18a866e842e?source=tag_archive---------7-----------------------</td>\n",
       "      <td>TikTok’s new feature — anime filter got million posts in 3 days | by Vicente Luego | Medium</td>\n",
       "      <td>Jun 28, 2020\\nTikTok is an application which has been used for talking materials between teens and startups for years now. Most of time we only see how it creates from a new emerging industry instead of investigating what makes the customer retention high as 39%.\\nTikTok’s Chinese version, Douyin, published a new filter in its app this week. Within 3 days, they gathered millions of posts which used this filter. The filter names as “Anime Change”. The main character is to change the video into animation.\\nIt’s not a new one to be honest, many applications have launched a similar filter before, such as B612. But the difference here is to change a video and to make the result acceptable.\\nThe technology used behind is one called Generative Adversarial Networks, AKA GAN. GAN is used for ge...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3813</td>\n",
       "      <td>LucianoSphere</td>\n",
       "      <td>22</td>\n",
       "      <td>https://towardsdatascience.com/alphafold-based-databases-and-fully-fledged-easy-to-use-alphafold-interfaces-poised-to-baf865c6d75e?source=tag_archive---------2-----------------------</td>\n",
       "      <td>AlphaFold-based databases and fully-fledged, easy-to-use, online AlphaFold interfaces poised to revolutionize biology | by LucianoSphere | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 26, 2021\\nNot only computational but also experimental biology. Thoughts on the future of data science niches in biology.\\nIn a recent story I covered the release of the academic paper describing AlphaFold’s version 2 and its source code, and I showed you how scientists around the world were starting to apply the program to their favorite proteins through Google Colab notebooks, for free and without any hardware needs. These notebooks are rapidly evolving to enable more features, allowing anybody to model not only isolated proteins but also complexes of multiple proteins, and including known structures of related proteins and multiple sequence alignments to improve the program’s results. Moreover, Deepmind and the European Bioinformatics Institute started to u...</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3814</td>\n",
       "      <td>Jean-Marc Beaujour</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@jmlbeaujour/real-time-matting-of-webcam-video-on-the-browser-part-1-2c71a330ed08?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Background Removal in Real-Time Video Chats using TensorflowJS, Part 1 | by Jean-Marc Beaujour | Medium</td>\n",
       "      <td>Jun 27, 2018\\nAn app that removes and replaces in real-time the background in webcam video streams, and all from within the browser! No need for a green screen or a uniform background. This project was made during my 4 weeks at the AI Program of Insight Data Science (Palo Alto).\\nTry it here!\\nThere is a trend in AI to move from Centralized Cloud Computing to Edge Computing [1], in particular for real time services application for which Centralized Cloud Computing suffers from higher latency. Furthermore, Edge Computing AI might provide solutions for privacy conscientious consumers [2]. One tool that is likely to help this trend is TensorflowJS (TFJS), in brief Tensorflow in Javascript wrapper. TFJS enables to create AI apps, which training and prediction can be conducted on the client...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3815</td>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Chatbots were the next big thing: what happened? | by Justin Lee | The Startup | Medium</td>\n",
       "      <td>The Startup\\nJun 5, 2018\\nOh, how the headlines blared:\\n“...the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nMessaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!\\nPlus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptan...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3816</td>\n",
       "      <td>Yash Patel</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/reinforcement-learning-w-keras-openai-actor-critic-models-f084612cfd69?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Reinforcement Learning w/ Keras + OpenAI: Actor-Critic Models | by Yash Patel | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2017\\nQuick Recap\\nLast time in our Keras/OpenAI tutorial, we discussed a very fundamental algorithm in reinforcement learning: the DQN. The Deep Q-Network is actually a fairly new advent that arrived on the seen only a couple years back, so it is quite incredible if you were able to understand and implement this algorithm having just gotten a start in the field. As with the original post, let’s take a quick moment to appreciate how incredible results we achieved are: in a continuous output space scenario and starting with absolutely no knowledge on what “winning” entails, we were able to explore our environment and “complete” the trials.\\nPut yourself in the situation of this simulation. This would essentially be like asking you to play a game, without a ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3817</td>\n",
       "      <td>Victor Roman</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Machine Learning Project: Predicting Boston House Prices With Regression | by Victor Roman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 20, 2019\\nIn this project, we will develop and evaluate the performance and the predictive power of a model trained and tested on data collected from houses in Boston’s suburbs.\\nOnce we get a good fit, we will use this model to predict the monetary value of a house located at the Boston’s area.\\nA model like this would be very valuable for a real state agent who could make use of the information provided in a dayly basis.\\nYou can find the complete project, documentation and dataset on my GitHub page:\\nhttps://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/tree/master/projects/boston_housing\\nThe dataset used in this project comes from the UCI Machine Learning Repository. This data was collected in 1978 and each of the 506 entries represent...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3818</td>\n",
       "      <td>Kaustubh Mhaisekar</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af?source=tag_archive---------0-----------------------</td>\n",
       "      <td>AdaBelief Optimizer: fast as Adam, generalizes as well as SGD | by Kaustubh Mhaisekar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 19, 2020\\nAll types of neural networks and many machine learning algorithms optimize their loss functions using gradient-based optimization algorithms. There are several such optimization algorithms, or optimizers, that exist and are used to train models - RMSprop, Stochastic Gradient Descent(SGD), Adaptive Moment Estimation(Adam) and so many more.\\nThere are two primary metrics to look at while determining the efficacy of an optimizer:\\nAdaptive algorithms like Adam have a good convergence speed, while algorithms like SGD generalize better.\\nBut recently researchers from Yale introduced a novel AdaBelief optimizer (AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients) that combines many benefits of existing optimization methods:\\nWe pro...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3819</td>\n",
       "      <td>James Briggs</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/how-to-train-a-bert-model-from-scratch-72cfce554fc6?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Train New BERT Model on Any Language | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 6, 2021\\nMany of my articles have been focused on BERT — the model that came and dominated the world of natural language processing (NLP) and marked a new age for language models.\\nFor those of you that may not have used transformers models (eg what BERT is) before, the process looks a little like this:\\nNow, this is a great approach, but if we only ever do this, we lack the understanding behind creating our own transformers models.\\nAnd, if we cannot create our own transformer models — we must rely on there being a pre-trained model that fits our problem, this is not always the case:\\nSo in this article, we will explore the steps we must take to build our own transformer model — specifically a further developed version of BERT, called RoBERTa.\\nThere are a fe...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3820</td>\n",
       "      <td>Maneesha Rajaratne</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/credit-card-fraud-detection-using-autoencoders-in-h2o-399cbb7ae4f1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Credit Card Fraud Detection using Autoencoders in H2O | by Maneesha Rajaratne | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 17, 2018\\nFrauds in the finance field are very rare to be identified. Because of that, it can do a severe damage to the financial field. It is estimated that fraud costs at least $80 billion a year across all lines of insurance. If there is a small possibility of detecting fraudulent activities, that can do a major impact on annual losses. That is why financial companies invest in machine learning as a preemptive approach to tackling fraud.\\nThe benefits of using a machine learning approach are that,\\nThe best way to detect frauds is anomaly detection.\\nAnomaly detection is a technique to identify unusual patterns that do not conform to the expected behaviors, called outliers. It has many applications in business from fraud detection in credit card transaction...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3821</td>\n",
       "      <td>Essam Wisam</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/backpropagation-the-natural-proof-946c5abf63b1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Backpropagation: The Simple Proof | by Essam Wisam | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 21, 2021\\nWhat sets artificial neural networks apart from other machine learning algorithms is how they can efficiently deal with big data and how they assume very little about your dataset.\\nYour neural network doesn’t care if your classification data isn’t linearly separable via a kernel or if the trend followed by your regression data is a roller coaster. As long that your dataset is some continuous mapping from one finite space (x) to another (y) then you can approximate that mapping to any degree of accuracy depending on your architecture. This follows from them being universal approximators as proven by the Universal Approximation Theory. The point is that back, when neural networks first showed up in the 40s, there was no fast way to make use of this as...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3822</td>\n",
       "      <td>John Olafenwa</td>\n",
       "      <td>12</td>\n",
       "      <td>https://heartbeat.comet.ml/basics-of-image-classification-with-pytorch-2f8973c51864?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Basics of Image Classification with PyTorch | by John Olafenwa | Heartbeat</td>\n",
       "      <td>Heartbeat\\nMay 17, 2018\\nMany deep learning frameworks have been released over the past few years. Among them, PyTorch from Facebook AI Research is very unique and has gained widespread adoption because of its elegance, flexibility, speed, and simplicity. Most deep learning frameworks have either been too specific to application development without sufficient support for research, or too specific for research without sufficient support for application development.\\nHowever, PyTorch blurs the line between the two by providing an API that’s very friendly to application developers while at the same time providing functionalities to easily define custom layers and fully control the training process, including gradient propagation. This makes it a great fit for both developers and researche...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3823</td>\n",
       "      <td>Arsh Chowdhry</td>\n",
       "      <td>8</td>\n",
       "      <td>https://blog.clairvoyantsoft.com/music-genre-classification-using-cnn-ef9461553726?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Music Genre Classification Using CNN | by Arsh Chowdhry | Clairvoyant Blog</td>\n",
       "      <td>Clairvoyant Blog\\nMay 7, 2021\\n“If Music is a Place — then Jazz is the City, Folk is the Wilderness, Rock is the Road, Classical is a Temple.” — Vera Nazarin\\nWe’ve all used some music streaming app to listen to music. But what is the app's logic for creating a personalized playlist for us?\\nOne general example of logic is by having a Music Genre Classification System.\\nMusic genre classification forms a basic step for building a strong recommendation system.\\nThe idea behind this project is to see how to handle sound files in python, compute sound and audio features from them, run Machine Learning Algorithms on them, and see the results.\\nIn a more systematic way, the main aim is to create a machine learning model, which classifies music samples into different genres. It aims to predi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3824</td>\n",
       "      <td>Kaushal Trivedi</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Multi-label Text Classification using BERT – The Mighty Transformer | by Kaushal Trivedi | HuggingFace | Medium</td>\n",
       "      <td>HuggingFace\\nJan 27, 2019\\nThe past year has ushered in an exciting age for Natural Language Processing using deep neural networks. Research in the field of using pre-trained models have resulted in massive leap in state-of-the-art results for many of the NLP tasks, such as text classification, natural language inference and question-answering.\\n3.3K \\n3.3K \\n30\\nStories @ Hugging Face\\n1K Followers\\nChief Architect &amp; Technologist, AI &amp; Machine Learning, Co-founder at utterworks\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3825</td>\n",
       "      <td>commander</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@mst3c/google-deepmind-style-datacenter-optimization-ai-model-on-the-cheap-75f054330d27?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Google DeepMind-style datacenter optimization AI model (on the cheap) | by commander | Medium</td>\n",
       "      <td>Aug 17, 2016\\nThere was news recently in bloomberg about how google was able to cut electricity usage in its datacenter by using an AI scheme made by DeepMind (of AlphaGo fame). Earlier this week, i decided to make a quick-and-dirty implemetation in python and share it here for anyone interested in a practical example of what exactly they did. First lets take a quick look at why one would want to make such a thing...\\nDatacenters (and indeed any other large scale structures that use a lot of energy) need to be carefully optimized for efficiency as even a 10% - 15% saving on the electricity bill can add up to millions of dollars a year. The biggest challenge here is that even though there are certain simple steps that anyone can take to reduce energy use (don’t use a very low server roo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3826</td>\n",
       "      <td>Acuity Derivatives</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/acuity-derivatives/the-volcker-metric-known-as-inventory-aging-and-thoughts-of-whisky-a6011bf720d4?source=tag_archive---------1-----------------------</td>\n",
       "      <td>The Volcker metric known as inventory aging... and thoughts of Whisky | by Acuity Derivatives | Acuity Derivatives | Medium</td>\n",
       "      <td>Acuity Derivatives\\nAug 1, 2014\\nInventory Aging is a rather innocuous looking member of the band of (now) seven metrics that, under the Volcker rule, banking entities with significant trading assets and liabilities are required to calculate daily and report monthly.\\nAs written, the metric description seems straightforward enough:\\nInventory Aging generally describes a schedule of the trading desk’s aggregate assets and liabilities and the amount of time that those assets and liabilities have been held. [It] should measure the age profile of the trading desk’s assets and liabilities and must include two schedules, an asset- aging schedule and a liability-aging schedule.\\nThe graphic below broadly outlines the processes of asset/liability tagging, matching, sorting and netting of trade...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3827</td>\n",
       "      <td>Jehill Parikh</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/prior-over-functions-gaussian-process-1c58e8c40272?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Prior over functions: Gaussian process | by Jehill Parikh | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 7, 2019\\nIn this post we discuss working of Gaussian process. Gaussian process fall under kernel methods, and are model free. Gaussian process are specially useful for low data regimen to “learn” complex functions. We shall review a very practical real world application (not related to deep learning or neural networks). The discussion follows from the talks of subject matter experts Prof Neil Lawrence and Prof Richard Tuner.\\nBackground reading:\\nMultivariate gaussian distribution: A Gaussian distribution can be specified using a mean (u), variance (σ2) and probability distribution function (PDF) as shown below\\nIf we have more than one independent gaussian distribution we can combine them. The combined PDF is also Gaussian i.e. a multivariate Gaussian. E.g. o...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3828</td>\n",
       "      <td>Wolf Garbe</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium</td>\n",
       "      <td>Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is &lt;=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3829</td>\n",
       "      <td>Amanda Iglesias Moreno</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Simple and multiple linear regression with Python | by Amanda Iglesias Moreno | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 27, 2019\\nLinear regression is an approach to model the relationship between a single dependent variable (target variable) and one (simple regression) or more (multiple regression) independent variables. The linear regression model assumes a linear relationship between the input and output variables. If this relationship is present, we can estimate the coefficients required by the model to make predictions on new data.\\nIn this article, you will learn how to visualize and implement the linear regression algorithm from scratch in Python using multiple libraries such as Pandas, Numpy, Scikit-Learn, and Scipy. Additionally, we will measure the direction and strength of the linear relationship between two variables using the Pearson correlation coefficient as well...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3830</td>\n",
       "      <td>Paul Ellis</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/swlh/ner-spacy-and-lasagne-51b56fdad57e?source=tag_archive---------6-----------------------</td>\n",
       "      <td>NER, SpaCy and Lasagne. One of the great things about NER is... | by Paul Ellis | The Startup | Medium</td>\n",
       "      <td>The Startup\\nFeb 2, 2021\\nOne of the great things about NER is trying to find those critters! I recently completed a project where one of the pre-requisites was to identify a location from large text fields containing randomly entered data.\\nOf course if there’s no control during the input of data then chaos reigns but we are where we are and if someone wants to put their homemade recipe for lasagne in an address field then hey it’s going to get messy but we’ll keep the lecture notes on data entry for another time and place.\\n34 \\n34 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n15 Followers\\nRandom ramblings from a sedate stroller.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3831</td>\n",
       "      <td>Olga Chernytska</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Word2vec with PyTorch: Implementing the Original Paper | by Olga Chernytska | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 29, 2021\\nWord Embeddings is the most fundamental concept in Deep Natural Language Processing. And word2vec is one of the earliest algorithms used to train word embeddings.\\nIn this post, I want to go deeper into the first paper on word2vec — Efficient Estimation of Word Representations in Vector Space (2013), which as of now has 24k citations, and this number is still growing.\\nOur plan is the following:\\nI am attaching my Github project with word2vec training. We will go through it in this post.\\nToday we are reviewing only the first paper on word2vec. However, there are several later papers, describing the evolution of word2vec:\\nI believe, if you understand the first paper, you’ll easily catch the ideas described in later papers. So let’s go!\\nDisclosure. ...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3832</td>\n",
       "      <td>Praveenkumar</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/a-short-introduction-of-stylegan-898fe781937?source=tag_archive---------5-----------------------</td>\n",
       "      <td>A short introduction to StyleGAN. Generative models(GAN) have always been... | by Praveenkumar | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 1, 2021\\nGenerative models(GAN) have always been the niche and hard-to-master domain of the Deep learning space. Control over distinct features of output image has been a challenging research topic. StyleGAN is an approach that addresses this aspect. It distances itself from the conventional architectures of GAN and introduces a novel approach to generate high-resolution synthetic images along with a fair control over the distinct features...\\n5 \\n5 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n10 Followers\\nAI Enthusiast; M.Sc., University of Stuttgart, Mercedes-Benz AG\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3833</td>\n",
       "      <td>Chijioke Nwagwu</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@wyhzest/css-box-model-and-positioning-9f0263d60759?source=tag_archive---------9-----------------------</td>\n",
       "      <td>CSS Box Model and Positioning. VGG Virtual Internship Assignment. | by Chijioke Nwagwu | Medium</td>\n",
       "      <td>Jan 21, 2020\\nCSS Box Model and Positioning\\nVGG Virtual Internship Assignment.\\nThe CSS box model is crucial and fundamental to understand as far as layout and positioning are concerned in styling of a web page. This is so because every element in HTML generate a box around it and these boxes have properties that can be illustrated using what is popularly know as the CSS Box Model. You can view the box model from the developer tool by simply right clicking on an element on the web page then click on “inspect”.\\nOnce you are in the developer tools menu, ensure the “Elements” tab and “Styles” tab are selected (might be slightly different for other browsers). Then scroll down, you will see the box model for the element you are inspecting as shown below.\\nFrom the image above, we can see ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3834</td>\n",
       "      <td>Shivam Duseja</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/text-summarization-using-deep-neural-networks-e7ee7521d804?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Text Summarization Using Deep Neural Networks | by Shivam Duseja | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 28, 2020\\nThe amount of textual data being produced every day is increasing rapidly both in terms of complexity as well as volume. Social Media, News articles, emails, text messages (the list goes on..), generate massive information and it becomes cumbersome to go through lengthy text materials (and boring too!). Thankfully with the advancements in Deep Learning, we can build models to shorten long pieces of text and produce a crisp and coherent summary to save time and understand the key points effectively.\\nWe can broadly classify text summarization into two types:\\n1. Extractive Summarization: This technique involves the extraction of important words/phrases from the input sentence. The underlying idea is to create a summary by selecting the most important ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3835</td>\n",
       "      <td>Jonny Brooks-Bartlett</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Probability concepts explained: Maximum likelihood estimation | by Jonny Brooks-Bartlett | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 3, 2018\\nIn this post I’ll explain what the maximum likelihood method for parameter estimation is and go through a simple example to demonstrate the method. Some of the content requires knowledge of fundamental probability concepts such as the definition of joint probability and independence of events. I’ve written a blog post with these prerequisites so feel free to read this if you think you need a refresher.\\nOften in machine learning we use a model to describe the process that results in the data that are observed. For example, we may use a random forest model to classify whether customers may cancel a subscription from a service (known as churn modelling) or we may use a linear model to predict the revenue that will be generated for a company depending on...</td>\n",
       "      <td>28380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3836</td>\n",
       "      <td>Rishit Dagli</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Build K-Means from scratch in Python | by Rishit Dagli | Medium</td>\n",
       "      <td>Oct 29, 2019\\nK-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity. The results of the K-means clustering algorithm are:\\nRather than defining groups before looking at the data, clustering allows you to find and analyze the groups that have formed organically. The “Choosing K” section below describes how the number of groups can be determined.\\nThis story covers:\\nThe algorithm can be used to confirm business ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3837</td>\n",
       "      <td>Sanne de Roever</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/using-resnet-for-time-series-data-4ced1f5395e3?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Using ResNet for ECG time-series data | by Sanne de Roever | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 29, 2020\\nRecurrent neural networks like plain RNN or more advanced models like LSTM and GRU used to be the goto models for deep-learning practitioners venturing into the time series domain. NLP, providing an abundance of sequence data, provided a willing subject. But transformer architectures like BERT and GPT have definitely taken over in the domain. Apart from these transformer architectures, CNN’s have also made a come-back or advance in the time-series domain. Are CNN’s good at modelling time-series?\\nHow good are CNN’s at modelling time-series?\\nTo answer this question tthis post replicates an article called “ECG Heartbeat Classification: A Deep Transferable Representation” [1] that applies ResNet, a CNN based architecture, to electrocardiogram (ECG) dat...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3838</td>\n",
       "      <td>Kirill Bondarenko</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@bond-kirill-alexandrovich/understanding-unet-27de538e08d8?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Understanding UNET. How to understand U-Net in the most... | by Kirill Bondarenko | Medium</td>\n",
       "      <td>Jul 2, 2019\\nHow to understand U-Net in the most simple way.\\nHello everyone!\\nIn this article I want to explain in simple way the one of the most popular models structures to solve image segmentation task — UNET.\\nIf you haven’t heard about it and haven’t seen its architecture, it’s not a problem, because in this article I will start with a simple structure and at the end will be traditional UNET. Let’s start.\\nUNET model was created for medicine purpose to find tumors in lungs or brain, but nowadays it has got much wider usage field.\\nFor example your task is to find rectangles on images, no matter what color or shape they are.\\nWe have a red one and yellow one rectangles on a green background. This is an input for UNET model.\\nWe need to define positive regions on the image where we...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3839</td>\n",
       "      <td>Goibibo Tech</td>\n",
       "      <td>1</td>\n",
       "      <td>https://tech.goibibo.com/presenting-goibibo-insights-6b2ea7b3abc4?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Presenting Goibibo Insights. Its now been quite some time for... | by Goibibo Tech | Backstage</td>\n",
       "      <td>Backstage\\nDec 9, 2012\\nIts now been quite some time for Goibibo in business, which means that there is a huge amount of data that we have generated over this period. As a part of converting this data to information, we present to you our new initiative — Goibibo Insights.\\nAs the name suggests,Insights aims to give you interesting trends across the travel industry as seen by the large data we crunch at Goibibo. We believe this will further assist you in fine-tuning your travel plans. After all, this is your data — we have simply organised it and given it back.\\nRead on for the first series of insights with the info-graphics.\\nInsights are publicly shared on our Group portal (IbiboGroup) and also with the press.\\nOriginally published at goibibo.github.io on December 9, 2012.\\nBehind th...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3840</td>\n",
       "      <td>Shi Yan</td>\n",
       "      <td>7</td>\n",
       "      <td>https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Understanding LSTM and its diagrams | by Shi Yan | ML Review</td>\n",
       "      <td>ML Review\\nMar 13, 2016\\nI just want to reiterate what’s said here:\\ncolah.github.io\\nI’m not better at explaining LSTM, I want to write this down as a way to remember it myself. I think the above blog post written by Christopher Olah is the best LSTM material you would find. Please visit the original link if you want to learn LSTM. (But I did create some nice diagrams.)\\nAlthough we don’t know how brain functions yet, we have the feeling that it must have a logic unit and a memory unit. We make decisions by reasoning and by experience. So do computers, we have the logic units, CPUs and GPUs and we also have memories.\\nBut when you look at a neural network, it functions like a black box. You feed in some inputs from one side, you receive some outputs from the other side. The decision i...</td>\n",
       "      <td>9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3841</td>\n",
       "      <td>Pavan Gurram</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@gurrampavan6/fast-and-faster-region-based-convolutional-network-6a391a5a247a?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Fast and Faster Region-based Convolutional Network | by Pavan Gurram | Medium</td>\n",
       "      <td>Nov 27, 2019\\nObject detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.\\nThis post contains the details of Fast R-CNN and Faster R-CNN, which are the incremental improvements of R-CNN( aka “slow R-CNN”).\\nFast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks.\\nThe main contribution of Fast-R-CNN is the RoI pooling followed by a two-headed fully connected network.\\nAn input image is passed through CNN(set of convolutional and maxpooling layers)....</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3842</td>\n",
       "      <td>Synced</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf?source=tag_archive---------4-----------------------</td>\n",
       "      <td>GAN 2.0: NVIDIA’s Hyperrealistic Face Generator | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nDec 14, 2018\\nLook at the two pictures below. Can you tell which is a photograph and which was generated by AI?\\nThe truth is... wait for for it... both images are AI-generated fakes, products of American GPU producer NVIDIA’s new...\\n632 \\n632 \\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology &amp; Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3843</td>\n",
       "      <td>Rajneesh Jha</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/automated-feature-engineering-tools-44d00be56e3a?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Automated Feature Engineering Tools | by Rajneesh Jha | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 22, 2020\\nFeature Engineering is a technique to convert raw data columns to something meaningful which can help in predicting the outcomes in a machine learning task. Feature Engineering can be a very tedious and often the most time taking in machine learning life cycle.\\nBut to our rescue comes some of the cool tools which automates the whole feature engineering process and creates a large pool of features in a very short span for both classification and regression tasks.\\nWe have found following tools which automates the whole feature engineering process and creates large number of features for both relation and non-relational data. While some of them only performs feature engineering, we have some tools which also perform feature selection. Many a times these t...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3844</td>\n",
       "      <td>Dimitris Panagopoulos</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Clustering documents with Python. A simple example with Wikipedia... | by Dimitris Panagopoulos | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 5, 2020\\nNatural Language Processing has made huge advancements in the last years. Currently, various implementations of neural networks are cutting edge and it seems that everybody talks about them. But, sometimes a simpler solution might be preferable. After all, one should try to walk before running. In this short article, I am going to demonstrate a simple method for clustering documents with Python. All code is available at GitHub (please note that it might be better to view the code in nbviewer).\\nWe are going to cluster Wikipedia articles using k-means algorithm. The steps for doing that are the following:\\n2. represent each article as a vector,\\n3. perform k-means clustering,\\n4. evaluate the result.\\nUsing the wikipedia package it is very easy to down...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3845</td>\n",
       "      <td>Mo Hajr</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@mohamedhajr/ophow-i-got-my-first-android-job-without-a-degree-and-experience-98c70b931a9d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>How I got my first android job without a degree or experience | by Mo Hajr | Medium</td>\n",
       "      <td>Oct 7, 2016\\nIt’s a great time to work as an android developer, as Millions of android devices activated every day a huge demand for android developers is required.\\nBegging as an android developer can be extremely challenging too, so in this post, I will try to elaborate all the basic requirements and skills anyone needs to land a job as an android developer without the need of a degree or experience.\\nSo below is a list of all generalized requirements based on my little experience as an android developer and my researching for junior-level positions , the requirements will always vary from company to another and you will hardly find any two job descriptions exactly the same but these requirements will be good to start with.\\nYou might consider that this a lot of things but you can bu...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3846</td>\n",
       "      <td>Javaid Nabi</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-basics-part-1-a36d38c7916?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Machine Learning —Fundamentals. Basic theory underlying the field of... | by Javaid Nabi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 15, 2018\\nThis article introduces the basics of machine learning theory, laying down the common concepts and techniques involved. This post is intended for the people starting with machine learning, making it easy to follow the core concepts and get comfortable with machine learning basics.\\nIn 1959, Arthur Samuel, a computer scientist who pioneered the study of artificial intelligence, described machine learning as “the study that gives computers the ability to learn without being explicitly programmed.”\\nAlan Turing’s seminal paper (Turing, 1950) introduced a benchmark standard for demonstrating machine intelligence, such that a machine has to be intelligent and responsive in a manner that cannot be differentiated from that of a human being.\\nMachine Learnin...</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3847</td>\n",
       "      <td>SAGAR SHARMA</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Activation Functions in Neural Networks | by SAGAR SHARMA | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 6, 2017\\nIt’s just a thing function that you use to get the output of node. It is also known as Transfer Function.\\nIt is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\\nThe Activation Functions can be basically divided into 2 types-\\nFYI: The Cheat sheet is given below.\\nAs you can see the function is a line or linear. Therefore, the output of the functions will not be confined between any range.\\nEquation : f(x) = x\\nRange : (-infinity to infinity)\\nIt doesn’t help with the complexity or various parameters of usual data that is fed to the neural networks.\\nThe Nonlinear Activation Functions are the most used activation functions. Nonlinearity helps t...</td>\n",
       "      <td>24186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3848</td>\n",
       "      <td>Moses Olafenwa</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Train Object Detection AI with 6 lines of code | by Moses Olafenwa | DeepQuestAI | Medium</td>\n",
       "      <td>DeepQuestAI\\nAug 1, 2019\\nStep-by-step tutorial on training object detection models on your custom dataset\\nObject detection is one of the most profound aspects of computer vision as it allows you to locate, identify, count and track any object-of-interest in images and videos. Object detection is used extensively in many interesting areas of work and study such as:\\nA number of pre-collected object detection datasets such as Pascal VOC, Microsoft’s COCO, Google’s Open Images are readily available along with their pre-trained models for detection and identifying only a fix set of items.\\nHowever, the challenge with using these public datasets and pre-trained models is that they do not provide a convenient way for you to easily train new object detection models to detect and identify yo...</td>\n",
       "      <td>2170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3849</td>\n",
       "      <td>Vincenzo Santopietro</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/intel-student-ambassadors/diving-into-abstractive-text-summarization-part-1-e8570d370021?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Diving into Abstractive Text Summarization — Part 1 | by Vincenzo Santopietro | Intel Student Ambassadors | Medium</td>\n",
       "      <td>Intel Student Ambassadors\\nFeb 14, 2019\\nText summarization is nowadays one of the most studied research topics in natural language processing (NLP) and has its applications in almost all domains of the internet, for example, e-shops, search engines and news websites that use summaries to give readers an overview of what a particular article might talk about.\\nText Summarization is a task to generate a shorter and concise version of a text while preserving the meaning of the original text.[1]\\nText summarization algorithms can be classified into two main categories:\\nExtractive text summarization algorithms are capable of extracting key sentences from a text without modifying any word [2][3]. Abstractive summarization, instead, involves a complex process understanding the language, the...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3850</td>\n",
       "      <td>Connor Shorten</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction to ResNets. This Article is Based on Deep Residual... | by Connor Shorten | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 24, 2019\\nThis Article is Based on Deep Residual Learning for Image Recognition from He et al. [2] (Microsoft Research): https://arxiv.org/pdf/1512.03385.pdf\\nIn 2012, Krizhevsky et al. [1] rolled out the red carpet for the Deep Convolutional Neural Network. This was the first time this architecture was more successful that traditional, hand-crafted feature learning on the ImageNet. Their DCNN, named AlexNet, contained 8 neural network layers, 5 convolutional and 3 fully-connected. This laid the foundational for the traditional CNN, a convolutional layer followed by an activation function followed by a max pooling operation, (sometimes the pooling operation is omitted to preserve the spatial resolution of the image).\\nMuch of the success of Deep Neural Network...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3851</td>\n",
       "      <td>Akash Panchal</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3?source=tag_archive---------3-----------------------</td>\n",
       "      <td>NLP — Text Summarization using NLTK: TF-IDF Algorithm | by Akash Panchal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 10, 2019\\nIn the Article Text summarization in 5 steps using NLTK, we saw how we summarize the text using Word Frequency Algorithm.\\nBonus: See in Action with Streamlit App\\nNow, we’ll summarize the text using Tf-IDF Algorithm.\\nNote that, we’re implementing the actual algorithm here, not using any library to do the most of the tasks, we’re highly relying on the Math only.\\nIn a simple language, TF-IDF can be defined as follows:\\nA High weight in TF-IDF is reached by a high term frequency(in the given document) and a low document frequency of the term in the whole collection of documents.\\nTF-IDF algorithm is made of 2 algorithms multiplied together.\\nTerm frequency (TF) is how often a word appears in a document, divided by how many words there are.\\nTF(t) = (...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3852</td>\n",
       "      <td>Vincenzo Lavorini</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/gaussian-mixture-model-clusterization-how-to-select-the-number-of-components-clusters-553bef45f6e4?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Gaussian Mixture Model clustering: how to select the number of components (clusters) | by Vincenzo Lavorini | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 21, 2018\\nIf you landed on this post, you probably already know what a Gaussian Mixture Model is, so I will avoid the general description of the this technique.\\nBut if you are not aware of the details, you can just see the GMM as a k-means which is able to form stretched clusters, like the ones you can see in Figure 2.\\nAll the code used for this post is in this notebook. In the same repository you can find the data to fully replicate the results you see plotted.\\nNow: suppose you are in the situation depicted in Figure 1, you want to discern how many clusters we have (or, if you prefer, how many gaussians components generated the data), and you don’t have information about the “ground truth”. A real case, where data do not have the nicety of behaving good as...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3853</td>\n",
       "      <td>Supriya Secherla</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/understanding-optimization-algorithms-in-machine-learning-edfdb4df766b?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Understanding Optimization Algorithms in Machine Learning | by Supriya Secherla | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 18, 2021\\nMathematics behind two important optimization techniques in machine learning\\nOptimization is the process where we train the model iteratively that results in a maximum and minimum function evaluation. It is one of the most important phenomena in Machine Learning to get better results.\\nWhy do we optimize our machine learning models? We compare the results in every iteration by changing the hyperparameters in each step until we reach the optimum results. We create an accurate model with less error rate. There are different ways using which we can optimize a model. In this article, let’s discuss two important Optimization algorithms: Gradient Descent and Stochastic Gradient Descent Algorithms; how they are used in Machine Learning Models, and the math...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3854</td>\n",
       "      <td>Hucker Marius</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=tag_archive---------4-----------------------</td>\n",
       "      <td>HRNet Explained: Human Pose Estimation, Semantic Segmentation and Object Detection | by Hucker Marius | Oct, 2021 | Towards Data Science | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 6, 2021\\nOutline of HRNet explained:\\nIf you know already the basics (CNN + Areas of Application), skip down to section 3 or section 4.\\nHRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.\\nBut first, let’s understand what the fields mean and what kind of algorithm hides behind HRNet.\\nSemantic Segmentation is used to categorize structures of an image into certain classes. This is done by labeling each pixel with a certain class [3]. In the example below all pixels representing the cyclist are a class person and all pixels representing the bicycle are class ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3855</td>\n",
       "      <td>Craig Villamor</td>\n",
       "      <td>1</td>\n",
       "      <td>https://cvil.ly/no-home-for-ipad-on-apple-com-88074e5ad99f?source=tag_archive---------4-----------------------</td>\n",
       "      <td>No home for iPad on Apple.com | by Craig Villamor | cvil.ly</td>\n",
       "      <td>cvil.ly\\nFeb 24, 2010\\nHave you noticed that there’s no spot in the Apple.com navigation for the iPad? I tried navigating to iPhone, iPod+iTunes and Mac and could not find iPad in any of those locations. I wonder when they plan to address this?\\n[caption id=”” align=”aligncenter” width=”576\" caption=”No home for iPad in Apple.com IA”]\\n[/caption]\\nUpdate: Now there is a home for iPad! Note that they also separated iPod &amp; iTunes.\\n[caption id=”” align=”aligncenter” width=”604\" caption=”Now there is a home for iPad on Aplle.com”]\\n[/caption]\\ndesign | technology | product\\n1.3K Followers\\nProduct leader, designer, tech and gadget nerd. Pragmatic optimist.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3856</td>\n",
       "      <td>Pranay Dugar</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Attention — Seq2Seq Models. Sequence-to-sequence (abrv. Seq2Seq)... | by Pranay Dugar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 13, 2019\\nSequence-to-sequence (abrv. Seq2Seq) models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning. Google Translate started using such a model in production in late 2016. These models are explained in the two pioneering papers (Sutskever et al., 2014, Cho et al., 2014).\\nA Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.\\nIn the case of Neural Machine Translation, the input is a series of words, and the output is the translated series of words.\\nNow let's work on reducing the blackness of our black box. The model is composed of an encoder and a decoder. The encoder captures the context of ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3857</td>\n",
       "      <td>Arthur Juliani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...</td>\n",
       "      <td>16886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3858</td>\n",
       "      <td>Dario Radečić</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/read-text-from-image-with-one-line-of-python-code-c22ede074cac?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Read Text from Image with One Line of Python Code | by Dario Radečić | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 28, 2019\\nDealing with images is not a trivial task. To you, as a human, it’s easy to look at something and immediately know what is it you’re looking at. But computers don’t work that way.\\nTasks that are too hard for you, like complex arithmetics, and math in general, is something that a computer chews without breaking a sweat. But here the exact opposite applies — tasks that are trivial to you, like recognizing is it cat or dog in an image are really hard for a computer. In a way, we are a perfect match. For now at least.\\nWhile image classification and tasks that involve some level of computer vision might require a good bit of code and a solid understanding, reading text from a somewhat well-formatted image turns out to be a one-liner in Python —and can b...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3859</td>\n",
       "      <td>André Ferreira</td>\n",
       "      <td>24</td>\n",
       "      <td>https://towardsdatascience.com/interpreting-recurrent-neural-networks-on-multivariate-time-series-ebec0edb8f5a?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Interpreting recurrent neural networks on multivariate time series | by André Ferreira | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nIn this article, we’ll explore a state-of-the-art method of machine learning interpretability and adapt it to multivariate time series data, a use case which it wasn’t previously prepared to work on. You’ll find explanations to core concepts, on what they are and how they work, followed by examples. We’ll also address the main ideas behind the proposed solution, as well as a suggested visualization of instance importance.\\nIt’s not just hype anymore, machine learning is becoming an important part of our lives. Sure, there aren’t any sentient machines nor Scarlett Johansson ear lovers (shoutout to Her) out there, but the evolution of these algorithms is undeniable. They can ride cars, assist in medical prognosis, predict stock, play videogames at a pr...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3860</td>\n",
       "      <td>Kate Marie Lewis</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/how-i-went-from-zero-coding-skills-to-data-scientist-in-6-months-c2207b65f2f3?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How I went from zero coding skills to data scientist in 6 months | by Kate Marie Lewis | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 24, 2020\\nI had just walked away from 8 years of study and hard work with no plan. You might be wondering why someone would do that. My boss was crushing my spirit and knew that I needed to make a change.\\nMy boyfriend suggested becoming a data scientist. I said ‘you're crazy!’ I didn’t know the first thing about programming. Surely he was overestimating what I was capable of. Imposter syndrome strikes again.\\nAbout two weeks later my friend Anna suggested the exact same thing, I thought about it some more and began to entertain the idea. Why not? I decided to become a beginner again and reinvent myself as a data scientist.\\nI wanted to learn at my own pace so I decided to take online courses. I figured that with a PhD in Neuroscience I probably had enough for...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3861</td>\n",
       "      <td>Taras Bakusevych</td>\n",
       "      <td>7</td>\n",
       "      <td>https://uxdesign.cc/20-ideas-for-better-data-visualization-73f7e3c2782d?source=tag_archive---------3-----------------------</td>\n",
       "      <td>20 ideas for better data visualization | by Taras Bakusevych | UX Collective</td>\n",
       "      <td>UX Collective\\nAug 17, 2021\\nApplications we design are becoming increasingly data-driven. The need for quality data visualization is high as ever. Confusing and misleading graphics are all around us, but we can change this by following these simple rules.\\nChoosing the wrong chart type, or defaulting to the most common type of data visualization could confuse users or lead to data misinterpretation. The same data set can be represented in many ways, depending on what users would like to see. Always start with a review of your data set and user interview.\\nYou can learn more on how to pick the right representation for your data, and how to design effective dashboards in my article about Dashboard design.\\nWhen using horizontal bars, plot negatives values on the left side and positive o...</td>\n",
       "      <td>12005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3862</td>\n",
       "      <td>Joshua Holmes</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@JoshDHolmes/blog-9-information-architecture-3bc96dabdc0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Blog 9- Information Architecture. 1. What is the purpose of metadata... | by Joshua Holmes | Medium</td>\n",
       "      <td>Oct 18, 2015\\n1. What is the purpose of metadata? What are the categories of metadata?\\nMetadata provides definitions about the data they are attached to. It can include descriptive information about the context, quality, condition and characteristics.\\nMetadata is broken into three categories; structural (describes information about the document), descriptive (enables the document to be identified) and administrative (identifies the relationship of the document to the business context).\\n2. What is a controlled vocabulary? How is a controlled vocabulary beneficial to a web site and/or organisation?\\nA controlled vocabulary is a list of equivalent terms in the form of a synonym ring or a list of preferred terms in the form of an authority file.\\nThis is beneficial as it helps categoris...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3863</td>\n",
       "      <td>Roan Gylberth</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/konvergen/understanding-dropout-ddb60c9f98aa?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Understanding Dropout. One particular layers that are useful... | by Roan Gylberth | Konvergen.AI | Medium</td>\n",
       "      <td>Konvergen.AI\\nJul 21, 2019\\nOne particular layer that is useful, yet mysterious when training neural networks is Dropout. Dropout is created as a regularization technique, that we can use to reduce the model capacity so that our model can achieve lower generalization error. The intuition is easy, we didn’t use all neurons but only turn on some neuron in each training iteration with probability p. But how does dropout works, and is it the same as the implementation?\\n105 \\n105 \\n2\\nThe sharing platform of Konvergen.ai. Visit our homepage at https://konvergen.ai\\n171 Followers\\nCofounder of Konvergen.AI\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3864</td>\n",
       "      <td>TokenGo Platform_RU</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@RU_TokenGo/tokengo-%D0%B7%D0%B0%D0%BF%D1%83%D1%81%D0%BA%D0%B0%D0%B5%D1%82-ico-15ed47e79fb7?source=tag_archive---------3-----------------------</td>\n",
       "      <td>TokenGo запускает ICO!. Приветствую вас, друзья! TokenGo... | by TokenGo Platform_RU | Medium</td>\n",
       "      <td>Feb 26, 2018\\nПриветствую вас, друзья! TokenGo запускает ICO!\\nМы долго шли к этому дню, к этому волнующему событию. До момента запуска ICO платформы TokenGo остались считанные часы.\\nВ первую очередь я хочу сказать спасибо всем тем, кто сегодня с нами! С кем-то мы знакомы уже несколько месяцев, успели пообщаться, обсудить будущее и подружиться, кто-то присоединяется только сейчас, изучает White Paper, читает темы на форумах, задает вопросы в Telegram-чате. И это очень здорово, что наше сообщество постоянно растет, укрепляется, и каждый участник вносит свой вклад в строительство экосистемы TokenGo. Отдельно хочу поздравить инвесторов, записавшихся в White List. Уверен, что полученный вами уникальный бонус вас обязательно порадует!\\nА в TokenGo все продолжает идти по плану. Совсем ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3865</td>\n",
       "      <td>karthic Rao</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@hackintoshrao/tips-to-avoid-the-pitfall-of-over-fitting-in-linear-regression-468e590c4f92?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Tips to avoid the pitfall of over fitting in Linear Regression | by karthic Rao | Medium</td>\n",
       "      <td>Jan 10, 2016\\nTips to avoid the pitfall of over fitting in Linear Regression\\n8. The choice of the model has to be based on the observation from training error and test error . Also its tricky to make choice of right features to come to make build the model for your predictions.\\n1 \\n1 \\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n743 Followers\\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3866</td>\n",
       "      <td>Pallawi</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/@pallawi-ds/step-by-step-understand-the-architecture-of-region-proposal-network-r-cnn-695a14a060a7?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Step by step -Understand the architecture of Region proposal network (R-CNN) | by Pallawi | Medium</td>\n",
       "      <td>Sep 5, 2020\\nThis blog is written to explain the evolution of object detection models in simple words and self-explanatory diagrams. This blog can be helpful to every individual who is entering into the field of computer vision and data science or has taken up a project which requires solving an object detection problem.\\nWe all must have heard about Faster R-CNN and there are high chances that you found this blog when you searched for the keyword “Faster R-CNN” as it has been among the state of arts used in many fields since January 2016.\\nA strong object detection architecture like Faster RCNN is built upon the successful research like R-CNN and Fast R-CNN. To honestly enjoy working, troubleshooting and pursuing the dream of creating your own model which can one day be called a state...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3867</td>\n",
       "      <td>Unchainet</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@unchainet/invest-in-unchainet-heterogeneous-cloud-computing-infrastructure-b61dd2ba36e0?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Invest in Unchainet |Heterogeneous Cloud Computing Infrastructure | by Unchainet | Medium</td>\n",
       "      <td>Aug 28, 2018\\nUnchainet is aiming to provide a decentralized cloud platform connecting providers with spare computing resources and clients who need them. Research shows 30% of servers in private data centers consume energy but are not being used. We are working to provide easy-to-install software for companies with private data centers, hosting companies and individuals so they can easily connect to the Unchainet network and start earning money on a transparent and efficient marketplace. Unchainet clients will include existing partners and all other cloud users. Our platform’s important differentiation from competing decentralized cloud platforms is familiar open source technology and bridging interfaces which completely removes friction associated with staff training and allows easy ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3868</td>\n",
       "      <td>Justin</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/teklit/coding-is-a-trap-get-out-14a6beb28c8?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Coding is a Trap. Get Out. | TekLit</td>\n",
       "      <td>TekLit\\nJul 10, 2021\\nThe looming threat to the average programmer.\\nLet’s face it. Unless you are talented enough for Google to hire you, you are probably limited to developing APIs, websites, or customizing an ERP-like business system.\\nIf toiling day after day, adding mundane features to boring systems isn’t enough for you, you have the added task of keeping up with the frameworks and tools that will evolve with...\\n8.8K \\n8.8K \\n295\\nWe’re software developers, for better or for worse. Friendlier than your average StackOverflow moderator, but we probably won’t fix your code.\\n1.9K Followers\\nSoftware Developer | Writer for TekLit\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3869</td>\n",
       "      <td>Daniel Emaasit</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/emaasit/in-case-you-missed-it-my-webinar-on-model-based-machine-learning-1ca6bef79ae?source=tag_archive---------1-----------------------</td>\n",
       "      <td>In case you missed it: My Webinar on Model-Based Machine Learning | by Daniel Emaasit | emaasit | Medium</td>\n",
       "      <td>emaasit\\nAug 3, 2016\\nIn case you missed my free webinar on “Model-Based Machine Learning”, here is the recording.\\nApologies for the poor quality of the video. Domino Data Lab’s webinar platform suffered a service degradation while recording the event. The webinar slides may be found below.\\n[slideshare id=64647075&amp;doc=3rdpresentationpaperreview-160803065711]\\nIf you have any questions, please do not hesitate to contact me. Finally, I would like to thank Daniel Enthoven and Daniel Chalef from Domino Data Lab for setting up this webinar.\\nEmaasit’s personal blog about R, Bayesian Machine Learning, Big Data, Bayesian Nonparametrics, &amp; Probabilistic Programming\\n252 Followers\\nFounder at @SparkIQ_Labs, PhD Student in Urban Mobility, Bayesian Machine Learning Research Scientist, Organizer...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3870</td>\n",
       "      <td>RomRoc</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/hackernoon/instance-segmentation-in-google-colab-with-custom-dataset-b3099ac23f35?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Instance Segmentation in Google Colab with Custom Dataset | by RomRoc | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nSep 18, 2018\\nThis article proposes an easy and free solution to train a Tensorflow model for instance segmentation in Google Colab notebook, with a custom dataset.\\nPrevious article was about Object Detection in Google Colab with Custom Dataset, where I trained a model to infer bounding box of my dog in pictures. The protagonist of my article is again my dog: in this case we take a step forward, we identify not only the bounding box, we make even pixel wise classification.\\nCompared to previous article, we hold the same characteristics:\\nThese features allow anybody following this tutorial to create an instance segmentation model, and test it in Google Colab or export the model to run in a local machine.\\nSource code of this article, including the sample dataset, is av...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3871</td>\n",
       "      <td>Javed Shaikh</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK. | by Javed Shaikh | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 23, 2017\\nLatest Update:I have uploaded the complete code (Python and Jupyter notebook) on GitHub: https://github.com/javedsha/text-classification\\nDocument/Text classification is one of the important and typical task in supervised machine learning (ML). Assigning categories to documents, which can be a web page, library book, media articles, gallery etc. has many applications like e.g. spam filtering, email routing, sentiment analysis etc. In this article, I would like to demonstrate how we can do text classification using python, scikit-learn and little bit of NLTK.\\nDisclaimer: I am new to machine learning and also to blogging (First). So, if there are any mistakes, please do let me know. All feedback appreciated.\\nLet’s divide the classification problem in...</td>\n",
       "      <td>8677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3872</td>\n",
       "      <td>Bruce Yang</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Deep Reinforcement Learning for Automated Stock Trading | by Bruce Yang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 25, 2020\\nNote from Towards Data Science’s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author’s contribution. You should not rely on an author’s works without seeking professional advice. See our Reader Terms for details.\\nThis blog is based on our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, presented at ICAIF 2020: ACM International Conference on AI in Finance.\\nOur codes are available on Github.\\ngithub.com\\nOur paper is available on SSRN.\\npapers.ssrn.com\\nIf you want to cite our paper, the reference format is as follows:\\nHongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated S...</td>\n",
       "      <td>2217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3873</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/the-official-unofficial-firefox-blog/the-first-inaugural-firefox-census-results-a1a05327ed7f?source=tag_archive---------2-----------------------</td>\n",
       "      <td>The First Inaugural Firefox Census Results | by Firefox | The Official Unofficial Firefox Blog | Medium</td>\n",
       "      <td>The Official Unofficial Firefox Blog\\nNov 10, 2016\\nWe did a bit of informal censusing last month to get to know our users in the best way possible: anonymously and collectively. You might have seen the survey, which we shared through email, our about:home page, and social media. You might have also noticed it came from our Bureau of Censusing (not an official team here), Department of Whimsy (also not an official department, but you better believe we’re doing some introspection now as to why not). It was totally voluntary and, like everything we do, about openness and transparency.\\nSo in that spirit, let’s look at the results! You can find the full report here, if you’re into that sort of thing. There were 44 questions and a ton of interesting ways to slice the data, so for the sake ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3874</td>\n",
       "      <td>Ketan Doshi</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Audio Deep Learning Made Simple: Automatic Speech Recognition (ASR), How it Works | by Ketan Doshi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 25, 2021\\nOver the last few years, Voice Assistants have become ubiquitous with the popularity of Google Home, Amazon Echo, Siri, Cortana, and others. These are the most well-known examples of Automatic Speech Recognition (ASR). This class of applications starts with a clip of spoken audio in some language and extracts the words that were spoken, as text. For this reason, they are also known as Speech-to-Text algorithms.\\nOf course, applications like Siri and the others mentioned above, go further. Not only do they extract the text but they also interpret and understand the semantic meaning of what was spoken, so that they can respond with answers, or take actions based on the user's commands.\\nIn this article, I will focus on the core capability of Speech-to-...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3875</td>\n",
       "      <td>Chunguang (Wayne) Zhang</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/eagleview-super-high-resolution-image-segmentation-with-deeplabv3-mask-rcnn-using-keras-arcgis-9be08caac42c?source=tag_archive---------5-----------------------</td>\n",
       "      <td>EagleView high-resolution image semantic segmentation with Mask-RCNN/DeepLabV3+ using Keras and ArcGIS Pro | by Chunguang (Wayne) Zhang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 10, 2019\\nComputer vision in Machine Learning provides enormous opportunities for GIS. Its tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions.[1][2][3][4] In the last several years, computer vision is increasingly shifting from traditional statistical methods to the state-of-art deep learning neural network techniques.\\nIn this blog, I will share several empirical practices using Keras and ESRI ArcGIS Pro tools with deep learning and transfer learning techniques to build a building footprint image segmentation network model from a super-high-resolution 3-inch of EagleView (Pi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3876</td>\n",
       "      <td>Uday Paila</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@udaybhaskarpaila/everything-you-need-to-know-about-logistic-regression-18e740be87a0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Everything You Need to Know about Logistic Regression | by Uday Paila | Medium</td>\n",
       "      <td>Feb 6, 2020\\nIn this article, I will discuss all cases of Logistic Regression that are useful while applying.\\nLet’s take x as an input feature vector, and y is a class (-1 or +1), then the probability of class given input vector represented by the below formula.\\nand log loss is\\nLoss with regularization for optimization is\\nN is the number of data points we have, C is hyperparameter to control regularization. Above I added l2 regularization notation. x_i is the data points features and y_i(+1 or -1) is the label we have for x_i. This formulation works only for Binary classification.\\nAlso, we can represent the Loss function as below, and that works for multiclass formulation as well.\\nLet’s take we have K classes and N number of data points. Now the Log loss function is represented a...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3877</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Gradient descent algorithms and adaptive learning rate adjustment methods | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 14, 2017\\nHere is a quick concise summary for reference. For more detailed explanation please read: http://ruder.io/optimizing-gradient-descent/\\nVanilla gradient descent, aka batch gradient descent, computes the gradient of the cost function w.r.t. to the parameters θ for the entire training dataset.\\nStochastic gradient descent (SGD) in contrast performs a parameter update for each training example x(i) and label y(i)\\nMini-batch gradient descent finally takes the best of both worlds and performs an update for every mini-batch of n training examples.\\nVanilla mini-batch gradient descent, however, does not guarantee good convergence, but offers a few challenges that need to be addressed:\\nSGD has trouble navigating ravines, i.e. areas where the surface curves...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3878</td>\n",
       "      <td>Charlie Kufs</td>\n",
       "      <td>6</td>\n",
       "      <td>https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English</td>\n",
       "      <td>Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3879</td>\n",
       "      <td>Tara Mullin</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd?source=tag_archive---------1-----------------------</td>\n",
       "      <td>DBSCAN Parameter Estimation Using Python | by Tara Mullin | Medium</td>\n",
       "      <td>Jul 10, 2020\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is an unsupervised machine learning technique used to identify clusters of varying shape in a data set (Ester et al. 1996). Another post I wrote goes into what DBSCAN is and when to use it. You can find it here. This post will focus on estimating DBSCAN’s two parameters:\\nThere is no automatic way to determine the MinPts value for DBSCAN. Ultimately, the MinPts value should be set using domain knowledge and familiarity with the data set. From some research I’ve done, here are a few rules of thumb for selecting the MinPts value:\\nAfter you select your MinPts value, you can move on to determining ε. One technique to automatically determine the optimal ε value is described in this paper. This technique calc...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3880</td>\n",
       "      <td>Amirhossein Heydarian</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/u-net-for-semantic-segmentation-on-unbalanced-aerial-imagery-3474fa1d3e56?source=tag_archive---------4-----------------------</td>\n",
       "      <td>U-Net for Semantic Segmentation on Unbalanced Aerial Imagery | by Amirhossein Heydarian | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 3, 2021\\nIn this article, we review the problem of semantic segmentation on unbalanced binary masks. Focal loss and mIoU are introduced as loss functions to tune the network parameters. Finally, we train the U-Net implemented in PyTorch to perform semantic segmentation on aerial images. The training codes and PyTorch implementations are available through Github.\\nThe dataset used here is “Semantic segmentation of aerial imagery” which contains 72 satellite images of Dubai, the UAE, and is segmented into 6 classes. The classes include water, land, road, building, vegetation, and unlabeled.\\nU-Net is a convolutional neural network that originally was presented for biomedical image segmentation at the Computer Science Department of the University of Freiburg. It ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3881</td>\n",
       "      <td>Learner Subodh</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/analytics-vidhya/dimensionality-reduction-by-stochastic-gradient-descent-f617ebde3c1b?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Dimensionality Reduction by Stochastic Gradient Descent | by Learner Subodh | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 27, 2020\\nThis post demonstrates the use of Stochastic Gradient Descent for Dimensionality Reduction.\\nWhat is Dimensionality Reduction?\\nDimensionality reduction is the process of reducing a potentially large set of features F to a smaller set of features F’ to be considered in a given machine learning or statistics problem.\\nIn an unsupervised setting, dimensionality reduction is often used for exploratory data analysis, for example to visualize the distribution of high dimensional data in human-digestible two or three dimensions. In a supervised setting, the main use is to reduce the number of parameters a learning machine has to determine. In other words: The goal of dimensionality reduction is to overcome the curse of dimensionality.\\nA straightforward approa...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3882</td>\n",
       "      <td>Walid Amamou</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647?source=tag_archive---------7-----------------------</td>\n",
       "      <td>How to Fine-Tune BERT Transformer with spaCy 3 | by Walid Amamou | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 28, 2021\\nSince the seminal paper “Attention is all you need” of Vaswani et al, Transformer models have become by far the state of the art in NLP technology. With applications ranging from NER, Text Classification, Question Answering or text generation, the applications of this amazing technology are limitless.\\nMore specifically, BERT — which stands for Bidirectional Encoder Representations from Transformers— leverages the transformer architecture in a novel way. For example, BERT analyses both sides of the sentence with a randomly masked word to make a prediction. In addition to predicting the masked token, BERT predicts the sequence of the sentences by adding a classification token [CLS] at the beginning of the first sentence and tries to predict if the sec...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3883</td>\n",
       "      <td>Arthur Juliani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...</td>\n",
       "      <td>16886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3884</td>\n",
       "      <td>Becky Zhu</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/unpackai/sgd-mnist-putting-it-all-together-2b09d21c9e9a?source=tag_archive---------8-----------------------</td>\n",
       "      <td>SGD: MNIST — Putting it all together | by Becky Zhu | unpackAI | Medium</td>\n",
       "      <td>unpackAI\\nJun 6, 2021\\nThere are 7 steps to train/get a model in deep learning like this chart:\\nWe now put it with the SGD together and look at them step by step:\\nStep 1: Initialize\\nIn this step, we initialize our parameters with random values and tell PyTorch that we want to track their gradients:\\nWe will do the following things in this step:\\nStep 2: Predict\\nIn this step,we will calculate the predictions to see how close our predictions to our targets. The code will like this\\npreds = f(time, params)\\nStep 3: Calculate the Loss\\nIn this step, can change the weight by a little in the direction of the slope, calculate the loss and adjustment again, and repeat this a few times. We will get to the lowest point on the curve. We can use “mse”or “l1”to calculate.\\n“mse”stands for *mean...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3885</td>\n",
       "      <td>Utkarsh Ankit</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f?source=tag_archive---------9-----------------------</td>\n",
       "      <td>What is Transformer Network | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 24, 2020\\nThe Transformer Neural Network is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease. It was proposed in the paper “Attention Is All You Need” 2017 [1]. It is the current state-of-the-art technique in the field of NLP.\\nBefore directly jumping to Transformer, I will take some time to explain the reason why we use it and from where it comes into the picture. (If you want to skip this part then directly go to the Transformer topic, but I suggest you read it sequentially for better understanding).\\nSo, the story starts with RNN (Recurrent Neural Networks).\\nWhat is RNN? How is it different from simple ANN? What is the major difference?\\nRNNs are the Feed Forward Neural Networks that are ro...</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3886</td>\n",
       "      <td>Venkatesh Tata</td>\n",
       "      <td>10</td>\n",
       "      <td>https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Simple Image Classification using Convolutional Neural Network — Deep Learning in python. | by Venkatesh Tata | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nDec 13, 2017\\nIn this article we will be solving an image classification problem, where our goal will be to tell which class the input image belongs to. The way we are going to achieve it is by training an artificial neural network on few thousand images of cats and dogs and make the NN(Neural Network) learn to predict which class the image belongs to, next time it sees an image having a cat or dog in it.\\nThe key thing to understand while following this article is that the model we are building now can be trained on any type of class you want, i am using cat and dog only as a simple example for making you understand how convolutional neural networks work. For example, if there are any doctors reading this, after completing this article...</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3887</td>\n",
       "      <td>Sarthak Jain</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/nanonets/how-to-easily-detect-objects-with-deep-learning-on-raspberrypi-225f29635c74?source=tag_archive---------2-----------------------</td>\n",
       "      <td>How to easily Detect Objects with Deep Learning on Raspberry Pi | by Sarthak Jain | NanoNets | Medium</td>\n",
       "      <td>NanoNets\\nMar 20, 2018\\nDisclaimer: I’m building nanonets.com to help build ML with less data and no hardware\\nIf you’re impatient scroll to the bottom of the post for the Github Repos\\nThe raspberry pi is a neat piece of hardware that has captured the hearts of a generation with ~15M devices sold, with hackers building even cooler projects on it. Given the popularity of Deep Learning and the Raspberry Pi Camera we thought it would be nice if we could detect any object using Deep Learning on the Pi.\\nNow you will be able to detect a photobomber in your selfie, someone entering Harambe’s cage, where someone kept the Sriracha or an Amazon delivery guy entering your house.\\n20M years of evolution have made human vision fairly evolved. The human brain has 30% of it’s Neurons work on proces...</td>\n",
       "      <td>5908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3888</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/an-intuitive-explanation-of-beam-search-9b1d744e7a0f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>An intuitive explanation of Beam Search | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 2, 2020\\nIn this article, we will learn:\\nmedium.com\\ntowardsdatascience.com\\nIn this article, you will get a detailed explanation of how neural machine translation developed using sequence to sequence algorithm to find the most relevant words in sentences for a target language.\\nWhat is Beam search?\\nTo understand the Beam search, we will use the neural machine translation use case of sequence to sequence.\\nThe sequence to sequence model uses an encoder and decoder framework with Long Short Term Memory(LSTM) or Gated Recurrent Unit(GRU) as the basic blocks.\\nEncoder maps a source sequence encodes the source information and passes it to the decoder. The decoder takes the encoded data from the encoder as an input along with the start-of-string &lt;START&gt; token as ...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3889</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/the-games-that-ai-won-ff8fd4a71efc?source=tag_archive---------6-----------------------</td>\n",
       "      <td>The Games That AI Won. And The Progress They Represent | by Brandon Walker | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 15, 2020\\nSome tasks that AI does are actually not impressive. Think about your camera recognizing and auto-focusing on faces in pictures. That technology has been around since 2001, and it doesn’t tend to excite people. Why not? Well, because you can do that too, you can focus your eyes on someone’s face very easily. In fact, it’s so easy you don’t even know how you do it. If AI can do it too, then who cares how it works? Though we may not explicitly understand how this AI works, its underlying mechanisms don’t do anything we can’t. At least, this is what I think most people are thinking.\\nGames are just the opposite. Rather than games being an innate ability we have (like focusing your vision), you have an understanding of how and why you make decisions with...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3890</td>\n",
       "      <td>bitsofinfo</td>\n",
       "      <td>16</td>\n",
       "      <td>https://medium.com/@bitsofinfo/clustering-liferay-globally-across-data-centers-gslb-with-jgroups-and-relay2-7786b8dbbb96?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Clustering Liferay globally across data centers (GSLB) with JGroups and RELAY2 | by bitsofinfo | Medium</td>\n",
       "      <td>May 21, 2014\\nRecently I’ve have been looking into options to solve the problem of GSLB’ing (global server load balancing) a Liferay Portal instance.\\nThis article is a work in progress... and a long one. Jan Eerdekens states it correctly in his article, “Configuring a Liferay cluster is part experience and part black magic” .... however doing it across data-centers however is like wielding black magic across N black holes....\\nFootnotes for this article are here: https://bitsofinfo.wordpress.com/2014/05/21/liferay-clustering-internals/\\nThe objective is a typical one.\\nHopefully this article will help others out there, point them in a new direction and give them some ideas on how to put something like this together.\\nI’d like to note that this is not necessarily the ideal way to do th...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3891</td>\n",
       "      <td>Andreas Yonathan</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@andreasyonathan/kuliah-itu-gak-penting-292defe6d476?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Kuliah Itu Gak Penting. “Buat apa kuliah kalo kalah sukses atau... | by Andreas Yonathan | Medium</td>\n",
       "      <td>May 2, 2017\\n“Buat apa kuliah kalo kalah sukses atau gaji aja kalah gede dari lulusan SMA/SMK?”\\nSerius, pasti banyak orang yang pernah terlintas pikiran brilian seperti diatas. Bahkan bisa jadi kamu yang membaca ini adalah satunya bukan? Tenang saja, kamu tidak sendirian karena saya juga pernah berpikir seperti itu kok hehehe :D\\nYa, tidak bisa dipungkiri karena kita sering melihat contoh orang-orang terkenal yang sukses padahal mereka OD (baca: Out Dewe, kalau DO kan Drop Out, jelek kesannya ditendang, sementara OD gak perlu nunggu ditendang udah keluar-keluar sendiri hehehe :p) atau bahkan sekolah pun gak tamat. Contohnya Brad Pitt, Oprah Winfrey, Lady Gaga, John Lennon, Eminem. Nama-nama itu pasti sudah tidak asing lagi kan?\\nMungkin ada yang berpikir orang yang OD maupun DO tidak ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3892</td>\n",
       "      <td>Rostyslav Neskorozhenyi</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/word-embeddings-in-2020-review-with-code-examples-11eb39a1ee6d?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Word embeddings in 2020. Review with code examples | by Rostyslav Neskorozhenyi  | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 24, 2020\\nIn this article we will study word embeddings — digital representation of words suitable for processing by machine learning algorithms.\\nOriginally I created this article as a general overview and compilation of current approaches to word embedding in 2020, which our AI Labs team could use from time to time as a quick refresher. I hope that my article will be useful to a wider circle of data scientists and developers. Each word embedding method in the article has a (very) short description, links for further study, and code examples in Python. All code is packed as Google Colab Notebook. So let’s begin.\\nAccording to Wikipedia, Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language pro...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3893</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/autoencoders-introduction-and-implementation-3f40483b0a85?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Autoencoders — Introduction and Implementation in TF. | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 26, 2017\\nAutoencoders (AE) are a family of neural networks for which the input is the same as the output (they implement a identity function). They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.\\nA really popular use for autoencoders is to apply them to images. The trick is to replace fully connected layers by convolutional layers. These, along with pooling layers, convert the input from wide and thin (let’s say 100 x 100 px with 3 channels — RGB) to narrow and thick. This helps the network extract visual features from the images, and therefore obtain a much more accurate latent space representation. The reconstruction process uses upsampling and convolutions.\\nThe resulting netwo...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3894</td>\n",
       "      <td>Anne Bonner</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Getting Started With Google Colab | by Anne Bonner | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 1, 2019\\nYou know it’s out there. You know there’s free GPU somewhere, hanging like a fat, juicy, ripe blackberry on a branch just slightly out of reach.\\nBeautiful lightning-fast speed waiting just for you.\\nWondering how on earth to get it to work? You’re in the right place!\\nFor anyone who doesn’t already know, Google has done the coolest thing ever by providing a free cloud service based on Jupyter Notebooks that supports free GPU. Not only is this a great tool for improving your coding skills, but it also allows absolutely anyone to develop deep learning applications using popular libraries such as PyTorch, TensorFlow, Keras, and OpenCV.\\nColab provides GPU and it’s totally free. Seriously!\\nThere are, of course, limits. (Nitty gritty details are availabl...</td>\n",
       "      <td>4477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3895</td>\n",
       "      <td>Diego Lopez Yse</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Your Guide to Natural Language Processing (NLP) | by Diego Lopez Yse | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 15, 2019\\nEverything we express (either verbally or in written) carries huge amounts of information. The topic we choose, our tone, our selection of words, everything adds some type of information that can be interpreted and value extracted from it. In theory, we can understand and even predict human behaviour using that information.\\nBut there is a problem: one person may generate hundreds or thousands of words in a declaration, each sentence with its corresponding complexity. If you want to scale and analyze several hundreds, thousands or millions of people or declarations in a given geography, then the situation is unmanageable.\\nData generated from conversations, declarations or even tweets are examples of unstructured data. Unstructured data doesn’t fit n...</td>\n",
       "      <td>2369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3896</td>\n",
       "      <td>Jessica Dafflon</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/pixelcnns-blind-spot-84e19a3797b9?source=tag_archive---------6-----------------------</td>\n",
       "      <td>PixelCNN’s Blind Spot. Limitations of the PixelCNN and how to... | by Jessica Dafflon | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 8, 2021\\nWritten by Walter Hugo Lopez Pinaya, Pedro F. da Costa, and Jessica Dafflon\\nHi everybody! Today, we will continue the series about autoregressive models and we will focus on one of the biggest limitations of PixelCNNs (i.e., blind spots) and how to improve to fix it.\\nSummary\\nFor each topic, the code is availiable in this repository.\\nIn the previous two posts, we introduced generative models, the concept behind PixelCNNs, and looked at how a coloured PixelCNN works. Recall that PixelCNNs are a type of generative models that learn the probability distribution of pixels, that means that the intensity of future pixels will be determined by previous pixels. In this blogpost series we implemented two PixelCNNs and noticed that the performance was not st...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3897</td>\n",
       "      <td>Matthew Stewart, PhD Researcher</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Simple Introduction to Convolutional Neural Networks | by Matthew Stewart, PhD Researcher | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 26, 2019\\nIn this article, I will explain the concept of convolution neural networks (CNN’s) using many swan pictures and will make the case of using CNN’s over regular multilayer perceptron neural networks for processing images.\\nImage Analysis\\nLet us assume that we want to create a neural network model that is capable of recognizing swans in images. The swan has certain characteristics that can be used to help determine whether a swan is present or not, such as its long neck, its white color, etc.\\nFor some images, it may be more difficult to determine whether a swan is present, consider the following image.\\nThe features are still present in the above image, but it is more difficult for us to pick out these characteristic features. Let us consider some mor...</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3898</td>\n",
       "      <td>Md Sohel Mahmood</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/practical-implementation-of-outlier-detection-in-python-90680453b3ce?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Practical implementation of outlier detection in python | by Md Sohel Mahmood | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 26, 2020\\nOutliers, one of the buzzwords in the manufacturing industry, has driven engineers and scientists to develop newer algorithms as well as robust techniques for continuous quality improvement. If the data include even if one outlier, it has the potential to dramatically skew the calculated parameters. Therefore, it is of utmost importance to analyze the data without those deviant points. It is also important to understand which of the data points are considered as outliers. Extreme data points do not always necessarily mean those are outliers.\\nIn this article, I will discuss the algorithm and the python implementation for three different outlier detection techniques. Those are Interquartile (IQR) method, Hampel method and DBSCAN clustering method.\\nIn...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3899</td>\n",
       "      <td>Vladimir Shapiro</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/sap-design/explaining-system-intelligence-68f8fcc07a64?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Explaining system intelligence. Empower your users, but don’t overwhelm... | by Vladimir Shapiro | SAP Design | Medium</td>\n",
       "      <td>SAP Design\\nApr 11, 2018\\nThis blog belongs to the SAP Design series about intelligent system design. You might also be interested in our previous post, 5 Challenges to Your Machine Learning Project.\\nOne of the guiding design principles for intelligent systems is to empower end users. If we want people to trust machines, we must share information about the underlying models and the reasoning behind the results of algorithms. This is even more vital for business applications, when users are held accountable for every decision they make.\\nIt’s widely accepted that intelligent systems must come with a certain level of transparency. There’s even a new term for it: explainable AI. But, that’s just the beginning. As designers, we need to ask ourselves how explainable AI is tied to user inte...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3900</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Topic Modeling and Latent Dirichlet Allocation (LDA) in Python | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 31, 2018\\nTopic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.\\nHere we are going to apply LDA to a set of documents and split them into topics. Let’s get started!\\nThe data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from Kaggle.\\nTake a peek of the data.\\n1048575\\nWe will perform the following steps:\\nLoading gensim and nltk libraries\\n[nltk_data] Downloading package wordnet to[nltk_data]...</td>\n",
       "      <td>5151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3901</td>\n",
       "      <td>Neeraj Varshney</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/analytics-vidhya/step-by-step-implementation-of-conditional-generative-adversarial-networks-54e4b47497d6?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Step by Step Implementation of Conditional Generative Adversarial Networks | by Neeraj Varshney | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJun 7, 2020\\nGenerative Adversarial Networks (GANs) have had a lot of success since they were introduced in 2014 by Ian Goodfellow. For somebody starting out in Machine Learning, the intricate Mathematics and the complex-looking architecture of GANs seems daunting. So, let’s demystify GANs/C-GANs and implement a simple application with PyTorch. This article is self-contained and is targeted for beginner to intermediate level Machine Learning enthusiasts.\\n159 \\n159 \\n2\\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n105 Followers\\nPh.D. student in Natural Language Processing (https://nrjvarshney.github.io)\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nT...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3902</td>\n",
       "      <td>Aakanksha NS</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/multiclass-text-classification-using-lstm-in-pytorch-eac56baed8df?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Multiclass Text Classification using LSTM in Pytorch | by Aakanksha NS | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 7, 2020\\nHuman language is filled with ambiguity, many-a-times the same phrase can have multiple interpretations based on the context and can even appear confusing to humans. Such challenges make natural language processing an interesting but hard problem to solve. However, we’ve seen a lot of advancement in NLP in the past couple of years and it’s quite fascinating to explore the various techniques being used. This article aims to cover one such technique in deep learning using Pytorch: Long Short Term Memory (LSTM) models.\\nHere’s a link to the notebook consisting of all the code I’ve used for this article: https://jovian.ml/aakanksha-ns/lstm-multiclass-text-classification\\nIf you’re new to NLP or need an in-depth read on preprocessing and word embeddings, y...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3903</td>\n",
       "      <td>Animesh Agarwal</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Linear Regression using Python. Linear Regression is usually the first... | by Animesh Agarwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 5, 2018\\nLinear Regression is usually the first machine learning algorithm that every data scientist comes across. It is a simple model but everyone needs to master it as it lays the foundation for other machine learning algorithms.\\nWhere can Linear Regression be used? It is a very powerful technique and can be used to understand the factors that influence profitability. It can be used to forecast sales in the coming months by analyzing the sales data for previous months. It can also be used to gain various insights about customer behaviour. By the end of the blog we will build a model which looks like the below picture i.e, determine a line which best fits the data.\\nThis is the first blog of the machine learning series that I am going to cover. One can get ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3904</td>\n",
       "      <td>Vindula Jayawardana</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/autoencoders-bits-and-bytes-of-deep-learning-eaba376f23ad?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Autoencoders — Bits and Bytes of Deep Learning | by Vindula Jayawardana | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 4, 2017\\nOne way to think of what deep learning does is as “A to B mappings,” says Andrew Ng, chief scientist at Baidu Research. “You can input an audio clip and output the transcript. That’s speech recognition.” As long as you have data to train the software, the possibilities are endless, he maintains. “You can input email, and the output could be: Is this spam or not?” Input loan applications, he says, and the output might be the likelihood a customer will repay it. Input usage patterns on a fleet of cars and the output could advise where to send a car next.\\nRather making the facts complicated by having complex definitions, think of deep learning as a subset of a subset. Artificial Intelligence encircles a wide range of technologies and techniques that ena...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3905</td>\n",
       "      <td>Dhruv Parthasarathy</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@dhruvp/how-to-write-a-neural-network-to-play-pong-from-scratch-956b57d4f6e0?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Write an AI to win at Pong from scratch with Reinforcement Learning | by Dhruv Parthasarathy | Medium</td>\n",
       "      <td>Sep 25, 2016\\nThere’s a huge difference between reading about Reinforcement Learning and actually implementing it.\\nIn this post, you’ll implement a Neural Network for Reinforcement Learning and see it learn more and more as it finally becomes good enough to beat the computer in Pong! You can play around with other such Atari games at the OpenAI Gym.\\nBy the end of this post, you’ll be able to do the following:\\nThe code and the idea are all tightly based on Andrej Karpathy’s blog post. The code in me_pong.py is intended to be a simpler to follow version of pong.py which was written by Dr. Karpathy.\\nTo follow along, you’ll need to know the following:\\nIf you want a deeper dive into the material at hand, read the blog post on which all of this is based. This post is meant to be a simpl...</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3906</td>\n",
       "      <td>Sebastian Theiler</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Basics of Using Pre-trained GloVe Vectors in Python | by Sebastian Theiler | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nSep 7, 2019\\nThis article will cover: * Downloading and loading the pre-trained vectors * Finding similar vectors to a given vector * “Math with words” * Visualizing the vectors\\nFurther reading resources, including the original GloVe paper, are available at the end.\\nGlobal Vectors for Word Representation, or GloVe, is an “unsupervised learning algorithm for obtaining vector representations for words.” Simply put, GloVe allows us to take a corpus of text, and intuitively transform each word in that corpus into a position in a high-dimensional space. This means that similar words will be placed together.\\nIf you would like a detailed explanation of how GloVe works, linked articles are available at the end.\\nHead over to https://nlp.stanford.edu/projects/glove/.Then un...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3907</td>\n",
       "      <td>Himanshu Chandra</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Pipelines &amp; Custom Transformers in scikit-learn: The step-by-step guide (with Python code) | by Himanshu Chandra | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 6, 2020\\nThis article will cover:\\nThere’s a video walkthrough of the code at the end for those who prefer the format. I personally like written tutorials, but I’ve had requests for video versions too in the past, so there it is.\\nSince you are here, there’s a very good chance you already know Pipelines make your life easy by pre-processing the data. I heard that too and tried to implement one in my code.\\nA shout-out to the few great tutorials I could find on the topic! I recommend you certainly browse through them, before or after the current article :\\ni. https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65ii. https://machinelearningmastery.com/how-to-transform-target-variables-for-regression-with-scikit-learniii...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3908</td>\n",
       "      <td>William Scott</td>\n",
       "      <td>19</td>\n",
       "      <td>https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089?source=tag_archive---------2-----------------------</td>\n",
       "      <td>TF-IDF from scratch in python on a real-world dataset. | by William Scott | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 15, 2019\\nTF-IDF stands for “Term Frequency — Inverse Document Frequency”. This is a technique to quantify words in a set of documents. We generally compute a score for each word to signify its importance in the document and corpus. This method is a widely used technique in Information Retrieval and Text Mining.\\nIf I give you a sentence for example “This building is so tall”. It's easy for us to understand the sentence as we know the semantics of the words and the sentence. But how can any program (eg: python) interpret this sentence? It is easier for any programming language to understand textual data in the form of numerical value. So, for this reason, we need to vectorize all of the text so that it is better represented.\\nBy vectorizing the documents we ca...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3909</td>\n",
       "      <td>Kevin Luxem</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/deep-latent-variable-models-unravel-hidden-structures-a5df0fd32ae2?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Deep Latent Variable Models: Unravel Hidden Structures | by Kevin Luxem | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nUnderstanding the underlying structure of real-world data is one of the most compelling quests in machine learning. But with the advent of deep generative models researcher and practitioners have a powerful method to unravel it.\\nReal-world data is often complex and high-dimensional. Traditional approaches of data analysis are in most cases ineffective and can only model a very simple data distribution. Nowadays, we can use machine learning models to directly learn the structure of our data. The most common approach in machine learning is supervised learning, where we ask the model to learn a mapping from an input to an output variable, e.g. an image x to a label y. However, labelled data is expensive and prone to errors or biases by the human annota...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3910</td>\n",
       "      <td>Sourav kumar</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Sentence correction using Deep learning techniques | by Sourav kumar | Medium</td>\n",
       "      <td>Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3911</td>\n",
       "      <td>Elif Meşeci</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@elifmeseci/r-cnn-ailesi-part-ii-76cce9e4a9d6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>R — CNN Ailesi Part II: Faster R-CNN &amp; Mask R-CNN | by Elif Meşeci | Medium</td>\n",
       "      <td>Aug 19, 2021\\nMerhaba, R-CNN Ailesi: Part I’ de CNN , R- CNN ve Fast R-CNN’den bahsetmiştim. Bu yazıda ise Faster R-CNN ile Mask R-CNN’in gelişimini, avantajlarını ve dezavantajlarını inceleyeceğiz.\\nBir önceki yazımda bahsettiğim R-CNN ve Fast R-CNN, bölge tekliflerini bulmak için seçici arama kullanır. Seçici arama, ağın performansını etkileyen yavaş ve zaman alıcı bir işlemdir. Bunun üzerine Shaoqing Ren ve ark. seçici arama algoritmasını ortadan kaldıran ve ağın bölge tekliflerini öğrenmesini sağlayan bir nesne algılama algoritması geliştirdi. Faster R-CNN’de bölge tekliflerini belirlemek için özellik haritası üzerinde Seçici Arama algoritması kullanmak yerine Bölge Teklif Ağı (RPN — Region Proposal Network) kullanılır.\\nFaster R-CNN’de izlenen adımlar:\\n...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3912</td>\n",
       "      <td>M Bharathwaj</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/clustering-techniques-hierarchical-and-non-hierarchical-b520b5d6a022?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Clustering Techniques. Clustering falls under the unsupervised... | by M Bharathwaj | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 22, 2020\\nClustering falls under the unsupervised learning technique. In this technique, the data is not labelled and there is no defined dependant variable. This type of learning is usually done to identify patterns in the data and/or to group similar data.\\nIn this post, a detailed explanation on the type of clustering techniques and a code walk-through is provided.\\nClustering is a method of grouping of similar objects. The objective of clustering is to create homogeneous groups out of heterogeneous observations. The assumption is that the data comes from multiple population, for example, there could be people from different walks of life requesting loan from a bank for different purposes. If the person is a student, he/she could ask for an education loan, ...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3913</td>\n",
       "      <td>Sairaj Neelam</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/analytics-vidhya/introduction-to-object-detection-with-rcnn-family-models-310558ce2033?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction to Object Detection with RCNN Family Models | by Sairaj Neelam | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 28, 2021\\nIn this post, you will discover a gentle introduction to the problem of object detection and state-of-the-art deep learning models designed to address it.\\nAfter reading this post, you will know:\\nLet’s get started.\\nThis article is divided into three parts; they are:\\n· Input: An image with a single object, such as a photograph.\\n· Output: A class label (e.g. one or more integers that are mapped to class labels).\\n2. Object Localization: Locate the objects in an image and output their location with a bounding box.\\n· Input: An image with one or more objects, such as a photograph.\\n· Output: One or more bounding boxes (e.g. defined by a point, width, and height).\\n3. Object Detection: Locate the objects with a bounding box and types or classes of the loc...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3914</td>\n",
       "      <td>Rowel Atienza</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537?source=tag_archive---------0-----------------------</td>\n",
       "      <td>LSTM by Example using Tensorflow. In Deep Learning, Recurrent Neural... | by Rowel Atienza | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 17, 2017\\nIn Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class of RNN that has found practical applications is Long Short-Term Memory (LSTM) because it is robust against the problems of long-term dependency. There is no shortage of articles and references explaining LSTM. Two recommended references are:\\nChapter 10 of Deep Learning Book by Goodfellow et. al.\\nUnderstanding LSTM Networks by Chris Olah\\nThere is also no shortage of good libraries to build machine learning applications based on LSTM. In GitHub, Google’s Tensorflow has now over 50,000 stars at the time of this writing suggesting a strong popularity among machine learning practitioners.\\nWhat seems to be lacking is a...</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3915</td>\n",
       "      <td>Michael Phi</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Illustrated Guide to LSTM’s and GRU’s: A step by step explanation | by Michael Phi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 24, 2018\\nHi and welcome to an Illustrated Guide to Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU). I’m Michael, and I’m a Machine Learning Engineer in the AI voice assistant space.\\nIn this post, we’ll start with the intuition behind LSTM ’s and GRU’s. Then I’ll explain the internal mechanisms that allow LSTM’s and GRU’s to perform so well. If you want to understand what’s happening under the hood for these two networks, then this post is for you.\\nYou can also watch the video version of this post on youtube if you prefer.\\nRecurrent Neural Networks suffer from short-term memory. If a sequence is long enough, they’ll have a hard time carrying information from earlier time steps to later ones. So if you are trying to process a paragraph of text ...</td>\n",
       "      <td>18245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3916</td>\n",
       "      <td>IPG Media Lab</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/ipg-media-lab/amazon-adds-photographic-product-search-to-ios-app-3c023e5d71ed?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Amazon Adds Photographic Product Search To iOS App | by IPG Media Lab | IPG Media Lab | Medium</td>\n",
       "      <td>IPG Media Lab\\nFeb 7, 2014\\nAmazon is raising the stakes of showrooming for retailers once again, folding its “Flow” technology, previously found in a standalone app released by its subsidiary, A9, into its main shopping app for iOS. “Flow” is visual product search, allowing users to photograph an object and see details about it on Amazon, which is even simpler than the previous norm of barcode recognition. Amazon’s competitive pricing is its main advantage in comparison to retailers, and by more effectively using other retailers as showrooms for the products it sells, it has the potential to further extend its dominance in more consumer categories.\\nThe media futures agency of IPG Mediabrands\\n1.99K Followers\\nKeeping brands ahead of the digital curve. An @IPGMediabrands company.\\nHel...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3917</td>\n",
       "      <td>Gabe Flomo</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How to cluster images based on visual similarity | by Gabe Flomo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 29, 2020\\nIn this tutorial, I'm going to walk you through using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.\\nThe pre-trained model that will be used in this tutorial is the VGG16 convolutional neural network (CNN), which is considered to be state of the art for image recognition tasks. We are going to be using this model as a feature extractor only, meaning that we will remove the final (prediction) layer so that we can obtain a feature vector.\\nThis implementation will use the flowers dataset from Kaggle which you can download here. The dataset contains 210 images of 10 different species of flowers that will be downloaded as png files.\\nBefore we get started, we need...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3918</td>\n",
       "      <td>Sumit Saha</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53?source=tag_archive---------2-----------------------</td>\n",
       "      <td>A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way | by Sumit Saha | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 15, 2018\\nArtificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.\\nThe agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image &amp; Video recognition, Image Analysis &amp; Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutiona...</td>\n",
       "      <td>7418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>3919</td>\n",
       "      <td>Diganta Kalita</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Solving the FrozenLake environment from OpenAI gym using Value Iteration | by Diganta Kalita | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nNov 28, 2019\\nSo I was trying to learn about Reinforcement Learning, and then I came across this thing called ‘Value Iteration’. I really couldn’t wrap my head around Value Iteration. It was very difficult for me to understand how it worked and how it could help an agent to find the optimal policy. Then I got an idea.\\nWhat better way to understand “Value Iteration” than to use it to solve some game or environment. Thus I began my journey to find some game easy enough problem to solve. And then I stumbled upon this fairy from OpenAI.\\nLet me explain the game/environment first.\\nThere are 64 states in the game. The agent starts from S (S for Start) and our goal is to get to G (G for Goal). So just go. Nope. Its a slippery surface. The F’s and the H’s in between are pre...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>3920</td>\n",
       "      <td>Lihi Gur Arie, PhD</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/neural-networks-backpropagation-by-dr-lihi-gur-arie-27be67d8fdce?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Neural Networks Backpropagation Made Easy | by Lihi Gur Arie, PhD | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 8, 2021\\nUnderstanding the mathematic operands behind Neural Networks (NNs) is highly important for the data scientist capabilities, in designing an efficient deep model. In this article, the high-level calculus of a fully connected NN will be demonstrated, with focus on the backward propagation step. The article is oriented to people with basic knowledge of NNs, that seek to dive deeper into the NNs structure.\\nThe objective of the training process is to find the weights (W) and biases (b) that minimize the error. It is done by the gradient descent algorithm. To begin with, the weights are randomly initialized, and an iterative process of a subtle weights change is performed until convergence.\\nEach iteration begins with a forward pass, that outputs the curre...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3921</td>\n",
       "      <td>Isaac Godfried</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/icml-2018-advances-in-transfer-multitask-and-semi-supervised-learning-2a15ef7208ec?source=tag_archive---------1-----------------------</td>\n",
       "      <td>ICML 2018: Advances in transfer, multitask, and semi-supervised learning | by Isaac Godfried | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 8, 2018\\nThe International Conference on Machine Learning took place last July in Stockholm. Altogether it showcased many interesting trends and directions in machine learning. Since, ICML was such a huge conference I will focus my attention on a few (of the many) interesting strands going on at the conference.\\nSpecifically, this year’s ICML split the oral talks into several different “tracks/sessions.” I was happy to see three of theses sessions focused on “transfer and multitask learning” as this has long been an area of interest of mine. Additionally, a large number of posters dealt with theses concepts as well as several orals from other tracks.\\nLack of large amounts of clean labeled data remains a barrier to the potential impact of deep learning. For ma...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>3922</td>\n",
       "      <td>Oleg Polosin</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/run-stylegan2-ada-on-an-aws-spot-instance-in-no-time-d2022fc1e119?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Run StyleGAN2 ADA on an AWS Spot Instance in No Time | by Oleg Polosin | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 1, 2020\\nRecently NVIDIA published a paper called “Training Generative Adversarial Networks with Limited Data” and released the code. They proposed an adaptive discriminator augmentation (ADA) mechanism that stabilizes StyleGAN2 training and achieves significantly better results on small datasets.\\nIn this post, we’ll show how to quickly run this code on an AWS Spot instance.\\n“A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly.”\\n— Spot Instances, AWS Documentation\\nTo launch a Spot instance and run a Docker container with the environment, we will be using Spotty. Spotty is an open-...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3923</td>\n",
       "      <td>Luís Roque</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/generating-text-with-recurrent-neural-networks-based-on-the-work-of-f-pessoa-1e804d88692d?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Generating text with Recurrent Neural Networks based on the work of F. Pessoa | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 19, 2021\\nSequences of discrete tokens can be found in many applications, namely words in a text, notes in a musical composition, pixels in an image, actions in a reinforcement learning agent, etc [1]. These sequences often show a strong correlation between consecutive or nearby tokens. The correlations on words in a sentence or characters in words express the underlying semantics and language characteristics. The next token in the sequence x_n can be modeled as:\\nwhere x_i represents the ith token in the sequence. In Natural Language Processing (NLP), these are defined as language models. Usually, each token stands for a separate word or n-gram. The output generated is a probability distribution from which we can sample to generate the next token in the seque...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3924</td>\n",
       "      <td>Adam Pickard</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@adampickard_44261/advancements-in-machine-learning-assisted-ideation-5c42cdf69c37?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Advancements in Machine Learning Assisted Ideation. | by Adam Pickard | Medium</td>\n",
       "      <td>Jun 23, 2020\\nThe most common debate around Artificial Intelligence and Machine Learning is “Will AI Take Your Job — or Make It Better?.” If most people had a choice, they would probably choose the latter. With any of these new technologies, it can be challenging to distinguish the hype from the headline. On one end, you have big tech companies and startups promising to fix problems ranging from detecting cancer to...\\n140 \\n140 \\n1\\nArt Director adampickard.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n13 Followers\\nArt Director adampickard.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3925</td>\n",
       "      <td>Jongdae Lim</td>\n",
       "      <td>24</td>\n",
       "      <td>https://medium.com/@jongdae.lim/%EA%B8%B0%EA%B3%84-%ED%95%99%EC%8A%B5-machine-learning-%EC%9D%80-%EC%A6%90%EA%B2%81%EB%8B%A4-part-5-83b7a44b797a?source=tag_archive---------8-----------------------</td>\n",
       "      <td>기계 학습(Machine Learning, 머신 러닝)은 즐겁다! Part 5 | by Jongdae Lim | Medium</td>\n",
       "      <td>Feb 24, 2017\\n딥러닝(Deep Learning)과 시퀀스(Sequence)의 마법을 사용한 언어 번역(Language Translation)\\n우리는 모두 마법처럼 100 가지 다른 언어를 즉시 번역 할 수 있는 웹 사이트 인 구글 번역(Google Translate)을 알고 있고 사랑합니다. 심지어 휴대 전화나 스마트 워치에서도 사용할 수 있습니다:\\n구글 번역에 사용된 기술을 기계 번역(Machine Translation)이라고 합니다. 다른 방법으로는 절대 불가능했던 전세계 사람들의 의사 소통을 가능하게 함으로써 세상을 변화시켰습니다.\\n그런데, 사실 고등학생들이... 음... 지난 15 년간 스페인어 숙제를 하기위해 구글 번역의 도움을 받아 왔다는 것을 모두 알고 있습니다. 그렇다면 이건 오래된 뉴스가 아닌가요?\\n지난 2 년 동안, 딥러닝(deep learning)은 기계 번역에 대하...</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3926</td>\n",
       "      <td>Daniel Godoy</td>\n",
       "      <td>21</td>\n",
       "      <td>https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Understanding PyTorch with an example: a step-by-step tutorial | by Daniel Godoy | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 7, 2019\\nUpdate (May 18th, 2021): Today I’ve finished my book: Deep Learning with PyTorch Step-by-Step: A Beginner’s Guide.\\nUpdate (February 23rd, 2022): The paperback edition is available now (in three volumes). For more details, please check pytorchstepbystep.com.\\nPyTorch is the fastest growing Deep Learning framework and it is also used by Fast.ai in its MOOC, Deep Learning for Coders and its library.\\nPyTorch is also very pythonic, meaning, it feels more natural to use it if you already are a Python developer.\\nBesides, using PyTorch may even improve your health, according to Andrej Karpathy :-)\\nThere are many many PyTorch tutorials around and its documentation is quite complete and extensive. So, why should you keep reading this step-by-step tutorial?\\...</td>\n",
       "      <td>9056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3927</td>\n",
       "      <td>Debarko De 🦁</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/hackernoon/rnn-or-recurrent-neural-network-for-noobs-a9afbb00e860?source=tag_archive---------6-----------------------</td>\n",
       "      <td>RNN or Recurrent Neural Network for Noobs | by Debarko De 🦁 | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nJun 19, 2018\\nWhat is a Recurrent Neural Network or RNN, how it works, where it can be used? This article tries to answer the above questions. It also shows a demo implementation of a RNN used for a specific purpose, but you would be able to generalise it for your needs.\\nKnowhow. Python, CNN knowledge is required. CNN is required to compare why and where RNN performs better than CNN? No need to understand the math. If you want to check then go back to my earlier article to check what is a CNN.\\nWe will begin with the word use of the word “Recurrent”. Why is it called Recurrent? In english the word recurrent means:\\noccurring often or repeatedly\\nIn the case of this type of Neural Network it’s called Recurrent since it does the same operation over and over on sets of se...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3928</td>\n",
       "      <td>Ayushi choudhary</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@2809ayushic/optimizers-in-deep-learning-31db684c73cf?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Optimizers in Deep Learning. What is Optimizers? | by Ayushi choudhary | Medium</td>\n",
       "      <td>Apr 5, 2021\\nWhat is Optimizers?\\nOptimizers are algorithms used to reduce the loss function and update the weights in backpropagation.\\nHere is the formula used by all the optimizers for updating the weights with a certain value of the learning rate.\\nThis is the most common optimizer used in neural networks. The weights are updated when the whole dataset gradient is calculated, If there is a huge amount of data weights updation takes more time and required huge amount of RAM size memory which will slow down the process and computationally expensive.\\nThere is also a saddle point problem. This is a point where the gradient is zero but is not an optimal point.\\nIn some cases, problems like Vanishing Gradient or Exploding Gradient may also occur due to incorrect parameter initialization...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3929</td>\n",
       "      <td>Samuele Mazzanti</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/isolation-forest-the-anomaly-detection-algorithm-any-data-scientist-should-know-1a99622eec2d?source=tag_archive---------1-----------------------</td>\n",
       "      <td>“Isolation Forest”: The Anomaly Detection Algorithm Any Data Scientist Should Know | by Samuele Mazzanti | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 4, 2021\\n“Isolation Forest” is a brilliant algorithm for anomaly detection born in 2009 (here is the original paper). It has since become very popular: it is also implemented in Scikit-learn (see the documentation).\\nIn this article, we will appreciate the beauty in the intuition behind this algorithm and understand how exactly it works under the hood, with the aid of some examples.\\nAnomaly (or outlier) detection is the task of identifying data points that are “very strange” compared to the majority of observations.\\nThis is useful in a range of applications, from fault detection to discovery of financial frauds, from finding health issues to identifying unsatisfied customers. Moreover, it can also be beneficial for machine learning pipelines, since it has be...</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3930</td>\n",
       "      <td>Mukul Malik</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/hackernoon/word2vec-part-1-fe2ec6514d70?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Word2Vec (Part 1). Word2Vec; the Steroids for Natural... | by Mukul Malik | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nOct 15, 2016\\nWord2Vec; the Steroids for Natural Language Processing\\nLet’s start with the Basics.\\nQ) What are word vectors?\\nAns) Representation of words with numbers.\\nQ) Why Word Vectors?\\nAns) I’ll sum it up with three main reasons:\\n1. Computer cannot do computations on strings.\\n2. Strings don’t hold much explicit information themselves.\\n3. Words Vectors are usually dense vector representations.\\nQ) So what is Explicit information?\\nAns) Yes, the word itself doesn’t say much about what it represents in real life. Example:\\nThe string “cat” just tells us it has three alphabets “c”, ”a” and “t”.\\nIt has no information about the animal it represents or the count or the context in which it is being used.\\nQ) Dense Vector Representation?\\nAns) Short answer (for now),...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3931</td>\n",
       "      <td>Dr. Varshita Sher</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/keywords-to-know-before-you-start-reading-papers-on-gans-8a08a665b40c?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Keywords to know before you start reading papers on GANs | by Dr. Varshita Sher | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 22, 2021\\nThere is no denying the fact that GANs are awesome! If you don’t know what they are, check out this article where I explain GANs from scratch to a 5-year old and how to implement GANs in Pytorch! In a nutshell, GANs belong to a category of generative models that let us generate incredibly realistic synthetic data, with the same qualities as that of the underlying training data. That means if you feed the model images of a few bedroom decors, after few hours of training it can generate never-seen-before brand-new ideas for your interior design.\\nOver the past few weeks, I have probably read a dozen papers on GANs (and its variants) and tinkered around with their code on custom images (courtesy open-source Github repos). While most of these papers are ...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3932</td>\n",
       "      <td>Rob Parkin</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@robparkin_38642/bayesian-variational-autoencoder-4bb698c84644?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Bayesian Variational Autoencoders | by Rob Parkin | Medium</td>\n",
       "      <td>Oct 5, 2017\\nThe main motivation for this post was that I wanted to get more experience with Bayesian types of Variational Autoencoders (VAEs) using Tensorflow.\\nAutoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we’ll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed...\\n248 \\n248 \\n1\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3933</td>\n",
       "      <td>Steven Shen</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/cubo-ai/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540?source=tag_archive---------5-----------------------</td>\n",
       "      <td>關於影像辨識,所有你應該知道的深度學習模型. Computer vision object detection... | by Steven Shen | Cubo AI | Medium</td>\n",
       "      <td>Cubo AI\\nFeb 4, 2018\\nComputer vision object detection models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO\\n這篇是簡介一些用來辨識影像中物體的 AI 模型。\\n在前面有提到,透過 CNN 模型,你可以輸入一張圖片,得到該圖片屬於哪種類別的結果,這過程我們把他稱作分類 (Classification)。\\n但在真實世界的應用情境通常要從一張圖片中辨識所有出現的物體, 並且標示出位置來 (標出位置稱之為 Object Localization)。你一定在網路上看過類似底下的影片,這段影片可以看出中國閉路攝影機(CCTV)發展的概況,不只是可以框出影像中每個物件,辨別物件種類,偵測出移動物體的動量,甚至是人臉辨識,實現楚門世界的惡夢。要做到這就需要靠深度學習中的 Object Detection 演算法,這也是最近幾年來深度學習最蓬勃發展的一塊領域。\\n基本的想法是,既然 CNN 對於物體的分類又快又好,那我們可不可以拿 CNN 來掃描並辨識圖片中的任何物體? 答案當然是 — 可以。\\n最簡單的作法就是用 Sliding Windows 的概念,也就是用一個固定大小的框框,逐一的掃過整張圖片,每次框出來的圖像丟到 CNN 中去判斷類別。由於物體的大小是不可預知的,所以還要用不同大小的框框去偵測。但是 Sliding Window 是非常暴力的作法,對單一影像我們需要掃描非常多次,每掃一次都需要算一次 CNN,這將會耗費大量的運算資源,而且速度慢,根本無法拿來應用!\\n所以後來就有人提出了 R-CNN (Regions with CNN)\\n與其用 Sliding Window 的方式掃過一輪,R-CNN 的作法是預先篩選出約 2000 個可能的區域,再將...</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3934</td>\n",
       "      <td>Robbie Tilton</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@robbietilton/emotional-computing-with-ai-3513884055fa?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Emotional Computing. Investigating the human to computer... | by Robbie Tilton | Medium</td>\n",
       "      <td>Apr 26, 2012\\nInvestigating the human to computer relationship through reverse engineering the Turing test\\nHumans are getting closer to creating a computer with the ability to feel and think. Although the processes of the human brain are at large unknown, computer scientists have been working to simulate the human capacity to feel and understand emotions. This paper explores what it means to live in an age where computers can have emotional depth and what this means for the future of human to computer interactions. In an experiment between a human and a human disguised as a computer, the Turing test is reverse engineered in order to understand the role computers will play as they become more adept to the processes of the human mind. Implications for this study are discussed and the di...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3935</td>\n",
       "      <td>Kyle Huang</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@huangkaikai/computational-creativity-generative-creature-design-for-concept-art-c4a1180ae0e6?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Computational creativity: generative creature design for concept art | by Kyle Huang | Medium</td>\n",
       "      <td>Oct 9, 2020\\nAbstract\\nWith the ever-powerful deep learning algorithm, computer graphics have been pushed to a new level. The generative adversarial network (GAN) can now generate almost any type of photo-realistic images with the proper size of datasets. However, most of the GAN use cases have been limited to the pursue of lifelike graphics. In this article, I prose a new framework “MonsterGAN,” combining machine learning, design, and psychology. MonsterGAN is a prototype of a generative design system (DRCI), which reduces the cognitive burden of creation and makes creativity scalable, for concept artists.\\nWhat happens if computer vision passes the Turing test? Where and how can we use it? As a designer, I’m fascinated by these questions because we designers are the graphic wizards w...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3936</td>\n",
       "      <td>James Lee</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/nurture-ai/learning-artistic-styles-from-images-a07037fa46e3?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Learning Artistic Styles from Images | by James Lee | Nurture.AI | Medium</td>\n",
       "      <td>Nurture.AI\\nFeb 2, 2018\\nIt’s currently an arms race in the tech scene right now with Deep Learning and Artificial Intelligence already the next industry-grade buzzword. Everyone’s looking to make the next big commercial success with a successful and innovative application of Artificial Intelligence.\\nOne such breakthrough is the use of deep learning neural networks to mathematically separate the content and style of images. What naturally entails is the idea of taking the content of one image and the style of another, and merging them both into one image. This idea was successfully implemented in 2015 by Gatys. et al in their paper “A Neural Algorithm of Artistic Style”.\\nSince then, there have been many insights and improvements of the base idea. Modern iterations of the algorithm ar...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>3937</td>\n",
       "      <td>Korbinian Koch</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/a-friendly-introduction-to-text-clustering-fa996bcefd04?source=tag_archive---------6-----------------------</td>\n",
       "      <td>A Friendly Introduction to Text Clustering | by Korbinian Koch | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 26, 2020\\nThe topics covered in this article include k-means, brown clustering, tf-idf, topic models and latent Dirichlet allocation (also known as LDA).\\nClustering is one of the biggest topics in data science, so big that you will easily find tons of books discussing every last bit of it. The subtopic of text clustering is no exception. This article can therefore not deliver an exhaustive overview, but it covers the main aspects. This being said, let us start by getting on common ground what clustering is and what it isn’t.\\nYou just scrolled by clusters!\\nIn fact, clusters are nothing more than groups that contain similar objects. Clustering is the process used for separating the objects into these groups.\\nObjects inside of a cluster should be as similar a...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3938</td>\n",
       "      <td>Shay Geller</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Normalization vs Standardization — Quantitative analysis | by Shay Geller | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 4, 2019\\nEvery ML practitioner knows that feature scaling is an important issue (read more here).\\nThe two most discussed scaling methods are Normalization and Standardization. Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\\nIn this blog, I conducted a few experiments and hope to answer questions like:\\nI’ll analyze the empirical results of applying different scaling methods on features in multiple experiments settings.\\nFirst, I was trying to understand what is the difference between Normalization and Standardization.So, I encountered this excellent blog by Sebastian Raschka that supplies a mathematical background that sat...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3939</td>\n",
       "      <td>jiawei hu</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/an-overview-for-text-representations-in-nlp-311253730af1?source=tag_archive---------6-----------------------</td>\n",
       "      <td>An Overview for Text Representations in NLP | by jiawei hu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 4, 2020\\nWriting is always a good choice when it comes to clarifying one’s understandings of a given topic. By putting thoughts on papers, ideas will be clarified and confusions exposed. Though it might not be the most comfortable thing to do it’s indeed an efficient way to learn and improve.\\nIf you ever find yourself having a hard time explaining something to a friend, something you’ve been studying for a while but somehow still didn’t manage to portray the subject clearly and intuitively, you should try writing it down.\\nIn this article, I attempt to summarize some of the ideas for text representations in NLP, aiming to build a foundation for future complex concepts to come and hoping to contribute my granito de arena to your learning as well.\\nThe above di...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>3940</td>\n",
       "      <td>Vivek Yadav</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@vivek-yadav/why-is-gradient-descent-robust-to-non-linearly-separable-data-a50c543e8f4a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Why is gradient descent robust to non-linearly separable data? | by Vivek Yadav | Medium</td>\n",
       "      <td>Nov 8, 2016\\nClarification: Gradient descent by itself is NOT robust to non-linearly separable data. However, when used with appropriate nonlinear activation functions it is.\\nThe reason is due to the kernel trick. In kernel trick, we apply a nonlinear transform on the data, so the resulting data set is linearly separable. This is illustrated below. Consider task of classifying blue and red points, they are not linearly separable. But what if we transform this data by adding a third variable (z = x2+y2), wecan draw a plane between blue and red points, and separate the two set of points. This is precisely what neural networks also do.\\nNeural networks’ learning can be viewed as a 2 part process where they learn some nonlinear transform of the data, and how to separate data based on this...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>3941</td>\n",
       "      <td>SYED JUNAID IQBAL</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/edureka/k-means-clustering-1db7b018a0a2?source=tag_archive---------0-----------------------</td>\n",
       "      <td>K-means Clustering Algorithm | Edureka</td>\n",
       "      <td>Edureka\\nFeb 10, 2017\\nThe majority of retail business holders find it hard to recognize customer needs. The reason why Data-driven companies such as Netflix, Walmart, Target, etc. are doing so well is that they have an army of Certified Data Analysts that grow their business by using the right tools to create personalized marketing strategies. We do understand that not all customers are alike and have the same taste. So, this leads to the challenge of marketing the right product to the right customer. An offer or product which might entice a particular customer segment may not be very helpful to other segments. So, you can apply the k-means clustering algorithm to segment your entire customer audience into groups with similar traits and preferences based on various metrics (such as th...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3942</td>\n",
       "      <td>Snehal Reddy Koukuntla</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/meta-learning-ai-generalised-1007b9695fe1?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Meta Learning — AI Generalised.. AI learning to learn, to help with... | by Snehal Reddy Koukuntla | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 8, 2019\\nDeep Learning has shown immense success in various fields and is continuing to spread its wings. But one of the major issues with training any traditional neural network model is the requirement of colossal amounts of data, and using this data to perform many iterative updates across many labeled examples.\\nLet’s take a look at a classic example of cats vs dogs classification. Although over the last two decades, we have made our models better and better to increase the accuracy, but the fundamental problem mentioned above still persists. We still need loads of labelled dogs and cats to get a decent accuracy.\\nHow do humans classify them with much lesser examples. Lets say all of a sudden you are shown two new animals, which are as visually distinguish...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3943</td>\n",
       "      <td>Aerin Kim</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/gamma-function-intuition-derivation-and-examples-5e5f72517dee?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Gamma Function — Intuition, Derivation, and Examples | by Aerin Kim | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 23, 2019\\nWhy should I care?\\nMany probability distributions are defined by using the gamma function — such as Gamma distribution, Beta distribution, Dirichlet distribution, Chi-squared distribution, and Student’s t-distribution, etc.For data scientists, machine learning engineers, researchers, the Gamma function is probably one of the most widely used functions because it is employed in many distributions. These distributions are then used for Bayesian inference, stochastic processes (such as queueing models), generative statistical models (such as Latent Dirichlet Allocation), and variational inference. Therefore, if you understand the Gamma function well, you will have a better understanding of a lot of applications in which it appears!\\nBecause we want to ...</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3944</td>\n",
       "      <td>Suhyun Kim</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-guide-to-convolutional-neural-networks-cnns-14649dbddce8?source=tag_archive---------4-----------------------</td>\n",
       "      <td>A Beginner’s Guide to Convolutional Neural Networks (CNNs) | by Suhyun Kim | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 15, 2019\\nA convolution is how the input is modified by a filter. In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge. Each time a match is found, it is mapped out onto an output image.\\nFor example, there is a picture of Eileen Collins and the matrix above the red arrow is used as a convolution to detect dark edges. As a result, we see an image where only dark edges are emphasized.\\nNote that an image is 2 dimensional with width and height. If the image is colored, it is considered to have one more dimension for RGB color. Fo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>3945</td>\n",
       "      <td>Aneesha Bakharia</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@aneesha/using-affinity-propagation-to-find-the-number-of-clusters-in-a-dataset-52f5dd3b0760?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Using Affinity Propagation to Find the Number of Clusters in a Dataset | by Aneesha Bakharia | Medium</td>\n",
       "      <td>Jan 11, 2016\\nClustering and dimension reduction algorithms help you to explore a dataset. Clustering and dimension reduction are unsupervised learning algorithms i.e., they don’t need labelled data to build a model. k-means is a popular clustering algorithm — you specify the the number of clusters (k) and it then finds the best cluster for each data instance. Choosing a good initial value for the number of clusters (k) can be problematic as k can be anything between 1 and the number of data instances. Finding the number of clusters is an active research field and techniques do exist (such as the Silhouette coefficient) but have varying success as the dimensionality of the data increases. I’m not going to go into any of these other techniques to find k in this blog post. Instead I’m go...</td>\n",
       "      <td>3493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3946</td>\n",
       "      <td>Matt.0</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92?source=tag_archive---------6-----------------------</td>\n",
       "      <td>10 Tips for Choosing the Optimal Number of Clusters | by Matt.0 | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 27, 2019\\nClustering is one of the most common unsupervised machine learning problems. Similarity between observations is defined using some inter-observation distance measures or correlation-based distance measures.\\nThere are 5 classes of clustering methods:\\n+ Hierarchical Clustering+ Partitioning Methods (k-means, PAM, CLARA)+ Density-Based Clustering+ Model-based Clustering+ Fuzzy Clustering\\nMy desire to write this post came mainly from reading about the clustree package, the dendextend documentation, and the Practical Guide to Cluster Analysis in R book written by Alboukadel Kassambara author of the factoextra package.\\nI will be using a lesser known data set from the cluster package: all.mammals.milk.1956, one which I haven’t looked at before.\\nThis sm...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3947</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 7, 2019\\nThis post was co-written with Baptiste Rocca.\\nYann LeCun described it as “the most interesting idea in the last 10 years in Machine Learning”. Of course, such a compliment coming from such a prominent researcher in the deep learning area is always a great advertisement for the subject we are talking about! And, indeed, Generative Adversarial Networks (GANs for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article Generative Adversarial Nets.\\nSo what are Generative Adversarial Networks ? What makes them so “interesting” ? In this post, we will see that adversarial training is an enlightening idea, beautiful by its simplicity, that represents a real conceptual progress for Machine Learning...</td>\n",
       "      <td>7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3948</td>\n",
       "      <td>Insight</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.insightdatascience.com/data-visualization-in-python-advanced-functionality-in-seaborn-20d217f1a9a6?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Data Visualization in Python: Advanced Functionality in Seaborn | by Insight | Insight</td>\n",
       "      <td>Insight\\nNov 13, 2015\\nSlater Stich is an Insight alum and was previously a Staff Data Scientist at Square. He is currently a Vice President at Valor Equity Partners.\\nSeaborn is a Python data visualization library with an emphasis on statistical plots. The library is an excellent resource for common regression and distribution plots, but where Seaborn really shines is in its ability to visualize many different features at once.\\nIn this post, we’ll cover three of Seaborn’s most useful functions: factorplot, pairplot, and jointgrid. Going a step further, we'll show how we can get even more mileage out of these functions by stepping up to their even-more-powerful forms: FacetGrid, PairGrid, and JointGrid.\\nTo showcase Seaborn, we’ll use the UCI “Auto MPG” data set. We did a bit of prepr...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3949</td>\n",
       "      <td>Kaustubh N</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/somx-labs/lets-talk-clustering-unsupervised-learning-1c89bc27e908?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Let’s talk Clustering (Unsupervised Learning) | by Kaustubh N | SomX Labs | Medium</td>\n",
       "      <td>SomX Labs\\nSep 2, 2016\\nSimple Definition:\\nA collection of similar objects to each other.\\nSlightly Complex Definition:\\nA connected component of a level set of the probability density function of underlying (and unknown) distribution from which our data samples are drawn.\\nYou are posed with a problem to solve, what you have is a large amount of data represented in lot of dimensions. The data can not be read or understood by looking at it raw by a human.\\nEven before you start defining your problem (hypothesis), you need to understand the data, perform an EDA on it. There are multiple ways to do it.\\nA. Perform Clustering\\nPerfect! Clustering is a good way of identifying interesting parts of data by grouping it.\\nClustering is a process of grouping a sample of data into smaller simil...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3950</td>\n",
       "      <td>Thomas Smith</td>\n",
       "      <td>9</td>\n",
       "      <td>https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------5-----------------------</td>\n",
       "      <td>I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero</td>\n",
       "      <td>OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder &amp; CEO of Gado Images. I write, speak &amp; consult about tech, food, privacy, AI &amp; photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3951</td>\n",
       "      <td>Ravi Prakash pandey</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@ravipandey71998/image-classifier-using-vgg-19-deep-learning-model-in-google-colab-notebook-dishes-detection-34861168e055?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Image Classifier using VGG-19 Deep learning model in Google Colab Notebook. Dishes Detection | by Ravi Prakash pandey | Medium</td>\n",
       "      <td>Aug 23, 2020\\nA simple Image classifier model to demonstrate the usage of VGG-19Deep Learning Model to predict input image. This model is developed in python programming and executed on a Colab notebook. At the end of this article you will learn how to develop a simple image classifier application that uses Pytorch Python based Deep Learning library to predict an image.\\nAt the end of this article you will learn:\\nVGG-19 is a variant of VGG model which in short consists of 19 layers (16 convolution layers, 3 Fully connected layer, 5 MaxPool layers and 1 SoftMax layer). There are other variants of VGG like VGG11, VGG16 and others.\\nAlexNet came out in 2012 and it improved on the traditional Convolutional neural networks, So we can understand VGG as a successor of the AlexNet.\\nVGG means...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3952</td>\n",
       "      <td>Aleksi Pietikäinen</td>\n",
       "      <td>14</td>\n",
       "      <td>https://medium.com/@aleksipietikinen/an-analysis-on-how-deepminds-starcraft-2-ai-s-superhuman-speed-could-be-a-band-aid-fix-for-the-1702fb8344d6?source=tag_archive---------2-----------------------</td>\n",
       "      <td>An Analysis On How Deepmind’s Starcraft 2 AI’s Superhuman Speed is Probably a Band-Aid Fix For The Limitations of Imitation Learning | by Aleksi Pietikäinen | Medium</td>\n",
       "      <td>Jan 27, 2019\\nAs all you have probably heard by now, an AI called AlphaStar developed by Google Deepmind has recently beaten human professionals in the real-time strategy game Starcraft 2. This is an unprecedented feat in the field of AI. However, I do have some constructive criticism about the way they did it.\\nI will try to make a convincing argument for the following:\\nFirst of all, I want to clarify that I am a layman. I’ve been following AI development and the Starcraft 2 scene for years but I do not claim to be an expert in either topic. If you notice any misconceptions in what I’m about to write please do point them out. I’m only a fanboy and all of this is incredibly fascinating to me. This essay will contain a lot of speculation and I admit that I can’t prove all of my core cl...</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3953</td>\n",
       "      <td>Darshan Adakane</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3954</td>\n",
       "      <td>Anish Shrestha</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Generating Modern Art using\\nGenerative Adversarial Network(GAN) on Spell | by Anish Shrestha | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2019\\nYou need to have a good understanding of:\\nAnd some basic knowledge of:\\nImage data used in this project has been collected from WikiArts.org.\\nIn this tutorial, we are going to look at the step by step process to create a Generative Adversarial Network to generate Modern Art and write a code for that using Python and Keras together.\\nAfter that, for training the model, we are going to use a powerful GPU Instance of Spell platform. Everything will be explained along the way and links will be provided for further readings.\\nLet’s get started!\\nBefore getting started, let’s look at our image dataset.\\nWikiArt has a huge collection of modern art with various different styles. For our particular project, we are going to use images of Cubism Style.\\nYou c...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3955</td>\n",
       "      <td>Synced</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129?source=tag_archive---------0-----------------------</td>\n",
       "      <td>A Brief Overview of Attention Mechanism | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nSep 25, 2017\\nAttention is simply a vector, often the outputs of dense layer using softmax function.\\nBefore Attention mechanism, translation relies on reading a complete sentence and compress all information into a fixed-length vector, as you can image, a sentence with hundreds of words represented by several words will surely lead to information loss, inadequate translation, etc.\\nHowever, attention partially fixes this problem. It allows machine translator to look over all the information the original sentence holds, then generate the proper word according to current word it works on and the context. It can even allow translator to zoom in or out (focus on local or global features).\\nAttention is not mysterious or complex. It is just an interface formulated by paramete...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3956</td>\n",
       "      <td>Bhuvana Kundumani</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/ner-tensorflow-2-2-0-9f10dcf5a0a?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Named Entity Recognition (NER) for CoNLL dataset with Tensorflow 2.2.0 | by Bhuvana Kundumani | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 22, 2020\\nThis blog details the steps for Named Entity Recognition (NER) tagging of sentences (CoNLL-2003 dataset ) using Tensorflow2.2.0\\nCoNLL-2003 dataset includes 1,393 English and 909 German news articles. We will be looking at the English data. The CoNLL-2003 data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of t...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3957</td>\n",
       "      <td>Sourav kumar</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Sentence correction using Deep learning techniques | by Sourav kumar | Medium</td>\n",
       "      <td>Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>3958</td>\n",
       "      <td>Wamika Jha</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/implementation-of-principal-component-analysis-pca-in-k-means-clustering-b4bc0aa79cb6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Implementation of Principal Component Analysis(PCA) in K Means Clustering | by Wamika Jha | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 19, 2021\\nPrerequisites\\nThis article assumes that you are familiar with the basic theory behind PCA, K Means Algorithm and know Python programming language.\\nK Means clustering is one of the simplest yet efficient unsupervised algorithms. First let us have a brief description of what this algorithm does.\\nK Means Algorithm Suppose we have a dataset with two features x1 and x2. This is unlabelled data and our objective is to find K number of groups or “clusters” which are similar to each other. Suppose our training set looks like this :-\\nWe can clearly see there are two clusters, let us name them cluster 0 and cluster 1. Each cluster is associated with a centroid which is unique to each cluster. This algorithm iterates until the centroids do not change its positi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3959</td>\n",
       "      <td>Maria Neumayer</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/a-problem-like-maria/ai-class-com-a-classroom-with-160-000-students-9c16f6e31390?source=tag_archive---------4-----------------------</td>\n",
       "      <td>AI-Class.com — A classroom with 160,000 students | by Maria Neumayer | A problem like Maria | Medium</td>\n",
       "      <td>A problem like Maria\\nOct 23, 2011\\nAI Class is a great experiment by two professors at the Stanford University: Sebastian Thrun and Peter Norvig. The course is being held as an actual course at Stanford University plus an online course for about 160,000 enrolled students. People in the advanced track have to do homework and write exams, people in the basic track just have to watch the lectures. Currently I’m in the advanced track, although I might switch to the basic track due to time problems (having a full time job + working on a private application + a University course is a bit too much). At the end of the course you’ll get a certificate, sadly not from Stanford but still. Pretty cool having done a course at Stanford... kind of.\\nI think it’s a great experience to attend a course ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>3960</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Multi-Class Text Classification with LSTM | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 10, 2019\\nAutomatic text classification or document classification can be done in many different ways in machine learning as we have seen before.\\nThis article aims to provide an example of how a Recurrent Neural Network (RNN) using the Long Short Term Memory (LSTM) architecture can be implemented using Keras. We will use the same data source as we did Multi-Class Text Classification with Scikit-Lean, the Consumer Complaints data set that originated from data.gov.\\nWe will use a smaller data set, you can also find the data on Kaggle. In the task, given a consumer complaint narrative, the model attempts to predict which product the complaint is about. This is a multi-class text classification problem. Let’s roll!\\nAfter first glance of the labels, we realized t...</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>3961</td>\n",
       "      <td>Mark Garvey</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/polynomial-regression-gradient-descent-from-scratch-279db2936fe9?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Polynomial Regression — Gradient Descent from Scratch | by Mark Garvey | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 18, 2021\\nGradient descent is an important algorithm to understand, as it underpins many of the more advanced algorithms used in Machine Learning and Deep Learning. Getting to grips with the inner workings of gradient descent will therefore be of great benefit to anyone who plans on exploring ML algorithms further.\\nThe best way to learn is by doing, so in this article I will be walking through the steps of how the gradient descent process works, without using ML libraries such as scikit-learn for example. In day-to-day work, it is of course quicker and neater to make use of such libraries, but regarding the learning process I have found the exercise of implementing by hand to be invaluable for this particular algorithm.\\nThe goal of gradient descent is to min...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3962</td>\n",
       "      <td>Synced</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/syncedreview/from-faces-to-kitties-to-apartments-gan-fakes-the-world-ae04e5cbddf6?source=tag_archive---------6-----------------------</td>\n",
       "      <td>From Faces to Kitties to Apartments: GAN Fakes the World | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nFeb 27, 2019\\nWith just a mouse click, you can delight in mega-litters of adorable kitties, admire countless fresh anime characters, or stare into the twinkling eyes of all sorts of beautiful people. The only catch is that they’re all fake. As Synced previously reported, these hyperrealistic images now flooding the Internet come from US chip giant NVIDIA’s StyleGAN, a generative adversarial network based face generator that performs so well that most people can’t distinguish its creations from photos of real people.\\nSoon after StyleGAN was open-sourced earlier this month, Uber software engineer Philip Wang used the tool to create “This Person Does Not Exist,” a website which generates a new hyperrealistic fake human face every time it’s refreshed. The site quickly went v...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>3963</td>\n",
       "      <td>Gorkem Polat</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/swlh/deep-learning-architectures-that-you-can-use-with-a-very-few-data-8e5b4fa1d5da?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Deep Learning Architectures That You Can Use with a Few Data | by Gorkem Polat | The Startup | Medium</td>\n",
       "      <td>The Startup\\nJun 26, 2020\\nConventional CNNs (AlexNet, VGG, GoogLeNet, ResNet, DenseNet ...) have good performances when there are many samples for each class in the dataset. Unfortunately, they generally do not work well when you have a small dataset. However, there are many real-life scenarios where it is challenging to gather data for your classes. For example, in face identification systems, there are...\\n373 \\n373 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n77 Followers\\nDeep learning researcher. PhD candidate at @METU. https://www.linkedin.com/in/gorkempolat/\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>3964</td>\n",
       "      <td>Taras Bakusevych</td>\n",
       "      <td>10</td>\n",
       "      <td>https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c?source=tag_archive---------1-----------------------</td>\n",
       "      <td>10 rules for better dashboard design | by Taras Bakusevych | UX Planet</td>\n",
       "      <td>UX Planet\\nJul 17, 2018\\nDashboard design is a frequent request these days. Businesses dream about a simple view that presents all information, shows trends and risky areas, updates users on what happened — a view that will guide them into a bright financial future.\\nFor me, a dashboard — is an at a glance preview of the most crucial information for the user at the moment he is looking at it, and an easy way to navigate directly to various areas of the application that require users attention. The term “dashboard” is a metaphor for a car dashboard, sometimes also called the cockpit area, usually near the front of an aircraft or spacecraft, from which a pilot controls the aircraft.\\nWorking on enterprise projects for years, I have designed countless dashboards. And every new one is the ...</td>\n",
       "      <td>22790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>3965</td>\n",
       "      <td>RAVI SHEKHAR TIWARI</td>\n",
       "      <td>9</td>\n",
       "      <td>https://becominghuman.ai/transfer-learning-part-4-0-vgg-16-and-vgg-19-d7f0045032de?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Transfer Learning — Part — 4.0!! VGG-16 and VGG-19 | by RAVI SHEKHAR TIWARI | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nOct 1, 2021\\nIn Part 3 of the Transfer Learning series we have discussed the datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch. In this, article we will discuss theoretically about the VGG-16 and VGG-19 and in article 4.2 and 4.3 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:\\nbecominghuman.ai\\nFor the repository and document please follow below two mentioned links:\\nKeras:\\nkeras.io\\nPyTorch:\\npytorch.org\\nAlexNet came out in 2012 and it improved on the...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3966</td>\n",
       "      <td>Synced</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/syncedreview/google-deepmind-releases-structure-predictions-for-coronavirus-linked-proteins-7dfb2fad05b6?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Google DeepMind Releases Structure Predictions for Coronavirus Linked Proteins | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nMar 5, 2020\\nThis is an updated version.\\nIn a bid to help the global research community better understand the coronavirus, DeepMind today released the structure predictions for six proteins associated with SARS-CoV-2, the virus that causes COVID-19, using the most up-to-date version of their AlphaFold system.\\nAs the world struggles with the COVID-19 outbreak, one research team after another in the global scientific community has stepped up to offer expertise, tools and possible solutions. In the early stages of the outbreak front-line labs open-sourced genomes of the virus which enabled other researchers to rapidly develop tests around the pathogen. Other labs modelled the coronavirus infection peak or produced molecular structures to develop drug compounds and treatmen...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3967</td>\n",
       "      <td>Ayush Pant</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Workflow of a Machine Learning project | by Ayush Pant | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 11, 2019\\nIn this blog, we will discuss the workflow of a Machine learning project this includes all the steps required to build the proper machine learning project from scratch.\\nWe will also go over data pre-processing, data cleaning, feature exploration and feature engineering and show the impact that it has on Machine Learning Model Performance. We will also cover a couple of the pre-modelling steps that can help to improve the model performance.\\nPython Libraries that would be need to achieve the task: 1. Numpy 2. Pandas 3. Sci-kit Learn 4. Matplotlib\\nWe can define the machine learning workflow in 3 stages.\\nOkay but first let’s start from the basics\\nThe machine learning model is nothing but a piece of code; an engineer or data scientist makes it smart ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3968</td>\n",
       "      <td>TokenGo Platform_RU</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------9-----------------------</td>\n",
       "      <td>ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium</td>\n",
       "      <td>May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3969</td>\n",
       "      <td>Boaz Shmueli</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Multi-Class Metrics Made Simple, Part II: the F1-score | by Boaz Shmueli | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 3, 2019\\nIn Part I of Multi-Class Metrics Made Simple, I explained precision and recall, and how to calculate them for a multi-class classifier. In this post I’ll explain another popular performance measure, the F1-score, or rather F1-scores, as there are at least 3 variants. I’ll explain why F1-scores are used, and how to calculate them in a multi-class setting.\\nBut first, a BIG FAT WARNING: F1-scores are widely used as a metric, but are often the wrong way to compare classifiers. You will often spot them in academic papers where researchers use a higher F1-score as “proof” that their model is better than a model with a lower score. However, a higher F1-score does not necessarily mean a better classifier. Use with care, and take F1 scores with a grain of sal...</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3970</td>\n",
       "      <td>Thiago Julio, MD</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/sa%C3%BAde-digital/rsna-2013-top-5-tend%C3%AAncias-em-ti-528f595225b7?source=tag_archive---------8-----------------------</td>\n",
       "      <td>RSNA 2013 — Top 5 Tendências em TI | by Thiago Julio, MD | Saúde Digital | Medium</td>\n",
       "      <td>Saúde Digital\\nJan 10, 2014\\nMuitas novidades foram apresentadas durante o congresso em Chicago. Muita inovação entre as aulas e sessões. Apresentações científicas com novas aplicações de conhecidas tecnologias e alguns novos protótipos. Diante de tanto conteúdo, seis dias passam rápido para quem gosta de tecnologia. Tentei elencar as cinco coisas mais bacanas que vi em termos de inovação e TI:\\n1. PACS 3.0\\nTermo repetido em inúmeras palestras. Ficou nítido que estamos diante de uma nova geração de PACS. Ferramentas de manipulação de imagens e workflow (manejo de worklists, aplicativos de laudo automatizados e reconhecimento de voz) já são considerados standart, e anualmente melhorados. As próximas versões de PACS, algumas já lançadas durante a feira, deverã...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3971</td>\n",
       "      <td>Netflix Technology Blog</td>\n",
       "      <td>5</td>\n",
       "      <td>https://netflixtechblog.com/extracting-image-metadata-at-scale-c89c60a2b9d2?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Extracting image metadata at scale | by Netflix Technology Blog | Netflix TechBlog</td>\n",
       "      <td>Netflix TechBlog\\nMar 21, 2016\\nWe have a collection of nearly two million images that play very prominent roles in helping members pick what to watch. This blog describes how we use computer vision algorithms to address the challenges of focal point, text placement and image clustering at a large scale.\\nAll images have a region that is the most interesting (e.g. a character’s face, sharpest region, etc.) part of the image. In order to effectively render an image on a variety of canvases like a phone screen or TV, it is often required to display only the interesting region of the image and dynamically crop the rest of an image depending on the available real-estate and desired user experience. The goal of the focal point algorithm is to use a series of signals to identify the most int...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>3972</td>\n",
       "      <td>Victor Zhou</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Machine Learning for Beginners: An Introduction to Neural Networks | by Victor Zhou | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 5, 2019\\nHere’s something that might surprise you: neural networks aren’t that complicated! The term “neural network” gets used as a buzzword a lot, but in reality they’re often much simpler than people imagine.\\nThis post is intended for complete beginners and assumes ZERO prior knowledge of machine learning. We’ll understand how neural networks work while implementing one from scratch in Python.\\nLet’s get started!\\nNote: I recommend reading this post on victorzhou.com — much of the formatting in this post looks better there.\\nFirst, we have to talk about neurons, the basic unit of a neural network. A neuron takes inputs, does some math with them, and produces one output. Here’s what a 2-input neuron looks like:\\n3 things are happening here. First, each inpu...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>3973</td>\n",
       "      <td>Bernardo Caldas</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/using-maskrcnn-to-predict-tropical-fruits-in-custom-dataset-4f079d05fbe1?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Using MaskRCNN to predict tropical fruits in custom dataset | by Bernardo Caldas | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJan 26, 2020\\nApplication to predict fruits using Mask_RCNN on custom dataset, this is a easy tutorial to how create a object detection application for a custom dataset, as a sample we are using a dataset of tropical fruits in this case only ( Oranges and Pineapple).\\nsource code in github : https://github.com/bernardcaldas/object-detection-custom-maskrcnn\\nin recent years we can see a lot applications in our life including, autonomous cars, facial detections app, education, military, finance etc.\\nInstance segmentation it's a task to identifying objects , detecting and delineating each distinct object of interest appearing in an image.\\nFollow the post created for Waleed Abdulla explaining how works Mask R-CNN one of the most used algorithm for image segmentation and...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3974</td>\n",
       "      <td>A Ydobon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@financial-engineering/tensorflow-2-0-variational-auto-encoder-vae-part-ii-df8adcd02f20?source=tag_archive---------9-----------------------</td>\n",
       "      <td>[TensorFlow 2.0] Variational Auto encoder (VAE) Part II | by A Ydobon | Medium</td>\n",
       "      <td>Nov 17, 2019\\nwww.tensorflow.org\\nLet’s get started!\\nIn the previous posting, we have finished two things, first, loading the dependent libraries to our workspace,\\n54 \\n54 \\n1\\nYdobon is nobody.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n85 Followers\\nYdobon is nobody.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>3975</td>\n",
       "      <td>Synced</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/syncedreview/deepmind-et-al-paper-trumpets-graph-networks-9c74a271b903?source=tag_archive---------9-----------------------</td>\n",
       "      <td>DeepMind et al Paper Trumpets Graph Networks | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nJun 15, 2018\\nThe paper Relational inductive biases, deep learning, and graph networks, published last week on arXiv by researchers from DeepMind, Google Brain, MIT and University of Edinburgh, has stimulated discussion in the artificial intelligence community. The paper introduces a new machine learning framework called Graph Networks, which some believe promises huge potential for approaching the holy grail of artificial general intelligence.\\nDue to the development of big data and increasingly powerful computational resources over the past few years, modern AI technology — primarily deep learning — has show its prowess and even outsmarted humans in tasks such as image recognition and speech detection. However, AI remains challenged by tasks that involve complicated lea...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3976</td>\n",
       "      <td>Helena Campbell</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/data-science-for-newbies-including-me-d1c6bf3e390b?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Data Science for Newbies (including me!) | by Helena Campbell | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 15, 2015\\nData Science for Newbies (including me!)\\nI’ve studied math, I’ve studied computer science, and of course I’ve focused on machine learning algorithms. But I’m still new to the field of data science. I don’t know yet how or whether I can make an impact. But if I explain what it is, then people will know what I can do, what I could learn to do, and most importantly, what they can ask me to do. Here’s the primer.\\nThere are several types of machine learning algorithms, but my focus is on finding patterns in data. Those patterns could be entirely numerical, they could be graphical, or they could even be written out in words. Humans are very good at finding patterns, even going too far sometimes and making stereotypes. We’re at a point where many people j...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>3977</td>\n",
       "      <td>NN Intruder</td>\n",
       "      <td>15</td>\n",
       "      <td>https://medium.com/@nnintruder/attacking-google-cloud-vision-api-with-adversarial-examples-d02af0174732?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Attacking Google Cloud Vision API with Adversarial Examples | by NN Intruder | Medium</td>\n",
       "      <td>May 11, 2018\\nAdversarial attacks have been a concerning topic in the field of deep learning research in recent years. We’ve long since known that deep neural networks don’t generate perfect classification boundaries (this article in 2013. .. Yes, 2013 is a long time ago in fields related to deep learning.). Researchers have found numerous ways to generate adversarial examples to cause models to make mistakes (see e.g. this review paper and reference therein). This is obviously dangerous in commercial applications such as self-driving cars, automated robots, and other audio/visual recognition tasks. The vulnerability to adversarial examples is one of the major risks for applying deep neural networks in safety-critical scenarios.\\nBefore we go into our implementation, we need to categor...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3978</td>\n",
       "      <td>Harald Scheidl</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c?source=tag_archive---------2-----------------------</td>\n",
       "      <td>An Intuitive Explanation of Connectionist Temporal Classification | by Harald Scheidl | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 10, 2018\\nIf you want a computer to recognize text, neural networks (NN) are a good choice as they outperform all other approaches at the moment. The NN for such use-cases usually consists of convolutional layers (CNN) to extract a sequence of features and recurrent layers (RNN) to propagate information through this sequence. It outputs character-scores for each sequence-element, which simply is represented by a matrix. Now, there are two things we want to do with this matrix:\\nBoth tasks are achieved by the CTC operation. An overview of the handwriting recognition system is shown in Fig. 1.\\nLet’s have a closer look at the CTC operation and discuss how it works without hiding the clever ideas it is based on behind complicated formulas. At the end, I will poin...</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>3979</td>\n",
       "      <td>Abdarhman Taha</td>\n",
       "      <td>4</td>\n",
       "      <td>https://blog.agolo.com/knowledge-graphs-for-automatic-multi-longform-document-summarization-8f946e1e1877?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Using Knowledge Graphs to Summarize Long Documents | by Abdarhman Taha | agolo</td>\n",
       "      <td>agolo\\nApr 19, 2021\\nAutomatic text summarization is the task of automatically identifying the salient topics/key-phrases in a document(s) and then either generates or extracts a summary.\\nCurrently, most state-of-the-art summarizers are focused on single, short document summarization. Recent progress in summarization, mostly transformers-based, struggles with long inputs due to the architecture limitations, which have led many researchers to explore using new ideas like the longformer to overcome this issue. However, the final summaries are 5–10 sentences long that lacks coherence, and don’t give enough info about the original document. And of course, such methods can’t handle even tougher situations where the input is more than one long document. Similar observations could be found w...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3980</td>\n",
       "      <td>Gerard Maggiolino</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/@gerardmaggiolino/creating-openai-gym-environments-with-pybullet-part-1-13895a622b24?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Creating OpenAI Gym Environments with PyBullet (Part 1) | by Gerard Maggiolino | Medium</td>\n",
       "      <td>Oct 22, 2019\\nThis guide assumes rudimentary knowledge of reinforcement learning and the structure of OpenAI Gym environments, along with proficiency in Python.\\nMany of the standard environments for evaluating continuous control reinforcement learning algorithms are built on the MuJoCo physics engine, a paid and licensed software. Bullet Physics provides a free and open source alternative to physics simulation with OpenAI Gym offering a set of environments built upon it. PyBullet is a library designed to provide Python bindings to the lower level C-API of Bullet. We will use PyBullet to design our own OpenAI Gym environments.\\nThis post will be the first of a two part series.\\nWe’ll go through building an environment step by step with enough explanations for you to learn how to indepe...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>3981</td>\n",
       "      <td>Surya Remanan</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Logistic Regression: A Simplified Approach Using Python | by Surya Remanan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 17, 2018\\nIn Logistic Regression, we wish to model a dependent variable(Y) in terms of one or more independent variables(X). It is a method for classification. This algorithm is used for the dependent variable that is Categorical. Y is modeled using a function that gives output between 0 and 1 for all values of X. In Logistic Regression, the Sigmoid (aka Logistic) Function is used.\\nAfter we train a logistic regression model on some training data, we will evaluate the performance of the model on some test data. For this, we use the Confusion Matrix. A Confusion Matrix is a table that is often used to describe the performance of the classification model on a set of test data for which the true values are already known. Given below is a Confusion Matrix.\\nHere, ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>3982</td>\n",
       "      <td>Nishanth N</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>3983</td>\n",
       "      <td>Maxime</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04?source=tag_archive---------0-----------------------</td>\n",
       "      <td>What is a Transformer?. An Introduction to Transformers and... | by Maxime | Inside Machine learning | Medium</td>\n",
       "      <td>Inside Machine learning\\nJan 4, 2019\\nNew deep learning models are introduced at an increasing rate and sometimes it’s hard to keep track of all the novelties. That said, one particular neural network model has proven to be especially effective for common natural language processing tasks. The model is called a Transformer and it makes use of several methods and mechanisms that I’ll introduce here. The papers I refer to in the post offer a more detailed and quantitative description.\\nThe paper ‘Attention Is All You Need’ describes transformers and what is called a sequence-to-sequence architecture. Sequence-to-Sequence (or Seq2Seq) is a neural net that transforms a given sequence of elements, such as the sequence of words in a sentence, into another sequence. (Well, this might not surp...</td>\n",
       "      <td>5341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>3984</td>\n",
       "      <td>Synced</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/syncedreview/quantum-chemistry-breakthrough-deepmind-uses-neural-networks-to-tackle-schr%C3%B6dinger-equation-a5ad4e3bfea0?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Quantum Chemistry Breakthrough: DeepMind Uses Neural Networks to Tackle Schrödinger Equation | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nSep 18, 2019\\nWave function represents the quantum state of an atom, including the position and movement states of the nucleus and electrons. For decades researchers have struggled to determine the exact wave function when analyzing a normal chemical molecule system, which has its nuclear position fixed and electrons spinning. Fixing wave function has proven problematic even with help from the Schrödinger equation.\\nPrevious research in this field used a Slater-Jastrow Ansatz application of quantum Monte Carlo (QMC) methods, which takes a linear combination of Slater determinants and adds the Jastrow multiplicative term to capture the close-range correlations.\\nNow, a group of DeepMind researchers have brought QMC to a higher level with the Fermionic Neural Network — or ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3985</td>\n",
       "      <td>Kamil Mysiak</td>\n",
       "      <td>31</td>\n",
       "      <td>https://towardsdatascience.com/explaining-k-means-clustering-5298dc47bad6?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Explaining K-Means Clustering. Comparing PCA and t-SNE dimensionality... | by Kamil Mysiak | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 13, 2020\\nToday’s data comes in all shapes and sizes. NLP data encompasses the written word, time-series data tracks sequential data movement over time (ie. stocks), structured data which allows computers to learn by example, and unclassified data allows the computer to apply structure. Whichever dataset you possess, you can be sure there is an algorithm ready to decipher its secrets. In this article, we want to cover a clustering algorithm named KMeans which attempts to uncover hidden subgroups hiding in your dataset. Furthermore, we will examine what effects dimension reduction has on the quality of the clusters obtained from KMeans.\\nIn our example, we will be examining a human resources dataset consisting of 15,000 individual employees. The dataset contain...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>3986</td>\n",
       "      <td>Josh</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/technology-invention-and-more/everything-you-need-to-know-about-artificial-neural-networks-57fac18245a1?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Everything You Need to Know About Artificial Neural Networks | by Josh | Technology, Invention, App, and More | Medium</td>\n",
       "      <td>Technology, Invention, App, and More\\nDec 28, 2015\\nThe year 2015 was a monumental year in the field of artificial intelligence. Not only are computers learning more and learning faster, but we’re learning more about how to improve their systems. Everything is starting to align, and because of it we’re seeing strides we’ve never thought possible until now. We have programs that can tell stories about pictures. We have cars that are driving themselves. We even have programs that create art. If you want to read more about advancements in 2015, read this article. Here at Josh.ai, with AI technology becoming the core of just about everything we do, we think it’s important to understand some of the common terminology and to get a rough idea of how it all works.\\nA lot of the advances in art...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>3987</td>\n",
       "      <td>Jacob Solawetz</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/liquid-neural-networks-in-computer-vision-4a0f718b464e?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Liquid Neural Networks in Computer Vision | by Jacob Solawetz | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 12, 2021\\nExcitement is building in the artificial intelligence community around MIT’s recent release of liquid neural networks. The breakthroughs that Hasani and team have made are incredible.\\nLet’s dive in.\\nArtificial intelligence research and applications involve the construction and training of deep neural networks. Until liquid neural networks, all deep learning systems have shared the same vulnerability — namely, that they learn a fixed mapping from input data to output prediction based on the training data that they are shown, making them brittle to the shifting environment around them. Furthermore, most deep learning models are context independent. For example, when applying an object detection model or a classification model to a video, the video wi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>3988</td>\n",
       "      <td>Andrej Karpathy</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Yes you should understand backprop | by Andrej Karpathy | Medium</td>\n",
       "      <td>Dec 19, 2016\\nWhen we offered CS231n (Deep Learning class) at Stanford, we intentionally designed the programming assignments to include explicit calculations involved in backpropagation on the lowest level. The students had to implement the forward and the backward pass of each layer in raw numpy. Inevitably, some students complained on the class message boards:\\n“Why do we have to write the backward pass when frameworks in the real world, such as TensorFlow, compute them for you automatically?”\\nThis is seemingly a perfectly sensible appeal - if you’re never going to write backward passes once the class is over, why practice writing them? Are we just torturing the students for our own amusement? Some easy answers could make arguments along the lines of “it’s worth knowing what’s unde...</td>\n",
       "      <td>17643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3989</td>\n",
       "      <td>James Faghmous</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4?source=tag_archive---------0-----------------------</td>\n",
       "      <td>New to Machine Learning? Avoid these three mistakes | by James Faghmous | Medium</td>\n",
       "      <td>Nov 7, 2013\\nMachine learning (ML) is one of the hottest fields in data science. As soon as ML entered the mainstream through Amazon, Netflix, and Facebook people have been giddy about what they can learn from their data. However, modern machine learning (i.e. not the theoretical statistical learning that emerged in the...\\n275 \\n275 \\n2\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n548 Followers\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3990</td>\n",
       "      <td>Aqeel Anwar</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Difference between AlexNet, VGGNet, ResNet, and Inception | by Aqeel Anwar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 7, 2019\\nIn this tutorial, I will quickly go through the details of four of the famous CNN architectures and how they differ from each other by explaining their W3H (When, Why, What, and How)\\nWhen?\\nWhy? AlexNet was born out of the need to improve the results of the ImageNet challenge. This was one of the first Deep convolutional networks to achieve considerable accuracy on the 2012 ImageNet LSVRC-2012 challenge with an accuracy of 84.7% as compared to the second-best with an accuracy of 73.8%. The idea of spatial correlation in an image frame was explored using convolutional layers and receptive fields.\\nWhat? The network consists of 5 Convolutional (CONV) layers and 3 Fully Connected (FC) layers. The activation used is the Rectified Linear Unit (ReLU). The ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>3991</td>\n",
       "      <td>Thilina Rajapakse</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca?source=tag_archive---------9-----------------------</td>\n",
       "      <td>A Hands-On Guide To Text Classification With Transformer Models (XLNet, BERT, XLM, RoBERTa) | by Thilina Rajapakse | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 3, 2019\\nPlease consider using the Simple Transformers library as it is easy to use, feature-packed, and regularly updated. The article still stands as a reference to BERT models and is likely to be helpful with understanding how BERT works. However, Simple Transformers offers a lot more features, much more straightforward tuning options, all the while being quick and easy to use! The links below should help you get started quickly.\\nThe Pytorch-Transformers (now Transformers) library has moved on quite a bit since this article was written. I recommend using SimpleTransformers as it is kept up to date with the Transformers library and is significantly more user-friendly. While the ideas and concepts in this article still stand, the code and the Github repo are...</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>3992</td>\n",
       "      <td>Rafi</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@today.rafi/demystifying-object-detection-using-deep-learning-d3f83e2fb832?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Demystifying Object Detection using Deep Learning | by Rafi | Medium</td>\n",
       "      <td>Dec 28, 2019\\nObject detection has been quite a center of attraction nowadays because of its wide range of applications and advancements in Deep Learning technology. Object Detection is a subdomain of image processing and computer vision that deals with identifying and localizing objects in videos or digital images. The credit for the evolution of object detection goes to the breakthrough in deep learning classification algorithms called CNN- Convolutional Neural Network and Graphic Processing Units that have shown great leads in the development of real-world solutions for computer vision problems like autonomous driving car, face detection and recognition, people detection, and tracking, video surveillance, security system design, etc.\\nObject detection can be done either using machin...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>3993</td>\n",
       "      <td>Adrien Lucas Ecoffet</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/paper-repro-deep-metalearning-using-maml-and-reptile-fd1df1cc81b0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Paper repro: Deep Metalearning using “MAML” and “Reptile” | by Adrien Lucas Ecoffet | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 2, 2018\\nIn this post I reproduce two recent papers in the field of metalearning: MAML and the similar Reptile. The full notebook for this reproduction can be found here.\\nThe goal of both of these papers is to solve the K-shot learning problem. In K-shot learning, we need to train a neural network to generalize based on a very small number of examples (often on the order of 10 or so) instead of the often thousands of examples we see in datasets like ImageNet.\\nHowever, in preparation for K-shot learning, you are allowed to train on many similar K-shot problems to learn the best way to generalize based on only K examples.\\nThis is learning to learn or metalearning. We have already seen metalearning in my post on “Learning to Learn by Gradient Descent by Gradie...</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3994</td>\n",
       "      <td>Patty Wu</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@pedin024/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%84%AA%E5%8C%96%E5%99%A8ranger-a-synergistic-optimizer-using-radam-rectified-adam-gradient-centralization-and-f022d9dd4217?source=tag_archive---------3-----------------------</td>\n",
       "      <td>深度學習優化器Ranger: a synergistic optimizer using RAdam (Rectified Adam), Gradient Centralization and LookAhead筆記 | by Patty Wu | Medium</td>\n",
       "      <td>Nov 20, 2020\\n今年人工智慧年會中,偶然聽到講師呼籲大家,都2020了,不要再用Adam了,請改用Ranger,因此著手來寫一篇Ranger的筆記。\\n今年有兩篇優化器相關的論文被提出,分別是LookAhead和RAdam,這兩種方法用不同角度對深度學習的優化做改進,後來研究員 Less Wright將兩個方法整合成一個新的優化器:Ranger,得到了更好的成果。\\n廢話不多說,先上PyTorch實現的GitHub:https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\\n要了解RAdam 和 LookAhead 是如何互補的,需要先分別討論他們的概念。\\n全名是Rectified Adam,白話地說,就是自動熱身(warmup)版的Adam。\\n概念\\nAdam是一種常用的自適應學習率 (adptive learning rate) 優化器,但類方法在訓練的初期,adptive learning rate的變異非常大,然後在少量的數據進行過度跳躍,下了錯誤決策,就容易收斂在local minimum。\\n為了解決這個問題,RAdam根據adaptive rate的變異程度去修正learning rate,讓Adam可以自動熱身,不需再手動調整,也避免模型收斂在local minimum。\\n概念是這樣:有個熱身用的開關,閥值為rho,這個rho代表adpative learning rate分配的自由度:\\n優點\\n如此的做法,讓RAdam在享有Adam快速收斂優勢的同時,又達到跟SGD差不多好的收斂結果。RAdam詳細概念可以參考我寫的另一篇文章:https://is.gd/2yxrE7。\\n2020由深度學習教父Geoffrey Hinton團隊發表的論文,LookAhead基於損失空...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3995</td>\n",
       "      <td>Nhan Tran</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/machine-learning-polynomial-regression-with-python-5328e4e8a386?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Machine Learning: Polynomial Regression with Python | by Nhan Tran | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 20, 2019\\nAbbreviations using in this post:\\nIn my previous post, we discussed about Linear Regression. Let’s take a look back. Linear Regression is applied for the data set that their values are linear as below example:\\nAnd real life is not that simple, especially when you observe from many different companies in different industries. Salary of 1 YE teacher is different from 1 YE engineer; even 1 YE civil engineer is different from mechanical engineer; and if you compare 2 mechanical engineers from 2 different companies, their salary mostly different as well. So how can we predict the salary of a candidate?\\nToday, we will use another data set to represent the Polynomial shape.\\nTo get an overview of the increment of salary, let’s visualize the data set into...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>3996</td>\n",
       "      <td>thirumalaivasan</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@thirumalaivasudev/how-i-struggled-to-convert-mbr-to-gpt-and-installed-linux-7755b7946b93?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How I struggled to Convert MBR to GPT and Installed Linux? | by thirumalaivasan | Medium</td>\n",
       "      <td>Apr 22, 2019\\nI was supposed to Install Linux in my PC which is having a storage of 500GB with Windows in it ,So as a regular Linux installation procedure I unallocated 60GB and started to install the linux OS during the installation I found something fishy ,The Unallocated space was not showing up as a free space to install the Operating System ,I was like What the heck is this as usual Searched this issue in the Internet and discussed it with my techie friends all they told is “YOU HAVE TO CONVERT GPT TO MBR” and they suggested me some tools too like MINITOOL PARTITION WIZARD,ES PARTITION MASTER but everything ended up in Popping up for PREMIUM ACCESS to perform the particular action .It again started to irritate me a lot , I restarted my Computer several times again and again and en...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>3997</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Multi-Class Text Classification Model Comparison and Selection | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 25, 2018\\nWhen working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier. The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\\nThis is what we are going to do today: use everything that we have presented about text classification in the previous articles (and more) and comparing between the tex...</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>3998</td>\n",
       "      <td>dan lee</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/ai%C2%B3-theory-practice-business/what-is-pre-training-in-nlp-introducing-5-key-technologies-455c54933054?source=tag_archive---------1-----------------------</td>\n",
       "      <td>What Is Pre-Training in NLP? Introducing 5 Key Technologies | by dan lee | AI3 | Theory, Practice, Business | Medium</td>\n",
       "      <td>AI3 | Theory, Practice, Business\\nFeb 24, 2020\\nWelcome back to my blog for engineers who want to learn AI!\\nStarting with this post, we’ll be launching into a new series of articles on pre-training in NLP. Today, we’ll begin by forming a big picture.\\n394 \\n394 \\nThe AI revolution is here! Navigate the ever changing industry with our thoughtfully written articles whether your a researcher, engineer, or entrepreneur\\n298 Followers\\nNLP Engineer, Google Developer Expert, AI Specialist in Yodo1\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3999</td>\n",
       "      <td>Pankaj Jainani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/vanishing-exploding-gradient-problem-b5b78c142bb7?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Does your model train too slow? Alleviating Vanishing Gradient Problem | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 11, 2021\\nYou must definitely have encountered the problem when training a model is getting slower for a very Deep Neural Network. This phenomenon happens prominently during the backpropagation training (using Gradient Descent) of the DNNs, wherein, each parameter’s gradient error is propagated along its way to the lower layers of the network. Why? This usually happens because gradients usually get smaller and smaller. As a result, the lower layers weights never change and training never converges to the good solution.\\nThis post categorically discuss about the ways to alleviate the Vanishing Gradient (or the Exploding Gradient) problem while training the DNNs\\nThere are various ways to overcome this challenge —\\nLet’s look into all these in detail...\\nWe know...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>4000</td>\n",
       "      <td>Michael Bronstein</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/graph-neural-networks-through-the-lens-of-differential-geometry-and-algebraic-topology-3a7c3c22d5f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Graph Neural Networks through the lens of Differential Geometry and Algebraic Topology | by Michael Bronstein | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 18, 2021\\n“Symmetry, as wide or as narrow as you may define its meaning, is one idea by which man through the ages has tried to comprehend and create order, beauty, and perfection.”\\nThis somewhat poetic description by Hermann Weyl [1] underlines the cornerstone role of symmetry in science. Felix Klein’s 1872 “Erlangen Programme” [2] characterised geometries through symmetry groups. Not only was this a breakthrough in mathematics, unifying the “zoo of geometries,” but also led to the development of modern physical theories that can be entirely derived from the first principles of symmetry [3]. Similar principles have emerged in machine learning under the umbrella of Geometric Deep Learning, a general blueprint for deriving the majority of popular neural networ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>4001</td>\n",
       "      <td>Nurlan Kerimov</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@kerimov.nurlan/anomaly-detection-in-brightfield-microscopy-images-c92cdddafcc3?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Anomaly detection in brightfield microscopy images | by Nurlan Kerimov | Medium</td>\n",
       "      <td>Jun 14, 2020\\nDisclaimer: This project was developed by Kaspar Hollo and Nurlan Kerimov for the Neural Networks course at the University of Tartu. The data and the code used in this project are not public and, in this blog-post only a few examples from the dataset will be shown. The data was provided by PerkinElmer.\\nNowadays, microscopy images are often used for doing medical diagnosis. For example, in this paper, a deep learning model was developed to count mitotic cells to help diagnose breast cancer. There is a problem though — the captured microscopy images may contain some so-called anomalies which can be considered as noise. It is found that the cell count and position predictions (cell segmentation) are performing badly in areas with anomalies. In our project, we tried to predi...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4002</td>\n",
       "      <td>Harald Scheidl</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Beam Search Decoding in CTC-trained Neural Networks | by Harald Scheidl | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 10, 2018\\nNeural networks (NN) consisting of convolutional NN layers and recurrent NN layers combined with a final connectionist temporal classification (CTC) layer are a good choice for (handwritten) text recognition.\\nThe output of the NN is a matrix containing character-probabilities for each time-step (horizontal position), an example is shown in Fig 1. This matrix must be decoded to get the final text. One algorithm to achieve this is beam search decoding which can easily integrate a character-level language model.\\nWe will start our discussion with a recap of CTC and best path decoding. Then we will discuss the building blocks (basic algorithm, CTC scoring, language model) of the CTC beam search decoding algorithm. Finally, I will point you to a Python i...</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>4003</td>\n",
       "      <td>Mikhail Mew</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/data-scientists-will-be-extinct-in-10-years-a6e5dd77162b?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Data Scientists Will be Extinct in 10 Years | by Mikhail Mew | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 10, 2021\\nAs advances in AI continue to progress in leaps and bounds, accessibility to data science at a base level has become increasingly democratized. Traditional entry barriers to the field such as a lack of data and computing power have been swept aside with a continuous supply of new data startups popping up(some offering access for as little as a cup of coffee a day) and all powerful cloud computing removing the need for expensive onsite hardware. Rounding out the trinity of prerequisites, is the skill and know-how to implement, which has arguably become the most ubiquitous aspect of data science. One does not need to look far to find online tutorials touting taglines like “implement X model in seconds” , “apply Z method to your data in just a few lines...</td>\n",
       "      <td>4564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>4004</td>\n",
       "      <td>Park Chansung</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>4005</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>4006</td>\n",
       "      <td>Kerish Heik</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@Dude_Next/the-dropout-tag-i-wear-9425f2cba27b?source=tag_archive---------8-----------------------</td>\n",
       "      <td>The Dropout Tag I Wear. *On a personal note, before reading... | by Kerish Heik | Medium</td>\n",
       "      <td>Jan 8, 2016\\n*On a personal note, before reading this article take a deep breath and relax yourself. In this article, you will neither hear any neighbor’s aunties gossiping ills about you nor see your parents hesitations when you say something cause you are wearing a dropout tag that isn’t sugar coated. This is an article on the bright side of the moon about how I get the inspiration to ultimately drop out.\\nThis moment in my life about a year ago I got the ultimate boredom to drop out of my class to do something of my own that I am really passionate about. Everyone in the class was doing the same thing, solving Irodov’s problems where the task itself would be a terror for every country’s layman and more importantly, till now I don’t find any usefulness of that things beside teaching t...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>4007</td>\n",
       "      <td>Anusha Lihala</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Attention and its Different Forms | by Anusha Lihala | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 29, 2019\\nI assume you are already familiar with Recurrent Neural Networks (including the seq2seq encoder-decoder architecture).\\nIn the encoder-decoder architecture, the complete sequence of information must be captured by a single vector. This poses problems in holding on to information at the beginning of the sequence and encoding long-range dependencies.\\nThe core idea of attention is to focus on the most relevant parts of the input sequence for each output. By providing a direct path to the inputs, attention also helps to alleviate the vanishing gradient problem.\\nAssume you have a sequential decoder, but in addition to the previous cell’s output and hidden state, you also feed in a context vector c.\\nWhere c is a weighted sum of the encoder hidden states...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4008</td>\n",
       "      <td>Supervise.ly</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/deep-systems/movix-ai-movie-recommendations-using-deep-learning-5903d6a31607?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Movix.ai — movie recommendations with Deep Learning | by Supervise.ly | Supervisely | Medium</td>\n",
       "      <td>Supervisely\\nMay 2, 2017\\n“What movie should i watch this evening?” — have you ever had to answer this question at least once when you came home from work? As for us — yes, and more than once. Here we will say a few words about what we’ve been working on for the past six months: an interactive movie recommender system Movix.ai. The system is based on Deep Learning and it adapts to the user preferences in real time. As big movie fans we felt the need for such a service, and we believe that it will be useful for every movie lover.\\nAt Deep Systems we are engaged in creating solutions and products based on machine learning and Deep Learning. Among our projects: developing a “mind” for self-driving car prototype and automatic defects detection for roads and airport runways. The important p...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>4009</td>\n",
       "      <td>Tobias Skovgaard Jepsen</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=tag_archive---------4-----------------------</td>\n",
       "      <td>How to do Deep Learning on Graphs with Graph Convolutional Networks | by Tobias Skovgaard Jepsen | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 18, 2018\\nMachine learning on graphs is a difficult task due to the highly complex, but also informative graph structure. This post is the first in a series on how to do deep learning on graphs with Graph Convolutional Networks (GCNs), a powerful type of neural network designed to work directly on graphs and leverage their structural information. The posts in the series are:\\nIn this post, I will give an introduction to GCNs and illustrate how information is propagated through the hidden layers of a GCN using coding examples. We’ll see how the GCN aggregates information from the previous layers and how this mechanism produces useful feature representations of nodes in graphs.\\nGCNs are a very powerful neural network architecture for machine learning on graphs....</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>4010</td>\n",
       "      <td>Merzmensch</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/generative-ai-visual-search-as-a-bridge-between-fiction-and-reality-46d2d78ee15?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Generative AI: Visual Search as a Bridge between Fiction and Reality | by Merzmensch | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 8, 2021\\nFirst, tell me, please, what is fiction and what is reality — in the context of Generative Adversarial Networks?\\nWe’ve seen a lot of things, which hadn’t existed before its AI-driven creation. Sure, the GAN-generated images in This Person Does Not Exist or This Artwork Does Not Exist have no direct reference in the material world — they are products of knowledge and AI models training. But being transported into our world, they might get their own story, specific meaning, and particular use, leaving the Latent Space and become more real than fiction.\\nIndeed, you can use them for making movies; you also can generate fraud and fakes. AI is not to blame for misuse, but us, humans. You cannot fix society by breaking technology.\\nNevertheless, in Digital...</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>4011</td>\n",
       "      <td>Akihiro FUJII</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@akichan-f/efficientnet-b6-autoaug%E3%81%A8%E5%90%8C%E7%AD%89%E7%A8%8B%E5%BA%A6%E3%81%AE%E7%B2%BE%E5%BA%A6%E3%81%A75%E5%80%8D%E6%97%A9%E3%81%84assemble-resnet-c3b8b846e0a2?source=tag_archive---------9-----------------------</td>\n",
       "      <td>EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNet | by Akihiro FUJII | Medium</td>\n",
       "      <td>Feb 2, 2020\\nこの記事は、EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNetを提案した2020/1/17投稿の論文””Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network [1]の解説記事です。\\nこの記事では以下のこと説明します。\\nこの論文のサマリは以下のような感じです。\\n既存のあらゆるテクニックを組み合わせて、EfficientNet B6+AutoAugと同等程度の精度で5倍早いネットワークを構築した研究。著者たちがいうにはAugMix等の最新のものはここでは使ってないので、まだ精度があがる可能性があるとのこと。\\nここでは、Assemble-ResNetのベースライン比較となっているEfficientNet+AutoAugmentの解説をします。EfficientNetは2019年に発表された既存のネットワークより大幅に軽くて高精度なネットワークです。AutoAugmentは2018年に発表された論文で、最適なデータ拡張を自動で探索する研究です。どちらも画像認識では頻繁にベースラインとして登場する強力な手法です。\\nEfficientNet[2]は2019/5/28に投稿された論文で、それまでの既存のネットワークより高速で高精度なネットワークです。論文の内容をまとめると下記のような感じです。今まで成されていなかった解像度・深さ・チャネル数を同時に最適化することによって、高速かつ高精度なネットワークを構築。式3におけるφ=1にしてMnasNetの探索空間でαβγを最適化(B0)、後にφを変...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>4012</td>\n",
       "      <td>Rakshith Vasudev</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/how-are-logistic-regression-ordinary-least-squares-regression-related-1deab32d79f5?source=tag_archive---------9-----------------------</td>\n",
       "      <td>How are Logistic Regression &amp; Ordinary Least Squares Regression (Linear Regression) Related? Why the “Regression” in Logistic? | by Rakshith Vasudev | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 5, 2018\\nIf you are like me bothered by “regression” in “logistic regression” which realistically should be called “logistic classification”, considering it does classification, I have an answer for your botheration!\\nLogistic regression is useful for situations where there could be an ability to predict the presence or absence of a characteristic or outcome, based on values of a set of predictor variables. It is similar to a linear regression model but is suited to models where the dependent variable is dichotomous. It’s coefficients can be used to estimate odd ratios for each of the independent variables in the model. It is applicable to a broader range of research situations than discriminant analysis. Logistic Regression on the other hand is used to ascert...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>4013</td>\n",
       "      <td>Thomas HARTMANN</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/datathings/meta-learning-learning-to-learn-a55cadd32b17?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Meta-Learning: Learning to Learn. Although artificial intelligence and... | by Thomas HARTMANN | DataThings | Medium</td>\n",
       "      <td>DataThings\\nFeb 6, 2019\\nAlthough artificial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. Meta-learning aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning algorithm.\\nArtificial intelligence and machine learning are currently extremely fashionable. In recent years, this technology has left the ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>4014</td>\n",
       "      <td>Nishanth N</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>4015</td>\n",
       "      <td>Chung-Yi</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81-gradient-descent-e97890236262?source=tag_archive---------7-----------------------</td>\n",
       "      <td>ML入門(十)Gradient Descent. 簡單回顧 | by Chung-Yi | 程式設計之旅 | Medium</td>\n",
       "      <td>程式設計之旅\\nSep 22, 2019\\n簡單回顧\\n在ML入門(五)Linear Regression有介紹什麼是Gradient Descent,就是對loss function做偏微分(切線斜率)就是找極大極小值的概念,找一組參數讓loss function越小越好。在ML入門(五)Linear Regression,我們要更新的是w, b,在這邊用一個theta表示。\\nGradient Descent如何運行\\n這邊可以搭配公式一起看,紅色箭頭就是loss function的gradient方向,當乘上learning rate後再乘上負號(改變方向)就會變成藍色箭頭,一直重複這樣的動作,這就是Gradient Descent的運行模式。\\nLearning Rate對 Loss Function的影響\\n調整learning rate的方法\\n既然learning rate有時候不是太大不然就是太小,是不是有什麼方法可以來讓機器自己調整。當一開始起始點離最低點還很遠的時候,learning rate可以大一點;當越來越接近最低點時,learning rate要小一點,這樣才能收斂在最低點附近。下面那張圖所示,假設定義learning rate是每次跟著更新次數做調整,也就是說你的更新次數越多,learning rate會跟次數的開根號成反比,learning rate會越小。那有人就覺得說可以根據不同參數調整不同的learning rate,以下會列出幾種方法:\\n現在對於每一個參數w都要給一個不同的η,就是每次更新的η就是等於前一次的η再除以σ^t,而 σ^t則代表的是第 t 次以前的所有梯度更新值之平方和開根號(root mean square),而ε只是為了不讓分母為0而加上去的值。\\n下面圖中的式子可以清楚看出,分子的部分(紅色框框)顯示,當g...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>4016</td>\n",
       "      <td>João Fernandes</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@joaomariafernandes/why-i-dropped-out-of-college-but-you-shouldn-t-73a4b99f9cf9?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Why I dropped out of college, but you shouldn’t | by João Fernandes | Medium</td>\n",
       "      <td>Oct 26, 2015\\nThis article’s title is even a surprise to me. This is not something that I expected to write and you’re probably wondering what happened to all that advice about “you grow your wings on your way down”. I know, but this is the kind of theme that creates a lot of fuss by itself and a lot of irresponsible advice is given.\\nHere I will clarify my position on pursuing an academic career and how is the life of a college drop out.\\nI’ve always been a decent student, I always knew that I could be one of the top students in the class, but I never felt like going after that status. Video games always seemed more interesting than boring themes with zero practical implication. So school never presented itself as a challenge when it came to studying. Even in college I pass at every s...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>4017</td>\n",
       "      <td>ASHNA JAIN</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/voice-tech-podcast/automatic-extractive-text-summarization-using-tfidf-3fc9a7b26f5?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Automatic Extractive Text Summarization using TF-IDF | by ASHNA JAIN | Voice Tech Podcast | Medium</td>\n",
       "      <td>Voice Tech Podcast\\nApr 1, 2019\\nIn the recent years, information grows rapidly along with the development of social media. With the increasing amount of information, it takes more effort and time to review the entire text document and understand its contents. One possible solution to the above problem is to read the summary of the document. The summary will not only retain the essence of the document, but will also save a lot of time and effort. An effective summary of the document will concise and fluent while preserving key information and overall meaning.\\nThere are two major text summarization approaches, abstractive and extractive summarization. The approach of Abstractive summarization selects words on the basis of semantic understanding, and even includes those words which do n...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>4018</td>\n",
       "      <td>Eric Elliott</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/javascript-scene/top-javascript-frameworks-and-tech-trends-for-2021-d8cb0f7bda69?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Top JavaScript Frameworks and Tech Trends for 2021 | by Eric Elliott | JavaScript Scene | Medium</td>\n",
       "      <td>JavaScript Scene\\nDec 31, 2020\\nHappy New Year! It’s time to review the big trends in JavaScript and technology in 2020 and consider our momentum going into 2021.\\nOur aim is to highlight the learning topics and technologies with the highest potential job ROI. This is not about which ones are best, but which ones have the most potential to land you (or keep you in) a great job in 2021. We’ll also look at some larger tech trends towards the end.\\nJavaScript still reigns supreme on GitHub and Stack Overflow. Tip #1: Learn JavaScript, and in particular, learn functional programming in JavaScript. Most of JavaScript’s top frameworks, including React, Redux, Lodash, and Ramda, are grounded in functional programming concepts.\\nTypeScript jumped past PHP, and C# into 4th place, behind only Ja...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>4019</td>\n",
       "      <td>Huangwei Wieniawska</td>\n",
       "      <td>10</td>\n",
       "      <td>https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting | by Huangwei Wieniawska | Level Up Coding</td>\n",
       "      <td>Level Up Coding\\nJun 25, 2020\\nDo you want to try some other methods to solve your forecasting problem rather than traditional regression? There are many neural network architectures, which are frequently applied in NLP field, can be used for time series as well. In this article, we are going to build two Seq2Seq Models in Keras, the simple Seq2Seq LSTM Model, and the Seq2Seq LSTM Model with Luong Attention, and compare their forecasting accuracy.\\nFirst of all, let’s create some time series data.\\nWe’ve just created two sequences, x1 and x2, by combining sin waves, trend, and random noise. Next we will preprocess x1 and x2.\\nSince the sequence length is n_ = 1000, the first 800 data points will be used as our train data, while the rest will be used as our test data.\\nIt is not a must ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4020</td>\n",
       "      <td>R. E. Warner</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/minds-on-media/finger-dasher-3332487b5f4e?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Finger Dasher | by R. E. Warner | Banapana | Medium</td>\n",
       "      <td>Banapana\\nJan 4, 2008\\nDasher is a novel piece of software that lets you point at what you want to write. Honestly, it’s kind of difficult to describe without [seeing the demonstration](http://www.youtube.com/watch?v=0d6yIquOKQ0). It’s very novel and makes novel use of some simple AI. I wonder if Apple would ever integrate this in to the iPhone? And it would seem to be of great use were it to be integrated into eye tracking software.\\nOur Minds on Media\\n86 Followers\\nWriter of story, poetry and code. Currently attempting to illustrate one Ism a day — https://ismisms.tumblr.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>4021</td>\n",
       "      <td>m.zaradzki</td>\n",
       "      <td>7</td>\n",
       "      <td>https://becominghuman.ai/a-news-analysis-neuralnet-learns-from-a-language-neuralnet-16646804fdeb?source=tag_archive---------9-----------------------</td>\n",
       "      <td>A news-analysis NeuralNet learns from a language NeuralNet | by m.zaradzki | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nMar 28, 2017\\nPython notebook, using Keras library, available on this GitHub repo.\\nA common way to solve a complex computing task is to chain together specialized components. In data-science this is the pipeline approach. Each component mostly treats the other components as I/O black-boxes. As developers we potentially have the full picture but the system does not.\\nWith Neural Network what happens between I and O is often too interesting to be ignored. One Neural Network can leverage the way another Neural Network processes its inputs.\\nIn this post I discuss the following scenario :\\nTo “understand” english is necessary to analyse news. Thus during training a standalone ’N’ NeuralNet would learn about the semantics of english as a by...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>4022</td>\n",
       "      <td>karthic Rao</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/kredo-ai-engineering/blog-series-on-ros-ai-ff28cc116560?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Building smart robots using AI + ROS: Part 1 | by karthic Rao | Kredo.ai Engineering | Medium</td>\n",
       "      <td>Kredo.ai Engineering\\nDec 8, 2017\\nMotivation for writing blog series on AI + Robotic Operating Systems:\\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\\nROS is used to create application for a physical robot without depending on the actual machine, thus saving cost and time. These applications can be transferred onto the physical robot without modifications.\\nThe decision making capability of the robots can be aided with AI. The cases where the robot agent has to learn optimal strategies in high dimensional state space often means that it is impractical to generate sufficient...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>4023</td>\n",
       "      <td>Thomas Filaire</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Clustering on mixed type data. A proposed approach using R | by Thomas Filaire | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 16, 2018\\nClustering unsupervised data is not an easy task. Indeed, data crunching and exploration is in such a context often driven by domain knowledge, if not pure intuition, and made difficult as there is no way to measure the accuracy of the resulting segmentation (as opposed to supervised learning).\\nIn addition, introductory courses to unsupervised learning quite often discuss ideal use cases, such as k-means tutorials, which only apply to numerical features.\\nHowever, real business situations often deviate from these ideal use cases, and need to analyze datasets made of mixed-type data, where numeric (the difference between two values is meaningful), nominal (categorical, not ordered) or ordinal (categorical, ordered) features coexist.\\nIn this post, I’...</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>4024</td>\n",
       "      <td>Alex Lenail</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@alexlenail/what-is-the-difference-between-ridge-regression-the-lasso-and-elasticnet-ec19c71c9028?source=tag_archive---------5-----------------------</td>\n",
       "      <td>What is the difference between Ridge Regression, the LASSO, and ElasticNet? | by Alex Lenail | Medium</td>\n",
       "      <td>Jul 31, 2017\\nThis article is about different ways of regularizing regressions. In the context of classification, we might use logistic regression but these ideas apply just as well to any kind of regression or GLM.\\nWith binary logistic regression, the goal is to find a way to separate your two classes. There are a number of ways of visualizing this.\\nNo matter which of these you choose to think of, we can agree logistic regression defines a decision rule\\nh(x|theta) = sigmoid(x dot theta + b)\\nand seeks a theta which minimizes some objective function, usually\\nloss(theta)= ∑ y*log(h(x|theta)) + (1−y)log(1−h(x|theta))\\nwhich is obfuscated by a couple clever tricks. It is derived from the intuitive objective function:\\nloss(theta)= ∑ (y - h(x|theta))\\ni.e. the number of misclassified x...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>4025</td>\n",
       "      <td>Michael L. Peng</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@lipeng2/dropout-is-so-important-e517bbe3ffcc?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Improving neural networks by preventing co-adaptation of feature detectors | by Michael L. Peng | Medium</td>\n",
       "      <td>May 7, 2018\\nThis blog post aims to provide readers some insights on deep neural networks and intuition about dropout technique.\\nDeep neural networks are models composed of multiple layers of simple, non-linear neurons. With composition of enough neurons, the model can learn extremely complex functions that can accurately perform complicated tasks that are impossibly difficult to hard code, such as image classification, translation, speech recognition, etc. The key aspect of deep neural networks is that they are able to automatically learn data representation needed for features detection or classification without any a priori knowledge1.\\nFor example, VGG16 (shown below) is a convolutional neural network that is trained on ImageNet Large Scale Visual Recognition Competition (ILSVRC) ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>4026</td>\n",
       "      <td>Marco Cerliani</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Extreme Event Forecasting with LSTM Autoencoders | by Marco Cerliani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 22, 2019\\nDealing with extreme event prediction is a frequent nightmare for every Data Scientist. Looking around I found very interesting resources that deal with this problem. Personally, I literally fall in love with the approach released by Uber Researchers. In their papers (two versions are available here and here) they developed an ML solution for daily future prediction of traveler demand. Their methodology stole my attention for its geniality, good explanation, and easy implementation. So my purpose is to reproduce their discovery in pythonic language. I’m very satisfied with this challenge and in the end, I improved my knowledge of regression forecasting.\\nThe most important takeaways from this post can be summarized as:\\nBut Keep Kalm and let’s procee...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>4027</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Natural Language Processing for Fuzzy String Matching with Python | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 12, 2018\\nIn computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\\nFuzzy string search can be used in various applications, such as:\\nSpeaking of dedupe, it may not as easy as it sounds, in particular if you have hundred thousands of records. Even Expedia does not make it 100% right:\\nThis post will explain what fuzzy string matching is together with its use cases and give examples using Python’s Fuzzywuzzy library.\\nEach hotel has its own nomenclature to name its rooms, the sam...</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>4028</td>\n",
       "      <td>Aji Abraham</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@ajiabs/socialdefender-social-reputation-management-platform-aji-abraham-593dafc771e2?source=tag_archive---------2-----------------------</td>\n",
       "      <td>SocialDefender — Social Reputation Management Platform — Aji Abraham | by Aji Abraham | Medium</td>\n",
       "      <td>Jan 11, 2013\\nSocial media can be hard to control. From small and medium-sized businesses lacking additional manpower to large companies requiring a method for scheduling numerous team members, we decided to create a tool that will add additional value to social media efforts.\\nSocial Defender provides real-time social media monitoring, insights and gives the ability to accurately moderate social media efforts and understand customer sentiment.\\nBy using the tool, businesses can manage multiple social media networks including Facebook, Twitter, Tumblr, YouTube, G+, blogs and forums using just one login. This social media management tool gives businesses the ability to analyze what is being said online about a brand, service, industry, and competitors. Analytics provided by Social Defen...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>4029</td>\n",
       "      <td>LucianoSphere</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/the-hype-on-alphafold-keeps-growing-with-this-new-preprint-a8c1f21d15c8?source=tag_archive---------6-----------------------</td>\n",
       "      <td>The hype on AlphaFold keeps growing with this new preprint | by LucianoSphere | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 18, 2021\\nI am sure you read about AlphaFold in late 2020 when it “won” the CASP14 “contest” on modeling protein structures, and in July 2021 when the peer-reviewed paper and AI model were released. If not, or if you want to refresh what protein structures are, why biologists prayed for decades for programs to accurately predict them, and how AlphaFold works and performs, then check this story and this one, then come back here.\\nThis new story brings you the latest news, based on a just-published preprint.\\nTable of contents\\nThis story is based on a preprint just posted in the bioRxiv that formally describes a tool dubbed ColabFold under the moto Making protein folding accessible to all (which I would have rather phrased Making modern protein structure modeli...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4030</td>\n",
       "      <td>Eitan Kosman</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@eitan-kosman/neural-image-retrieval-72029a0dbd00?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Neural Image Retrieval. Assume you have an image I and an image... | by Eitan Kosman | Medium</td>\n",
       "      <td>Jul 4, 2020\\nAssume you have an image I and an image database X containing thousands of other images. You want to find a subset S⊆X containing images that are most similar to I. This is a task called image retrieval. However, before solving this, you may ask yourself, what is the meaning of similar images? Is it based on the colors in the images? Or maybe the content? In the second case, two images containing dogs could be considered similar regardless of their breed, which obviously may have different colors. In this post, I will describe a simple implementation of this. The implementation is based on neural networks and is done by comparing the similarity between the embeddings of the two images.\\nGiven a query image I, I extract the features using VGG-19 and use the output of the fi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>4031</td>\n",
       "      <td>Benedict Neo</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/top-20-movies-about-machine-learning-ai-and-data-science-8382d408c8c3?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Top 20 Must-Watch Artificial Intelligence movies | by Benedict Neo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 9, 2020\\nMovies are more than just blockbusters hit with explosions and superpowers, it’s the main idea behind the movie that changes people and injects a notion in the viewer’s head.\\nTo illustrate, the movie Joker wasn’t a hero vs villain film, fighting with superpowers and wreaking havoc on New York City. It portrayed how there is a distinct chasm between the rich and the poor, the lucky and the unlucky, and how mental illness can distort a person’s morality and value system.\\nSo, movies are more than just an activity for enjoyment and amusement, it plays an imperative role in shaping our view on the world and communal consciousness.\\nIn short, movies educate people and spread ideas in ways a paperback book early does today.\\nOne reason for the effectivenes...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>4032</td>\n",
       "      <td>Luuk Derksen</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@luckylwk/transfer-learning-in-tensorflow-on-the-kaggle-rainforest-competition-4e978fadb571?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Transfer Learning in TensorFlow on the Kaggle Rainforest competition | by Luuk Derksen | Medium</td>\n",
       "      <td>Jul 31, 2017\\nWhen I first noticed the Kaggle competition: “Planet: Understanding the Amazon from space” I was immediately thinking of trying out Transfer Learning using a pre-trained model. I had never really played with Transfer Learning before so I thought this would be a good one to try it out on. Transfer Learning is described by Wikipedia as:\\n“a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem”\\nwhere in this case the ‘relatedness’ of the problem is that both the Kaggle competition and the pre-trained model(s) are addressing computer vision problems. For more information on Transfer Learning there is a good resource from Stanfords CS class and a fun blog by Sebastian Ruder.\\...</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>4033</td>\n",
       "      <td>Ryan Kemmer</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/clustering-on-mixed-data-types-in-python-7c22b3898086?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Clustering on Mixed Data Types in Python | by Ryan Kemmer | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJan 25, 2021\\nDuring my first ever data science internship, I was given a seemingly simple task to find clusters within a dataset. Given my basic knowledge of clustering algorithms like K-Means, DBSCAN, and GMM I thought that I could easily get this task done. However, as I took a closer look into the dataset, I realized the data contained a mixture of categorical and continuous data, and many common methods of clustering I knew would not easily work.\\nCategorical data consists of multiple discrete categories that commonly do not have any clear order or relationship to each-other. This data might look like “Android” or “iOS”.\\nContinuous data consists of real numbers that can take any value. This data might look like “3.14159” or “43\".\\nMany datasets contain a mixture...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>4034</td>\n",
       "      <td>Haripriya Reddy</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/insight-into-faster-r-cnn-for-object-detection-f1e64240eee1?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Insight into Faster R-CNN for Object Detection. | by Haripriya Reddy | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nJan 23, 2020\\nFaster R-CNN is an object detection architecture presented by Ross Girshick, Shaoqing Ren, Kaiming He and Jian Sun in 2015, and is one of the famous object detection architectures that uses convolution neural networks.It detects and classifies objects in an image as shown below:\\nBefore diving into Faster R-CNN let’s learn about R-CNN, Fast R-CNN and RPN which are the building blocks...\\n303 \\n303 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n24 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>4035</td>\n",
       "      <td>Masumi Mutsuda</td>\n",
       "      <td>2</td>\n",
       "      <td>https://blog.mutsuda.com/intelligent-agent-based-wastewater-management-system-741b793f1c5c?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Intelligent Agent Based Wastewater Management System | by Masumi Mutsuda | mutsuda</td>\n",
       "      <td>mutsuda\\nMar 22, 2012\\nFa dos anys, a l’assignatura d’AIA (Aplicacions de la Intel·ligència Artificial), ens van fer implementar un sistema intel·ligent que dominaria tot el procés de depuració d’aigua de Catalunya. Les diferents plantes havien de ser intel·ligents i tenir suficient coneixement del seu entorn com per decidir, entre elles, de quina manera actuar en cas de detecció d’un contaminant, pluja torrencial, etc. Elles soles decidien mitjançant diverses polítiques què fer en cadascuna de les situacions per tal de resoldre els problemes.\\nLes plantes entre si es comunicaven mitjançant missatges en format d’ontologia, que ve a ser una representació lògica del context en què s’està treballant. En aquest cas l’ontologia contenia informació sobre els tòxics, l’aigua, ai...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>4036</td>\n",
       "      <td>Uri Eliabayev</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Springer has released 65 Machine Learning and Data books for free | by Uri Eliabayev | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 26, 2020\\nHundreds of books are now free to download\\nSpringer has released hundreds of free books on a wide range of topics to the general public. The list, which includes 408 books in total, covers a wide range of scientific and technological topics. In order to save you some time, I have created one list of all the books (65 in number) that are relevant to the data and Machine Learning field.\\nAmong the books, you will find those dealing with the mathematical side of the domain (Algebra, Statistics, and more), along with more advanced books on Deep Learning and other advanced topics. You also could find some good books in various programming languages such as Python, R, and MATLAB, etc.\\nIf you are looking for more recommended books about Machine Learning a...</td>\n",
       "      <td>15553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>4037</td>\n",
       "      <td>Ravindra Kompella</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/using-lstms-to-forecast-time-series-4ab688386b1f?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Using LSTMs to forecast time-series | by Ravindra Kompella | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 17, 2018\\nThere are several time-series forecasting techniques like auto regression (AR) models, moving average (MA) models, Holt-winters, ARIMA etc., to name a few. So, what is the need for yet another model like LSTM-RNN to forecast time-series? This is quite a valid question to begin with and here are the reasons that I could come up with (respond below if you are aware of more, I will be curious to know)—\\nOn the other hand, there are the usual downsides that one needs to be careful about, while using LSTM’s (or any DNN architectures for that matter) — requirement of lots of data, multiple hyper-parameters to be tuned etc., I also came across few articles that mentioned that LSTM’s are not supposedly good at auto regression type of series. So take this wit...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>4038</td>\n",
       "      <td>Roland Hewage</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models | by Roland Hewage | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 12, 2020\\nKeras provides a set of deep learning models that are made available alongside pre-trained weights on ImageNet dataset. These models can be used for prediction, feature extraction, and fine-tuning. Here I’m going to discuss how to extract features, visualize filters and feature maps for the pretrained models VGG16 and VGG19 for a given image.\\nHere we first import the VGG16 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG16 model. The numpy module is imported for array-processing. Then the VGG16 model is loaded with the pretrained weights for the imagenet dataset. VGG16 model is a series of convolutional layers followed ...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>4039</td>\n",
       "      <td>Tan</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/ai-academy-taiwan/%E5%B8%B6%E4%BD%A0%E8%AA%8D%E8%AD%98vector-quantized-variational-autoencoder-%E7%90%86%E8%AB%96%E7%AF%87-49a1829497bb?source=tag_archive---------6-----------------------</td>\n",
       "      <td>帶你認識Vector-Quantized Variational AutoEncoder - 理論篇 | by Tan | Taiwan AI Academy | Medium</td>\n",
       "      <td>Taiwan AI Academy\\nApr 28, 2020\\n說到近年來最火紅以深度學習為主的生成模型,大家必定會想到生成對抗網路(Generative Adversarial Network, GAN),然而在GAN(2014)還沒被提出來之前,有另外一個同樣屬於生成模型的Variational AutoEnoder (VAE)常被大家所使用,很可惜的是當時GAN在許多任務上所產生的圖片清晰度較高,因此VAE類型的模型相對而言就勢弱了一些(當然GAN在訓練的特性上有一些難以克服的問題至今也尚未完全解決)。\\n故事總不會就這樣結束,2017年DeepMind在NIPS研討會上提出了Vector-Quantized Variational AutoEncoder模型,雖然在效果上仍然是先與VAE做比較,但VQ-VAE提出的概念讓它擁有比其它生成模型更獨特的地方,甚至在後續2019年6月提出的VQ-VAE2甚至宣稱在生成1024*1024的高解析度人臉時與當時效果最佳的BigGAN可作比擬。如果你開始對VQ-VAE感到好奇,就跟著我們一起看下去吧。\\n註1:如果你對Variational AutoEncoder甚至是AutoEncoder的概念還沒那麼熟的話,可以參考此篇AutoEncoder介紹、此篇VAE介紹、或是尋找其他資源唷。\\n我們可以這樣解讀AutoEncoder家族在做的事情,Encoder試圖找出輸入圖片x在潛在空間上的表徵(representation),在大多數的狀況中,大家使用連續型的分布去模擬z的樣貌(e.g. AE將輸入x投影至潛在空間的一個點;VAE則改為使用高斯分布模擬輸入x在潛在空間的樣貌),然而VQVAE的作者提到離散的潛在表徵在很多情境上也許才是比較適合的,例如語言概念,因此VQ-VAE主要的突破就是試圖讓Encoder產出離散的...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>4040</td>\n",
       "      <td>Progress</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/stories-by-progress/true-democratization-of-analytics-with-meta-learning-cdefe3c7ddd5?source=tag_archive---------4-----------------------</td>\n",
       "      <td>True Democratization of Analytics with Meta-Learning | by Progress | Stories by Progress | Medium</td>\n",
       "      <td>Stories by Progress\\nAug 14, 2017\\nThe democratization of analytics has become a popular term, and a quick Google search will generate results that explore the necessity of empowering more people with analytics and the rise of citizen data scientists. The ability to easily make better use of your (constantly growing) pool of data is a critical driver of business success, but many of the existing solutions that claim to democratize analytics only do so within severe limits. If you have a complex business scenario and are looking to get revolutionary insights using them, it’s easy to come away disappointed.\\nHowever, the democratization of analytics isn’t just a buzzword that refers to a narrow approach. It’s possible to do so much more. Let’s quickly review the current state of the mark...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>4041</td>\n",
       "      <td>Md Shahidullah Kawsar</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@kawsar34/machine-learning-quiz-05-decision-tree-part-1-3ea71fa312e5?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Machine Learning Quiz 05: Decision Tree (Part 1) | by Md Shahidullah Kawsar | Medium</td>\n",
       "      <td>Jun 1, 2021\\nLet’s check your basic knowledge of Decision Tree. Here are 10 multiple-choice questions for you and there’s no time limit. Have fun!\\nQuestion 1: Decision trees are also known as CART. What is CART?(A) Classification and Regression Trees(B) Customer Analysis and Research Tool(C) Communication Access Real-time Translation(D) Computerized Automatic Rating Technique\\nQuestion 2: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees implicitly perform variable screening or feature selection(B) Can handle both numerical and categorical data(C) Can handle multi-output problems.(D) All of the above\\nQuestion 3: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees require relatively less effort from users for ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>4042</td>\n",
       "      <td>Dmitry Kan</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/speeding-up-bert-search-in-elasticsearch-750f1f34f455?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Speeding up BERT Search in Elasticsearch | by Dmitry Kan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 15, 2021\\nIn two previous blog posts on my journey with BERT: Neural Search with BERT and Solr and Fun with Apache Lucene and BERT I’ve taken you through the practice of what it takes to enable semantic search powered by BERT in Solr (in fact, you can plug in any other dense embeddings method, other than BERT, as long as it outputs a float vector; a binary vector can also work). While it feels cool and modern to empower your search experience with a tech like BERT, making it performant is still important for productization. You want your search engine operations team to be happy in a real industrial setting. And you want your users to enjoy your search solution.\\nDevops cares about disk sizes, RAM and CPU consumption a lot. In some companies, they also care ab...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>4043</td>\n",
       "      <td>Justin Chen</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/@interjc/%E5%86%99%E5%9C%A8%E7%9C%8B%E5%AE%8C%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9Aii%E4%B9%8B%E5%90%8E-ea5d294d2bd3?source=tag_archive---------0-----------------------</td>\n",
       "      <td>写在看完变形金刚II之后 | by Justin Chen | Medium</td>\n",
       "      <td>Jun 29, 2009\\n变形金刚II(Transformers:ROF)这样一部电影,从我从电影院看完他的第一部就开始期待了,昨天终于有幸去电影院看了。画面很,庞大,震撼说不上,可能在1的时候已经给我震完了吧。影院的效果就是好,所以看这个电影确实是一种享受的。当然就我个人看来他想超越1或者是原版动漫是没有多大可能了。我不是一个喜欢搞剧透的人,所以我非常不想说剧情。\\n只说一下对于剧情的感受:1. 剧情太商业化,变形金刚这么强大的战斗力和防御力,我不知道拿着枪的人类可以对他们造成什么样的威胁呢?美国大兵们与变形金刚们短兵相接,难道是为了方便狂派们刷数据么?2. 由于是美国电影,所以一定要展现美国军备的强大,所以战舰上的秘密武器可以KO看上去甚是强大的纸老虎 — — 狂派合体机器人;3. 主角一定得是人类,为了烘托人类主角的伟大性,不惜牺牲同样伟大但没有他伟大的各位领袖同志,主角由于起点比较低,所以随便摸一下某个能量体就可以吸收里面的精髓;4. 赶新潮,年轻人做网站办公司、经济危机,再在电影里融入一点青春元素,把学生宿舍比喻为霍格沃茨,可惜这方面的篇幅太短,如果开发一下说不定会为本集贫乏的剧情添加一点色彩;5. 冷兵器,变形金刚们之间的斗争,如果想要解决对方,就必须使用冷兵器或者蛮力,这方面是我所欣赏的,我可不希望擎天柱、威震天是被一把麦林爆头干掉的;6. HappyEnding,每一部想拍续集的电影都有那么一个HappyEnding,狂派还会回来的誓言也是必需的~\\n综上所述,这的确是一部好电影,看的时候请放松您的大脑,因为没什么可以让你去思考的。\\nBTW:搬到cosbeta的主机以后速度很快,很快,我非常欣慰。\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Follower...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>4044</td>\n",
       "      <td>Jhen Hilario</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@ellehilly/classes-of-novels-c8207342dc0b?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Classes of Novels. According to Creative Writing Now, the... | by Jhen Hilario | Medium</td>\n",
       "      <td>Oct 31, 2015\\nAccording to Creative Writing Now, the publishing world tends to classify Fiction as either Commercial (built to make money), or Literary (a work of art). There are no further explanations why art cannot also make money, but things just doesn’t work that way. Observe how Commercial Fiction and Literary Fiction are handled as separate categories. Commercial Fiction is divided into several genres. This kind of classification can help readers to determine what kind of novel do they like to read. Each genre also has its own rubric. Literary fiction has been generally chunked all together in bookstores as “General Fiction”. Because the precedence of literary authors is to produce works of art, while selling books is only a second thought. Literary authors are less likely to th...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>4045</td>\n",
       "      <td>Akshika Wijesundara</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@akshikawijesundara/object-recognition-with-opencv-on-android-6435277ab285?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Object Recognition with OpenCV on Android | by Akshika Wijesundara | Medium</td>\n",
       "      <td>Dec 20, 2016\\nThis article is for a person who has some knowledge on Android and OpenCV. We will look at how to use the OpenCV library to recognize objects on Android using feature extraction.\\nI am using Android Studio and you can follow this link to download and install Android studio and SDK tools but if you are a die hard eclipse fan you also can follow this tutorial( no hard feelings ;) )\\n2. Setting up OpenCV library inside Android Studio\\nYou have to download and import OpenCV library to android studio and there is a stackoverflow answer which you can follow to setup everything. If you are using Eclipse use this link.\\nNow you are ready to mingle with me ;). The algorithm we are going to use is ORB(Oriented FAST and Rotated BRIEF). As an OpenCV enthusiast, the most important thi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>4046</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@jonathan-hui/ssd-object-detection-single-shot-multibox-detector-for-real-time-processing-9bd8deac0e06?source=tag_archive---------7-----------------------</td>\n",
       "      <td>SSD object detection: Single Shot MultiBox Detector for real-time processing | by Jonathan Hui | Medium</td>\n",
       "      <td>Mar 14, 2018\\nSSD is designed for object detection in real-time. Faster R-CNN uses a region proposal network to create boundary boxes and utilizes those boxes to classify objects. While it is considered the start-of-the-art in accuracy, the whole process runs at 7 frames per second. Far below what real-time processing needs. SSD speeds up the process by eliminating the need for the region proposal network. To recover the drop in accuracy, SSD applies a few improvements including multi-scale features and default boxes. These improvements allow SSD to match the Faster R-CNN’s accuracy using lower resolution images, which further pushes the speed higher. According to the following comparison, it achieves the real-time processing speed and even beats the accuracy of the Faster R-CNN. (Accu...</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4047</td>\n",
       "      <td>Kai Stinchcombe</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Blockchain is not only crappy technology but a bad vision for the future | by Kai Stinchcombe | Medium</td>\n",
       "      <td>Apr 5, 2018\\nBlockchain is not only crappy technology but a bad vision for the future. Its failure to achieve adoption to date is because systems built on trust, norms, and institutions inherently function better than the type of no-need-for-trusted-parties systems blockchain envisions. That’s permanent: no matter how much blockchain improves it is still headed in the wrong direction.\\nThis December I wrote a widely-circulated article on the inapplicability of blockchain to any actual problem. People objected mostly not to the technology argument, but rather hoped that decentralization could produce integrity.\\nLet’s start with this: Venmo is a free service to transfer dollars, and bitcoin transfers are not free. Yet after I wrote an article last December saying bitcoin had no use, som...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>4048</td>\n",
       "      <td>Luiz Fonseca</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>4049</td>\n",
       "      <td>Haaya Naushan</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/swlh/transformer-based-sentence-embeddings-cd0935b3b1e0?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Transformer-based Sentence Embeddings | by Haaya Naushan | The Startup | Medium</td>\n",
       "      <td>The Startup\\nDec 22, 2020\\nNatural language processing (NLP) is a diverse field; the approaches and techniques are as varied...\\n172 \\n172 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n637 Followers\\nResearch Consultant and Data Scientist. Enthusiastic about machine learning, social justice, video games and philosophy.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>4050</td>\n",
       "      <td>Jerome Bouchon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@botcho/stash-data-center-%E3%83%99%E3%83%BC%E3%82%BF%E7%89%88%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9-git-%E3%82%92%E5%A4%A7%E8%A6%8F%E6%A8%A1%E3%81%AB%E5%88%A9%E7%94%A8-2f0f46d5f2dd?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Stash Data Center ベータ版リリース。Git を大規模に利用 | by Jerome Bouchon | Medium</td>\n",
       "      <td>Sep 16, 2014\\nこれまで Stash は常に、最高のスピードと安全性を実現する Git リポジトリ管理ツール製品となってきました。そして今回、最高の拡張性も提供します。Stash Data Center のリリースの発表です (本日、ベータ版リリース)! このクラスタリング搭載の Stash Data Center デプロイメント オプションは、エンタープライズの大規模システムでのニーズを満たすことを目的としています。\\n今すぐベータ版トライアル\\nStash Data Center はアクティブ/アクティブ クラスタリングを提供し、ユーザーは途切れることなく確実に Git リポジトリにアクセスできます。 Data Center は負荷バランシング技術と冗長化技術を使い、ハードウェア障害による予期せぬシステムのダウンタイムのリスクを軽減します。データベースクラスタリングと共有ファイルシステムの業界標準技術を組み合わせ、Stash は単一障害点を排除します。Stash Data Center の初期設定プロセスの中で、クラスタリングは簡単に設定できますので、チームはすぐに立ち上げ稼働することができます。さらに、稼働規模を拡張するためのノードの追加や削除にダウンタイムは不要ですので、開発チームやビルドプロセスを妨害することはありません。\\n組織内で Git ベースのソリューションを利用するチームが増えるにつれ、開発者とビルドサーバーからのトラフィック量が急速に増加し、リソースを圧迫することがあります。Stash Data Center は、負荷継続時やピーク負荷時に、より高いアプリケーションスループットに対応でき、ユーザーやビルドの追加...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4051</td>\n",
       "      <td>Halil Ertan</td>\n",
       "      <td>19</td>\n",
       "      <td>https://towardsdatascience.com/cnn-lstm-based-models-for-multiple-parallel-input-and-multi-step-forecast-6fe2172f7668?source=tag_archive---------2-----------------------</td>\n",
       "      <td>CNN-LSTM-Based Models for Multiple Parallel Input and Multi-Step Forecast | by Halil Ertan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 17, 2021\\nTime series forecasting is a very popular field of machine learning. The reason behind this is the widespread usage of time series in daily life in almost every domain. Going into details for time series forecasting, we encounter lots of different kinds of sub-fields and approaches. In this writing, I will focus on a specific subdomain that is performing multi-step forecasts by receiving multiple parallel time series, and also mention basic key points that should be taken into consideration in time series forecasting. Note that forecasting models differ from predictive models at various points.\\nLet's think about lots of network devices spread over a large geography, and traffic flows through these devices continuously. Another example might be about...</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4052</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/sentiment-analysis-using-rnns-lstm-60871fa6aeba?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Sentiment analysis using RNNs(LSTM) | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 21, 2017\\nHere we use the example of reviews to predict sentiment (even though it can be applied more generically to other domains for example sentiment analysis for tweets, comments, customer feedback, etc). Whole idea here is that movie reviews are made of sequence of words and order of words encode lot of information that is useful to predict sentiment. Step 1 is to map words to word embeddings (see post 1 and 2 for more context on word embeddings). Step 2 is the RNN that receives a sequence of vectors as input and considers the order of the vectors to generate prediction.\\nThe architecture for this network is shown below.\\nHere, we’ll pass in words to an embedding layer. You can actually train up an embedding with word2vec and use it here. But it’s good en...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4053</td>\n",
       "      <td>Chinmay</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@chinmaychetan04/activation-functions-78a99738a47c?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Activation Functions | by Chinmay | Medium</td>\n",
       "      <td>Aug 15, 2021\\nWhat are Activation Functions? Why are they used? why are there so many types? Does one works better than other?\\nFirstly, lets recap. A deep layer neural network as seen below receives the input and makes the decision based on its weights and biases which are learned during its backpropagation. As the Hidden layers increases , the decision making becomes more complex and sometimes leads to taking noise into consideration. When output is produced , mot all the neurons in the layers have equal say/contribution, and its because of the weights and bias updated during backpropagation. Done.\\nThen were is Activation function used? And Why?\\nSo basically, Activation functions decide whether the particular neuron or node to be fired /activated or not.\\nAs said, Activation functi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4054</td>\n",
       "      <td>Sourav kumar</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Sentence correction using Deep learning techniques | by Sourav kumar | Medium</td>\n",
       "      <td>Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4055</td>\n",
       "      <td>ProjectAGI</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/project-agi/introduction-71d920ed051c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction | by ProjectAGI | Project AGI | Medium</td>\n",
       "      <td>Project AGI\\nApr 7, 2014\\nby David Rawlinson and Gideon Kowadlo\\nThis blog will be written by several people. Other contributors are welcome — send us an email to introduce yourself!\\nThe content will be a series of short articles about a set of common architectures for artificial general intelligence (AGI). Specifically, we will look at the commonalities in Deep Belief Networks and Numenta’s Memory Prediction Framework (MPF). MPF is these days better known by its concrete implementations CLA (Cortical Learning Algorithm) and HTM (Hierarchical Temporal Memory). For an introduction to Deep Belief Networks, read one of the papers by Hinton et al.\\nThis blog will typically use the term MPF to collectively describe all the current implementations — CLA, HTM, NUPIC etc. We see MPF as an int...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4056</td>\n",
       "      <td>Stepan Ulyanin</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Implementing Grad-CAM in PyTorch. Recently I have come across a chapter... | by Stepan Ulyanin | Medium</td>\n",
       "      <td>Feb 22, 2019\\nRecently I have come across a chapter in François Chollet’s “Deep Learning With Python” book, describing the implementation of Class Activation Mapping for the VGG16 network. He implemented the algorithm using Keras as he is the creator of the library. Hence, my instinct was to re-implement the CAM algorithm using PyTorch.\\nGrad-CAM\\nThe algorithm itself comes from this paper. It was a great addition to the computer vision analysis tools for a single primary reason. It provides us with a way to look into what particular parts of the image influenced the whole model’s decision for a specifically assigned label. It is particularly useful in analyzing wrongly classified samples. The Grad-CAM algorithm is very intuitive and reasonably simple to implement.\\nThe intuition behi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>4057</td>\n",
       "      <td>Adam King</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Creating Bitcoin trading bots don’t lose money | by Adam King | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 27, 2019\\nIn this article we are going to create deep reinforcement learning agents that learn to make money trading Bitcoin. In this tutorial we will be using OpenAI’s gym and the PPO agent from the stable-baselines library, a fork of OpenAI’s baselines library.\\nThe purpose of this series of articles is to experiment with state-of-the-art deep reinforcement learning technologies to see if we can create profitable Bitcoin trading bots. It seems to be the status quo to quickly shut down any attempts to create reinforcement learning algorithms, as it is “the wrong way to go about building a trading algorithm”. However, recent advances in the field have shown that RL agents are often capable of learning much more than supervised learning agents within the same p...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>4058</td>\n",
       "      <td>Sachin Abeywardana</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@sachin-abeywardana/hi-tal-7212811eeb03?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Hi Tal,. Maybe I’m missing something here, but... | by Sachin Abeywardana | Medium</td>\n",
       "      <td>Dec 22, 2016\\nTal Perry\\nHi Tal,\\nMaybe I’m missing something here, but 1. I don’t think your first layer is a embedding layer but a dense layer. You are converting 4000 NUMBERS into 300 by multiplying by a matrix. Embedding layer is when you have categorical variables mapped to vectors, which doesn’t seem to be what’s happening. Unless you are using the name of the stock.\\n2. You mentioned that your output is 5 minute data, but your input is daily data. This is a bit confusing since the time intervals of the input and output have to be the same? If you are getting 5 minute stock data, where do you download them from (I haven’t been able to find anything of the sort).\\nCheers\\n11 \\n11 \\nPhD in Machine Learning | Founder of DeepSchool.io\\nLove podcasts or audiobooks? Learn on the go wit...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>4059</td>\n",
       "      <td>Brian Ward</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/using-word-embeddings-to-identify-company-names-and-stock-tickers-f194e3648a66?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Using Word Embeddings to Identify Company Names and Stock Tickers | by Brian Ward | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 13, 2021\\nProject Goal: Using word embeddings identify company names and stock tickers from natural text.\\nAssumption: Stock tickers and company names are used in similar context in natural text such as a Reddit post or a tweet.\\nUnder this assumption, word embeddings should be a good fit for identifying these target words as word embeddings are trained by the context in which words are found.\\nIn this post, I will skip describing what word embeddings are and how the Word2Vec algorithm works. I have written a much more detailed paper on the same project which can be found here. In this paper, I explain the details of what word embeddings are as well as how the Word2Vec Algorithm works. I also detail sentiment analysis via Naive Bayes. In this post, I will just...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4060</td>\n",
       "      <td>Kyle Dorman</td>\n",
       "      <td>19</td>\n",
       "      <td>https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Building a Bayesian deep learning classifier | by Kyle Dorman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 17, 2017\\nIn this blog post, I am going to teach you how to train a Bayesian deep learning classifier using Keras and tensorflow. Before diving into the specific training example, I will cover a few important high level concepts:\\nI will then cover two techniques for including uncertainty in a deep learning model and will go over a specific example using Keras to train fully connected layers over a frozen ResNet50 encoder on the cifar10 dataset. With this example, I will also discuss methods of exploring the uncertainty predictions of a Bayesian deep learning classifier and provide suggestions for improving the model in the future.\\nThis post is based on material from two blog posts (here and here) and a white paper on Bayesian deep learning from the Universit...</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>4061</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>20</td>\n",
       "      <td>https://medium.com/free-code-camp/every-single-machine-learning-course-on-the-internet-ranked-by-your-reviews-3c4a7b8026c0?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Every single Machine Learning course on the internet, ranked by your reviews | by David Venturi | We’ve moved to freeCodeCamp.org/news | Medium</td>\n",
       "      <td>We’ve moved to freeCodeCamp.org/news\\nMay 3, 2017\\nA year and a half ago, I dropped out of one of the best computer science programs in Canada. I started creating my own data science master’s program using online resources. I realized that I could learn everything I needed through edX, Coursera, and Udacity instead. And I could learn it faster, more efficiently, and for a fraction of the cost.\\nI’m almost finished now. I’ve taken many data science-related courses and audited portions of many more. I know the options out there, and what skills are needed for learners preparing for a data analyst or data scientist role. So I started creating a review-driven guide that recommends the best courses for each subject within data science.\\nFor the first guide in the series, I recommended a few...</td>\n",
       "      <td>6719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>4062</td>\n",
       "      <td>Nick Kasten</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/codait/art-ai-the-logic-behind-deep-learning-style-transfer-1f59f51441d1?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Art &amp; AI: The Logic Behind Deep Learning ‘Style Transfer’ | by Nick Kasten | Center for Open Source Data and AI Technologies | Medium</td>\n",
       "      <td>Center for Open Source Data and AI Technologies\\nFeb 21, 2019\\nWhen humans and machines collaborate, we can produce things neither would create on their own. The intersection of art and AI is an area that I find really exciting, but with all the business impact AI can have, I personally feel it doesn’t always get enough attention. In this spirit, I recently set out on a personal quest to learn more about PyTorch, the machine learning library that’s been creating a lot of buzz since its 1.0 release late last year, and I was pleasantly surprised by what I found.\\nFor me, PyTorch turned out to be more than just an interesting alternative to TensorFlow, with dynamic graphs and an imperative coding style. One of the examples from their official docs inspired me to track down some academic p...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4063</td>\n",
       "      <td>Jiahao Weng</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/how-to-perform-abstractive-summarization-with-pegasus-3dd74e48bafb?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How to Perform Abstractive Summarization with PEGASUS | by Jiahao Weng | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 4, 2021\\nNote: For those of you who prefer watching videos, please feel free to play above video on the same content.\\nGiven long documents to read, our natural preference is to not read, or at least, to scan just the main points. So having a summary would always be great to save us time ⏳ and brain processing power.\\nHowever, auto-summarization used to be an impossible task. Specifically, abstractive summarization is very challenging. Differing from extractive summarization (which extracts important sentences from a document and combines them to form a “summary”), abstractive summarization involves paraphrasing words and hence, is more difficult but can potentially give a more coherent and polished summary.\\nIt was not until the development of techniques like...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>4064</td>\n",
       "      <td>Wenchen's ai fantasy</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@wenchen-li/text-summarization-applications-ed319f0bb13c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>text summarization: applications. this article is mainly a summarization... | by Wenchen's ai fantasy | Medium</td>\n",
       "      <td>May 25, 2017\\nthis article is mainly a summarization of Yasemin Altun’s presentation in May 2014 on how google applies text summarization.\\ntext summarization is highly related to google knowledge graph project:\\nentities description within red circle use text summarization from wiki to give a one sentence description of the entity.\\n7 \\n7 \\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n83 Followers\\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4065</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313?source=tag_archive---------5-----------------------</td>\n",
       "      <td>🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning | by Thomas Wolf | HuggingFace | Medium</td>\n",
       "      <td>HuggingFace\\nMay 9, 2019\\nA few years ago, creating a chatbot -as limited as they were back then- could take months 🗓, from designing the rules to actually writing thousands of answers to cover some of the conversation topics.\\nWith the recent progress in deep-learning for NLP, we can now get rid of this petty work and build much more powerful conversational AI 🌟 in just a matter of hours 🍃 as you will see in this tutorial.\\nWe’ve set up a demo running the pretrained model we’ll build together in this tutorial at convai.huggingface.co. Be sure to check it out! 🎮\\nHere is what we will learn and play with today:\\nTogether with this post, we released a clean and commented code base with a pretrained model! Check the Github repo here ✈️\\nThe story of this post began a few months ago in Mon...</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4066</td>\n",
       "      <td>Neelabh Pant</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/cube-dev/time-series-prediction-using-recurrent-neural-networks-lstms-807fa6ca7f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs) | by Neelabh Pant | Cube Dev | Medium</td>\n",
       "      <td>Cube Dev\\nSep 7, 2017\\nThe Statsbot team has already published the article about using time series analysis for anomaly detection. Today, we’d like to discuss time series prediction with a long short-term memory model (LSTMs). We asked a data scientist, Neelabh Pant, to tell you about his experience of forecasting exchange rates using recurrent neural networks.\\nAs an Indian guy living in the US, I have a constant flow of money from home to me and vice versa. If the USD is stronger in the market, then the Indian rupee (INR) goes down, hence, a person from India buys a dollar for more rupees. If the dollar is weaker, you spend less rupees to buy the same dollar.\\nIf one can predict how much a dollar will cost tomorrow, then this can guide one’s decision making and can be very important ...</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4067</td>\n",
       "      <td>TokenGo Platform_RU</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------0-----------------------</td>\n",
       "      <td>ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium</td>\n",
       "      <td>May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4068</td>\n",
       "      <td>Chandra Churh Chatterjee</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>4069</td>\n",
       "      <td>Arun Kumar</td>\n",
       "      <td>16</td>\n",
       "      <td>https://towardsdatascience.com/semantic-image-segmentation-using-fully-convolutional-networks-bf0189fa3eb8?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Semantic Image Segmentation using Fully Convolutional Networks | by Arun Kumar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 10, 2020\\nHumans have the innate ability to identify the objects that they see in the world around them. The visual cortex present in our brain can distinguish between a cat and a dog effortlessly in almost no time. This is true not only with cats and dogs but with almost all the objects that we see. But a computer is not as smart as a human brain to be able to this on its own. Over the past few decades, Deep Learning researchers have tried to bridge this gap between human brain and computer through a special type of artificial neural networks called Convolutional Neural Networks(CNNs).\\nAfter a lot of research to study mammalian brains, researchers found that specific parts of the brain get activated to specific type of stimulus. For example, some parts in th...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4070</td>\n",
       "      <td>Ceshine Lee</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/the-artificial-impostor/build-a-summarization-system-in-minutes-5f10c141bfe6?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Building a Summarization System in Minutes | by Ceshine Lee | Veritable | Medium</td>\n",
       "      <td>Veritable\\nNov 1, 2018\\n(This is sort of a sequel or an update to “Building a Translation System in Minutes” published a year ago. This time we use a publicly available dataset, a different NLP task, and some task-specific evaluation metrics)\\nSummarization is the task of producing a shorter version of one or several documents that preserves most of the input’s meaning. [1]\\nThe text summarization task is mostly solved using variants of the seq2seq structure [2] these days. The seq2seq structure is much more complicated than the usual RNN models, and that makes implementing the model from scratch a rather daunting task. Luckily, OpenNMT project [3] provides ready-to-use implementations of seq2seq models that are close to state-of-the-art. We can use it as a starting point.\\nIn this pos...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>4071</td>\n",
       "      <td>Jack Morris</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/what-are-adversarial-examples-in-nlp-f928c574478e?source=tag_archive---------6-----------------------</td>\n",
       "      <td>What are adversarial examples in NLP? | by Jack Morris | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 28, 2020\\nThis article talks about the concept of adversarial examples as applied to NLP (natural language processing). The terminology can be confusing at times, so we’ll begin with an overview of the language used to talk about adversarial examples and adversarial attacks. Then, we’ll talk about TextAttack, our open-source Python library for adversarial examples, data augmentation, and adversarial training in NLP that’s changing the way people research the robustness of NLP models. We’ll conclude with some thoughts on the future of this area of research.\\nAn adversarial example is an input designed to fool a machine learning model [1]. An adversarial example crafted as a change to a benign input is known as an adversarial perturbation. ‘Adversarial perturbat...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4072</td>\n",
       "      <td>William Ryan</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@williamr/reducing-memory-usage-in-r-especially-for-regressions-8ed8070ae4d8?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Reducing Memory Usage in R (especially for regressions) | by William Ryan | Medium</td>\n",
       "      <td>Jun 28, 2016\\nR uses a ton of memory. Here are ways to make it use a little less. Definitely not an expert, this is largely a resource/reference for myself, but thought it might be useful for others as well.\\nThe best introduction to how R uses memory is likely this guide, by Hadley Wickham.\\nGarbage collector: gc()\\nMy impression is that this function used to be more useful. R uses it to release memory it isn’t using, but will usually run it automatically. So you shouldn’t have to call it explicitly. However, if you want to see when this is happening, use gcinfo(TRUE) — you probably won’t want to leave this on all the time, it will get annoying. But, it can be very useful for finding the peak memory used by a function.\\nObject size: object.size()\\nTo find the size of a given R object,...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>4073</td>\n",
       "      <td>Satyam Kumar</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/6-applications-of-auto-encoders-every-data-scientist-should-know-dc703cbc892b?source=tag_archive---------5-----------------------</td>\n",
       "      <td>7 Applications of Auto-Encoders every Data Scientist should know | by Satyam Kumar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 20, 2021\\nAuto-Encoders are a popular type of unsupervised artificial neural network that takes un-labeled data and learns efficient codings about the structure of the data that can be used for another context. Auto-Encoders approximates the function that maps the data from full input space to lower dimension coordinates and further approximates to the same dimension of input space with minimum loss.\\nFor classification or regression tasks, auto-encoders can be used to extract features from the raw data to improve the robustness of the model. There are various other applications of an Auto-Encoder network, that can be used for some other context. We will 7 of such applications of auto-encoder in this article:\\nBefore diving into the applications of AutoEncoder...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>4074</td>\n",
       "      <td>Park Chansung</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>4075</td>\n",
       "      <td>Shiva Verma</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Understanding 1D and 3D Convolution Neural Network | Keras | by Shiva Verma | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 20, 2019\\nWhen we say Convolution Neural Network (CNN), generally we refer to a 2 dimensional CNN which is used for image classification. But there are two other types of Convolution Neural Networks used in the real world, which are 1 dimensional and 3-dimensional CNNs. In this guide, we are going to cover 1D and 3D CNNs and their applications in the real world. I am assuming you are already familiar with the concept of Convolutions Networks in general.\\nThis is the standard Convolution Neural Network which was first introduced in Lenet-5 architecture. Conv2D is generally used on Image data. It is called 2 dimensional CNN because the kernel slides along 2 dimensions on the data as shown in the following image.\\nThe whole advantage of using CNN is that it can e...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4076</td>\n",
       "      <td>Anuj shah (Exploring Neurons)</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/analytics-vidhya/when-neural-networks-saw-the-first-image-of-black-hole-3205e28b6578?source=tag_archive---------7-----------------------</td>\n",
       "      <td>When Neural Networks saw the first image of Black Hole. | by Anuj shah (Exploring Neurons) | Medium</td>\n",
       "      <td>Apr 19, 2019\\nOn April 10th, scientists and engineers from Event Horizon Telescope team achieved a remarkable breakthrough in quest to understand the cosmos by unveiling the first image of black hole. This furthers strengthens Einstein theory of general relativity — “ massive objects cause a distortion in space-time, which is felt as gravity”.\\nWell I am not a physicist or astronomer to comprehend and explain in detail about this but like me there are millions and millions of people who despite being in different fields are fascinated by cosmos and specially black hole. The first image of black hole has send wave of excitement all over the world. I am a Deep learning engineer who mainly works with convolution neural network and I wanted to see what AI algorithms thinks about the black ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4077</td>\n",
       "      <td>Ethan Siegel</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/starts-with-a-bang/weekend-diversion-the-ultimate-superhero-cake-129a990c35c?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Weekend Diversion: The Ultimate Superhero Cake | by Ethan Siegel | Starts With A Bang! | Medium</td>\n",
       "      <td>Starts With A Bang!\\nAug 30, 2015\\nThanks to 3D printing, creativity and a lot of effort, this DIY Optimus Prime cake is unlike any other.\\n“When he came home, I could see a change. He was quieter and he was a man and a hero to me. I watched him and listened to him. I’d never had an opportunity to do a superhero, and when that came, [that voice] just came right out of me and I sounded like Optimus.” -Peter Cullen, on his brother\\nBeing a hero is something we all dream about in our own way. On our birthdays, everyone deserves to live out that fantasy, if only for a day. Have a listen to Tracy Chapman’s reflective and provocative song, Change,\\nwhile you consider the ultimate in “changing” superheros: Optimus Prime.\\nUnlike the flashy Decepticons, who transformed from robots into fighter...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>4078</td>\n",
       "      <td>Prakash Pandey</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/deep-generative-models-25ab2821afd3?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Deep Generative Models | by Prakash Pandey | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 31, 2018\\nA Generative Model is a powerful way of learning any kind of data distribution using unsupervised learning and it has achieved tremendous success in just few years. All types of generative models aim at learning the true data distribution of the training set so as to generate new data points with some variations. But it is not always possible to learn the exact distribution of our data either implicitly or explicitly and so we try to model a distribution which is as similar as possible to the true data distribution. For this, we can leverage the power of neural networks to learn a function which can approximate the model distribution to the true distribution.\\nTwo of the most commonly used and efficient approaches are Variational Autoencoders (VAE) a...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4079</td>\n",
       "      <td>Hubert Baniecki</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/responsibleml/adversarial-attacks-on-explainable-ai-f65d41e83c5f?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Adversarial attacks on Explainable AI | by Hubert Baniecki | ResponsibleML</td>\n",
       "      <td>ResponsibleML\\nJan 23, 2021\\nAre explainability methods black-box themselves?\\nThere are various adversarial attacks on machine learning models; hence, ways of defending, e.g. by using Explainable AI methods. Nowadays, attacks on model explanations come to light, so does the defense to such adversary. Here, we introduce fundamental concepts related to the domain. A further reference list is available at https://github.com/hbaniecki/adversarial-explainable-ai.\\nWhen considering an explanation as a function of model and data, there is a possibility to change one of these variables to achieve a different result.\\nThe first concept is to manipulate model explanations via data change. Dombrowski et al. [2019] showcase that perturbed images produce arbitrarily made visual explanations (e.g. ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>4080</td>\n",
       "      <td>Charles Kapelke</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/cltc-bulletin/adversarial-machine-learning-43b6de6aafdb?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Adversarial Machine Learning. A Brief Introduction for Non-Technical... | by Charles Kapelke | CLTC Bulletin | Medium</td>\n",
       "      <td>CLTC Bulletin\\nDec 3, 2019\\nA Brief Introduction for Non-Technical Audiences\\nRecent years have seen a rapid increase in the use of machine learning, through which computers can be programmed to identify patterns in information and make increasingly accurate predictions over time. Machine learning is a key enabling technology behind artificial intelligence (AI), and is used for such valuable applications as email spam filters and malware detection, as well as more complex technologies like speech recognition, facial recognition, robotics, and self-driving cars.\\nWhile machine learning models have many potential benefits, they may be vulnerable to manipulation. Cybersecurity researchers refer to this risk as “adversarial machine learning,” as AI systems can be deceived (by attackers or ...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4081</td>\n",
       "      <td>Alfi Salim</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/bisa-ai/intersection-over-union-a8d1532899b3?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Intersection Over Union. Pada masalah deteksi objek, output yang... | by Alfi Salim | BISA.AI | Medium</td>\n",
       "      <td>BISA.AI\\nMar 25, 2020\\nPada masalah deteksi objek, output yang dihasilkan berupa bounding box (kotak pembatas) hasil prediksi sistem terhadap objek yang telah ditentukan. Bounding box ini merepresentasikan posisi objek dalam sebuah gambar. Untuk mengevaluasi model deteksi objek yang telah kita latih terdapat beberapa cara, salah satu caranya adalah dengan menggunakan metode Intersection Over Union (IOU). IOU memanfaatkan bounding box yang terdapat pada gambar.\\nIntersection Over Union (IOU) adalah nilai berdasarkan statistik kesamaan dan keragaman set sampel yang tujuannya untuk mengevaluasi area tumpang tindih (area yang beririsan) antara dua bounding box, yaitu bounding box hasil prediksi dan bounding box ground truth (kebenaran). Jadi, syarat untuk menerapkan IOU adalah mempunyai ke...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>4082</td>\n",
       "      <td>Marie Imokoyende</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/variational-autoencoder-in-finance-53ee5eb9ed98?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Variational Autoencoder In Finance | by Marie Imokoyende | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 15, 2019\\nThis article explores the use of a variational autoencoder to reduce the dimensions of financial time series with Keras and Python. We will further detect similarities between financial instruments in different markets and will use the results obtained to construct a custom index.\\nDisclaimer: The research presented in this article comes from our Winter 2019 Term Project for the Deep Learning course at the University of Toronto School of Continuing Studies. It was done in collaboration with Humberto Ribeiro de Souza. The concepts and ideas are our own. We are in no way representing our current or previous employers.\\nIn this section, we will discuss:\\nCreating The Geometric Moving Average Dataset\\nIn order to compare time series of various price rang...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>4083</td>\n",
       "      <td>Stefan Kojouharov</td>\n",
       "      <td>8</td>\n",
       "      <td>https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning &amp; Big Data | by Stefan Kojouharov | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nJul 9, 2017\\nOver the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.\\nThis is the most complete list and the Big-O is at the very end, enjoy...\\n&gt;&gt;&gt; Update: We have recently redesigned these cheat sheets into a Super High Definition PDF. Check them out below:\\nbecominghuman.ai\\nchatbotslife.com\\naijobsboard.com\\nThis machine learning cheat sheet will help you find the right estimator for the job which is the most difficult part. The flowchart will help you che...</td>\n",
       "      <td>84087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>4084</td>\n",
       "      <td>Sambasivarao. K</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Region of Interest Pooling. A Technique which allowed a new... | by Sambasivarao. K | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 22, 2019\\nThe major hurdle for going from image classification to object detection is fixed size input requirement to the network because of existing fully connected layers. In object detection, each proposal will be of a different shape. So there is a need for converting all the proposals to fixed shape as required by fully connected layers. ROI Pooling is exactly doing this.\\nRegion of Interest (ROI) pooling is used for utilising single feature map for all the proposals generated by RPN in a single pass. ROI pooling solves the problem of fixed image size requirement for object detection network.\\nROI pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>4085</td>\n",
       "      <td>Jimmi Dyson</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.fabric8.io/clustering-on-kubernetes-openshift3-using-dns-d786bfd681d9?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Clustering on Kubernetes &amp; OpenShift3 using DNS | by Jimmi Dyson | fabric8 io</td>\n",
       "      <td>fabric8 io\\nApr 17, 2015\\nOne of the big promises of Kubernetes &amp; OpenShift is really easy management of your containerised applications. For standalone or load-balanced stateless applications, Kubernetes works brilliantly, but one thing that I had a bit of trouble figuring out was how do perform cluster discovery for my applications? Say one of my applications needs to know about at least one other node (seed node) that it should join a cluster with.\\nThere is an example in the Kubernetes repo for Cassandra that requests existing service endpoints from the Kubernetes API server &amp; use those as the seed servers. You can see the code for it here. That works great for a cluster that allows unauthenticated/unauthorized access to the API server, but hopefully most people are going to lock d...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>4086</td>\n",
       "      <td>DataAnalysis For Beginner</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@univprofblog1/support-vector-machine-matlab-r-and-python-codes-856a342fc35d?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Support Vector Machine: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium</td>\n",
       "      <td>Aug 17, 2016\\nI release MATLAB, R and Python codes of Support Vector Machine (SVM). They are very easy to use. You prepare data set, and just run the code! Then, SVM and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/XdZSo Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/OyXVZ Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/AtOvT Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofb...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>4087</td>\n",
       "      <td>Viet Hoang Tran Duong</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Intro to reinforcement learning: temporal difference learning, SARSA vs. Q-learning | by Viet Hoang Tran Duong | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 23, 2021\\nReinforcement learning (RL) is surely a rising field, with the huge influence from the performance of AlphaZero (the best chess engine as of now). RL is a subfield of machine learning that teaches agents to perform in an environment to maximize rewards overtime.\\nAmong RL’s model-free methods is temporal difference (TD) learning, with SARSA and Q-learning (QL) being two of the most used algorithms. I chose to explore SARSA and QL to highlight a subtle difference between on-policy learning and off-learning, which we will discuss later in the post.\\nThis post assumes you have basic knowledge of the agent, environment, action, and rewards within RL's scope. A brief introduction can be found here.\\nThe outline of this post include:\\nWe will compare these...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>4088</td>\n",
       "      <td>Chris Fotache</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/object-detection-and-tracking-in-pytorch-b3cf1a696a98?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Object detection and tracking in PyTorch | by Chris Fotache | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 10, 2018\\nIn my previous story, I went over how to train an image classifier in PyTorch, with your own images, and then use it for image recognition. Now I’ll show you how to use a pre-trained classifier to detect multiple objects in an image, and later track them across a video.\\nWhat’s the difference between image classification (recognition) and object detection? In classification, you identify what’s the main object in the image and the entire image is classified by a single class. In detection, multiple objects are identified in the image, classified, and a location is also determined (as a bounding box).\\nThere are several algorithms for object detection, with YOLO and SSD among the most popular. For this story, I’ll use YOLOv3. I won’t get into the tech...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4089</td>\n",
       "      <td>Thomas Smith</td>\n",
       "      <td>9</td>\n",
       "      <td>https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------0-----------------------</td>\n",
       "      <td>I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero</td>\n",
       "      <td>OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder &amp; CEO of Gado Images. I write, speak &amp; consult about tech, food, privacy, AI &amp; photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>4090</td>\n",
       "      <td>Robin Vinod</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/a-detailed-explanation-of-the-attention-u-net-b371a5590831?source=tag_archive---------4-----------------------</td>\n",
       "      <td>A detailed explanation of the Attention U-Net | by Robin Vinod | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 1, 2020\\nIn this story, I explain the Attention U-Net from Attention U-Net:Learning Where to Look for the Pancreas written by Oktay et. al. The paper was written in 2018 and proposed a novel attention gate (AG) mechanism that allows the U-Net to focus on target structures of varying size and shape.\\nAttention, in the context of image segmentation, is a way to highlight only the relevant activations during training. This reduces the computational resources wasted on irrelevant activations, providing the network with better generalisation power. Essentially, the network can pay “attention” to certain parts of the image.\\na. Hard Attention\\nAttention comes in two forms, hard and soft. Hard attention works on the basis of highlighting relevant regions by cropping ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4091</td>\n",
       "      <td>Ravish Chawla</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/ml2vec/overview-of-conditional-random-fields-68a2a20fa541?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Overview of Conditional Random Fields | by Ravish Chawla | ML 2 Vec | Medium</td>\n",
       "      <td>ML 2 Vec\\nAug 7, 2017\\nConditional Random Fields are a discriminative model, used for predicting sequences. They use contextual information from previous labels, thus increasing the amount of information the model has to make a good prediction. In this post, I will go over some topics that will introduce CRFs. I will go over:\\nMachine Learning models have two common categorizations, Generative and Discriminative. Conditional Random Fields are a type of Discriminative classifier, and as such, they model the decision boundary between the different classes. Generative models, on the other hand, model how the data was generated, which after having learnt, can be used to make classifications. As a simple example, Naive Bayes, a very simple and popular probabilistic classifier, is a Generati...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4092</td>\n",
       "      <td>Frank Bonsal III</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/bonsal-capital/the-charm-of-a-gritty-city-82bc645a4313?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The Charm of a Gritty City. Baltimore as Entrepreneurship Hub | by Frank Bonsal III | Bonsal Capital | Medium</td>\n",
       "      <td>Bonsal Capital\\nJan 25, 2014\\nSome people ask me Why Baltimore? Couldn’t you do what you do from anywhere in the U.S.? Isn’t this the place where the acclaimed HBO series The Wire was filmed? Has Baltimore ever been on a tech entrepreneur-friendly list? Aren’t there more voluminous entrepreneurial hubs? While the concise response is pegged to an authentic and ever-congealing entrepreneurial ecosystem more focused on the act of doing (the scoreboard) than a Top Ten List, the more interesting answer is found in an array of professional and personal attributes. Let me paint a picture as to why Baltimore is a great city to build a business, a career, a life.\\nBaltimore has a nearly three hundred year history of resilience and determination. What many do not grasp is that Baltimore is a top...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4093</td>\n",
       "      <td>Ekin Tiu</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Understanding Latent Space in Machine Learning | by Ekin Tiu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 4, 2020\\nIf I have to describe latent space in one sentence, it simply means a representation of compressed data.\\nImagine a large dataset of handwritten digits (0–9) like the one shown above. Handwritten images of the same number (i.e. images that are 3’s) are the most similar to each other compared to other images of different numbers (i.e. 3s vs. 7s). But can we train an algorithm to recognize these similarities? How?\\nIf you have trained a model to classify digits, then you have also trained the model to learn the ‘structural similarities’ between images. In fact, this is how the model is able to classify digits in the first place- by learning the features of each digit.\\nIf it seems that this process is ‘hidden’ from you, it’s because it is. Latent, by de...</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4094</td>\n",
       "      <td>Ryan Burke</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/bitcoin-bonanza-2cb208026bbd?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Bitcoin Bonanza!. Comparing the efficacy of GRU, LSTM... | by Ryan Burke | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 25, 2021\\nI have been following crypto prices for several years now. I am fascinated with the evolution of the blockchain and its implications. I’ve chuckled more than once at the idea of digital currency. Not that it’s new, but I was born in the 80’s when we had to fill out a paper and speak with a human if we wanted to withdraw actual paper money...Remember paper money?\\nIn any case, today I want to share one of my recent projects with you. I will be comparing three models to determine their efficacy at predicting the price of Bitcoin, the King of Crypto. For this project, I used gated recurrent units (GRU), long short term memory units (LSTM), and bidirectional LSTM units (BiLSTM). First, let’s take a quick dive into the workings of these mysterious predict...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4095</td>\n",
       "      <td>Matt Schlicht</td>\n",
       "      <td>11</td>\n",
       "      <td>https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca?source=tag_archive---------7-----------------------</td>\n",
       "      <td>The Complete Beginner’s Guide To Chatbots | by Matt Schlicht | Chatbots Magazine</td>\n",
       "      <td>Chatbots Magazine\\nApr 20, 2016\\nWhat are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?\\nThese are the questions we’re going to answer for you right now.\\nReady? Let’s do this.\\n(Do you work in ecommerce? Stop reading and click here, we made something for you.)\\n(p.s. here is where I believe the future of bots is headed, you will probably disagree with me at first.)\\n(p.p.s. My newest guide about conversational commerce is up, I think you’ll find it super interesting.)\\n“~90% of our time on mobile is spent on email and messaging platforms. I would love to back teams that build stuff for places where the consumers hang out!” — Niko Bonatsos, Managing Director at General Catalyst\\nA chatbot is a s...</td>\n",
       "      <td>8763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4096</td>\n",
       "      <td>Manish Nayak</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011?source=tag_archive---------9-----------------------</td>\n",
       "      <td>An Introduction To Conditional GANs (CGANs) | by Manish Nayak | DataDrivenInvestor</td>\n",
       "      <td>DataDrivenInvestor\\nMay 9, 2019\\nConditional GANs (CGANs) are an extension of the GANs model. You can read about a variant of GANs called DCGANs in my previous post here. CGANs are allowed to generate images that have certain conditions or attributes.\\nLike DCGANs, Conditional GANs also has two components.\\nwww.datadriveninvestor.com\\nConditional GANs (CGANs): The Generator and Discriminator both receive some additional conditioning input information. This could be the class of the current image or some other property.\\nFor example, if we train a DCGANs to generate new MNIST images, There is no control over which specific digits will be produced by the Generator. There is no mechanism for how to request a particular digit from the Generator. This problem can be addressed by a variation...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>4097</td>\n",
       "      <td>Prem Prakash</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Perturbation Theory in Deep Neural Network (DNN) Training | by Prem Prakash | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 23, 2020\\nVanishing Gradient, Saddle Point, Adversarial Training\\nPrerequisite- this post assumes the reader has an introductory-level understanding of neural network architectures, and have trained some form of deep networks, during which might have faced some issues related to training or robustness of a model.\\nA small perturbation or nudge in various parameters/components associated with training such as gradients, weights, inputs etc. can affect DNN training in overcoming some of the issues one might bump into, for example, vanishing gradient problem, saddle point trap, or creating a robust model to avoid malicious attacks through adversarial training etc.\\nTypically, perturbation theory is the study of a small change in a system which can be as a result ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>4098</td>\n",
       "      <td>Mohantysandip</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289?source=tag_archive---------8-----------------------</td>\n",
       "      <td>A Step by Step approach to Solve DBSCAN Algorithms by tuning its hyper parameters | by Mohantysandip | Medium</td>\n",
       "      <td>Mar 12, 2020\\nDBSCAN is a clustering method that is used in machine learning to separate clusters of high density from clusters of low density region. Its a very efficient clustering algorithm as it used to segregate the data points with high density observations vs data points of low density observations in form of various clusters.It can sort the data into various shapes of clusters as well. Major challenge of using DBSCAN algorithm is to find right set hyper parameters(eps and min_samples values) to fit in to the algorithm for getting accurate result.\\nLet’s look at a Spatial data of two dimensional coordinates (x,y) using we need to find out various possible star coagulation or dense clusters from this data.\\nRead the input data using Pandas dataframe.\\nAn initial plotting of the d...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>4099</td>\n",
       "      <td>Mohammed AL-Ma'amari</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Deep Neural Networks for Regression Problems | by Mohammed AL-Ma'amari | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 29, 2018\\nNeural networks are well known for classification problems, for example, they are used in handwritten digits classification, but the question is will it be fruitful if we used them for regression problems?\\nIn this article I will use a deep neural network to predict house pricing using a dataset from Kaggle .\\nYou can download the dataset from Here\\nI highly recommend you to try running the code using my notebook on Google colab [Here]\\n1- Process the dataset2- Make the deep neural network3- Train the DNN4- Test the DNN5- Compare the result from the DNN to another ML algorithm\\nFirst of all, we will import the needed dependencies :\\nWe will not go deep in processing the dataset, all we want to do is getting the dataset ready to be fed into our models...</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4100</td>\n",
       "      <td>Vishal Maini</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Machine Learning for Humans, Part 2.1: Supervised Learning | by Vishal Maini | Machine Learning for Humans | Medium</td>\n",
       "      <td>Machine Learning for Humans\\nAug 19, 2017\\nHow much money will we make by spending more dollars on digital advertising? Will this loan applicant pay back the loan or not? What’s going to happen to the stock market tomorrow?\\nIn supervised learning problems, we start with a data set containing training examples with associated correct labels. For example, when learning to classify handwritten digits, a supervised learning algorithm takes thousands of pictures of handwritten digits along with labels containing the correct number each image represents. The algorithm will then learn the relationship between the images and their associated numbers, and apply that learned relationship to classify completely new images (without labels) that the machine hasn’t seen before. This is how you’re a...</td>\n",
       "      <td>8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4101</td>\n",
       "      <td>Nikhil Parmar</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@nikhilparmar9/simple-sgd-implementation-in-python-for-linear-regression-on-boston-housing-data-f63fcaaecfb1?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Simple SGD implementation in Python for Linear Regression on Boston Housing Data | by Nikhil Parmar | Medium</td>\n",
       "      <td>Dec 11, 2019\\nHello Folks, in this article we will build our own Stochastic Gradient Descent (SGD) from scratch in Python and then we will use it for Linear Regression on Boston Housing Dataset. Just after a short recap of SGD, we will start building our own custom SGD.\\nTo keep the concept simple and easy to understand, we will touch the math calculations in an extremely simple step by step manner with its Python Code.\\nThen in the end we will combine all the code to solve the Linear Regression on Boston Housing Dataset.\\nWikipedia says: “ Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties. ”\\nLet’s begin, the Linear Regression optimization problem is to optimize or MINimize the SQUARED ERROR as shown below.\\nBut...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>4102</td>\n",
       "      <td>Akanksha Rawat</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/implementing-binary-logistic-regression-in-r-7d802a9d98fe?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Binary Logistic Regression. An overview and implementation in R | by Akanksha Rawat | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 31, 2017\\nHave you ever come across a situation where you want to predict a binary outcome like:\\nA very simple Machine Learning algorithm which will come to your rescue is Logistic Regression.\\nLogistic Regression is a classification algorithm which is used when we want to predict a categorical variable (Yes/No, Pass/Fail) based on a set of independent variable(s).\\nIn the Logistic Regression model, the log of odds of the dependent variable is modeled as a linear combination of the independent variables.\\nLet’s get more clarity on Binary Logistic Regression using a practical example in R.\\nConsider a situation where you are interested in classifying an individual as diabetic or non-diabetic based on features like glucose concentration, blood pressure, age etc...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4103</td>\n",
       "      <td>Hemant Ranvir</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/@hemantranvir/spam-detection-using-rnn-simplernn-lstm-with-step-by-step-explanation-530367608071?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Intuitive guide to word embedding, RNN (SimpleRNN, LSTM) with step by step implementation in keras for spam detection | by Hemant Ranvir | Medium</td>\n",
       "      <td>Jun 20, 2019\\nThis tutorial will guide you through the implementation and intuitive grasp on what is actually happening underneath the RNN networks.\\nThere has been extensive writing on this subject but I could not find a single source where the complete walk through of word...\\n68 \\n68 \\n2\\nSoftware Design and Product Management\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n14 Followers\\nSoftware Design and Product Management\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>4104</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/@jonathan-hui/yolov4-c9901eaa8e61?source=tag_archive---------3-----------------------</td>\n",
       "      <td>YOLOv4. While object detection matures in the... | by Jonathan Hui | Medium</td>\n",
       "      <td>May 4, 2020\\nEven object detection starts maturing in the last few years, the competition remains fierce. As shown below, YOLOv4 claims to have state-of-the-art accuracy while maintains a high processing frame rate. It achieves an accuracy of 43.5% AP (65.7% AP50) for the MS COCO with an approximately 65 FPS inference speed on Tesla V100. In object detection, high accuracy is not the only holy grail anymore. We want the model to run smoothly in the edge devices. How to process input video in real-time with low-cost hardware becomes important also.\\nThe fun part of reading the YOLOv4 development is what new technologies have been evaluated, modified, and integrated into YOLOv4. And it also makes changes to make the detector more suitable for training on a single GPU.\\nImprovements can b...</td>\n",
       "      <td>2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>4105</td>\n",
       "      <td>Geneonline-基因線上</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@geneonline/%E7%99%8C%E7%B4%B0%E8%83%9E%E7%94%9F%E9%95%B7%E7%9A%84%E9%96%8B%E9%97%9C-%E5%9F%BA%E5%9B%A0%E5%95%9F%E5%8B%95%E5%AD%90-promoter-ed16fab2e013?source=tag_archive---------0-----------------------</td>\n",
       "      <td>癌細胞生長的開關:基因啟動子(Promoter)?. 啟動子 (Promoter)... | by Geneonline-基因線上 | Medium</td>\n",
       "      <td>May 19, 2016\\n啟動子 (Promoter) 在人體遺傳基因扮演著重要角色,宛如人體一個開關,可以決定基因的活動,並控制細胞開始生產人體所需的蛋白質。當啟動子發生突變時,將可能導致基因表現的調節障礙。近期國際學者在癌細胞基因組的研究中發現,基因啟動子中的 DNA 突變數量增加,是因結合 DNA 控制基因表現的某些蛋白質,阻止人體的一個細胞修復系統去修復損傷的 DNA。啟動子突變的多寡與 DNA 修復系統相互作用,引發癌細胞生長有了重要的發現。\\n皮膚癌啟動子的突變密度特別高\\n2016 年 4 月發表在《Nature》的研究指出,科學家們分析來自 14 種癌症類型、1,161 個腫瘤的 2000 多萬 DNA 突變。他們發現在許多癌症類型,尤其是皮膚癌中,基因啟動子的基因組區域內突變數量特別高。研究進一步探究發現,人體控制基因表達的一些蛋白質,降低人體細胞修復系統的功能發揮,導致無法正常修復受損的 DNA,這個系統被稱為核苷酸切除修復 (NER, Nucleotide Excision-Repair)。NER 是唯一能修復紫外線造成的 DNA 損傷的系統,不僅如此,它還能處理抽煙誘導的遺傳損傷。\\n(上圖為DNA修復示意圖)\\n延伸閱讀:腫瘤的轉移與「偽轉移」 基因定序分析癌細胞親緣\\nDNA 修復如何參與癌細胞生長\\n西班牙研究團隊人員利用來自人類黑色素瘤樣本的全基因組序列分析調控區域的突變,並進一步分析核苷酸切除修復 (NER) 活性位點。結果發現,NER 功能的下降可導致一些轉錄因子位點的突變率增高。除此,在肺癌樣本中,他們也證實一些轉錄因子結合位點的突變率增高,尤其是與抽煙相關的突變。另一研究中,研究人員則分析多個癌症類型調控元件的突變。結果發現預測轉錄因子將結合的位置,即調控區域的核心,比側翼序列的突變率高達 5 倍。\\n總結,這項研究提示,在...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4106</td>\n",
       "      <td>Hemanth Pedamallu</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/rnn-vs-gru-vs-lstm-863b0b7b1573?source=tag_archive---------4-----------------------</td>\n",
       "      <td>RNN vs GRU vs LSTM. In this post, I will make you go... | by Hemanth Pedamallu | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nNov 14, 2020\\nIn this post, I will make you go through the theory of RNN, GRU and LSTM first and then I will show you how to implement and use them with code.\\nThere are already many posts on these topics out there. But in this post, I wanted to provide a much better understanding and comparison with help of code.\\nLet’s start with RNN!\\nRecurrent Neural Networks (RNN) are designed to work with sequential data. Sequential data(can be time-series) can be in form of text, audio, video etc.\\nRNN uses the previous information in the sequence to produce the current output. To understand this better I’m taking an example sentence.\\n“My class is the best class.”\\nAt the time(T0 ), the first step is to feed the word “My” into the network. the RNN produces an output.\\nAt the t...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>4107</td>\n",
       "      <td>Maximus Mutschler</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/fancy-and-custom-neural-style-transfer-filters-for-video-conferencing-7eba2be1b6d5?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Fancy and custom Neural Style Transfer filters for video conferencing | by Maximus Mutschler | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 27, 2021\\nMy open-source GitHub script provides AI-based filters which apply a rather new technology called Artistic Neural Style Transfer to the input stream of your physical webcam device. In contrast to traditional filters, these AI-based filters are feature-aware. Depending on what kind of features are apparent in the video, the AI adapts the output. In addition, these kinds of filters can be learned from any real-world image. Since the provided filters are directly applied on the webcam video stream, they can be used in all types of video conferencing tools, such as Zoom, Skype, Discord, MS-Teams....\\nIn detail, my script sets up a virtual webcam device that applies Artistic Neural Style Transfer to the input stream of the physical webcam device. This new...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>4108</td>\n",
       "      <td>Nick Komissarenko</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@bigdataschool/3-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%B0-%D0%B4%D0%B5%D1%82%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2-c-deep-learning-r-cnn-fast-r-cnn-%D0%B8-faster-r-cnn-acdf6380fd33?source=tag_archive---------4-----------------------</td>\n",
       "      <td>3 метода детектирования объектов c Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN | by Nick Komissarenko | Medium</td>\n",
       "      <td>Jul 24, 2020\\nПроблема классификации объекта на изображении уже решена — сверточные нейронные сети (Convolutional Neural Networks, CNN) уже неплохо справляются с определением кошек или собак. Но если на изображении много объектов, которые нужно найти, задача сразу усложняется. На смену обычным сверточным нейросетям пришли более сложные модели. В этой статье рассмотрим 3 популярных способа детектирования изображений методами Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN.\\nРаспознавание образов — это общий термин, описывающий круг задач компьютерного зрения, которые решают проблему обнаружения объектов на изображении или видеокадрах. К ним относятся классификация изображения, локализация объектов, детектирование объектов и сегментация. Проведем между ними грань:\\nКлассификация и...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>4109</td>\n",
       "      <td>Ryan Kwok</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>4110</td>\n",
       "      <td>Puneet Singh</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/puneetsl/1-creating-a-q-a-system-introduction-81d404dfb3e4?source=tag_archive---------0-----------------------</td>\n",
       "      <td>1. Creating a Q-A system (Introduction) | by Puneet Singh | techpsl | Medium</td>\n",
       "      <td>techpsl\\nNov 11, 2013\\nWikipedia says, “Question Answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.”As I have taken the course of “Information Retrieval” this fall at UB, my final project is decided to be a Q-A system. Well we (me and my 3 group partners) have not decided much on features, which can make our project stand out, but for now we would like to start with a small goal. Somehow index the infobox of Wikipedia, and try to query it using natural language. My initial research suggests that IBM has already created something similar but on a very large scale, and they call it Watson.As we d...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>4111</td>\n",
       "      <td>Saket Dingliwal</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@saketdingliwal97/model-agnostic-meta-learning-maml-an-intuitive-way-f7539e043c0b?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Model Agnostic Meta-Learning (MAML): An Intuitive Way | by Saket Dingliwal | Medium</td>\n",
       "      <td>Jan 22, 2020\\nThere has been a great advancement in the research in the area of meta-learning in recent years. And so has been an expansion in the available literature and blog posts.\\nModel Agnostic Meta-Learning (MAML) lies at the heart of the developments in the area. There have been many excellent blog-posts explaining meta-learning in general (here and here) and MAML in particular (here and here). The heavy terms and complex equations make the algorithm to look like a big shot rocket science. However, through this blog, I want to provide intuitive reasoning behind the algorithm that can be easy to understand for a person who has no idea about meta-learning. All one needs to know is the basic idea all machine learning researchers have been following from its inception: “Throw all y...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4112</td>\n",
       "      <td>Shivon Zilis</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@shivon/the-current-state-of-machine-intelligence-f76c20db2fe1?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The Current State of Machine Intelligence | by Shivon Zilis | Medium</td>\n",
       "      <td>Dec 10, 2014\\n(The 2016 Machine Intelligence landscape and post can be found here)\\nI spent the last three months learning about every artificial intelligence, machine learning, or data related startup I could find — my current list has 2,529 of them to be exact. Yes, I should find better things to do with my evenings and weekends but until then...\\nWhy do this?\\nA few years ago, investors and startups were chasing “big data” (I helped put together a landscape on that industry). Now we’re seeing a similar explosion of companies calling themselves artificial intelligence, machine learning, or somesuch — collectively I call these “machine intelligence” (I’ll get into the definitions in a second). Our fund, Bloomberg Beta, which is focused on the future of work, has been investing in thes...</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4113</td>\n",
       "      <td>Shiva Verma</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@shiva-verma/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Understanding Input and Output shapes in LSTM | Keras | by Shiva Verma | Medium</td>\n",
       "      <td>Jan 14, 2019\\nEven if we understand LSTMs theoretically, still many of us are confused about its input and output shapes while fitting the data to the network. This guide will help you understand the Input and Output shapes of the LSTM.\\nLet’s first understand the Input and its shape in LSTM Keras. The input data to LSTM looks like the following diagram.\\n1.95K \\n1.95K \\n17\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n918 Followers\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>4114</td>\n",
       "      <td>Akash Deep</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/analytics-vidhya/keras-embedding-layer-and-programetic-implementation-of-glove-pre-trained-embeddings-step-by-step-7a4b2fa71544?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Keras Embedding layer and Programetic Implementation of GLOVE Pre-Trained Embeddings | by Akash Deep | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nAug 23, 2020\\nKeras Embedding layer is first of Input layer for the neural networks. After the conversion of our raw input data in the token and padded sequence, now its time to feed the prepared input to the neural networks. In our previous two post we had covered step by step conversion of words into token and padded sequence, so i highly recommend to just...\\n53 \\n53 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n28 Followers\\nData scientist, (NLP, CV,ML,DL) Expert 007011\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4115</td>\n",
       "      <td>Shashank Yadav</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@shashank7-iitd/understanding-vector-quantized-variational-autoencoders-vq-vae-323d710a888a?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Understanding Vector Quantized Variational Autoencoders (VQ-VAE) | by Shashank Yadav | Medium</td>\n",
       "      <td>Sep 1, 2019\\nFrom my most recent escapade into the deep learning literature I present to you this paper by Oord et. al. which presents the idea of using discrete latent embeddings for variational auto encoders. The proposed model is called Vector Quantized Variational Autoencoders (VQ-VAE). I really liked the idea and the results that came with it but found surprisingly few resources to develop an understanding. Here’s an attempt to help other who might venture into this domain after me.\\nLike numerous other people Variational Autoencoders (VAEs) are my choice of generative models. Unlike GANs they are easier to train and reason about (No offence intended dear GANs). Going forward I assume you have some understanding of VAEs. If you don’t I suggest going through this post, I found it t...</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>4116</td>\n",
       "      <td>Jaimin Mungalpara</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/what-does-it-mean-by-bidirectional-lstm-63d6838e34d9?source=tag_archive---------8-----------------------</td>\n",
       "      <td>What does it mean by Bidirectional LSTM? | by Jaimin Mungalpara | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 9, 2021\\nThis has turn the old approach by giving an input from both the direction and by this it can remember the long sequences.\\nIn my previous article we discussed about RNN, LSTM and GRU. Now, there are certain limitations are still persist with LSTM because it is not able to remember the context for a longer period of time.\\nYou can see in this LSTM architecture that information is still have to pass from longer path. LSTM and GRU are introduced to overcome the problem of vanishing gradient and sequential data memory but the architecture of both are having multiple sequential path. Thus, vanishing gradient problem is still persist. Also, LSTM and GRU can remember sequences of 10s and 100s but not 1000s or more.\\nBidirectional Network\\nNow, when we are dealin...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>4117</td>\n",
       "      <td>Ekta Sharma</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------4-----------------------</td>\n",
       "      <td>K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>4118</td>\n",
       "      <td>Jordi TORRES.AI</td>\n",
       "      <td>23</td>\n",
       "      <td>https://towardsdatascience.com/drl-01-a-gentle-introduction-to-deep-reinforcement-learning-405b79866bf4?source=tag_archive---------4-----------------------</td>\n",
       "      <td>A gentle introduction to Deep Reinforcement Learning | by Jordi TORRES.AI | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 15, 2020\\nThis is the first post of the series “Deep Reinforcement Learning Explained”; an introductory series that gradually and with a practical approach introduces the reader to the basic concepts and methods used in modern Deep Reinforcement Learning.\\nSpanish version of this publication:\\nmedium.com\\nDeep Reinforcement Learning (DRL), a very fast-moving field, is the combination of Reinforcement Learning and Deep Learning. It is also the most trending type of Machine Learning because it can solve a wide range of complex decision-making tasks that were previously out of reach for a machine to solve real-world problems with human-like intelligence.\\nToday I’m starting a series about Deep Reinforcement Learning that will bring the topic closer to the reader....</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>4119</td>\n",
       "      <td>Tejas Morkar</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/generative-adversarial-networks-gans-89ef35a60b69?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Learning to Build a Model for Sketch-to-Color Image Generation using Conditional GANs | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 23, 2020\\nThis article is a part of the Gans-Series published by me on TowardsDataScience Publication on Medium. If you do not know what GANs are or if you have an idea about it but wish to quickly go over it again, I highly recommend you read the previous article which is just a 7 minutes long read and provides a simple understanding of GANs for people who are new to this amazing domain of Deep Learning.\\nAs you can tell from the gif shown above, this article is going to be all about learning how to create a Conditional GAN to predict colorful images from the given black and white sketch inputs without knowing the actual ground truth.\\nSketch to Color Image generation is an image-to-image translation model using Conditional Generative Adversarial Networks as ...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>4120</td>\n",
       "      <td>Matheus Jacques</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.datadriveninvestor.com/batch-vs-mini-batch-vs-stochastic-gradient-descent-with-code-examples-cd8232174e14?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Batch vs Mini-batch vs Stochastic Gradient Descent with Code Examples | by Matheus Jacques | DataDrivenInvestor</td>\n",
       "      <td>DataDrivenInvestor\\nMay 5, 2020\\nOne of the main questions that arise when studying Machine Learning and Deep Learning is the several types of Gradient Descent. Should I use Batch Gradient Descent? Mini-batch Gradient Descent or Stochastic Gradient Descent? In this post, we are going to understand the difference between those concepts and take a look at code implementations from Gradient Descent, to clarify these methods.\\nEdit: Updated version here.\\nAt this point, we know that our matrix of weights W and our vector of bias b are the core values of our Neural Networks (NN) (Check the Deep Learning Basics post). We can make an analogy with these concepts with the memory in which a NN stores patterns, and it is through tuning these parameters that we teach a NN. The acting of tuning is ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4121</td>\n",
       "      <td>Susan Maina</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/lambda-functions-with-practical-examples-in-python-45934f3653a8?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Lambda Functions with Practical Examples in Python | by Susan Maina | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 17, 2021\\nWhen I first came across lambda functions in python, I was very much intimidated and thought they were for advanced Pythonistas. Beginner python tutorials applaud the language for its readable syntax, but lambdas sure didn’t seem user-friendly.\\nHowever, once I understood the general syntax and examined some simple use cases, using them was less scary.\\nSimply put, a lambda function is just like any normal python function, except that it has no name when defining it, and it is contained in one line of code.\\nA lambda function evaluates an expression for a given argument. You give the function a value (argument) and then provide the operation (expression). The keyword lambda must come first. A full colon (:) separates the argument and the expression.\\...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4122</td>\n",
       "      <td>Mohammed Sunasra</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Performance Metrics for Classification problems in Machine Learning | by Mohammed Sunasra | Medium</td>\n",
       "      <td>Nov 11, 2017\\n“Numbers have an important story to tell. They rely on you to give them a voice.” — Stephen Few\\nAfter doing the usual Feature Engineering, Selection, and of course, implementing a model and getting some output in forms of a probability or a class, the next step is to find out how effective is the model based on some metric using test datasets. Different performance metrics are used to evaluate different Machine Learning Algorithms. For now, we will be focusing on the ones used for Classification problems. We can use classification performance metrics such as Log-Loss, Accuracy, AUC(Area under Curve) etc. Another example of metric for evaluation of machine learning algorithms is precision, recall, which can be used for sorting algorithms primarily used by search engines.\\...</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>4123</td>\n",
       "      <td>Igor Susmelj</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/few-shot-learning-with-fast-ai-81c66064e372?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Few-Shot Learning with fast.ai. In few-shot learning, we train a model... | by Igor Susmelj | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 27, 2020\\nLately, posts and tutorials about new deep learning architectures and training strategies have dominated the community. However, one very interesting research area, namely few-shot learning, is not getting the attention it deserves. If we want widespread adoption of ML we need to find ways to train them efficiently, with little data and code. In this tutorial, we will go through a Google Colab Notebook to train an image classification model using only 5 labeled samples per class. Using only 5 exemplary samples is also called 5-shot learning.\\nDon’t forget to check out our Google Colab Notebook for the full code of this tutorial!\\nJupyter Notebook (Google Colab)The full code of this tutorial will be provided as a notebook. Jupyter Notebooks are python...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>4124</td>\n",
       "      <td>Manish Chablani</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c?source=tag_archive---------4-----------------------</td>\n",
       "      <td>GAN — Introduction and Implementation — PART1: Implement a simple GAN in TF for MNIST handwritten digit generation | by Manish Chablani | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 27, 2017\\nThe idea behind GANs is that you have two networks, a generator GG and a discriminator DD, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it’s received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistinguishable from real data to the discriminator.\\nThis is equilibrium state and expectation is discriminator is emitting a probability of 0.5 for both real and fake data.\\nThe general structure of a ...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>4125</td>\n",
       "      <td>Ajinkya Sonawane</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.goodaudience.com/solving-8-puzzle-using-a-algorithm-7b509c331288?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Solving 8-Puzzle using A* Algorithm | Good Audience</td>\n",
       "      <td>Good Audience\\nSep 15, 2018\\nSolving the sliding puzzle using a basic AI algorithm.\\nN-Puzzle or sliding puzzle is a popular puzzle that consists of N tiles where N can be 8, 15, 24, and so on. In our example N = 8. The puzzle is divided into sqrt(N+1) rows and sqrt(N+1) columns. Eg. 15-Puzzle will have 4 rows and 4 columns and an 8-Puzzle will have 3 rows and 3 columns. The puzzle consists of N tiles and one empty space where the tiles can be moved. Start and Goal configurations (also called state) of the puzzle are provided. The puzzle can be solved by moving the tiles one by one in the single empty space and thus achieving the Goal configuration.\\nThe tiles in the initial(start) state can be moved in the empty space in a particular order and thus achieve the goal state.\\nNote: There...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>4126</td>\n",
       "      <td>Ashish Singhal</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/datapy-ai/nlp-building-text-summarizer-part-1-902fec337b81?source=tag_archive---------9-----------------------</td>\n",
       "      <td>NLP: Building Text Summarizer — Part 1 | by Ashish Singhal | DataPy.ai | Medium</td>\n",
       "      <td>DataPy.ai\\nNov 18, 2019\\n105 \\n105 \\n3\\nSchool for Data Science\\n98 Followers\\nTrying to become ( .* ?) | MSc @ University of Twente | ML-NLP-Big Data-DL | tencsor.github.io | theguywithblacktie.github.io\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>4127</td>\n",
       "      <td>Hely Marleena</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/@helymarleena/from-metaphor-to-reality-15790952657?source=tag_archive---------4-----------------------</td>\n",
       "      <td>From metaphor to reality. When does artificial intelligence stop... | by Hely Marleena | Medium</td>\n",
       "      <td>Jul 19, 2014\\n“A mind is like a computer program that is executed in our brain” says the computer metaphor of the mind. It was developed in the 1950s. It basically compares the human mind to a computer program, suggesting that computers and our brain function on the same principles.\\nIn the philosophy of artificial intelligence (AI), the brain is perceived as a similar information processing machine as a digital computer.\\nThere is no doubt that some of our thinking processes, such as mental calculation and logical reasoning, are algorithmic. The digital computer functions with binary computer language where the symbols ‘1’ and ‘0’ represent the state of circuit’s gate. This means that an electrical impulse either goes through (state ‘1’) or does not (state ‘0’). It is similar to the f...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>4128</td>\n",
       "      <td>Wolf Garbe</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------2-----------------------</td>\n",
       "      <td>1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium</td>\n",
       "      <td>Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is &lt;=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>4129</td>\n",
       "      <td>Klas Leino</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/training-provably-robust-neural-networks-1e15f2d80be2?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Training Provably-Robust Neural Networks | by Klas Leino | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2021\\nOver the last several years, deep networks have extensively been shown to be vulnerable to attackers that can cause the network to make perplexing mistakes, simply by feeding maliciously-perturbed inputs to the network. Clearly, this raises concrete safety concerns for neural networks deployed in the wild, especially in safety-critical settings, e.g., in autonomous vehicles. In turn, this has motivated a volume of work on practical defenses, ranging from attack detection strategies to modified training routines that aim to produce networks that are difficult — or impossible — to attack. In this article, we’ll take a look at an elegant and effective defense I designed with my colleagues at CMU (appearing in ICML 2021) that modifies the architecture of...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>4130</td>\n",
       "      <td>Udacity India</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@UdacityINDIA/tensorflow-or-pytorch-the-force-is-strong-with-which-one-68226bb7dab4?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Tensorflow or PyTorch : The force is strong with which one? | by Udacity India | Medium</td>\n",
       "      <td>Apr 24, 2018\\nBy — Yashwardhan Jain\\nSo, since you’re reading this article, I’m going to assume you have started your deep learning journey and have been playing around for a while with artificial neural nets. Or maybe, you’re just thinking of starting. Whichever case it be, you find yourself in a bit of a dilemma. You have read about various deep learning frameworks and libraries and maybe two really stand out. The two most popular deep learning libraries: Tensorflow and PyTorch. And you can’t quite figure out what exactly is the difference. Fret not! I’m here to add one more article to the unending repository of the Internet. And maybe, help you get some clarity. Also, I’m going to make it easier and quicker for you, and give you just five points. Five points of comparison, no more. ...</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4131</td>\n",
       "      <td>Kacper Kubara</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/gaussian-mixture-models-vs-k-means-which-one-to-choose-62f2736025f0?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Gaussian Mixture Models vs K-Means. | by K.Kubara | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 8, 2020\\nK-Means and Gaussian Mixtures (GMs) are both clustering models. Many data scientist, however, tend to choose a more popular K-Means algorithm. Even if GMs can prove superior in certain clustering problems.\\nIn this article, we will see that both models offer a different performance in terms of speed and robustness. We will also see that it is possible to use K-Means as an initializer for GMs which tends to boost the performance of the clustering model.\\nFirst, let’s review the theoretical part of these algorithms. It will help us to understand their behaviour later in the article.\\nK-Means is a popular non-probabilistic clustering algorithm. The goal of the algorithm is to minimize the distortion measure J. We achieve that by the following iterative p...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>4132</td>\n",
       "      <td>Emil Lykke Jensen</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras | by Emil Lykke Jensen | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 25, 2020\\nThe internet is full of text classification articles, most of which are BoW-models combined with some kind of ML-model typically solving a binary text classification problem. With the rise of NLP, and in particular BERT (take a look here, if you are not familiar with BERT) and other multilingual transformer based models, more and more text classification problems can now be solved.\\nHowever, when it comes to solving a multi-label, multi-class text classification problem using Huggingface Transformers, BERT, and Tensorflow Keras, the number of articles are indeed very limited and I for one, haven’t found any... Yet!\\nTherefore, with the help and inspiration of a great deal of blog posts, tutorials and GitHub code snippets all relating to either BERT, ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>4133</td>\n",
       "      <td>Victor Roman</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/unsupervised-classification-project-building-a-movie-recommender-with-clustering-analysis-and-4bab0738efe6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Unsupervised Classification Project: Building a Movie Recommender with Clustering Analysis and K-Means | by Victor Roman | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 19, 2019\\nThe goal of this project is to find out similarities within groups of people in order to build a movie recommending system for users. We are going to analyze a dataset from Netflix database to explore the characteristics that people share in movies’ taste, based on how they rate them.\\nData will come from the MovieLens user rating dataset.\\nThis dataset has two files, we will import both and work with both of them.\\nWe will want to find out how the structure of the dataset works and how many records do we have in each of these tables.\\nWe will start by considering a subset of users and discovering what are their favourite genre. We will do this by defining a function that will calculate each user’s average rating for all science fiction and romance m...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>4134</td>\n",
       "      <td>Jane Huang</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/data-science-at-microsoft/causal-inference-part-2-of-3-selecting-algorithms-a966f8228a2d?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Causal inference (Part 2 of 3): Selecting algorithms | by Jane Huang | Data Science at Microsoft | Medium</td>\n",
       "      <td>Data Science at Microsoft\\nNov 5, 2020\\nBy Jane Huang, Daniel Yehdego, and Siddharth Kumar\\nThis is the second article of a series focusing on causal inference methods and applications. In Part 1, we discussed when and why causal models can help with different business problems. We also provided fundamentals for causal inference analysis and compared a few popular Python packages for causal analysis. In this article, we dive into details of various causal inference estimation methods and discuss algorithm selection for your own problem settings. Causal inference can be used on top of A/B tests in multiple ways to extract insights, but this article focuses mainly on estimation methods under unconfoundedness or on quasi-experimental bases when a randomized control trial (RCT) is not feas...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>4135</td>\n",
       "      <td>Mayank Mishra</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Convolutional Neural Networks, Explained | by Mayank Mishra | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 26, 2020\\nA Convolutional Neural Network, also known as CNN or ConvNet, is a class of neural networks that specializes in processing data that has a grid-like topology, such as an image. A digital image is a binary representation of visual data. It contains a series of pixels arranged in a grid-like fashion that contains pixel values to denote how bright and what color each pixel should be.\\nThe human brain processes a huge amount of information the second we see an image. Each neuron works in its own receptive field and is connected to other neurons in a way that they cover the entire visual field. Just as each neuron responds to stimuli only in the restricted region of the visual field called the receptive field in the biological vision system, each neuron i...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>4136</td>\n",
       "      <td>Pau Labarta Bajo</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/adversarial-examples-to-break-deep-learning-models-e7f543833eae?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Adversarial Examples to Break Deep Learning Models | by Pau Labarta Bajo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 16, 2021\\nDo you think it is impossible to fool the vision system of a self-driving Tesla car?\\nOr that machine learning models used in malware detection software are too good to be evaded by hackers?\\nOr that face recognition systems in airports are bulletproof?\\nLike any of us machine learning enthusiasts, you might fall into the trap of thinking that deep models used out there are perfect.\\nWell, you are WRONG.\\nThere are easy ways to build adversarial examples that can fool any deep learning model and create security issues. In this post, we will cover the following:\\nLet’s start!\\nIn the last 10 years, deep learning models have left the academic kindergarten, become big boys, and transformed many industries. This is especially true for computer vision mod...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>4137</td>\n",
       "      <td>Madeline Schiappa</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/understanding-the-backbone-of-video-classification-the-i3d-architecture-d4011391692?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Understanding the Backbone of Video Classification: The I3D Architecture | by Madeline Schiappa | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 7, 2020\\nOne of the distinctive differences between information in a single image and information in a video is the temporal element. This has led to improvements of deep learning model architectures to incorporate 3D processing in order to additionally process temporal information. This article summarizes the architectural changes from images to video through the I3D model.\\nThe I3D model was presented by researchers from DeepMind and the University of Oxford in a paper called “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” [1]. The paper compares previous approaches to the problem of action detection in videos while additionally presenting a new architecture, the focus here. Their approach starts with a 2D architecture and inflates all ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>4138</td>\n",
       "      <td>DataAnalysis For Beginner</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@univprofblog1/random-forests-classification-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-fb60ff088db4?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Random Forests Classification: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium</td>\n",
       "      <td>Aug 23, 2016\\nI release MATLAB, R and Python codes of Random Forests Classification (RFC). They are very easy to use. You prepare data set, and just run the code! Then, RFC and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/RciDk Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/gdJgy Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/nDrmZ Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://un...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>4139</td>\n",
       "      <td>Pranoy Radhakrishnan</td>\n",
       "      <td>8</td>\n",
       "      <td>https://becominghuman.ai/transformers-in-vision-e2e87b739feb?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Why Transformers are Slowly Replacing CNNs in Computer Vision? | by Pranoy Radhakrishnan | Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine\\nAug 31, 2021\\nBefore getting into Transformers, let’s understand why researchers were interested in building something like Transformers inspite of having MLPs , CNNs and RNNs.\\nEveryone wants a universal model to solve different tasks with accuracy and speed. Just like MLPs which are universal function approximators, Transformer models are universal approximators of sequence-to-sequence functions.\\nTransformers use the concept of Attention mechanism. Let’s look what is attention and briefly go through self attention mechanisms.\\nAttention mechanism enhances the important parts of the input data and fades out the rest. Take the example of you captioning an image. You will have to focus on the relevant part of the image to generate meani...</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>4140</td>\n",
       "      <td>platfarm tech team</td>\n",
       "      <td>14</td>\n",
       "      <td>https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225?source=tag_archive---------6-----------------------</td>\n",
       "      <td>어텐션 메커니즘과 transfomer(self-attention) | by platfarm tech team | mojitok | Medium</td>\n",
       "      <td>mojitok\\nMar 10, 2019\\n어텐션 메커니즘은 자연어 기계 번역을 위한 Seq2Seq 모델에 처음 도입되었습니다. 어텐션 메커니즘은 NLP 태스크 뿐만 아니라, 도메인에 관계 없이 다양하게 쓰이고 있습니다. 현재의 SOTA NLP모델들은 대부분 어텐션 메커니즘을 적용하고 있으니 최근 논문을 이해함에 있어 이해하고 넘어가야 하는 부분입니다.\\n코드는 이곳(https://github.com/graykode/nlp-tutorial)을 참고해주세요 .\\n1. Seq2Seq (링크)2. Seq2Seq with Attention (링크)3. Bi-LSTM with Attention (링크)4. Transformer (링크)\\nSeq2Seq 모델은 대중적이므로 가볍게 짚고만 넘어가겠습니다. Seq2Seq 모델에 대한 자세한 설명들은 ratsgo님의 블로그를 참조하면 볼 수 있습니다. 더불어 자세한 내용은 원작 논문인 Neural Machine Translation by Jointly Learn...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>4141</td>\n",
       "      <td>Parul Pandey</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Understanding the Mathematics behind Gradient Descent. | by Parul Pandey | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 18, 2019\\n“Premature optimization is the root of all evil.” ― Donald Ervin Knuth\\nAgile is a pretty well-known term in the software development process. The basic idea behind it is simple: build something quickly, ➡️ get it out there, ➡️ get some feedback ➡️ make changes depending upon the feedback ➡️ repeat the process. The goal is to get the product near the user and guide you with feedback to obtain the best possible product with the least error. Also, the steps taken for improvement need to be small and should constantly involve the user. In a way, an Agile software development process involves rapid iterations. The idea of — start with a solution as soon as possible, measure and iterate as frequently as possible, is Gradient descent under the hood.\\nGradi...</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>4142</td>\n",
       "      <td>Martín Pellarolo</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Logistic Regression from scratch in Python | by Martín Pellarolo | Medium</td>\n",
       "      <td>Feb 23, 2018\\nWhile Python’s scikit-learn library provides the easy-to-use and efficient LogisticRegression class, the objective of this post is to create an own implementation using NumPy. Implementing basic models is a great idea to improve your comprehension about how they work.\\nWe will use the well known Iris data set. It contains 3 classes of 50 instances each, where each class refers to a type of iris plant. To simplify things, we take just the first two feature columns. Also, the two non-linearly separable classes are labeled with the same category, ending up with a binary classification problem.\\nGiven a set of inputs X, we want to assign them to one of two possible categories (0 or 1). Logistic regression models the probability that each input belongs to a particular category...</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>4143</td>\n",
       "      <td>Reo Neo</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-3-9d686d0d85d9?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Beginner Guide to Variational Autoencoders (VAE) with PyTorch Lightning (Part 3) | by Reo Neo | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 10, 2021\\nThis blog post is part of a mini-series that talks about the different aspects of building a PyTorch Deep Learning project using Variational Autoencoders.\\nPart 1: Mathematical Foundations and ImplementationPart 2: Supercharge with PyTorch LightningPart 3: Convolutional VAE, Inheritance and Unit TestingPart 4: Streamlit Web App and Deployment\\nIn this section, we will look at how we can use the code we wrote in the previous section and use it to build a convolutional VAE. This VAE would be better at identifying important features in the images and thus generate even better images.\\nThe best part is that this new model can be built with minimal additional code thanks to PyTorch modules and class inheritance.\\nConvolution is an operation commonly used ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4144</td>\n",
       "      <td>Aman Kharwal</td>\n",
       "      <td>2</td>\n",
       "      <td>https://medium.com/coders-camp/60-python-projects-with-source-code-919cd8a6e512?source=tag_archive---------5-----------------------</td>\n",
       "      <td>60 Python Projects with Source Code | by Aman Kharwal | Coders Camp | Medium</td>\n",
       "      <td>Coders Camp\\nJan 14, 2021\\nPython has been in the top 10 popular programming languages for a long time, as the community of Python programmers has grown a lot due to its easy syntax and library support. In this article, I will introduce you to 60 amazing Python projects with source code solved and explained for free.\\nIf you’re a newbie to Python where you’ve just learned lists, tuples, dictionaries, and some basic Python modules like the random module, here are some Python projects with source code for beginners for you:\\nIf you have learned the fundamental Python libraries and some of the external libraries, you should now know how to install external libraries and work with them. So if you are at that level now, you can work on all the advanced Python projects with source code menti...</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>4145</td>\n",
       "      <td>Haihan Lan</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/the-softmax-function-neural-net-outputs-as-probabilities-and-ensemble-classifiers-9bd94d75932?source=tag_archive---------9-----------------------</td>\n",
       "      <td>The Softmax Function, Neural Net Outputs as Probabilities, and Ensemble Classifiers | by Haihan Lan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 13, 2017\\nIn this article, we’ll look at:\\nLinks to my other articles:\\nIn many cases when using neural network models such as regular deep feedforward nets and convolutional nets for classification tasks over some set of class labels, one wonders whether it is possible to interpret the output, for example y = [0.02, 0, 0.005, 0.975], as the probability of some input being in a class equal to the respective component values yi in the output vector. Skipping straight to the long answer: no, unless you have a softmax layer as your output layer and train the net with the cross-entropy loss function. This point is important because it is sometimes omitted in online sources and even in some textbooks regarding classification with neural networks. We’ll take a look ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>4146</td>\n",
       "      <td>Pranav Budhwant</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/binaryandmore/beginners-guide-to-deriving-and-implementing-backpropagation-e3c1a5a1e536?source=tag_archive---------3-----------------------</td>\n",
       "      <td>A beginner’s guide to deriving and implementing backpropagation | by Pranav Budhwant | binaryandmore | Medium</td>\n",
       "      <td>binaryandmore\\nJul 16, 2018\\nThis article is divided into two sections:1. Derivation — In this section, we will be deriving all the required formulae for performing backpropagation. I strongly recommend that you derive the equations on paper as you read through the article.2. Implementation — In this part, we will use the derived formulae to implement backpropagation from scratch. We will be solving a binary classification problem in python using numpy.\\nDisclaimerThis article assumes a basic understanding of neural networks and how they work. If you are not familiar with neural networks, or think your concepts are a little rusty, you may want to review chapter 1 of the amazing book, Neural Networks and Deep Learning, by Michael Nielsen, or if you prefer video lectures, you might want ...</td>\n",
       "      <td>2511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>4147</td>\n",
       "      <td>Shivy Yohanandan</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2?source=tag_archive---------1-----------------------</td>\n",
       "      <td>mAP (mean Average Precision) might confuse you! | by Shivy Yohanandan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 9, 2020\\nOne can be forgiven for taking mAP (mean average precision) to literally mean the average of precisions. Nevertheless, you couldn’t be further from the truth!\\nLet me explain.\\nIn computer vision, mAP is a popular evaluation metric used for object detection (i.e. localisation and classification). Localization determines the location of an instance (e.g. bounding box coordinates) and classification tells you what it is (e.g. a dog or cat).\\nMany object detection algorithms, such as Faster R-CNN, MobileNet SSD, and YOLO, use mAP to evaluate their models for publishing their research.\\nYou might ask, if it’s such a popular metric, why is it still confusing?\\nFair enough!\\nmAP stands for Mean Average Precision (as you might already have guessed looking at...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>4148</td>\n",
       "      <td>Kyle McDonald</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How to recognize fake AI-generated images | by Kyle McDonald | Medium</td>\n",
       "      <td>Dec 5, 2018\\nIn 2014 machine learning researcher Ian Goodfellow introduced the idea of generative adversarial networks or GANs. “Generative” because they output things like images rather than predictions about input (like “hotdog or not”); “adversarial networks” because they use two neural networks competing with each other in a “cat-and-mouse game”, like a cashier and a counterfeiter: one trying to fool the other into thinking it can generate real examples, the other trying to distinguish real from fake.\\nThe first GAN images were easy for humans to identify. Consider these faces from 2014.\\nBut the latest examples of GAN-generated faces, published in October 2017, are more difficult to identify.\\nHere are some things you can look for when trying to recognize an image produced by a GA...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4149</td>\n",
       "      <td>Peter Bulyaki</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@peter.bulyaki/a-brief-introduction-to-artificial-neural-networks-9962114c3bad?source=tag_archive---------3-----------------------</td>\n",
       "      <td>A brief introduction to artificial neural networks | by Peter Bulyaki | Medium</td>\n",
       "      <td>Nov 2, 2012\\nThis post will try to give you a brief introduction to artificial neural networks or at least to some types of them. I will skip the introduction to biological neural networks as I am neither a biologist nor a doctor, I prefer not to write about what I do not fully understand.\\nOverview of artificial neural networks and supervised learning\\nI think it is very important to note that artificial neural networks are neither magical AI circuits nor oracles with the ability of predicting stock market movements. You can save one as a file on the disk and you can name it skynet if you like but it will not get more intelligent from that. In reality they are simply mathematical tools that can come very handy in solving certain problems (and can prove to be completely useless for oth...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>4150</td>\n",
       "      <td>Synced</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/syncedreview/biggan-a-new-state-of-the-art-in-image-synthesis-cf2ec5694024?source=tag_archive---------2-----------------------</td>\n",
       "      <td>BigGAN: A New State of the Art in Image Synthesis | by Synced | SyncedReview | Medium</td>\n",
       "      <td>SyncedReview\\nOct 2, 2018\\n“Best GAN samples ever yet? Very impressive ICLR submission! BigGAN improves Inception Scores by &gt;100.”\\nThe above Tweet is from renowned Google DeepMind research scientist Oriol Vinyals. It was retweeted last week by Google Brain researcher and “Father of Generative Adversarial Networks” Ian Goodfellow, and picked up momentum and praise from AI researchers on social media.\\n402 \\n402 \\n5\\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology &amp; Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4151</td>\n",
       "      <td>Nir Ben-Zvi</td>\n",
       "      <td>22</td>\n",
       "      <td>https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86?source=tag_archive---------7-----------------------</td>\n",
       "      <td>A 2022-Ready Deep Learning Hardware Guide | by Nir Ben-Zvi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 15, 2020\\nThis is as up to date as: 3/1/2022\\nThis is a vastly revised version of the older version you all know and love.Almost every part of this guide has been thoroughly rewritten. The original guide has been getting updated over the course of 6 years, so I decided it’s time to basically (almost) write it from scratch.This time I tried to make this a bit more thorough and general. I’ll keep updating this, but I also want to make sure my readers can understand the topic even if I stop doing so one day.\\nSo, you’ve decided you want to purchase a machine dedicated to training machine learning models. Or, rather, you work in an organization where the buzzwords of this guide are constantly thrown around and you simply want to know a bit more about what they mea...</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4152</td>\n",
       "      <td>Nathan Cooper Jones</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/@nathancooperjones/these-bored-apes-do-not-exist-6bed2c73f02c?source=tag_archive---------1-----------------------</td>\n",
       "      <td>These Bored Apes Do Not Exist: GAN to NFT Pipeline | Medium</td>\n",
       "      <td>Dec 6, 2021\\nTL;DR — I complain about NFTs, then attempt to train both a GAN and super-resolution model to generate Bored Apes that do not exist. You can check out all the generated images on thisboredapedoesnotexist.nathancooperjones.com.\\nFriday, November 12th, 2021 started out as a normal day for me. Before starting my day at work, I decided to open Twitter to see if I missed anything since the night before.\\nThen, it happened. I saw this Tweet:\\nSay what you will about how Jimmy Fallon tells and reacts to jokes, but if this was a joke, I did not understand it. An animated monkey dressed in a sailor cap? I soon learned that this wasn’t just any animated ape, but one of exactly 10,000 unique images produced in a collection called Bored Ape Yacht Club. After ten minutes down a Twitter...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4153</td>\n",
       "      <td>Ahmet Genç</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@ahmetxgenc/detecting-empty-car-parking-lot-with-mask-rcnn-model-4f6202794a6?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Detecting Empty Parking Lots With Mask RCNN Model | by Ahmet Genç | Medium</td>\n",
       "      <td>Dec 20, 2019\\nNowadays, there are big problems about parking areas. The large number of vehicles in the cities and the scarcity of parking spaces lead to parking problems in the cities. The biggest solution that can be brought to this problem is to provide people with the information whether the parking spaces are automatically empty or full. Using a mask...\\n17 \\n17 \\n1\\nSoftware Engineer\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n49 Followers\\nSoftware Engineer\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>4154</td>\n",
       "      <td>Max Pagels</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/value-stream-design/online-machine-learning-515556ff72c5?source=tag_archive---------6-----------------------</td>\n",
       "      <td>What is Online Machine Learning?. Making machines learn in real time | by Max Pagels | The Hands-on Advisors | Medium</td>\n",
       "      <td>The Hands-on Advisors\\nApr 20, 2018\\nDuring the start of my career, I was fortunate enough to work on a subfield of machine learning known as online learning (also known as incremental or out-of-core learning). Compared to “traditional” ML solutions, online learning is a fundamentally different approach, one that embraces the fact that learning environments can (and do) change from second to second. It’s tricky to get right, but when applied correctly, the results you can achieve with online learning are nothing short of remarkable. In this post, I’ll give a quick introduction to the technique.\\nUpdate 27/09/2019: lots of people have asked if there exist any purpose-built incremental learning libraries. Yes! Vowpal Wabbit is extremely powerful, and has been around for quite a while. Fo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>4155</td>\n",
       "      <td>Chris Loughnane</td>\n",
       "      <td>7</td>\n",
       "      <td>https://pdnotebook.com/image-analysis-intro-using-python-opencv-18791f4edf22?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Image analysis intro using python &amp; opencv | by Chris Loughnane | Product Development Notebook</td>\n",
       "      <td>Product Development Notebook\\nOct 26, 2015\\nIt’s been a while since I first wrote about how useful computer vision can be in product development, and I recently put together a quick demo for other engineers at my new gig (@ Continuum) that is cleaner and more thorough than previous versions (plus it uses the cv2 library instead of the deprecated cv library I used before).\\n(and of course it’s written in python)\\n...\\n...\\n...\\nImage analysis is hugely powerful, particularly in the context of product development. Most of the challenges in computer vision (and AI in general) comes from trying to process unstructured and/or uncontrolled information.\\nFortunately, we product development engineers spend a bunch of time setting up experiments in the lab. In those cases we have much more cont...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>4156</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Multi Class Text Classification with LSTM using TensorFlow 2.0 | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 8, 2019\\nA lot of innovations on NLP have been how to add context into word vectors. One of the common ways of doing it is using Recurrent Neural Networks. The following are the concepts of Recurrent Neural Networks:\\nThe above is the architecture of Recurrent Neural Networks.\\nAssuming we are solving document classification problem for a news article data set.\\nTherefore, we generally do not use vanilla RNNs, and we use Long Short Term Memory instead. LSTM is a type of RNNs that can solve this long term dependency problem.\\nIn our document classification for news article example, we have this many-to- one relationship. The input are sequences of words, output is one single class or label.\\nNow we are going to solve a BBC news document classification problem w...</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>4157</td>\n",
       "      <td>Pandorabots</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/pandorabots-blog/using-oob-tags-in-aiml-part-i-21214b4d2fcd?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Using OOB Tags in AIML: Part I. Suppose you are building an Intelligent... | by Pandorabots | pandorabots-blog | Medium</td>\n",
       "      <td>pandorabots-blog\\nOct 9, 2014\\nSuppose you are building an Intelligent Virtual Agent or Virtual Personal Assistant (VPA) that uses a Pandorabot as the natural language processing engine. You might want this VPA to be able to perform tasks such as sending a text message, adding an event to a calendar, or even just initiating a phone call. OOB tags allow you to do just that!\\nOOB stands for “out of band,” which is an engineering term used to refer to activity performed on a separate, hidden channel. For a Pandorabot VPA, this translates to activities which fall outside of the scope of an ordinary conversation, such as placing a phone call, checking dynamic information like the weather, or searching wikipedia for the answer to some question. The task is executed, but does not necessarily ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>4158</td>\n",
       "      <td>Harsh Sharma</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Understanding Encoders-Decoders with Attention Based Mechanism | DataX Journal</td>\n",
       "      <td>DataX Journal\\nFeb 1, 2021\\nHow attention-based mechanism completely transformed the working of neural machine translations while exploring contextual relations in sequences!\\nWhen it comes to applying deep learning principles to natural language processing, contextual information weighs in a lot! In the past few years, it has been shown that various improvement in existing neural network architectures concerned with NLP has shown an amazing performance in extracting featured information from textual data and performing various operations for a day to day life. One of the models which we will be discussing in this article is encoder-decoder architecture along with the attention model.\\nThe encoder-decoder architecture for recurrent neural networks is actually proving to be powerful for...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4159</td>\n",
       "      <td>Prajwal Paudyal</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/should-ai-explain-itself-or-should-we-design-explainable-ai-so-that-it-doesnt-have-to-90e75bb6089e?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Should AI explain itself? or should we design Explainable AI so that it doesn’t have to | by Prajwal Paudyal | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 4, 2019\\nIn this article, I’ll go over:\\nThis article got longer that what I originally intended, so for the busy souls, here is a synopsis.\\nExplanations for AI behavior that are generated Ad-hoc or post-hoc are more like justifications and may not be capture the truth of the decision process. If trust and accountability is needed, that has to be taken into account early on in the design process. Explainable AI (XAI )is NOT an AI that can explain itself, it is a design decision by developers. It is AI that is transparent enough so that the explanations that are needed are part of the design process.\\nNow, the full story.\\nA self driving car knocked down and killed a pedestrian in Tempe, AZ in 2018. Issues like who is to blame (accountability), who to prevent ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4160</td>\n",
       "      <td>Yang S</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/an-introduction-to-perceptron-algorithm-40f2ab4e2099?source=tag_archive---------2-----------------------</td>\n",
       "      <td>An Introduction to Perceptron Algorithm | by Yang S | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 19, 2019\\nThis blog will cover following questions and topics\\n1. What is Perceptron?\\n2. Stochastic Gradient Descent for Perceptron\\n3. Implementation in Python\\n1. What is Perceptron?\\nPerceptron set the foundations for Neural Network models in 1980s. The algorithm was developed by Frank Rosenblatt and was encapsulated in the paper “Principles of Neuro-dynamics: Perceptrons and the Theory of Brain Mechanisms” published in 1962. At that time, Rosenblatt’s work was criticized by Marvin Minksy and Seymour Papert, arguing that neural networks were flawed and could only solve linear separation problem. However, such limitation only occurs in the single layer neural network.\\nPerceptron can be used to solve two-class classification problem. The generalized form of...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4161</td>\n",
       "      <td>Karl N.</td>\n",
       "      <td>7</td>\n",
       "      <td>https://gab41.lab41.org/taking-keras-to-the-zoo-9a76243152cb?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Taking Keras to the Zoo. If you follow any of the popular blogs... | by Karl N. | Gab41</td>\n",
       "      <td>Gab41\\nDec 13, 2015\\nIf you follow any of the popular blogs like Google’s research, FastML, Smola’s Adventures in Data Land, or one of the indie-pop ones like Edwin Chen’s blog, you’ve probably also used ModelZoo. Actually, if you’re like our boss, you affectionately call it “The Zoo”. (Actually x 2, if you have interesting blogs that you read, feel free to let us know!)\\nUnfortunately, ModelZoo is only supported in Caffe. Fortunately, we’ve taken a look at the difference between the kernels in Keras, Theano, and Caffe for you, and after reading this blog, you’ll be able to load models from ModelZoo into any of your favorite Python tools.\\nWhy this post? Why not just download our Github code?\\nIn short, it’s better you figure out how these things work before you use them. That way, you...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4162</td>\n",
       "      <td>ASHISH RANA</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Introduction: Reinforcement Learning with OpenAI Gym | by ASHISH RANA | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 21, 2018\\nUnderstand the basic goto concepts to get a quick start on reinforcement learning and learn to test your algorithms with OpenAI gym to achieve research centric reproducible results.\\nThis article first walks you through the basics of reinforcement learning, its current advancements and a somewhat detailed practical use-case of autonomous driving. After that we get dirty with code and learn about OpenAI Gym, a tool often used by researchers for standardization and benchmarking results. When the coding section comes please open your terminal and get ready for some hands on.A time saver tip: You can directly skip to ‘Conceptual Understanding’ section if you want to skip basics and only want try out Open AI gym directly.\\nMainly three categories of learn...</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4163</td>\n",
       "      <td>Volkan Levent Soylu</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@vlknlvnt/reinforcement-learning-peki%C5%9Ftirmeli-%C3%B6%C4%9Frenme-i%CC%87nsan-beyniyle-aradaki-fark-kapan%C4%B1rken-c0d0a6f7c2e8?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Reinforcement Learning (Pekiştirmeli Öğrenme) — İnsan Beyniyle Aradaki Fark Kapanırken | by Volkan Levent Soylu | Medium</td>\n",
       "      <td>Nov 23, 2017\\nHatırlarsınız, önce 1997’de DeepMind’ın bilgisayarı Deep Blue Kasparov’u satrançta yenmişti. Bir sonraki adımdaysa AlphaGo önce dünya Go şampiyonu Ke Jie’yi, sonrasında da bir üst model AlphaGo Zero en iyi Go oyuncularından biri sayılan Lee Sedol’u 2016’da 3 kez yendi. Şimdi yeni adımın StarCraft olacağı söyleniyor; ki bilen bilir StarCraft koordinasyon, hızlı karar alma, dikkat olarak epey zorlayıcı bir oyundur. AlphaGo bütün bunları Reinforcement Learning (Pekiştirmeli Öğrenme) ile yaptı.\\nPekiştirmeli Öğrenme, Makine Öğrenmesi’nin alt kollarından biri. Makine Öğrenmesi’nde genellikle Markov Karar Süreci adı verilen bir model kullanılıyor. Bu model yapay zekânın önceden bilgilendirilmesine ve yönlendirilmesine dayalı. Kesin bir neden sonuç ili...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>4164</td>\n",
       "      <td>editorCapire.info</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/capire-info/sugerencias-para-definir-un-men%C3%BA-de-navegaci%C3%B3n-e6efe33bfe22?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Sugerencias para definir un menú de navegación | by editorCapire.info | Capire.info | Medium</td>\n",
       "      <td>Capire.info\\nJun 18, 2008\\nEscribe Jorge Garrido G.\\nAlgunas sugerencias sobre cómo construir un menú que entregue orientación y control al usuario, sin perder claridad en su forma de presentarse.¿Qué es un menú? ¿Qué representa? ¿Qué comunica? ¿Para qué sirve? ¿Todo sitio web o aplicación debe tener un menú?\\nLas respuestas no son tan sencillas ni están tan claras; mucho menos se puede considerar este como un tema superado. No lo creo por lo que percibo cuando navego, periódicamente. Veo menús poco cuidados, incomprendidos, mal diseñados, desenfocados.\\nHay muchos otros recursos, fuera de los menús de navegación, para destacar los contenidos más importantes: Accesos directos con características gráficas sobresalientes, listados de hotlinks, nubes de tags y un largo ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>4165</td>\n",
       "      <td>Enoch Kan</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc?source=tag_archive---------0-----------------------</td>\n",
       "      <td>How to implement an Adam Optimizer from Scratch | by Enoch Kan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 6, 2020\\nIt’s not as hard as you think!\\nTl;dr if you want to skip the tutorial. Here is the notebook I created.\\nAdam is algorithm the optimizes stochastic objective functions based on adaptive estimates of moments. The update rule of Adam is a combination of momentum and the RMSProp optimizer.\\nThe rules are simple. Code Adam from scratch without the help of any external ML libraries such as PyTorch, Keras, Chainer or Tensorflow. Only libraries we are allowed to use arenumpy and math .\\n(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ\\nThe easiest way to learn how Adam’s works is to watch Andrew Ng’s video. Alternatively, you can read Adam’s original paper to get a better understanding of the motivation and intuition behind it.\\nTwo values that Adam depend on are ...</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>4166</td>\n",
       "      <td>Towards AI Editorial Team</td>\n",
       "      <td>26</td>\n",
       "      <td>https://pub.towardsai.net/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Machine Learning Algorithms For Beginners with Code Examples in Python | by Towards AI Editorial Team | Towards AI</td>\n",
       "      <td>Towards AI\\nJun 3, 2020\\nAuthor(s): Pratik Shukla, Roberto Iriondo, Sherwin Chen\\nLast updated April 14, 2021\\nmembers.towardsai.net\\nMachine learning (ML) is rapidly changing the world, from diverse types of applications and research pursued in industry and academia. Machine learning is affecting every part of our daily lives. From voice assistants using NLP and machine learning to make appointments, check our calendar, and play music, to programmatic advertisements — that are so accurate that they can predict what we will need before we even think of it.\\nMore often than not, the complexity of the scientific field of machine learning can be overwhelming, making keeping up with “what is important” a very challenging task. However, to make sure that we provide a learning path to those ...</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>4167</td>\n",
       "      <td>Francesco Gadaleta</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/hackernoon/gradient-descent-vs-coordinate-descent-9b5657f1c59f?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Gradient descent vs coordinate descent | by Francesco Gadaleta | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nMay 31, 2014\\nWhen it comes to function minimization, it’s time to open a book of optimization and linear algebra. I am currently working on variable selection and lasso-based solutions in genetics. What lasso does is basically minimizing the loss function and an penalty in order to set to zero some regression coefficients and select only those covariates that are really associated with the response. Pheew, the shortest summary of lasso ever!\\nWe all know that, provided the function to be minimized is convex, a good direction to follow, in order to find a local minimum, is towards the negative gradient of the function. Now, my question is how good or bad is following the negative gradient with respect to a coordinate descent approach that loops across all dimensions and...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>4168</td>\n",
       "      <td>surendranath bobba</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/hackernoon/how-i-deployed-my-spark-document-classification-logistic-regression-model-s-as-a-standalone-app-64b05b44e102?source=tag_archive---------3-----------------------</td>\n",
       "      <td>How I deployed my spark document classification(Logistic Regression) model/s as a standalone app for real-time prediction | by surendranath bobba | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nOct 4, 2016\\nTLDR — Use pipelines to save TF-IDF model generated from the training set, and SVM model for prediction. So essentially save two models, one for feature extraction and transformation of input, the other for prediction.\\nOne of the big challenges when you develop a text classification model, the trained model which you get is not enough for prediction if your plan was to train offline and deploy only the model for prediction in some cases. Especially in the case where we are extracting features from the training set using `Hashing Trick` and to normalise the importance of a feature/term to the document using `Inverse Document Frequency`, the most frequent terms in documents actually have lesser importance to the whole corpus. This is all commonly labelled ac...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>4169</td>\n",
       "      <td>Hshan.T</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/mlearning-ai/demonstrating-customers-segmentation-with-dbscan-clustering-using-python-8a2ba0db2a2e?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Demonstrating Customers Segmentation with DBSCAN Clustering Using Python | by Hshan.T | MLearning.ai | Medium</td>\n",
       "      <td>MLearning.ai\\nMar 4, 2021\\n4 \\n4 \\nData Scientists must think like an artist when finding a solution when creating a piece of code. ⚪️ Artists enjoy working on interesting problems, even if there is no obvious answer ⚪️ linktr.ee/mlearning 🔵 Follow to join our 18K+ Unique DAILY Readers 🟠\\n36 Followers\\nData.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>4170</td>\n",
       "      <td>Sudip Shrestha, PhD</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/nlp-spam-detection-in-sms-text-data-using-deep-learning-b8632db85cc8?source=tag_archive---------7-----------------------</td>\n",
       "      <td>NLP: Spam Detection in SMS (text) data using Deep Learning | by Sudip Shrestha, PhD | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 27, 2020\\nToday, internet and social media have become the fastest and easiest ways to get information. In this age, reviews, opinions, feedbacks, messages and recommendations have become significant source of information. Thanks to advancement in technologies, we are now able to extract meaningful information from such data using various Natural Language Processing (NLP) techniques. NLP , a branch of Artificial Intelligence (AI), makes use of computers and human natural language to output valuable information. NLP is commonly used in text classification task such as spam detection and sentiment analysis, text generation, language translations and document classification.\\nThe purpose of this article is to understand how we can use TensorFlow2 to build SMS spa...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>4171</td>\n",
       "      <td>Tanya Dayanand</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/pos-tagging-using-rnn-7f08a522f849?source=tag_archive---------4-----------------------</td>\n",
       "      <td>POS Tagging Using RNN. Learn how to use RNNs to tag words in... | by Tanya Dayanand | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 3, 2020\\nThe classical way of doing POS tagging is using some variant of Hidden Markov Model. Here we'll see how we could do that using Recurrent neural networks. The original RNN architecture has some variants too. It has a novel RNN architecture — the Bidirectional RNN which is capable of reading sequences in the ‘reverse order’ as well and has proven to boost performance significantly.\\nThen two important cutting-edge variants of the RNN which have made it possible to train large networks on real datasets. Although RNNs are capable of solving a variety of sequence problems, their architecture itself is their biggest enemy due to the problems of exploding and vanishing gradients that occur during the training of RNNs. This problem is solved by two popular ga...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4172</td>\n",
       "      <td>Renu Khandelwal</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/geekculture/deep-convolutional-generative-adversarial-network-using-pytorch-ece1260acc47?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Deep Convolutional Generative Adversarial Network using PyTorch | by Renu Khandelwal | Geek Culture | Medium</td>\n",
       "      <td>Geek Culture\\nMay 6, 2021\\nThis post will learn to create a DCGAN using PyTorch on the MNIST dataset.\\nA basic understanding of CNN\\nA sample implementation using CNN\\nUnderstanding Deep Convolutional GAN\\nGANs were invented by Ian Goodfellow in 2014 and first described in the paper Generative...\\n3 \\n3 \\n1\\nA new tech publication by Start it up (https://medium.com/swlh).\\n3.7K Followers\\nLoves learning, sharing, and discovering myself. Passionate about Machine Learning and Deep Learning\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>4173</td>\n",
       "      <td>Chi-Feng Wang</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------5-----------------------</td>\n",
       "      <td>A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...</td>\n",
       "      <td>4430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>4174</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>18</td>\n",
       "      <td>https://medium.com/@jonathan-hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3 | by Jonathan Hui | Medium</td>\n",
       "      <td>Mar 18, 2018\\nYou only look once (YOLO) is an object detection system targeted for real-time processing. We will introduce YOLO, YOLOv2 and YOLO9000 in this article. For those only interested in YOLOv3, please forward to the bottom of the article. Here is the accuracy and speed comparison provided by the YOLO web site.\\nA demonstration from the YOLOv2.\\nLet’s start with our own testing image below.\\nThe objects detected by YOLO:\\nGrid cell\\nFor our discussion, we crop our original photo. YOLO divides the input image into an S×S grid. Each grid cell predicts only one object. For example, the yellow grid cell below tries to predict the “person” object whose center (the blue dot) falls inside the grid cell.\\nEach grid cell predicts a fixed number of boundary boxes. In this example, the ye...</td>\n",
       "      <td>8487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>4175</td>\n",
       "      <td>Arun Kumar</td>\n",
       "      <td>17</td>\n",
       "      <td>https://towardsdatascience.com/mercari-price-suggestion-97ff15840dbd?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Price Prediction using Machine Learning Regression — a case study | by Arun Kumar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 30, 2020\\nThis article is a detailed account of my approach to solving a regression problem, which is also a popular Kaggle competition. Hope you find it useful and enjoy reading it :)\\nArtificial Intelligence is an integral part of all major e-commerce companies today. With the evolution of the information industry and extensive research in the field of AI in the past two decades, businesses have started to explore the ways to automate various activities using state of the art Machine Learning algorithms and Deep Neural Networks. Many IT giants and start-ups have already taken a big leap in this field and have dedicated teams and resources for research and development of cutting edge AI applications. Online retail platforms today are extensively driven by AI-...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>4176</td>\n",
       "      <td>Bayan Bennett</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/swlh/embeddings-in-machine-learning-548eef7b2b5?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Embeddings in Machine Learning. Embeddings are a basic method to encode... | by Bayan Bennett | The Startup | Medium</td>\n",
       "      <td>The Startup\\nAug 13, 2020\\nI first came across the concept of embeddings while developing the RNN typing practice app.\\nEven though I am just beginning to understand the range of uses for embeddings, I thought it would be useful to write down some of the basics.\\nFirst, let’s look at what I knew before embeddings, one-hot vectors.\\n52 \\n52 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers &amp; +754K followers.\\n13 Followers\\nMy goal is to serve humanity and to bring happiness to others. I want to understand the problems around us and help find solutions. https://www.bayanbennett.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>4177</td>\n",
       "      <td>George Seif</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------3-----------------------</td>\n",
       "      <td>The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...</td>\n",
       "      <td>38267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>4178</td>\n",
       "      <td>Shashank Yadav</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@shashank7-iitd/understanding-attention-mechanism-35ff53fc328e?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Understanding Attention Mechanism | by Shashank Yadav | Medium</td>\n",
       "      <td>Feb 5, 2019\\nAttention mechanism for sequence modelling was first introduced in the paper: Neural Machine Translation by jointly learning to align and translate, Bengio et. al. ICLR 2015. Even though the paper itself mentions the word “attention” scarcely (3 times total in 2 consecutive lines!!) the term has caught on. A lot of prominent work that came later on uses the same naming convention (Well, I for one think it’s more of a “soft memory” rather than “attention”).\\nThis post focuses on Bengio et. al. 2015 and tries to give a step by step explanation of the (attention) model explained in their paper. Probably it’s just me but the explanation given in the paper and the diagrams that came with it left a lot to the imagination. This post tries to make understanding their great work a ...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>4179</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking | by Joseph Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 23, 2019\\nThis post was co-written with Baptiste Rocca.\\n“Unity is strength”. This old saying expresses pretty well the underlying idea that rules the very powerful “ensemble methods” in machine learning. Roughly, ensemble learning methods, that often trust the top rankings of many machine learning competitions (including Kaggle’s competitions), are based on the hypothesis that combining multiple models together can often produce a much more powerful model.\\nThe purpose of this post is to introduce various notions of ensemble learning. We will give the reader some necessary keys to well understand and use related methods and be able to design adapted solutions when needed. We will discuss some well known notions such as boostrapping, bagging, random forest, bo...</td>\n",
       "      <td>8908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>4180</td>\n",
       "      <td>Kopal Jain</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba?source=tag_archive---------8-----------------------</td>\n",
       "      <td>How to Improve Naive Bayes?. Section 3: Tuning the Model in Python | by Kopal Jain | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nApr 2, 2021\\nReference How to Implement Naive Bayes? Section 2: Building the Model in Python, prior to continuing...\\n[10] Define Grid Search Parameters\\nWhy this step: To set the selected parameters used to find the optimal combination. By referencing the sklearn.naive_bayes.GaussianNB documentation, you can find a completed list of parameters with descriptions that can be used in grid search functionalities.\\n[11] Hyperparameter Tune using Training Data\\nNote: Total number of fits is 1000 since the cv is defined as 10 and there are 100 candidates (var_smoothing has 100 defined parameters). Therefore, the calculation for a total number of fits → 10 x [100] = 1000.\\nWhy this step: To find an optimal combination of hyperparameters that minimizes a predefined loss funct...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>4181</td>\n",
       "      <td>Amin Ag</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/ai%C2%B3-theory-practice-business/object-detection-in-deep-learning-part2-855b78689f13?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Object detection in Deep learning (Part2) | by Amin Ag | AI3 | Theory, Practice, Business | Medium</td>\n",
       "      <td>AI3 | Theory, Practice, Business\\nSep 22, 2019\\nR-CNN &amp; Fast R-CNN\\nFollowing part1, an object-detection-algorithm has to draw up to several bounding boxes representing different objects of interest within the image and you would not know how many beforehand.\\nA direct approach (brut force) to solve this issue would be to take different regions of interest from the image and use a CNN to classify the presence of the object within that region. The problem here, the objects of interest might have different spatial locations within the image and different aspect ratios. Hence, you would have to select a huge number of regions and this could computationally hard (increasingly hard). Therefore, algorithms like R-CNN, YOLO, etc have been developed to find these occurrences and find them fast...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>4182</td>\n",
       "      <td>Sema Zeynep Bulut</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/mlearning-ai/a-brief-overview-of-r-cnn-fast-r-cnn-and-faster-r-cnn-9c6843c9ffc0?source=tag_archive---------1-----------------------</td>\n",
       "      <td>A brief overview of R-CNN, Fast R-CNN and Faster R-CNN | by Sema Zeynep Bulut | MLearning.ai | Medium</td>\n",
       "      <td>MLearning.ai\\nMay 6, 2021\\nR-CNN architecture is used to detect the classes of objects in the images and the bounding boxes of these objects. RCNN architecture has been developed since classification cannot be made for more than one object with CNN in visuals containing more than one object.\\nThe general working principle of R-CNN takes place in two steps. First, the features where the object can be found in the visual are determined with selective search, then after the regions are determined, each region is given as an input to a CNN model and the prediction process is performed for classes and bounding boxes.\\nSelective Search:\\nIt is used to determine the regions on the image that should be captured. Small areas are determined first. Then, similar regions are combined to create lar...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>4183</td>\n",
       "      <td>ilmoi</td>\n",
       "      <td>12</td>\n",
       "      <td>https://towardsdatascience.com/evasion-attacks-on-machine-learning-or-adversarial-examples-12f2283e06a1?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Evasion attacks on Machine Learning (or “Adversarial Examples”) | by ilmoi | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 14, 2019\\nMachine learning is exciting. However, just like any new technology or invention, not only does ML enable new amazing capabilities — but also, unfortunately, new vulnerabilities.\\nPreviously I’ve discussed how to think about these vulnerabilities in a structured way (or how to develop a “threat model” for your ML). This time I’d like to dive deep into how your ML system can be exploited during inference time through what is known as an evasion attack.\\nWith no time to waste, let’s get started.\\nAn evasion attack happens when the network is fed an “adversarial example” — a carefully perturbed input that looks and feels exactly the same as its untampered copy to a human — but that completely throws off the classifier.\\nDespite all the hype around adver...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>4184</td>\n",
       "      <td>Andrew Marmon</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/@andrewmarmon/fine-tuned-named-entity-recognition-with-hugging-face-bert-d51d4cb3d7b5?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Fine-Tuned Named Entity Recognition with Hugging Face BERT | by Andrew Marmon | Medium</td>\n",
       "      <td>Aug 5, 2021\\nIn many organizations, there is a unique vocabulary that maps names to known entities within that domain. At the United Nations, for instance, we have many specific entities which it is useful to identify in documents, including specific named committees and assemblies, important topics like the Sustainable Development Goals (SGDs), and many different countries and cultural groups that must be identified correctly. Exhaustively naming each and every important topic that may appear in a document, however, is not reasonable considering the shear number that may be important, especially considering the context of a document or sentence in which this entity is present. Instead, we want to be able to automatically identify and predict named entities using Named Entity Recogniti...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>4185</td>\n",
       "      <td>Prince Grover</td>\n",
       "      <td>8</td>\n",
       "      <td>https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Gradient Boosting from scratch. Simplifying a complex algorithm | by Prince Grover | ML Review</td>\n",
       "      <td>ML Review\\nDec 9, 2017\\nSimplifying a complex algorithm\\nAlthough most of the Kaggle competition winners use stack/ensemble of various models, one particular model that is part of most of the ensembles is some variant of Gradient Boosting (GBM) algorithm. Take for an example the winner of latest Kaggle competition: Michael Jahrer’s solution with representation learning in Safe Driver Prediction. His solution was a blend of 6 models. 1 LightGBM (a variant of GBM) and 5 Neural Nets. Although his success is attributed to the semi-supervised learning that he used for the structured data, but gradient boosting model has done the useful part too.\\nEven though GBM is being used widely, many practitioners still treat it as complex black-box algorithm and just run the models using pre-built lib...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>4186</td>\n",
       "      <td>Andre Violante</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning: Q-learning | by Andre Violante | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMar 18, 2019\\nOne of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it seemed to make sense. In this quick post I’ll discuss q-learning and provide the basic background to understanding the algorithm.\\nQ-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It’s considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn’t needed. More specifically, q-learning seeks to learn a policy that maximizes the total reward.\\nThe ‘q’ in q-learning stands for quali...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>4187</td>\n",
       "      <td>Arthur Juliani</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium</td>\n",
       "      <td>Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...</td>\n",
       "      <td>16886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4188</td>\n",
       "      <td>Rizky Luthfianto</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/blog-rilut/neural-networks-without-backpropagation-direct-feedback-alignment-30d5d4848f5?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Neural Networks without Backpropagation: Direct Feedback Alignment | by Rizky Luthfianto | Blog rilut | Medium</td>\n",
       "      <td>Blog rilut\\nJan 3, 2017\\nHere’s a quick summary on Arild Nøkland’s 2016 paper “Direct Feedback Alignment” which is not only written clearly but also interesting. Both Lillicrap et al. (2016) and Nøkland (2016) were able to train a Neural Network (NN) without Backpropagation.\\nFirst, create a simple NN like this:\\nwith cross-entropy as its loss function.\\nSo here is our implementation so far:\\nTo train a NN, we have to get the loss function derivative w.r.t to softmax function. Let’s take a look at Equation 5 from Nøkland’s paper.\\nwhich simply corresponds to:\\nI am sorry as I am not going to explain the Calculus behind this. Should you refer to Sadowski’s Notes on Backpropagation if you want the explanation.\\nThis is our implementation of Backpropagation:\\nWhere d1, d2, and ewill be us...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4189</td>\n",
       "      <td>Azad Soni</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/clustering-with-gaussian-mixture-model/clustering-with-gaussian-mixture-model-c695b6cd60da?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Clustering with Gaussian Mixture Model | by Azad Soni | Clustering with Gaussian Mixture Model | Medium</td>\n",
       "      <td>Clustering with Gaussian Mixture Model\\nDec 5, 2017\\nOne of the popular problems in unsupervised learning is clustering. Clustering is the assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense.\\nAs in above diagram the result of clustering is colouring of the squares into three clusters.\\nOne of the basic approach to solve cluster analysis problem is K-means. K-means algorithm partitioned the data into K clusters .\\nK means:\\nIn general, suppose we have n data points, that have to be partitioned in K clusters. The goal is to assign a cluster to each data point. K-means is a clustering method that aims to find the K positions of the clusters that minimize the distance(for example Euclidian distance) from the...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>4190</td>\n",
       "      <td>JP Zamanillo</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/training-a-spacy-ner-pipeline-with-prodigy-ca58350cb868?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Training a spaCy NER Pipeline with Prodigy | by JP Zamanillo | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nApr 26, 2021\\nThe success of a custom Named Entity Recognition (NER) model is dependent on the quality of data passed to it. However, supplying a model with sufficient examples of training data is typically a time-consuming and exhaustive process. Using Prodigy, the task of labeling your data for building a custom NER pipeline to a spaCy model is much quicker and simpler.\\nAccording to the official Prodigy site:\\nProdigy is a modern annotation tool for creating training and evaluation data for machine learning models. You can also use Prodigy to help you inspect and clean your data, do error analysis and develop rule-based systems to use in combination with your statistical models.\\nProdigy makes it easy to label your data to use in model training. For this overview, ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>4191</td>\n",
       "      <td>Anson Wong</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/solving-the-multi-armed-bandit-problem-b72de40db97c?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Solving the Multi-Armed Bandit Problem | by Anson Wong | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 25, 2017\\nThe multi-armed bandit problem is a classic reinforcement learning example where we are given a slot machine with n arms (bandits) with each arm having its own rigged probability distribution of success. Pulling any one of the arms gives you a stochastic reward of either R=+1 for success, or R=0 for failure. Our objective is to pull the arms one-by-one in sequence such that we maximize our total reward collected in the long run.\\nThe non-triviality of the multi-armed bandit problem lies in the fact that we (the agent) cannot access the true bandit probability distributions — all learning is carried out via the means of trial-and-error and value estimation. So the question is:\\nHow can we design a systematic strategy that adapts to these stochastic re...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>4192</td>\n",
       "      <td>Patrick Langechuan Liu</td>\n",
       "      <td>16</td>\n",
       "      <td>https://towardsdatascience.com/single-stage-instance-segmentation-a-review-1eeb66e0cc49?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Single Stage Instance Segmentation — A Review | by Patrick Langechuan Liu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 28, 2020\\nUpdate:\\nInstance segmentation is a challenging computer vision task that requires the prediction of object instances and their per-pixel segmentation mask. This makes it a hybrid of semantic segmentation and object detection.\\nEver since Mask R-CNN was invented, the state-of-the-art method for instance segmentation has largely been Mask RCNN and its variants (PANet, Mask Score RCNN, etc). It adopts the detect-then-segment approach, first perform object detection to extract bounding boxes around each object instances, and then perform binary segmentation inside each bounding box to separate the foreground (object) and the background.\\nThere are some other instance segmentation methods other than the top-down approach of detect-then-segment (or segmen...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>4193</td>\n",
       "      <td>Aqeel Anwar</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Difference between AutoEncoder (AE) and Variational AutoEncoder (VAE) | by Aqeel Anwar | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 3, 2021\\nThe ability to simplify means to eliminate the unnecessary so that the necessary may speak — Hans Hofmann\\nData compression is an essential phase in training a network. The idea is to compress the data so that the same amount of information can be represented by fewer bits. This also helps with the problem of the curse of dimensionality. A dataset with many attributes is different to train with because it tends to overfit the model. Hence dimensionality reduction techniques need to be applied before the dataset can be used for training.\\nThis is where the Autoencoder (AE) and Variational Autoencoder (VAE) come into play. They are end-to-end networks that are used to compress the input data. Both Autoencoder and Variational Autoencoder are used to tran...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>4194</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/predict-customer-churn-with-r-9e62357d47b4?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Predict Customer Churn with R. For any service company that bills on a... | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 16, 2017\\nFor any service company that bills on a recurring basis, a key variable is the rate of churn. Harvard Business Review, March 2016\\nFor just about any growing company in this “as-a-service” world, two of the most important metrics are customer churn and lifetime value. Entrepreneur, February 2016\\nCustomer churn occurs when customers or subscribers stop doing business with a company or service, also known as customer attrition. It is also referred as loss of clients or customers. One industry in which churn rates are particularly useful is the telecommunications industry, because most customers have multiple options from which to choose within a geographic location.\\nSimilar concept with predicting employee turnover, we are going to predict customer c...</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>4195</td>\n",
       "      <td>Boris Knyazev</td>\n",
       "      <td>16</td>\n",
       "      <td>https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Anisotropic, Dynamic, Spectral and Multiscale Filters Defined on Graphs | by Boris Knyazev | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 12, 2019\\nI’m presenting an overview of important Graph Neural Network works, by distilling key ideas and explaining simple intuition behind milestone methods using Python and PyTorch. This post continues the first part of my tutorial.\\nIn the “Graph of Graph Neural Network (GNN) and related works” above, I added papers on graphs that I have come across in the last year. In this graph, a directed edge between two works denotes that one paper is based on the other (while not necessary citing it) and a color of the work denotes:\\nNote, that some other important works and edges are not shown to avoid further clutter, and only a tiny fraction of works, highlighted in bold boxes, will be covered in this post. Disclaimer: I still found room to squeeze our own recent...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>4196</td>\n",
       "      <td>Sabina Pokhrel</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/important-topics-in-machine-learning-you-need-to-know-21ad02cc6be5?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Important Topics in Machine Learning You Need to Know | by Sabina Pokhrel | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 4, 2019\\nMachine learning is a hot topic right now and everyone is trying to get their hands on any information they can get about the topic. With the amount of information that is out there about machine learning, one can get overwhelmed. In this post, I have listed some of the most important topics in machine learning that you need to know, along with some resources which can help you in further reading about the topics which you are interested to know in-depth.\\nAI is a branch of computer science that aims to create intelligent machines that mimic human behaviour such as knowledge, reasoning, problem-solving, perception, learning, planning, ability to manipulate and move objects\\nAI is an area of computer science that emphasizes the creation of intelligent ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>4197</td>\n",
       "      <td>Essam Wisam</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Deriving Backpropagation with Cross-Entropy Loss | by Essam Wisam | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 2, 2021\\nThere is a myriad of loss functions that you can choose for your neural network. The choice of loss function is imperative for the network’s performance because eventually the parameters in the network are going to be set such that the loss is minimized.\\nCross-Entropy loss is a popular choice if the problem at hand is a classification problem, and in and of itself it can be classified into either categorical cross-entropy or multi-class cross-entropy (with binary cross-entropy being a special case of the former.) In case you’re scratching your head about how different are these, I’ll try to introduce each before delving into the derivation.\\nLet’s start with categorical cross-entropy. For this loss function our y’s are one-hot encoded to denote the c...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>4198</td>\n",
       "      <td>Zijing Zhu</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/wthe-ultimate-guide-to-clustering-algorithms-and-topic-modeling-4f7757c115?source=tag_archive---------4-----------------------</td>\n",
       "      <td>The Ultimate Guide to Clustering Algorithms and Topic Modeling | by Zijing Zhu | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 23, 2021\\nClustering is one of the most used unsupervised machine learning algorithms. You can think of clustering as putting unorganized data points into different categories so that you can learn more about the structures of your data. Clustering has a variety of applications in extracting information from data without labels. For example, companies cluster customers based on their characteristics, like purchasing behaviors, to make better market campaigns, to set pricing strategies to make more profit, etc. Clustering algorithms are also widely used in natural language processing (NLP) to extract information from unstructured textual data, and topic modeling is one example.\\nThe series of articles aims to provide readers with a thorough view of two common b...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>4199</td>\n",
       "      <td>Varun Saravanan</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/text-summarization-from-scratch-using-encoder-decoder-network-with-attention-in-keras-5fa80d12710e?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Text Summarization from scratch using Encoder-Decoder network with Attention in Keras | by Varun Saravanan | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 14, 2020\\nDuring our school days, most of us would have encountered the reading comprehension section of our English paper. We would be given a paragraph or Essay based on which we need to answer several questions.\\nHow do we as humans approach this task at hand? We go through the entire text, make sense of the context in which the question is asked and then we write answers. Is there a way we can use AI and deep learning techniques to mimic this behavior of us?\\nAutomatic text summarization is a common problem in machine learning and natural language processing (NLP). There are two approaches to this problem.\\n2. Abstractive Summarization-Abstractive text summarization, on the other hand, is a technique in which the summary is generated by generating novel se...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>4200</td>\n",
       "      <td>DataAnalysis For Beginner</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/@univprofblog1/linear-discriminant-analysis-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-4acfffc4726?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Linear Discriminant Analysis: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium</td>\n",
       "      <td>Aug 26, 2016\\nI release MATLAB, R and Python codes of Linear Discriminant Analysis (LDA). They are very easy to use. You prepare data set, and just run the code! Then, LDA and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/uVtRo Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/bZPL Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/JHFt Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univp...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>4201</td>\n",
       "      <td>Carlos E. Perez</td>\n",
       "      <td>12</td>\n",
       "      <td>https://medium.com/intuitionmachine/the-strange-loop-in-alphago-zeros-self-play-6e3274fcdd9f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Why AlphaGo Zero is a Quantum Leap Forward in Deep Learning | by Carlos E. Perez | Intuition Machine | Medium</td>\n",
       "      <td>Intuition Machine\\nOct 22, 2017\\nSelf-play is Automated Knowledge Creation\\nThe 1983 movie “War Games” has a memorable climax where the supercomputer known as WOPR (War Operation Plan Response) is asked to train on itself to discover the concept of an un-winnable game. The character played by Mathew Broderick asks “Is there any way that it can play itself?”\\n34 years later, DeepMind has shown how this is exactly done in real life! The solution is the same, set the number of players to zero (i.e. zero humans).\\nThere is plenty to digest about this latest breakthrough in Deep Learning technology. DeepMind authors use the term “self-play reinforcement learning”. As I remarked in the piece about “Tribes of AI”, DeepMind is particularly fond of their Reinforcement Learning (RL) approach. De...</td>\n",
       "      <td>3355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>4202</td>\n",
       "      <td>Ilma Arifiany</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@arifiany/segmentasi-semantik-untuk-klasifikasi-citra-a004b3906250?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Segmentasi Semantik untuk Klasifikasi Citra | by Ilma Arifiany | Medium</td>\n",
       "      <td>Sep 3, 2018\\nSegmentasi citra merupakan bagian dari proses pengolahan citra. Segmentasi citra (image segmentation) mempunyai arti membagi suatu citra menjadi wilayah-wilayah yang homogen berdasarkan kriteria keserupaan tertentu antara suatu piksel dengan piksel — piksel tetangganya, kemudian hasil dari proses segmentasi ini akan digunakan untuk proses tingkat tinggi lebih lanjut yang dapat dilakukan terhadap suatu citra, misalnya proses klasifikasi citra dan proses identifikasi objek.\\nSegmentasi semantik adalah proses klasifikasi setiap piksel dari sebuah citra sebagai sebuah label kelas untuk memahami citra dalam tingkat per piksel. Label kelas yang yang dimaksud adalah kelas objek, seperti rumah, buku, manusia, dan lain-lain.\\nSelain mengenali dan membedakan pengendara dan motor, se...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>4203</td>\n",
       "      <td>Dinesh</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@humble_bee/rnn-recurrent-neural-networks-lstm-842ba7205bbf?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Beginner’s Guide to RNN &amp; LSTMs. Let’s understand how exactly RNN and... | by Dinesh | Medium</td>\n",
       "      <td>Dec 5, 2019\\nWhat is RNN?\\nRecurrent Neural Network is basically a generalization of feed-forward neural network that has an internal memory. RNNs are a special kind of neural networks that are designed to effectively deal with sequential data. This kind of data includes time series (a list of values of some parameters over a certain period of time) text documents, which can be seen as a sequence of words, or audio, which can be seen as a sequence of sound frequencies over time.RNN is recurrent in nature as it performs the same function for every input of data while the output of the current input depends on the past one computation. For making a decision, it considers the current input and the output that it has learned from the previous input.\\nCells that are a function of inputs fro...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>4204</td>\n",
       "      <td>Boris Anthony</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@borisanthony/puppyslugs-r-us-part-1-88461c2104ba?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Puppyslugs ‘R Us: Part 1. In “Puppyslugs ‘R Us: Part 0”, I... | by Boris Anthony | Medium</td>\n",
       "      <td>Aug 5, 2015\\nIn “Puppyslugs ‘R Us: Part 0”, I started out quite cheekily on a topic I hope to explore here in a bit more serious detail.\\nI am going to start with the recent Google “DeepDream” release and the so-called Puppyslug images you’ve likely encountered, explaining roughly what those are and how they come to be. I will connect that to AI and algorithms in general and then move specifically to how they already appear in your everyday mobile experience. From there we can paint a picture of what’s in store for us, and why I say... the Puppyslugs are Us. I’ll conclude by setting up Part 2, and how all of this lands squarely in the lap of Design to deal with.\\nPuppyslugs. Quick background:\\nAbout two months ago (early June 2015), Google Researchers start showing off some algorithmic...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>4205</td>\n",
       "      <td>Shuchen Du</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/ai-salon/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Understanding Deep Self-attention Mechanism in Convolution Neural Networks | by Shuchen Du | AI Salon | Medium</td>\n",
       "      <td>AI Salon\\nJan 8, 2020\\nConvolution neural networks (CNN) are broadly used in deep learning and computer vision algorithms. Even though many CNN-based algorithms meet industry standards and can be embedded in commercial products...\\n422 \\n422 \\n1\\nA tea drinking place to talk about AI\\n198 Followers\\nMachine learning engineer based in Tokyo\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>4206</td>\n",
       "      <td>Rising Odegua</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Transfer learning and Image classification using Keras on Kaggle kernels. | by Rising Odegua | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 2, 2018\\nIn my last post, we trained a convnet to differentiate dogs from cats. We trained the convnet from scratch and got an accuracy of about 80%. Not bad for a model trained on very little dataset (4000 images).\\nBut in real world/production scenarios, our model is actually under-performing.\\nAlthough we suggested tuning some hyperparameters — epochs, learning rates, input size, network depth, backpropagation algorithms e.t.c — to see if we could increase our accuracy.\\nWell, I did try...\\nAnd truth is, after tuning, re-tuning, not-tuning , my accuracy wouldn’t go above 90% and at a point It was useless.\\nOf course having more data would have helped our model; But remember we’re working with a small dataset, a common problem in the field of deep learning.\\...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>4207</td>\n",
       "      <td>Prem Chandra Singh</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/analytics-vidhya/understanding-the-stylegan-and-stylegan2-architecture-add9e992747d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Understanding the StyleGAN and StyleGAN2 Architecture | by Prem Chandra Singh | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nFeb 12, 2021\\nThe article contains the introduction of StyleGAN and StyleGAN2 architecture which will give you an idea. It may help you to start with StyleGAN. You will find some metric or the operations name which you don’t know, to gain a deep understanding of StyleGAN and StyleGAN2 you can go through the paper whose link is provided in the resources section.\\nLet’s start with the StyleGAN and then we move towards StyleGAN 2.\\nThe major changes they have done in the Generator part of the “Progressive Growing of GANs” architecture. Below you can see both the traditional and the style-based generator (new one or StyleGAN network) network.\\nIn the traditional network, latent vectors directly pass into the block just after the normalization whereas in the StyleGAN netwo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>4208</td>\n",
       "      <td>Jonathan Hui</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/@jonathan-hui/map-mean-average-precision-for-object-detection-45c121a31173?source=tag_archive---------1-----------------------</td>\n",
       "      <td>mAP (mean Average Precision) for Object Detection | by Jonathan Hui | Medium</td>\n",
       "      <td>Mar 7, 2018\\nAP (Average precision) is a popular metric in measuring the accuracy of object detectors like Faster R-CNN, SSD, etc. Average precision computes the average precision value for recall value over 0 to 1. It sounds complicated but actually pretty simple as we illustrate it with an example. But before that, we will do a quick recap on precision, recall, and IoU first.\\nPrecision &amp; recall\\nPrecision measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\\nRecall measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions.\\nHere are their mathematical definitions:\\nFor example, in the testing for cancer:\\nIoU (Intersection over union)\\nIoU measures the overlap between ...</td>\n",
       "      <td>6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>4209</td>\n",
       "      <td>EarnSkins</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@earnskins/guide-pop-slots-casino-level-27-13-easy-a387f127d9f3?source=tag_archive---------7-----------------------</td>\n",
       "      <td>GUIDE: POP! Slots Casino — Level 27 &amp; 34 ($13+) [EASY] | by EarnSkins | Medium</td>\n",
       "      <td>Jul 8, 2020\\nGuide made for EarnSkins users, by JaxStart the offer now at www.earnskins.gg to earn some side money!Use referral code ‘wolf’ to get yourself a free 50 points to start with.\\nUPDATE: The offer is currently to finish Level 34, this strategy still works, tested and confirmed, however it takes a bit longer now.\\nVideo Guide: https://youtu.be/AIEBGMRPe7I\\nThe POP! Slots offer is a casino/slots based app offer that exists for both iOS and Android phones. The offer required me to reach level 27 in the app, which was easily obtainable and you can automate it really easy making the time spent actually doing anything is extremely low.\\nThere’s three different types of this offer that I’m aware of. One requires you to reach level 27, one level 26 while the last one requires you to ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>4210</td>\n",
       "      <td>Gene Su</td>\n",
       "      <td>13</td>\n",
       "      <td>https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-2-cf81bf32c73d?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Seq2seq pay Attention to Self Attention: Part 2 | by Gene Su | Medium</td>\n",
       "      <td>Oct 3, 2018\\nPart 1 https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-1-d332e85e9aad\\nChinese Version https://medium.com/%40bgg/seq2seq-pay-attention-to-self-attention-part-2-%E4%B8%AD%E6%96%87%E7%89%88-ef2ddf8597a4\\nWe have talked about Seq2seq and Attention model in the first part. In this part, I will be focusing on Self attention, proposed by Google in the paper “Attention is all you need”. Self attention is the concept of “The transformer”model, which outperforms the attention model in various tasks. Two main concepts of the “transformer” model are “self attention” and “multi-head”.\\nThe biggest advantage comes from how The Transformer lends itself to parallelization and self attention.\\nHope you enjoy it.\\nI will use the figure in part 1 as a quick overview. We...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>4211</td>\n",
       "      <td>Isaac Godfried</td>\n",
       "      <td>14</td>\n",
       "      <td>https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Attention for time series forecasting and classification | by Isaac Godfried | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 10, 2019\\nTransformers (specifically self-attention) have powered significant recent progress in NLP. They have enabled models like BERT, GPT-2, and XLNet to form powerful language models that can be used to generate text, translate text, answer questions, classify documents, summarize text, and much more. With their recent success in NLP one would expect widespread adaptation to problems like time series forecasting and classification. After all, both involve processing sequential data. However, to this point research on their adaptation to time series problems has remained limited. Moreover, while some results are promising, others remain more mixed. In this article, I will review current literature on applying transformers as well as attention more broadly ...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>4212</td>\n",
       "      <td>Ashutosh Bhardwaj</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Silhouette Coefficient. This is my first medium story, so... | by Ashutosh Bhardwaj | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 26, 2020\\nAfter learning and applying several supervised ML algorithms like least square regression, logistic regression, SVM, decision tree etc. most of us try to have some hands-on unsupervised learning by implementing some clustering techniques like K-Means, DBSCAN or HDBSCAN.\\nWe usually start with K-Means clustering. After going through several tutorials and Medium stories you will be able to implement k-means clustering easily. But as you implement it, a question starts to bug your mind: how can we measure its goodness of fit? Supervised algorithms have lots of metrics to check their goodness of fit like accuracy, r-square value, sensitivity, specificity etc. but what can we calculate to measure the accuracy or goodness of our clustering technique? The a...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>4213</td>\n",
       "      <td>Destin Gong</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/clustering-algorithm-for-customer-segmentation-e2d79e28cbc3?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Clustering Algorithm for Customer Segmentation | by Destin Gong | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 4, 2021\\nIn a business context: Clustering algorithm is a technique that assists customer segmentation which is a process of classifying similar customers into the same segment. Clustering algorithm helps to better understand customers, in terms of both static demographics and dynamic behaviors. Customer with comparable characteristics often interact with the business similarly, thus business can benefit from this technique by creating tailored marketing strategy for each segment.\\nIn a data science context: Clustering algorithm is an unsupervised machine learning algorithm that discovers groups of data points that are closely related. The fundamental difference between supervised and unsupervised algorithm is that:\\nAfter giving an overview of what is cluster...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>4214</td>\n",
       "      <td>Sagi eppel</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/train-neural-net-for-semantic-segmentation-with-pytorch-in-50-lines-of-code-830c71a6544f?source=tag_archive---------8-----------------------</td>\n",
       "      <td>Train a neural net for semantic segmentation in 50 lines of code, with Pytorch | by Sagi eppel | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 3, 2021\\nHow to train a neural net for semantic segmentation in less than 50 lines of code (40 if you exclude imports). The goal here is to give the fastest simplest overview of how to train semantic segmentation neural net in PyTorch using the built-in Torchvision neural nets (DeepLabV3).\\nCode is available: https://github.com/sagieppel/Train-Semantic-Segmentation-Net-with-Pytorch-In-50-Lines-Of-Code\\nThe goal is semantic segmentation is to take images and identify regions belonging to specific classes. This is done by processing the image through a convolution neural network that outputs a map with a class per pixel. The classes are given as a set of numbers. For example, in this case, we will use the LabPics V1 dataset with three classes (shown in the figur...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>4215</td>\n",
       "      <td>Jake Grigsby</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/multivariate-time-series-forecasting-with-transformers-384dc6ce989b?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Multivariate Time Series Forecasting with Transformers | by Jake Grigsby | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 28, 2021\\nMany real-world applications of Machine Learning involve making predictions about the outcomes of a group of related variables based on historical context. We might want to forecast the traffic conditions on connected roads, the weather at nearby locations, or the demand for similar products. By modeling multiple time series together, we hope that changes in one variable may reveal key information about the behavior of related variables. Multivariate Time Series Forecasting (TSF) datasets have two axes of difficulty: we need to learn temporal relationships to understand how values change over time and spatial relationships to know how variables impact one another.\\nPopular statistical approaches to TSF can struggle to interpret long context sequences...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>4216</td>\n",
       "      <td>Piero Esposito</td>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/blitz-a-bayesian-neural-network-library-for-pytorch-82f9998916c7?source=tag_archive---------4-----------------------</td>\n",
       "      <td>BLiTZ — A Bayesian Neural Network library for PyTorch | by Piero Esposito | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 4, 2020\\nThis is a post on the usage of a library for Deep Bayesian Learning. If you are new to the theme, you may want to seek one of the many posts on medium about it or just the documentation section on Bayesian DL of our lib repo.\\nAs there is a rising need for gathering uncertainty over neural network predictions, using Bayesian Neural Network layers became one of the most intuitive approaches — and that can be confirmed by the trend of Bayesian Networks as a study field on Deep Learning.\\nIt occurs that, despite the trend of PyTorch as a main Deep Learning framework (for research, at least), no library lets the user introduce Bayesian Neural Network layers intro their models with as ease as they can do it with nn.Linear and nn.Conv2d, for example.\\nLogic...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>4217</td>\n",
       "      <td>Adrian Yijie Xu</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/gradientcrescent/neural-art-style-transfer-with-keras-theory-and-implementation-91b7fb08ee81?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Neural Art Style Transfer with Keras — Theory and Implementation | by Adrian Yijie Xu | GradientCrescent | Medium</td>\n",
       "      <td>GradientCrescent\\nFeb 4, 2019\\nIntroduction\\nOver the past five years, neural networks have received attention through AI-generated art pieces, whether these be paintings, poetry, or music. During October of last year, an AI-generated art piece sold for over $400,000 at an auction at Christie’s, sparking debate and discussion over the intrinsic value and nature of art generated by machines.\\nWhile most of these mentioned art pieces were original pieces generated through Generative Adversarial Networks (GAN’s, which we will discuss in a future tutorial), apps such as PRISMA have been receiving attention for being able to apply the styles of famous paintings to one’s own photos. The concept, known as neural style transfer (henceforth NST), was first introduced in a paper by Leon Gatys et...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>4218</td>\n",
       "      <td>Maryam Fallah</td>\n",
       "      <td>12</td>\n",
       "      <td>https://techblog.ezra.com/different-embedding-models-7874197dc410?source=tag_archive---------6-----------------------</td>\n",
       "      <td>What are the common word embeddings? | The Ezra Tech Blog</td>\n",
       "      <td>The Ezra Tech Blog\\nMar 4, 2021\\nEmbeddings are an important component of natural language processing pipelines. They refer to the vector representation of textual data. You can think of embeddings as a transformation from human-readable text to computer-readable numbers or vectors as seen in Fig. 1. These embeddings can be used in any machine learning task that takes text as the input, e.g. question answering, classification, text generation.\\nDifferent embedding techniques vary in their complexity and capabilities. For instance, the most simple form of word embeddings can be represented with one-hot encodings where each word in the corpus of size V is mapped to a unique index in a vector of the same size. This gives us a vector of all zeros except for one element that indicates the w...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>4219</td>\n",
       "      <td>The NYT Open Team</td>\n",
       "      <td>3</td>\n",
       "      <td>https://open.nytimes.com/equake-85b6566b7f2?source=tag_archive---------8-----------------------</td>\n",
       "      <td>EQuake. Riley Davis and David Souther... | by The NYT Open Team | NYT Open</td>\n",
       "      <td>NYT Open\\nSep 30, 2013\\nBy RILEY DAVIS and DAVID SOUTHER\\nRiley Davis and David Souther collaborated on EQuake, a 3D earthquake visualizer they developed in about a day. They discuss their motivations and approach in this piece.\\nWe were inspired by this xkcd comic imagining a situation in which tweets about an earthquake spread faster than the earthquake’s seismic waves.\\nWe both like to make complex scientific information more accessible by tying it to scales that people already understand. We thought it would be interesting to plot waves from real earthquakes onto a globe to show how fast the waves actually travel through the crust. This tool could easily be used to map out tweets (or any other geographic data) when other earthquakes occurred. To implement this, we were able to use ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>4220</td>\n",
       "      <td>Kenny Jones</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/gangogh-creating-art-with-gans-8d087d8f74a1?source=tag_archive---------1-----------------------</td>\n",
       "      <td>GANGogh: Creating Art with GANs. Introduction: | by Kenny Jones | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 18, 2017\\nIntroduction:\\nThe work here presented is the result of a semester long independent research performed by Kenny Jones and Derrick Bonafilia (both Williams College 2017) under the guidance of Professor Andrea Danyluk. The code associated with this project can be found at https://github.com/rkjones4/GANGogh. Kenny and Derrick are both heading to Facebook next year as Software Engineers and hope to continue studying GANs in whatever capacity is available to them.\\nBackground:\\nGenerative Adversarial Networks (GANS) were introduced by Ian Goodfellow et. al. in a 2014 paper. GANs address the lack of relative success of deep generative models compared to deep discriminative models. The authors cite the intractable nature of the maximum likelihood estimatio...</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>4221</td>\n",
       "      <td>Charlie Kufs</td>\n",
       "      <td>6</td>\n",
       "      <td>https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------1-----------------------</td>\n",
       "      <td>The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English</td>\n",
       "      <td>Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>4222</td>\n",
       "      <td>Boris Knyazev</td>\n",
       "      <td>17</td>\n",
       "      <td>https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-1-3d9fada3b80d?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Tutorial on Graph Neural Networks for Computer Vision and Beyond | by Boris Knyazev | Medium</td>\n",
       "      <td>Aug 4, 2019\\nI’m answering questions that AI/ML/CV people not familiar with graphs or graph neural networks typically ask. I provide PyTorch examples to clarify the idea behind this relatively new and exciting kind of model.\\nThe questions addressed in this part of my tutorial are:\\nTo answer them, I’ll provide motivating examples, papers and Python code making it a tutorial on Graph Neural Networks (GNNs). Some basic knowledge of machine learning and computer vision is expected, however, I’ll provide some background and intuitive explanation as we go.\\nFirst of all, let’s briefly recall what is a graph? A graph G is a set of nodes (vertices) connected by directed/undirected edges. Nodes and edges typically come from some expert knowledge or intuition about the problem. So, it can be a...</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>4223</td>\n",
       "      <td>DataCrafts @ DataWeave</td>\n",
       "      <td>3</td>\n",
       "      <td>https://medium.com/dataweave/smartphones-vs-tablets-does-size-matter-963ab7dd6052?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Smartphones vs Tablets: Does size matter? | by DataCrafts @ DataWeave | DataWeave | Medium</td>\n",
       "      <td>DataWeave\\nAug 4, 2015\\nWe have seen a steady increase in the number of smartphones and tablets since the last five years. Looking at the number of smartphones, tablets and now wearables ( smart watches and fitbits ) that are being launched in the mobiles market, we can truly call this ‘The Mobile Age’.\\nWe, at DataWeave, deal with millions of data points related to products which vary from electronics to apparel. One of the main challenges we encounter while dealing with this data is the amount of noise and variation present for the same products across different stores.\\nOne particular problem we have been facing recently is detecting whether a particular product is a mobile phone (smartphone) or a tablet. If it is mentioned explicitly somewhere in the product information or metadata...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>4224</td>\n",
       "      <td>Baptiste Monpezat</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/stochastic-gradient-descent-for-machine-learning-clearly-explained-cadcc17d3d11?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Stochastic Gradient Descent for machine learning clearly explained | by Baptiste Monpezat | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 1, 2020\\nAs you may know, supervised machine learning consists in finding a function, called a decision function, that best models the relation between input/output pairs of data. In order to find this function, we have to formulate this learning problem into an optimization problem.\\nLet’s consider the following task: finding the best linear function that maps the input space, the variable X to the output space, the variable Y.\\nAs we try to model the relation between X and Y by a linear function, the set of functions that the learning algorithm is allowed to select is the following :\\nThe term b is the intercept, also called bias in machine learning. This set of functions is our hypothesis space.But how do we choose the values for the parameters a,b and how ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>4225</td>\n",
       "      <td>Maarten Grootendorst</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Keyword Extraction with BERT | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 29, 2020\\nWhen we want to understand key information from specific documents, we typically turn towards keyword extraction. Keyword extraction is the automated process of extracting the words and phrases that are most relevant to an input text.\\nWith methods such as Rake and YAKE! we already have easy-to-use packages that can be used to extract keywords and keyphrases. However, these models typically work based on the statistical properties of a text and not so much on semantic similarity.\\nIn comes BERT. BERT is a bi-directional transformer model that allows us to transform phrases and documents to vectors that capture their meaning.\\nWhat if we were to use BERT instead of statistical models?\\nAlthough there are many great papers and solutions out there that ...</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4226</td>\n",
       "      <td>Chi-Feng Wang</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------0-----------------------</td>\n",
       "      <td>A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...</td>\n",
       "      <td>4430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>4227</td>\n",
       "      <td>Bruce MacDonald</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/fooling-facial-detection-with-fashion-d668ed919eb?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Fooling Facial Detection with Fashion | by Bruce MacDonald | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 4, 2019\\nUsage of facial recognition is on the rise. With the recent debates over the ethics of facial recognition potential adversarial attacks against facial detection have been on my mind. Facial recognition is being used everywhere from airports to social media. It seems to be near impossible to opt-out of having your face scanned.\\nAn ideal attack on facial detection would be an article of clothing that looks inconspicuous to the uninformed. With inspiration from the Hyperface project I decided to research and implement a wearable adversarial example. In this article I’ll detail the process of creating an adversarial image to fool a selected type of facial detection and how I implemented a practical example on a face mask.\\nThe first thing it’s important ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>4228</td>\n",
       "      <td>Connor Shorten</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/stylegan2-ace6d3da405d?source=tag_archive---------2-----------------------</td>\n",
       "      <td>StyleGAN2. This article explores changes made in... | by Connor Shorten | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 17, 2019\\nThe first version of the StyleGAN architecture yielded incredibly impressive results on the facial image dataset known as Flicker-Faces-HQ (FFHQ). The most impressive characteristic of these results, compared to early iterations of GANs such as Conditional GANs or DCGANs, is the high resolution (10242) of the generated images. In addition to resolution, GANs are compared along dimensions such as the diversity of images generated (avoiding mode collapse) and a suite of quantitative metrics comparing real and generated images such as FID, Inception Score, and Precision and Recall.\\nFrechet Inception Distance (FID) is one of the most common automated metrics used to evaluate images sampled from generative models. This metric is based on comparing activa...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>4229</td>\n",
       "      <td>Pankaj Mathur</td>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/pankajmathur/logistic-regression-with-tensorflow-a02c2bd2bd1e?source=tag_archive---------1-----------------------</td>\n",
       "      <td>Quick Logistic Regression with TensorFlow | by Pankaj Mathur | Pankaj Mathur | Medium</td>\n",
       "      <td>Pankaj Mathur\\nApr 1, 2016\\nHere is a simple logistic regression model built with TensorFlow. We are using MNIST Image example data set which is provided by default with Tensorflow package.\\nHere are the hyperparameters we choose to run initial model:\\nWe achieved impressive 90.8% accuracy in 20 epochs with a learning rate of 0.01 by running simple logistic regression model build with Tensorflow on MNIST dataset.\\nI am using Conda to install TensorFlow. You might already have a TensorFlow environment, but please check below to make sure you have all the necessary packages. If you have never used Conda environments before, please go through my other tutorial What is Anaconda and Why should I bother about it?\\nAssuming you have conda install on your machine, please run the following comm...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>4230</td>\n",
       "      <td>Luiz Fonseca</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4231</td>\n",
       "      <td>Susan Li</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/time-series-of-price-anomaly-detection-13586cd5ff46?source=tag_archive---------4-----------------------</td>\n",
       "      <td>Time Series of Price Anomaly Detection | by Susan Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 23, 2019\\nAlso known as outlier detection, anomaly detection is a data mining process used to determine types of anomalies found in a data set and to determine details about their occurrences. Automatic anomaly detection is critical in today’s world where the sheer volume of data makes it impossible to tag outliers manually. Auto anomaly detection has a wide range of applications such as fraud detection, system health monitoring, fault detection, and event detection systems in sensor networks, and so on.\\nBut I would like to apply anomaly detection to hotel room prices. The reason is somewhat selfish.\\nHave you had experience that, lets say, you travel to a certain destination for business regularly and you always stay at the same hotel. While most of the time...</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4232</td>\n",
       "      <td>Zhi Li</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92?source=tag_archive---------2-----------------------</td>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model | by Zhi Li | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 30, 2019\\nWord embedding is one of the most important techniques in natural language processing(NLP), where words are mapped to vectors of real numbers. Word embedding is capable of capturing the meaning of a word in a document, semantic and syntactic similarity, relation with other words. It also has been widely used for recommender systems and text classification. This tutorial will show a brief introduction of genism word2vec model with an example of generating word embedding for the vehicle make model.\\nWord2vec is one of the most popular technique to learn word embeddings using a two-layer neural network. Its input is a text corpus and its output is a set of vectors. Word embedding via word2vec can make natural language computer-readable, then further imp...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>4233</td>\n",
       "      <td>Chi-Feng Wang</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484?source=tag_archive---------0-----------------------</td>\n",
       "      <td>The Vanishing Gradient Problem. The Problem, Its Causes, Its... | by Chi-Feng Wang | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 8, 2019\\nAs more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\\nCertain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.\\nAs an example, Image 1 is the sigmoid function and its derivative. Note how when the inputs of the sigmoid function becomes larger or smaller (when |x| becomes bigger), the derivative becomes close to zero.\\nFor shallow network with only a few layers that use these activations, this isn’t a big problem. However, when more ...</td>\n",
       "      <td>1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>4234</td>\n",
       "      <td>Prashant Gupta</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Regularization in Machine Learning | by Prashant Gupta | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nNov 15, 2017\\nOne of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don’t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.\\nThe concept of balancing bias and variance, is helpful in understanding the phenomenon of overfitting.\\nmedium.com\\nOne of the ways of avoiding overfitting is using cross validation, that helps in estimating the error over test set, and in deciding what parameters work best for your model.\\nmedium.com\\nThis arti...</td>\n",
       "      <td>4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>4235</td>\n",
       "      <td>Saul Dobilas</td>\n",
       "      <td>9</td>\n",
       "      <td>https://towardsdatascience.com/gmm-gaussian-mixture-models-how-to-successfully-use-it-to-cluster-your-data-891dc8ac058f?source=tag_archive---------7-----------------------</td>\n",
       "      <td>GMM: Gaussian Mixture Models — How to Successfully Use It to Cluster Your Data? | by Saul Dobilas | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nMay 23, 2021\\nThis article is part of the series that explains how different Machine Learning algorithms work and provides you a range of Python examples to help you get started with your own Data Science project.\\nWhile it is not always possible to categorize every algorithm perfectly, it is still beneficial to try and do so. The below interactive chart is my attempt to help you see the broader universe of Machine Learning.\\nMake sure to click👇 on different categories to enlarge and reveal more.\\nNote, in many cases, the same algorithm can be used to solve multiple types of problems. E.g., one can use Neural Networks for classification, regression, and as part of the reinforcement learning.\\nIf you enjoy Data Science and Machine Learning, please subscribe to get ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>4236</td>\n",
       "      <td>Vincenzo Lavorini</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/hackernoon/speeding-up-your-code-2-vectorizing-the-loops-with-numpy-e380e939bed3?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Speeding up your code (2): vectorizing the loops with Numpy | by Vincenzo Lavorini | HackerNoon.com | Medium</td>\n",
       "      <td>HackerNoon.com\\nAug 18, 2017\\nFrom this series:\\nIn the previous post I described the working environment and the basic code for clusterize points in the Poincaré ball space. Here I will improve that code transforming two loops to matrix operations.\\nI ended that post with a very promising plot about the speed improvement on a element-wise product of two vectors. So let’s detail it.\\nSuppose we have two arrays:\\nand we want to obtain as result an array where the elements are the element-wise multiplication of them:\\nWe can do it in two ways: with a loop over the elements, or with a vectorized operation. Now: what happens in terms of execution time? I did this calculations with arrays of different dimensions, ranging from 100.000 to 10.000.000.\\nIn the right plot you see the execution ...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>4237</td>\n",
       "      <td>Dr. Robert Kübler</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211?source=tag_archive---------2-----------------------</td>\n",
       "      <td>Bayesian Linear Regression in Python via PyMC3 | by Dr. Robert Kübler | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nDec 30, 2020\\nIn this article, we will see how to conduct Bayesian linear regression with PyMC3. If you got here without knowing what Bayes or PyMC3 is, don’t worry! You can use my articles as a primer\\nYou can view Bayesian linear regression as a more verbose version of standard linear regression. Linear regression gives you single values, for the model parameters as well as the predictions. Bayesian linear regression, in turn, gives you distributions.\\nWe will see what this exactly means in a second. Let us quickly introduce a simple dataset to be able to compare both linear regression approaches.\\nWe have done it all several times: Grabbing a dataset containing features and continuous labels, then shoving a line through the data, and call it a day. As a running...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>4238</td>\n",
       "      <td>Baptiste Rocca</td>\n",
       "      <td>22</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Introduction to recommender systems | by Baptiste Rocca | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJun 2, 2019\\nThis post was co-written with Joseph Rocca.\\nDuring the last few decades, with the rise of Youtube, Amazon, Netflix and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\\nIn a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy or anything else depending on industries).\\nRecommender systems are really critical in some industries as they can generate a huge amount of income wh...</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>4239</td>\n",
       "      <td>Kenneth Cortés Aguas</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b?source=tag_archive---------1-----------------------</td>\n",
       "      <td>A guide to transfer learning with Keras using ResNet50 | by Kenneth Cortés Aguas | Medium</td>\n",
       "      <td>Jul 4, 2020\\nIn this blog post we will provide a guide through for transfer learning with the main aspects to take into account in the process, some tips and an example implementation in Keras using ResNet50 as the trained model. The task is to transfer the learning of a ResNet50 trained with Imagenet to a model that identify images from CIFAR-10 dataset. Several methods were tested to achieve a greater accuracy which we provide to show the variety of options for a training. However with the final model of this blog we get an accuracy of 94% on test set.\\nLearning something new takes time and practice but we find it easy to do similar tasks. This is thanks to human association involved in learning. We have the capability to identify patterns from previous knowledge an apply it into new...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4240</td>\n",
       "      <td>Dave Gershgorn</td>\n",
       "      <td>8</td>\n",
       "      <td>https://onezero.medium.com/gpt-3-is-an-amazing-research-tool-openai-isnt-sharing-the-code-d048ba39bbfd?source=tag_archive---------4-----------------------</td>\n",
       "      <td>GPT-3 Is an Amazing Research Tool. But OpenAI Isn’t Sharing the Code. | by Dave Gershgorn | OneZero</td>\n",
       "      <td>OneZero\\nAug 20, 2020\\nFor years, A.I. research lab OpenAI has been chasing the dream of an algorithm that can write like a human.\\nIts latest iteration on that concept, a language-generation algorithm called GPT-3...\\n532 \\n532 \\n4\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n19.1K Followers\\nSenior Writer at OneZero covering surveillance, facial recognition, DIY tech, and artificial intelligence. Previously: Qz, PopSci, and NYTimes.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4241</td>\n",
       "      <td>Ayush Pant</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to-machine-learning-for-beginners-eed6024fdb08?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Introduction to Machine Learning for Beginners | by Ayush Pant | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJan 7, 2019\\nWe have seen Machine Learning as a buzzword for the past few years, the reason for this might be the high amount of data production by applications, the increase of computation power in the past few years and the development of better algorithms.\\nMachine Learning is used anywhere from automating mundane tasks to offering intelligent insights, industries in every sector try to benefit from it. You may already be using a device that utilizes it. For example, a wearable fitness tracker like Fitbit, or an intelligent home assistant like Google Home. But there are much more examples of ML in use.\\nIt was in the 1940s when the first manually operated computer system, ENIAC (Electronic Numerical Integrator and Computer), was invented. At that time the word ...</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>4242</td>\n",
       "      <td>Jeff Nickoloff</td>\n",
       "      <td>8</td>\n",
       "      <td>https://medium.com/on-docker/federated-clusters-with-docker-swarm-dce5516ecc8d?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Federated Clusters with Docker Swarm | by Jeff Nickoloff | On Docker | Medium</td>\n",
       "      <td>On Docker\\nMar 30, 2016\\nTL;DR Federated clustering overview with a focus on Swarm. Includes architecture diagrams and tools for building an experiment in AWS. Swarm’s API is a great building block that helps you create much more sophisticated deployment architectures or scale/diversify underlying infrastructure. Whale-Mullet is a Swarm fork I built to make the whole thing work.\\nDocker Swarm provides an abstraction that allows a user to treat a cluster like a single node. That is the case as long as the Swarm API is mostly compatible with the Docker API. This begs the question, “If I can treat a Swarm like a single machine can I create a Swarm of Swarm clusters?” This is called cluster federation. This article describes what how I tried to build a federated Swarm cluster, what problem...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4243</td>\n",
       "      <td>Syed Sadat Nazrul</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/clustering-based-unsupervised-learning-8d705298ae51?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Clustering Based Unsupervised Learning | by Syed Sadat Nazrul | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nApr 3, 2018\\nUnsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from “unlabeled” data (a classification or categorization is not included in the observations). Common scenarios for using unsupervised learning algorithms include:- Data Exploration- Outlier Detection- Pattern Recognition\\nWhile there is an exhaustive list of clustering algorithms available (whether you use R or Python’s Scikit-Learn), I will attempt to cover the basic concepts.\\nThe most common and simplest clustering algorithm out there is the K-Means clustering. This algorithms involve you telling the algorithms how many possible cluster (or K) there are in the dataset. The algorithm then iteratively moves the k-centers and selects the d...</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4244</td>\n",
       "      <td>Utkarsh Desai</td>\n",
       "      <td>6</td>\n",
       "      <td>https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610?source=tag_archive---------9-----------------------</td>\n",
       "      <td>Training a Conditional DC-GAN on CIFAR-10 | by Utkarsh Desai | Medium</td>\n",
       "      <td>Jun 8, 2018\\nAfter some promising results and tons of learning (summarized in my previous post) with a basic DC-GAN on CIFAR-10 data, I wanted to play some more with GANs. One issue with a traditional DC-GAN was that the data is expected to have similar properties in order for the training to converge properly. For instance, in case of CIFAR-10, training the DC-GAN on images of a single class was much easier and more likely to produce sharp images than training on all 10 classes. In that post on GAN learnings, I had casually mentioned Conditional GANs as an improvement over traditional GANs when the training data might come from different classes. This post describes how to setup a Conditional DC-GAN to generate images from all the classes of CIFAR-10 data.\\nGenerative Adversarial Netw...</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>4245</td>\n",
       "      <td>Félix Revert</td>\n",
       "      <td>8</td>\n",
       "      <td>https://towardsdatascience.com/the-proper-way-to-use-machine-learning-metrics-4803247a2578?source=tag_archive---------8-----------------------</td>\n",
       "      <td>The proper way to use Machine Learning metrics | by Félix Revert | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nSep 10, 2019\\nNote I focus on binary classification problems in this article, but the approach would be similar with multi classification and regression problems.\\nTry to convince someone that your ML model is accurate and should be trusted because it has a LogLoss of 0.34. Non data scientists will surely gawk at you while data scientists will ask for a lot more information.\\nAs a data scientist, you know it’s hard to make it clear (particularly to non data scientists) why your model should be trusted because you cannot easily translate complex measures of accuracy into tangible elements. And that’s 100% legitimate, models should be understood by everyone, at least their accuracy.\\nOn top of it, if your approach is scientifically correct, your model should have at...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>4246</td>\n",
       "      <td>Alexander Hirner</td>\n",
       "      <td>5</td>\n",
       "      <td>https://medium.com/moonvision/few-shot-object-detection-in-practice-4f8fa98cba57?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Few-shot Object Detection in Practice | by Alexander Hirner | Moonvision | Medium</td>\n",
       "      <td>Moonvision\\nApr 12, 2019\\nObject detection is vital to automate manual tasks, such as checking the completeness of objects and the exact types of its parts. In contrast to segmentation, objects are located and classified as discrete instances. This is achieved by decoding regression and activation maps after a cascade of convolutions. You can read more about state-of-the art in object detection in this survey.\\nHowever, contemporary issues in object detection are often studied in isolation. In production use cases though, multiple constraints must be solved at once. In this post, we describe the combination of techniques that we’ve developed over time that meet many of these constraints.\\nAs with any machine learning task, the amount of training data is limited. As we will review below...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>4247</td>\n",
       "      <td>Gabriel Cassimiro</td>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=tag_archive---------6-----------------------</td>\n",
       "      <td>Object detection with Tensorflow model and OpenCV | by Gabriel Cassimiro | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nJul 15, 2021\\nIn this article, I’m going to demonstrate how to use a trained model to detect objects in images and videos using two of the best libraries for this kind of problem. For the detection, we need a model capable of predicting multiple classes in an image and returning the location of those objects so that we can place boxes on the image.\\nWe are going to use a model from the Tensorflow Hub library, which has multiple ready to deploy models trained in all kinds of datasets and to solve all kinds of problems. For our use, I filtered models trained for object detection tasks and models in the TFLite format. This format is usually used for IoT applications, for its small size and faster performance than bigger models. I choose this format because I intend t...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>4248</td>\n",
       "      <td>Lavanya Gupta</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/analytics-vidhya/how-batch-normalization-and-relu-solve-vanishing-gradients-3f1a8ace1c88?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Batch Normalization and ReLU for solving Vanishing Gradients | by Lavanya Gupta | Analytics Vidhya | Medium</td>\n",
       "      <td>Analytics Vidhya\\nApr 26, 2021\\nA logical and sequential roadmap to understanding the advanced concepts in training deep neural networks.\\nWe will break our discussion into 4 logical parts that build upon each other. For the best reading experience, please go through them sequentially:\\n1. What is Vanishing Gradient? Why is it a problem? Why does it happen?2. What is Batch Normalization? How does it help in Vanishing Gradient?3. How does ReLU help in Vanishing Gradient?4. Batch Normalization for Internal Covariate Shift\\nFirst, let’s understand what vanishing means:\\nVanishing means that it goes towards 0 but will never really be 0.\\nVanishing gradient refers to the fact that in deep neural networks, the backpropagated error signal (gradient) typically decreases exponentially as a func...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>4249</td>\n",
       "      <td>Tim Löhr</td>\n",
       "      <td>10</td>\n",
       "      <td>https://towardsdatascience.com/k-means-clustering-and-the-gap-statistics-4c5d414acd29?source=tag_archive---------5-----------------------</td>\n",
       "      <td>K-Means Clustering and the Gap-Statistics | by Tim Löhr | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nOct 22, 2020\\nThere is a lot of code going on under the hood. That’s why I provide my Github repository at the end of this post and I show just a little code of the K-Means.\\nClustering is an important technique in Pattern Analysis to identify distinct groups in data. Due to data being mostly more than three-dimensional, we perform dimensionality reduction methods like PCA or Laplacian Eigenmaps before applying a clustering technique. The data is then available in 2D or 3D and this allows us to visualize the found clusters very nicely to humans. Even though this is a basic workflow, it is not always the case.\\nData is also often unlabeled. This means you have no clear definition of what you want to find within this data. That’s why clustering is a good data explor...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>4250</td>\n",
       "      <td>Dan Hill</td>\n",
       "      <td>20</td>\n",
       "      <td>https://medium.com/dark-matter-and-trojan-horses/of-brains-and-cities-neuroscience-and-cultures-of-decision-making-6bc6abb48d4b?source=tag_archive---------0-----------------------</td>\n",
       "      <td>Of brains and cities; neuroscience and cultures of decision-making | by Dan Hill | Dark Matter and Trojan Horses | Medium</td>\n",
       "      <td>Dark Matter and Trojan Horses\\nDec 21, 2011\\nA chilly December night in 2011. I had been invited to take part in an evening event called the North House Salon, one of a series of salons...\\nArticles, cases and considerations regarding strategic design practice and thinking.\\n21K Followers\\nDesigner, urbanist, etc. Director of Strategic Design at Vinnova, Swedish govt. Prof. AHO Oslo, Visiting Prof. UCL Bartlett IIPP, Design Academy Eindhoven, RMIT\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4251</td>\n",
       "      <td>Tiago M. Leite</td>\n",
       "      <td>9</td>\n",
       "      <td>https://medium.com/ensina-ai/redes-neurais-perceptron-multicamadas-e-o-algoritmo-backpropagation-eaf89778f5b8?source=tag_archive---------5-----------------------</td>\n",
       "      <td>Redes Neurais, Perceptron Multicamadas e o Algoritmo Backpropagation | by Tiago M. Leite | Ensina.AI | Medium</td>\n",
       "      <td>Ensina.AI\\nMay 10, 2018\\nVocê já se perguntou como funcionam os sistemas de reconhecimento de imagem? Como um aplicativo do seu celular faz para detectar rostos, ou um teclado inteligente sugere a próxima palavra? As chamadas Redes Neurais tem sido amplamente usadas para tarefas como essas, mas mostraram-se úteis também em outras áreas, como aproximação de funções, previsão de séries temporais e processamento de linguagem natural.\\nNeste artigo, explico como funciona um tipo básico de Rede Neural, o Perceptron Multicamadas, e um fascinante algoritmo responsável pelo aprendizado da rede, o backpropagation. Tal modelo de rede serviu de base para os modelos mais complexos hoje existentes, como as Redes Convolucionais, que são o estado da arte para classificação de imagens...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4252</td>\n",
       "      <td>Tejan Karmali</td>\n",
       "      <td>6</td>\n",
       "      <td>https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73?source=tag_archive---------7-----------------------</td>\n",
       "      <td>Spam Classifier in Python from scratch | by Tejan Karmali | Towards Data Science</td>\n",
       "      <td>Towards Data Science\\nAug 2, 2017\\nWe all face the problem of spams in our inboxes. Let’s build a spam classifier program in python which can tell whether a given message is spam or not! We can do this by using a simple, yet powerful theorem from probability theory called Baye’s Theorem. It is mathematically expressed as\\nWe have a message m = (w1, w2, . . . . , wn), where (w1, w2, . . . . , wn) is a set of unique words contained in the message. We need to find\\nIf we assume that occurrence of a word are independent of all other words, we can simplify the above expression to\\nIn order to classify we have to determine which is greater\\nWe are going to make use of NLTK for processing the messages, WordCloud and matplotlib for visualization and pandas for loading data, NumPy for generatin...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4253</td>\n",
       "      <td>Insight</td>\n",
       "      <td>5</td>\n",
       "      <td>https://blog.insightdatascience.com/preparing-for-insight-ca7cc6087f91?source=tag_archive---------3-----------------------</td>\n",
       "      <td>Preparing for Insight | by Insight | Insight</td>\n",
       "      <td>Insight\\nApr 16, 2014\\nJohn Joo is an Insight alumnus from the August 2013 session with a PhD in applied physics from Harvard. He recently joined Insight as a Program Director in January, leading the most recent cohort of Fellows in their transition from academia to industry.\\nWhen I was first considering making the transition from applied physics to data science, I had a lot of questions. What skills did I need to develop to get started in data science? What courses should I take? Did I need to know how to program and code? What languages? How much statistics did I need to know? The list goes on. Now that I’ve spent a few months as a Program Director here at Insight, I think it’s time I shared with you the tools and tips that got me, and nearly 100 other Insight Fellows, started on ou...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4254</td>\n",
       "      <td>Aleksey Tikhonov</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/altsoph/google-ai-contest-eed23cfdeb6f?source=tag_archive---------3-----------------------</td>\n",
       "      <td>GOOGLE AI CONTEST | by Aleksey Tikhonov | Altsoph’s blog | Medium</td>\n",
       "      <td>Altsoph’s blog\\nSep 16, 2010\\nВчера узнал, что сейчас идет Google AI Contest.\\nВ двух словах, задача состоит в написании логики бота, играющего в некоторый аналог игры Galcon — космической стратегии, основанной на разделении ресурсов. Прием ботов на конкурс идет до 27 ноября, а потом их будут стравливать и выявлять победителя. Языки доступны из списка C++, C#, Java, Python.\\nБыло бы времени побольше, я бы, наверное, поучавствовал.\\nВспоминаются стародавние времена, когда мы еще в школе рубились в RobotBattle, а потом на первом курсе с группой сотоварищей писали интерпретатор RedCode на придуманной нами модели тороидальной памяти (ToroWars).\\nRandom notes on people and machines\\n274 Followers\\nhttp://altsoph.com, Senior Data Analyst, Researcher.\\nHelp\\nStatus\\nWriters\\nBlog\\nCar...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4255</td>\n",
       "      <td>Victor Sanh</td>\n",
       "      <td>10</td>\n",
       "      <td>https://medium.com/huggingface/distilbert-8cf3380435b5?source=tag_archive---------5-----------------------</td>\n",
       "      <td>🏎 Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT | by Victor Sanh | HuggingFace | Medium</td>\n",
       "      <td>HuggingFace\\nAug 28, 2019\\n2019, October 3rd — Update: We are releasing our NeurIPS 2019 workshop paper describing our approach on DistilBERT with improved results: 97% of BERT’s performance on GLUE (the results in the paper superseed the results presented here). The approach is slightly different from the one explained in this present blog post so this blog post should be a good entry point to the paper! We applied the same method to GPT2 and are releasing DistilGPT2! Training code and pre-trained weights for DistilBERT and DistilGPT2 are available here. 🤗\\nIn the last 18 months, transfer learning from large-scale language models has significantly improved upon the state-of-the-art on pretty much every Natural Language Processing task.\\nUsually based on the Transformer architecture of...</td>\n",
       "      <td>5102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d6176f6-824c-47eb-ac24-f77b65c2b1c4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0d6176f6-824c-47eb-ac24-f77b65c2b1c4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0d6176f6-824c-47eb-ac24-f77b65c2b1c4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       id                           author  reading_time  \\\n",
       "0    3756                     Rohit Thakur             8   \n",
       "1    3757               Giuliano Giacaglia            14   \n",
       "2    3758                  Darshan Adakane             7   \n",
       "3    3759                   Sachin Palewar             1   \n",
       "4    3760                      SDGCounting             2   \n",
       "5    3761                         Tam Pham             7   \n",
       "6    3762                   Virginia Peón             1   \n",
       "7    3763                          The Awl            10   \n",
       "8    3764                      Ekta Sharma             9   \n",
       "9    3765                    Igor de Sousa             3   \n",
       "10   3766                     Adam Geitgey            15   \n",
       "11   3767                            Viraf            10   \n",
       "12   3768                   Pankaj Kishore            17   \n",
       "13   3769                  Ruben Winastwan             9   \n",
       "14   3770                    Ronak Nathani             9   \n",
       "15   3771                      George Seif            11   \n",
       "16   3772                 Record Evolution            18   \n",
       "17   3773                   Lachlan Miller             5   \n",
       "18   3774                     Julia Powles             8   \n",
       "19   3775                    Pulkit Sharma            13   \n",
       "20   3776                        Ryan Kwok             9   \n",
       "21   3777                       Hongri Jia             7   \n",
       "22   3778                    Justin Davies             1   \n",
       "23   3779                 Johannes Schmidt             6   \n",
       "24   3780                   Harsh Pokharna             5   \n",
       "25   3781                  Debmalya Biswas             8   \n",
       "26   3782                      Javaid Nabi             9   \n",
       "27   3783                  Renu Khandelwal             8   \n",
       "28   3784            Hrishikesh Huilgolkar             4   \n",
       "29   3785                    Jan Schultink             1   \n",
       "30   3786                 Siladittya Manna             4   \n",
       "31   3787                            Knoyd             4   \n",
       "32   3788                       Ryan Burke            10   \n",
       "33   3789                   Jeremie Harris             4   \n",
       "34   3790                  Pavel Shestakov             2   \n",
       "35   3791                      Saidakbar P            15   \n",
       "36   3792                     Prince Yadav             9   \n",
       "37   3793                     Julia Powles             8   \n",
       "38   3794                 Gabriel Pierobon             5   \n",
       "39   3795                    Anas Al-Masri            10   \n",
       "40   3796                       Matt Kiser             4   \n",
       "41   3797                  Pedro Marcelino            14   \n",
       "42   3798                      michaelulin            10   \n",
       "43   3799               Chi-Lan Yang | 楊期蘭             7   \n",
       "44   3800                    Manjeet Singh             6   \n",
       "45   3801                      Elior Cohen             9   \n",
       "46   3802                 Sambit Mahapatra             6   \n",
       "47   3803                      Ceshine Lee             3   \n",
       "48   3804                   Daniel Voshart             4   \n",
       "49   3805         Chandra Churh Chatterjee             8   \n",
       "50   3806                  Gustavo Chávez             6   \n",
       "51   3807                   Apdullah Yayik             4   \n",
       "52   3808                  Renu Khandelwal            12   \n",
       "53   3809                  Erik Hallström             7   \n",
       "54   3810                   Veysel Kocaman            11   \n",
       "55   3811          Marcio Geovani Jasinski             3   \n",
       "56   3812                    Vicente Luego             2   \n",
       "57   3813                    LucianoSphere            22   \n",
       "58   3814               Jean-Marc Beaujour             4   \n",
       "59   3815                       Justin Lee            11   \n",
       "60   3816                       Yash Patel            13   \n",
       "61   3817                     Victor Roman            17   \n",
       "62   3818               Kaustubh Mhaisekar             8   \n",
       "63   3819                     James Briggs             7   \n",
       "64   3820               Maneesha Rajaratne             8   \n",
       "65   3821                      Essam Wisam            10   \n",
       "66   3822                    John Olafenwa            12   \n",
       "67   3823                    Arsh Chowdhry             8   \n",
       "68   3824                  Kaushal Trivedi             7   \n",
       "69   3825                        commander             6   \n",
       "70   3826               Acuity Derivatives             2   \n",
       "71   3827                    Jehill Parikh             8   \n",
       "72   3828                       Wolf Garbe             6   \n",
       "73   3829           Amanda Iglesias Moreno            11   \n",
       "74   3830                       Paul Ellis             8   \n",
       "75   3831                  Olga Chernytska            13   \n",
       "76   3832                     Praveenkumar             5   \n",
       "77   3833                  Chijioke Nwagwu             3   \n",
       "78   3834                    Shivam Duseja             9   \n",
       "79   3835            Jonny Brooks-Bartlett             8   \n",
       "80   3836                     Rishit Dagli             6   \n",
       "81   3837                  Sanne de Roever             7   \n",
       "82   3838                Kirill Bondarenko             6   \n",
       "83   3839                     Goibibo Tech             1   \n",
       "84   3840                          Shi Yan             7   \n",
       "85   3841                     Pavan Gurram             7   \n",
       "86   3842                           Synced             4   \n",
       "87   3843                     Rajneesh Jha             6   \n",
       "88   3844            Dimitris Panagopoulos             4   \n",
       "89   3845                          Mo Hajr             7   \n",
       "90   3846                      Javaid Nabi            13   \n",
       "91   3847                     SAGAR SHARMA             5   \n",
       "92   3848                   Moses Olafenwa             9   \n",
       "93   3849             Vincenzo Santopietro             6   \n",
       "94   3850                   Connor Shorten             6   \n",
       "95   3851                    Akash Panchal            10   \n",
       "96   3852                Vincenzo Lavorini             7   \n",
       "97   3853                 Supriya Secherla             5   \n",
       "98   3854                    Hucker Marius            10   \n",
       "99   3855                   Craig Villamor             1   \n",
       "100  3856                     Pranay Dugar             6   \n",
       "101  3857                   Arthur Juliani             6   \n",
       "102  3858                  Dario Radečić             5   \n",
       "103  3859                  André Ferreira            24   \n",
       "104  3860                 Kate Marie Lewis             8   \n",
       "105  3861                 Taras Bakusevych             7   \n",
       "106  3862                    Joshua Holmes             4   \n",
       "107  3863                    Roan Gylberth             6   \n",
       "108  3864              TokenGo Platform_RU             4   \n",
       "109  3865                      karthic Rao             2   \n",
       "110  3866                          Pallawi             9   \n",
       "111  3867                        Unchainet             2   \n",
       "112  3868                           Justin             3   \n",
       "113  3869                   Daniel Emaasit             1   \n",
       "114  3870                           RomRoc             5   \n",
       "115  3871                     Javed Shaikh             7   \n",
       "116  3872                       Bruce Yang            15   \n",
       "117  3873                          Firefox             4   \n",
       "118  3874                      Ketan Doshi            14   \n",
       "119  3875          Chunguang (Wayne) Zhang             8   \n",
       "120  3876                       Uday Paila             7   \n",
       "121  3877                  Manish Chablani             5   \n",
       "122  3878                     Charlie Kufs             6   \n",
       "123  3879                      Tara Mullin             3   \n",
       "124  3880            Amirhossein Heydarian             5   \n",
       "125  3881                   Learner Subodh             8   \n",
       "126  3882                     Walid Amamou             7   \n",
       "127  3883                   Arthur Juliani             6   \n",
       "128  3884                        Becky Zhu             3   \n",
       "129  3885                    Utkarsh Ankit            13   \n",
       "130  3886                   Venkatesh Tata            10   \n",
       "131  3887                     Sarthak Jain            10   \n",
       "132  3888                  Renu Khandelwal             6   \n",
       "133  3889                   Brandon Walker             6   \n",
       "134  3890                       bitsofinfo            16   \n",
       "135  3891                 Andreas Yonathan             6   \n",
       "136  3892          Rostyslav Neskorozhenyi            13   \n",
       "137  3893                  Manish Chablani             4   \n",
       "138  3894                      Anne Bonner             8   \n",
       "139  3895                  Diego Lopez Yse            13   \n",
       "140  3896                  Jessica Dafflon             9   \n",
       "141  3897  Matthew Stewart, PhD Researcher             9   \n",
       "142  3898                 Md Sohel Mahmood             6   \n",
       "143  3899                 Vladimir Shapiro             7   \n",
       "144  3900                         Susan Li             5   \n",
       "145  3901                  Neeraj Varshney            10   \n",
       "146  3902                     Aakanksha NS             6   \n",
       "147  3903                  Animesh Agarwal             7   \n",
       "148  3904              Vindula Jayawardana             5   \n",
       "149  3905              Dhruv Parthasarathy            11   \n",
       "150  3906                Sebastian Theiler             7   \n",
       "151  3907                 Himanshu Chandra             8   \n",
       "152  3908                    William Scott            19   \n",
       "153  3909                      Kevin Luxem            10   \n",
       "154  3910                     Sourav kumar            12   \n",
       "155  3911                     Elif Meşeci             4   \n",
       "156  3912                     M Bharathwaj            11   \n",
       "157  3913                    Sairaj Neelam            11   \n",
       "158  3914                    Rowel Atienza             6   \n",
       "159  3915                      Michael Phi            10   \n",
       "160  3916                    IPG Media Lab             1   \n",
       "161  3917                       Gabe Flomo             6   \n",
       "162  3918                       Sumit Saha             7   \n",
       "163  3919                   Diganta Kalita             6   \n",
       "164  3920               Lihi Gur Arie, PhD             7   \n",
       "165  3921                   Isaac Godfried             8   \n",
       "166  3922                     Oleg Polosin             4   \n",
       "167  3923                      Luís Roque            11   \n",
       "168  3924                     Adam Pickard             5   \n",
       "169  3925                      Jongdae Lim            24   \n",
       "170  3926                     Daniel Godoy            21   \n",
       "171  3927                     Debarko De 🦁            12   \n",
       "172  3928                 Ayushi choudhary             4   \n",
       "173  3929                 Samuele Mazzanti             6   \n",
       "174  3930                      Mukul Malik             8   \n",
       "175  3931                Dr. Varshita Sher            12   \n",
       "176  3932                       Rob Parkin             5   \n",
       "177  3933                      Steven Shen            15   \n",
       "178  3934                    Robbie Tilton            15   \n",
       "179  3935                       Kyle Huang            11   \n",
       "180  3936                        James Lee             7   \n",
       "181  3937                   Korbinian Koch            15   \n",
       "182  3938                      Shay Geller            13   \n",
       "183  3939                        jiawei hu            17   \n",
       "184  3940                      Vivek Yadav             2   \n",
       "185  3941                SYED JUNAID IQBAL            12   \n",
       "186  3942           Snehal Reddy Koukuntla             6   \n",
       "187  3943                        Aerin Kim             8   \n",
       "188  3944                       Suhyun Kim             7   \n",
       "189  3945                 Aneesha Bakharia             3   \n",
       "190  3946                           Matt.0            15   \n",
       "191  3947                     Joseph Rocca            20   \n",
       "192  3948                          Insight             5   \n",
       "193  3949                       Kaustubh N             3   \n",
       "194  3950                     Thomas Smith             9   \n",
       "195  3951              Ravi Prakash pandey             6   \n",
       "196  3952              Aleksi Pietikäinen            14   \n",
       "197  3953                  Darshan Adakane             7   \n",
       "198  3954                   Anish Shrestha            17   \n",
       "199  3955                           Synced             5   \n",
       "200  3956                Bhuvana Kundumani             5   \n",
       "201  3957                     Sourav kumar            12   \n",
       "202  3958                       Wamika Jha             5   \n",
       "203  3959                   Maria Neumayer             1   \n",
       "204  3960                         Susan Li             5   \n",
       "205  3961                      Mark Garvey             7   \n",
       "206  3962                           Synced             5   \n",
       "207  3963                     Gorkem Polat             7   \n",
       "208  3964                 Taras Bakusevych            10   \n",
       "209  3965              RAVI SHEKHAR TIWARI             9   \n",
       "210  3966                           Synced             4   \n",
       "211  3967                       Ayush Pant             9   \n",
       "212  3968              TokenGo Platform_RU             3   \n",
       "213  3969                     Boaz Shmueli             7   \n",
       "214  3970                 Thiago Julio, MD             3   \n",
       "215  3971          Netflix Technology Blog             5   \n",
       "216  3972                      Victor Zhou             9   \n",
       "217  3973                  Bernardo Caldas             6   \n",
       "218  3974                         A Ydobon             5   \n",
       "219  3975                           Synced             3   \n",
       "220  3976                  Helena Campbell             5   \n",
       "221  3977                      NN Intruder            15   \n",
       "222  3978                   Harald Scheidl             8   \n",
       "223  3979                   Abdarhman Taha             4   \n",
       "224  3980                Gerard Maggiolino             9   \n",
       "225  3981                    Surya Remanan             6   \n",
       "226  3982                       Nishanth N             3   \n",
       "227  3983                           Maxime            13   \n",
       "228  3984                           Synced             3   \n",
       "229  3985                     Kamil Mysiak            31   \n",
       "230  3986                             Josh             9   \n",
       "231  3987                   Jacob Solawetz             4   \n",
       "232  3988                  Andrej Karpathy             7   \n",
       "233  3989                   James Faghmous             6   \n",
       "234  3990                      Aqeel Anwar             9   \n",
       "235  3991                Thilina Rajapakse             8   \n",
       "236  3992                             Rafi             5   \n",
       "237  3993             Adrien Lucas Ecoffet             8   \n",
       "238  3994                         Patty Wu             7   \n",
       "239  3995                        Nhan Tran             5   \n",
       "240  3996                  thirumalaivasan             2   \n",
       "241  3997                         Susan Li             7   \n",
       "242  3998                          dan lee             8   \n",
       "243  3999                   Pankaj Jainani             6   \n",
       "244  4000                Michael Bronstein            11   \n",
       "245  4001                   Nurlan Kerimov            13   \n",
       "246  4002                   Harald Scheidl             9   \n",
       "247  4003                      Mikhail Mew             4   \n",
       "248  4004                    Park Chansung             9   \n",
       "249  4005                  Renu Khandelwal            12   \n",
       "250  4006                      Kerish Heik             3   \n",
       "251  4007                    Anusha Lihala             6   \n",
       "252  4008                     Supervise.ly            11   \n",
       "253  4009          Tobias Skovgaard Jepsen             9   \n",
       "254  4010                       Merzmensch             7   \n",
       "255  4011                    Akihiro FUJII            13   \n",
       "256  4012                 Rakshith Vasudev             8   \n",
       "257  4013                  Thomas HARTMANN             7   \n",
       "258  4014                       Nishanth N             3   \n",
       "259  4015                         Chung-Yi             5   \n",
       "260  4016                  João Fernandes             5   \n",
       "261  4017                       ASHNA JAIN            10   \n",
       "262  4018                     Eric Elliott            11   \n",
       "263  4019              Huangwei Wieniawska            10   \n",
       "264  4020                     R. E. Warner             1   \n",
       "265  4021                       m.zaradzki             7   \n",
       "266  4022                      karthic Rao             6   \n",
       "267  4023                   Thomas Filaire             7   \n",
       "268  4024                      Alex Lenail             7   \n",
       "269  4025                  Michael L. Peng             4   \n",
       "270  4026                   Marco Cerliani             7   \n",
       "271  4027                         Susan Li             5   \n",
       "272  4028                      Aji Abraham             2   \n",
       "273  4029                    LucianoSphere             9   \n",
       "274  4030                     Eitan Kosman             6   \n",
       "275  4031                     Benedict Neo            14   \n",
       "276  4032                     Luuk Derksen             6   \n",
       "277  4033                      Ryan Kemmer             5   \n",
       "278  4034                  Haripriya Reddy             6   \n",
       "279  4035                   Masumi Mutsuda             2   \n",
       "280  4036                    Uri Eliabayev             4   \n",
       "281  4037                Ravindra Kompella             7   \n",
       "282  4038                    Roland Hewage            11   \n",
       "283  4039                              Tan            10   \n",
       "284  4040                         Progress             5   \n",
       "285  4041            Md Shahidullah Kawsar             3   \n",
       "286  4042                       Dmitry Kan            13   \n",
       "287  4043                      Justin Chen             2   \n",
       "288  4044                     Jhen Hilario             1   \n",
       "289  4045              Akshika Wijesundara             6   \n",
       "290  4046                     Jonathan Hui            11   \n",
       "291  4047                  Kai Stinchcombe            11   \n",
       "292  4048                     Luiz Fonseca             8   \n",
       "293  4049                    Haaya Naushan             8   \n",
       "294  4050                   Jerome Bouchon             5   \n",
       "295  4051                      Halil Ertan            19   \n",
       "296  4052                  Manish Chablani             4   \n",
       "297  4053                          Chinmay             5   \n",
       "298  4054                     Sourav kumar            12   \n",
       "299  4055                       ProjectAGI             5   \n",
       "300  4056                   Stepan Ulyanin            11   \n",
       "301  4057                        Adam King            14   \n",
       "302  4058               Sachin Abeywardana             1   \n",
       "303  4059                       Brian Ward             8   \n",
       "304  4060                      Kyle Dorman            19   \n",
       "305  4061                    David Venturi            20   \n",
       "306  4062                      Nick Kasten             9   \n",
       "307  4063                      Jiahao Weng             5   \n",
       "308  4064             Wenchen's ai fantasy             3   \n",
       "309  4065                      Thomas Wolf            12   \n",
       "310  4066                     Neelabh Pant            11   \n",
       "311  4067              TokenGo Platform_RU             3   \n",
       "312  4068         Chandra Churh Chatterjee             8   \n",
       "313  4069                       Arun Kumar            16   \n",
       "314  4070                      Ceshine Lee             6   \n",
       "315  4071                      Jack Morris             7   \n",
       "316  4072                     William Ryan             5   \n",
       "317  4073                     Satyam Kumar             5   \n",
       "318  4074                    Park Chansung             9   \n",
       "319  4075                      Shiva Verma             5   \n",
       "320  4076    Anuj shah (Exploring Neurons)             6   \n",
       "321  4077                     Ethan Siegel             5   \n",
       "322  4078                   Prakash Pandey            12   \n",
       "323  4079                  Hubert Baniecki             4   \n",
       "324  4080                  Charles Kapelke            10   \n",
       "325  4081                       Alfi Salim             5   \n",
       "326  4082                 Marie Imokoyende             9   \n",
       "327  4083                Stefan Kojouharov             8   \n",
       "328  4084                  Sambasivarao. K             4   \n",
       "329  4085                      Jimmi Dyson             5   \n",
       "330  4086        DataAnalysis For Beginner             4   \n",
       "331  4087            Viet Hoang Tran Duong             9   \n",
       "332  4088                    Chris Fotache             7   \n",
       "333  4089                     Thomas Smith             9   \n",
       "334  4090                      Robin Vinod             5   \n",
       "335  4091                    Ravish Chawla             7   \n",
       "336  4092                 Frank Bonsal III             8   \n",
       "337  4093                         Ekin Tiu             9   \n",
       "338  4094                       Ryan Burke             9   \n",
       "339  4095                    Matt Schlicht            11   \n",
       "340  4096                     Manish Nayak             5   \n",
       "341  4097                     Prem Prakash             7   \n",
       "342  4098                    Mohantysandip             4   \n",
       "343  4099             Mohammed AL-Ma'amari             5   \n",
       "344  4100                     Vishal Maini            13   \n",
       "345  4101                    Nikhil Parmar             6   \n",
       "346  4102                   Akanksha Rawat             6   \n",
       "347  4103                    Hemant Ranvir             9   \n",
       "348  4104                     Jonathan Hui            18   \n",
       "349  4105                  Geneonline-基因線上             4   \n",
       "350  4106                Hemanth Pedamallu             7   \n",
       "351  4107                Maximus Mutschler             3   \n",
       "352  4108                Nick Komissarenko             4   \n",
       "353  4109                        Ryan Kwok             9   \n",
       "354  4110                     Puneet Singh             4   \n",
       "355  4111                  Saket Dingliwal             4   \n",
       "356  4112                     Shivon Zilis            10   \n",
       "357  4113                      Shiva Verma             3   \n",
       "358  4114                       Akash Deep             8   \n",
       "359  4115                   Shashank Yadav             5   \n",
       "360  4116                Jaimin Mungalpara             7   \n",
       "361  4117                      Ekta Sharma             9   \n",
       "362  4118                  Jordi TORRES.AI            23   \n",
       "363  4119                     Tejas Morkar            11   \n",
       "364  4120                  Matheus Jacques             5   \n",
       "365  4121                      Susan Maina             6   \n",
       "366  4122                 Mohammed Sunasra            10   \n",
       "367  4123                     Igor Susmelj             5   \n",
       "368  4124                  Manish Chablani             5   \n",
       "369  4125                 Ajinkya Sonawane             5   \n",
       "370  4126                   Ashish Singhal             5   \n",
       "371  4127                    Hely Marleena            10   \n",
       "372  4128                       Wolf Garbe             6   \n",
       "373  4129                       Klas Leino            11   \n",
       "374  4130                    Udacity India             3   \n",
       "375  4131                    Kacper Kubara             6   \n",
       "376  4132                Emil Lykke Jensen             8   \n",
       "377  4133                     Victor Roman            13   \n",
       "378  4134                       Jane Huang            18   \n",
       "379  4135                    Mayank Mishra             9   \n",
       "380  4136                 Pau Labarta Bajo            10   \n",
       "381  4137                Madeline Schiappa             4   \n",
       "382  4138        DataAnalysis For Beginner             3   \n",
       "383  4139             Pranoy Radhakrishnan             8   \n",
       "384  4140               platfarm tech team            14   \n",
       "385  4141                     Parul Pandey            10   \n",
       "386  4142                Martín Pellarolo             4   \n",
       "387  4143                          Reo Neo             8   \n",
       "388  4144                     Aman Kharwal             2   \n",
       "389  4145                       Haihan Lan             7   \n",
       "390  4146                  Pranav Budhwant            10   \n",
       "391  4147                 Shivy Yohanandan             5   \n",
       "392  4148                    Kyle McDonald             7   \n",
       "393  4149                    Peter Bulyaki             5   \n",
       "394  4150                           Synced             3   \n",
       "395  4151                      Nir Ben-Zvi            22   \n",
       "396  4152              Nathan Cooper Jones            12   \n",
       "397  4153                      Ahmet Genç             5   \n",
       "398  4154                       Max Pagels             7   \n",
       "399  4155                  Chris Loughnane             7   \n",
       "400  4156                         Susan Li             7   \n",
       "401  4157                      Pandorabots             3   \n",
       "402  4158                     Harsh Sharma             9   \n",
       "403  4159                  Prajwal Paudyal             9   \n",
       "404  4160                           Yang S             6   \n",
       "405  4161                          Karl N.             7   \n",
       "406  4162                      ASHISH RANA            12   \n",
       "407  4163              Volkan Levent Soylu             4   \n",
       "408  4164                editorCapire.info             5   \n",
       "409  4165                        Enoch Kan             3   \n",
       "410  4166        Towards AI Editorial Team            26   \n",
       "411  4167               Francesco Gadaleta             4   \n",
       "412  4168               surendranath bobba             5   \n",
       "413  4169                          Hshan.T             7   \n",
       "414  4170              Sudip Shrestha, PhD            17   \n",
       "415  4171                   Tanya Dayanand            15   \n",
       "416  4172                  Renu Khandelwal             8   \n",
       "417  4173                    Chi-Feng Wang             8   \n",
       "418  4174                     Jonathan Hui            18   \n",
       "419  4175                       Arun Kumar            17   \n",
       "420  4176                    Bayan Bennett             3   \n",
       "421  4177                      George Seif            11   \n",
       "422  4178                   Shashank Yadav             5   \n",
       "423  4179                     Joseph Rocca            20   \n",
       "424  4180                       Kopal Jain             4   \n",
       "425  4181                          Amin Ag             4   \n",
       "426  4182                Sema Zeynep Bulut             6   \n",
       "427  4183                            ilmoi            12   \n",
       "428  4184                    Andrew Marmon             5   \n",
       "429  4185                    Prince Grover             8   \n",
       "430  4186                   Andre Violante             5   \n",
       "431  4187                   Arthur Juliani             6   \n",
       "432  4188                 Rizky Luthfianto             4   \n",
       "433  4189                        Azad Soni             3   \n",
       "434  4190                     JP Zamanillo             5   \n",
       "435  4191                       Anson Wong             6   \n",
       "436  4192           Patrick Langechuan Liu            16   \n",
       "437  4193                      Aqeel Anwar             8   \n",
       "438  4194                         Susan Li            10   \n",
       "439  4195                    Boris Knyazev            16   \n",
       "440  4196                   Sabina Pokhrel            13   \n",
       "441  4197                      Essam Wisam             6   \n",
       "442  4198                       Zijing Zhu             8   \n",
       "443  4199                  Varun Saravanan            15   \n",
       "444  4200        DataAnalysis For Beginner             3   \n",
       "445  4201                  Carlos E. Perez            12   \n",
       "446  4202                    Ilma Arifiany             4   \n",
       "447  4203                           Dinesh            13   \n",
       "448  4204                    Boris Anthony             6   \n",
       "449  4205                       Shuchen Du             4   \n",
       "450  4206                    Rising Odegua            11   \n",
       "451  4207               Prem Chandra Singh             5   \n",
       "452  4208                     Jonathan Hui             7   \n",
       "453  4209                        EarnSkins             4   \n",
       "454  4210                          Gene Su            13   \n",
       "455  4211                   Isaac Godfried            14   \n",
       "456  4212                Ashutosh Bhardwaj             3   \n",
       "457  4213                      Destin Gong            11   \n",
       "458  4214                       Sagi eppel             9   \n",
       "459  4215                     Jake Grigsby             8   \n",
       "460  4216                   Piero Esposito             5   \n",
       "461  4217                  Adrian Yijie Xu             8   \n",
       "462  4218                    Maryam Fallah            12   \n",
       "463  4219                The NYT Open Team             3   \n",
       "464  4220                      Kenny Jones            13   \n",
       "465  4221                     Charlie Kufs             6   \n",
       "466  4222                    Boris Knyazev            17   \n",
       "467  4223           DataCrafts @ DataWeave             3   \n",
       "468  4224                Baptiste Monpezat             7   \n",
       "469  4225             Maarten Grootendorst             7   \n",
       "470  4226                    Chi-Feng Wang             8   \n",
       "471  4227                  Bruce MacDonald             7   \n",
       "472  4228                   Connor Shorten             8   \n",
       "473  4229                    Pankaj Mathur             4   \n",
       "474  4230                     Luiz Fonseca             8   \n",
       "475  4231                         Susan Li             9   \n",
       "476  4232                           Zhi Li             8   \n",
       "477  4233                    Chi-Feng Wang             3   \n",
       "478  4234                   Prashant Gupta             7   \n",
       "479  4235                     Saul Dobilas             9   \n",
       "480  4236                Vincenzo Lavorini             6   \n",
       "481  4237               Dr. Robert Kübler            10   \n",
       "482  4238                   Baptiste Rocca            22   \n",
       "483  4239            Kenneth Cortés Aguas            11   \n",
       "484  4240                   Dave Gershgorn             8   \n",
       "485  4241                       Ayush Pant             6   \n",
       "486  4242                   Jeff Nickoloff             8   \n",
       "487  4243                Syed Sadat Nazrul             6   \n",
       "488  4244                    Utkarsh Desai             6   \n",
       "489  4245                    Félix Revert             8   \n",
       "490  4246                 Alexander Hirner             5   \n",
       "491  4247                Gabriel Cassimiro             3   \n",
       "492  4248                    Lavanya Gupta             7   \n",
       "493  4249                        Tim Löhr            10   \n",
       "494  4250                         Dan Hill            20   \n",
       "495  4251                   Tiago M. Leite             9   \n",
       "496  4252                    Tejan Karmali             6   \n",
       "497  4253                          Insight             5   \n",
       "498  4254                 Aleksey Tikhonov             1   \n",
       "499  4255                      Victor Sanh            10   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                     link  \\\n",
       "0                                                                                                                                                                                https://towardsdatascience.com/step-by-step-r-cnn-implementation-from-scratch-in-python-e97101ccde55?source=tag_archive---------0-----------------------   \n",
       "1                                                                                                                                                                                                                            https://towardsdatascience.com/transformers-141e32e69591?source=tag_archive---------8-----------------------   \n",
       "2                                                                                                                                                                                                   https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------4-----------------------   \n",
       "3                                                                                                                                                                                                 https://medium.com/@palewar/amazons-artificial-artificial-intelligence-a5d89253184e?source=tag_archive---------0-----------------------   \n",
       "4                                                                                                                                                                                                 https://medium.com/sdg-counting/this-week-in-the-sdgs-february-17-2017-d88bc4d62dac?source=tag_archive---------0-----------------------   \n",
       "5                                                                                                                                                                                     https://medium.com/@mrtampham/my-unconventional-year-after-dropping-out-of-college-befb536852dc?source=tag_archive---------3-----------------------   \n",
       "6                                                                                                                                                                                                    https://lab.elconfidencial.com/introducci%C3%B3n-a-machine-learning-e3caed58e37a?source=tag_archive---------2-----------------------   \n",
       "7                                                                                                                                                                                                   https://medium.com/the-awl/when-exactly-did-it-get-cool-to-be-a-geek-44d360e98ba5?source=tag_archive---------0-----------------------   \n",
       "8                                                                                                                                                                                                            https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------7-----------------------   \n",
       "9                                                                                                                                                                                             https://medium.com/@igordesousa/lou-reed-entre-transformer-e-berlin-o-mito-3c5ff2c36f59?source=tag_archive---------3-----------------------   \n",
       "10                                                                                                                                                                                                                  https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471?source=tag_archive---------1-----------------------   \n",
       "11                                                                                                                                                                    https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047?source=tag_archive---------5-----------------------   \n",
       "12                                                                                                                                                  https://towardsdatascience.com/it-support-ticket-classification-and-deployment-using-machine-learning-and-aws-lambda-8ef8b82643b6?source=tag_archive---------2-----------------------   \n",
       "13                                                                                                                                                                                               https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f?source=tag_archive---------0-----------------------   \n",
       "14                                                                                                                                                                                        https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db?source=tag_archive---------0-----------------------   \n",
       "15                                                                                                                                                                                https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------0-----------------------   \n",
       "16                                                                                                                                                               https://medium.com/iot-and-cloud/iot-learning-algorithms-and-predictive-maintenance-3-few-shot-learning-95154b606197?source=tag_archive---------6-----------------------   \n",
       "17                                                                                                                                       https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd?source=tag_archive---------5-----------------------   \n",
       "18                                                                                                                                                                                 https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------7-----------------------   \n",
       "19                                                                                                                                          https://medium.com/analytics-vidhya/computer-vision-tutorial-implementing-mask-r-cnn-for-image-segmentation-with-python-code-fe34da5b99cd?source=tag_archive---------8-----------------------   \n",
       "20                                                                                                                                                                                                 https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------0-----------------------   \n",
       "21                                                                                                                                                                                                                 https://medium.com/henry-jia/how-to-score-your-credit-1c08dd73e2ed?source=tag_archive---------7-----------------------   \n",
       "22                                                                                                                                                                                    https://medium.com/@justindavies/from-gensim-models-doc2vec-import-labeledsentence-9b631f9f567f?source=tag_archive---------5-----------------------   \n",
       "23                                                                                                                                        https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862?source=tag_archive---------3-----------------------   \n",
       "24                                                                                                                                                           https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8?source=tag_archive---------9-----------------------   \n",
       "25                                                                                                                                                      https://medium.com/@debmalyabiswas/i-had-an-opportunity-to-attend-the-oreilly-ai-london-conference-oct-9-11-2018-bf304ad69fd8?source=tag_archive---------6-----------------------   \n",
       "26                                                                                                                                                                   https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456?source=tag_archive---------0-----------------------   \n",
       "27                                                                                                                                                                                  https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1?source=tag_archive---------0-----------------------   \n",
       "28                                                                                                                                                                              https://medium.com/@hrishikeshio/traveling-santa-problem-an-incompetent-algorists-attempt-49ad9d26b26?source=tag_archive---------9-----------------------   \n",
       "29                                                                                                                                                                                          https://medium.com/slidemagic/data-without-context-is-meaningless-and-boring-c4a9944959a8?source=tag_archive---------4-----------------------   \n",
       "30                                                                                                                                                                                                           https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538?source=tag_archive---------4-----------------------   \n",
       "31                                                                                                                                                                                                    https://medium.com/@Knoyd/gotta-catch-them-all-but-which-one-first-7d808378de72?source=tag_archive---------5-----------------------   \n",
       "32                                                                                                                                                                                                                        https://towardsdatascience.com/glove-elmo-bert-9dbbc9226934?source=tag_archive---------6-----------------------   \n",
       "33                                                                                                                                                                                                   https://towardsdatascience.com/ai-safety-and-the-scaling-hypothesis-76bfee57f924?source=tag_archive---------8-----------------------   \n",
       "34                                                                                                                                  https://medium.com/@am1goo/%D0%BF%D0%BE%D0%B4%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D0%B5-%D0%BA%D0%B0%D0%BC%D0%BD%D0%B8-unet-%D0%B2-unity-5-8e78a0e673b8?source=tag_archive---------0-----------------------   \n",
       "35                                                                                                                                                                                                      https://medium.com/@saidakbarp/real-time-face-recognition-tflite-3fb818ac039a?source=tag_archive---------4-----------------------   \n",
       "36                                                                                                                                                                                                      https://towardsdatascience.com/decision-tree-in-machine-learning-e380942a4c96?source=tag_archive---------4-----------------------   \n",
       "37                                                                                                                                                                                 https://onezero.medium.com/deepminds-latest-a-i-health-breakthrough-has-some-problems-5cd14e2c77ef?source=tag_archive---------1-----------------------   \n",
       "38                                                                                                                                                                   https://towardsdatascience.com/dbscan-clustering-for-data-shapes-k-means-cant-handle-well-in-python-6be89af4e6ea?source=tag_archive---------0-----------------------   \n",
       "39                                                                                                                                                                            https://towardsdatascience.com/how-does-back-propagation-in-artificial-neural-networks-work-c7cad873ea7?source=tag_archive---------4-----------------------   \n",
       "40                                                                                                                                                          https://medium.com/emergent-future/teslas-big-plans-deepmind-pays-for-itself-internet-drones-and-moore-s-law-54e6bd8e2750?source=tag_archive---------8-----------------------   \n",
       "41                                                                                                                                                                                              https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751?source=tag_archive---------1-----------------------   \n",
       "42                                                                                                                                                                                 https://medium.com/@michaelulin/serving-pytorch-models-on-aws-lambda-with-caffe2-onnx-7b096806cfac?source=tag_archive---------8-----------------------   \n",
       "43                                                                                                                                       https://medium.com/%E4%BA%BA%E6%A9%9F%E5%85%B1%E7%94%9F%E4%BD%A0%E6%88%91%E5%AE%83/explainable-ai-for-intelligent-systems-part2-be9296529582?source=tag_archive---------5-----------------------   \n",
       "44                                                                                                                                                                  https://medium.com/data-science-group-iitr/artistic-style-transfer-with-convolutional-neural-network-7ce2476039fd?source=tag_archive---------0-----------------------   \n",
       "45                                                                                                                                                                             https://blog.mlreview.com/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07?source=tag_archive---------5-----------------------   \n",
       "46                                                                                                                                                                          https://towardsdatascience.com/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15?source=tag_archive---------3-----------------------   \n",
       "47                                                                                                                                                                                              https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66?source=tag_archive---------1-----------------------   \n",
       "48                                                                                                                                                                                                        https://medium.com/@voshart/appearance-of-the-principate-pt-ii-3df539f18fe5?source=tag_archive---------4-----------------------   \n",
       "49                                                                                                                                                                                                              https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------9-----------------------   \n",
       "50                                                                                                                                                                                         https://towardsdatascience.com/understanding-logistic-regression-step-by-step-704a78be7e0a?source=tag_archive---------2-----------------------   \n",
       "51                                                                                                                                                                https://medium.com/@apdullahyayik/mask-rcnn-object-recognition-and-segmentation-with-colab-application-cd0b5e490130?source=tag_archive---------8-----------------------   \n",
       "52                                                                                                                                                                              https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------0-----------------------   \n",
       "53                                                                                                                                                                                                                      https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767?source=tag_archive---------1-----------------------   \n",
       "54                                                                                                                                                             https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32?source=tag_archive---------1-----------------------   \n",
       "55                                                                                                                                                                                        https://medium.com/@marciogj/dbscan-on-trajectories-determining-eps-and-minpts-ba3aa7c4ed7c?source=tag_archive---------2-----------------------   \n",
       "56                                                                                                                                                                         https://medium.com/@vicenteluego/tiktoks-new-feature-anime-filter-got-million-posts-in-3-days-c18a866e842e?source=tag_archive---------7-----------------------   \n",
       "57                                                                                                                                                 https://towardsdatascience.com/alphafold-based-databases-and-fully-fledged-easy-to-use-alphafold-interfaces-poised-to-baf865c6d75e?source=tag_archive---------2-----------------------   \n",
       "58                                                                                                                                                                               https://medium.com/@jmlbeaujour/real-time-matting-of-webcam-video-on-the-browser-part-1-2c71a330ed08?source=tag_archive---------1-----------------------   \n",
       "59                                                                                                                                                                                                https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=tag_archive---------7-----------------------   \n",
       "60                                                                                                                                                                              https://towardsdatascience.com/reinforcement-learning-w-keras-openai-actor-critic-models-f084612cfd69?source=tag_archive---------1-----------------------   \n",
       "61                                                                                                                                                                https://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d?source=tag_archive---------2-----------------------   \n",
       "62                                                                                                                                                                             https://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af?source=tag_archive---------0-----------------------   \n",
       "63                                                                                                                                                                                                 https://towardsdatascience.com/how-to-train-a-bert-model-from-scratch-72cfce554fc6?source=tag_archive---------6-----------------------   \n",
       "64                                                                                                                                                                                  https://towardsdatascience.com/credit-card-fraud-detection-using-autoencoders-in-h2o-399cbb7ae4f1?source=tag_archive---------7-----------------------   \n",
       "65                                                                                                                                                                                                      https://towardsdatascience.com/backpropagation-the-natural-proof-946c5abf63b1?source=tag_archive---------7-----------------------   \n",
       "66                                                                                                                                                                                                https://heartbeat.comet.ml/basics-of-image-classification-with-pytorch-2f8973c51864?source=tag_archive---------9-----------------------   \n",
       "67                                                                                                                                                                                                 https://blog.clairvoyantsoft.com/music-genre-classification-using-cnn-ef9461553726?source=tag_archive---------7-----------------------   \n",
       "68                                                                                                                                                                      https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d?source=tag_archive---------2-----------------------   \n",
       "69                                                                                                                                                                         https://medium.com/@mst3c/google-deepmind-style-datacenter-optimization-ai-model-on-the-cheap-75f054330d27?source=tag_archive---------2-----------------------   \n",
       "70                                                                                                                                                              https://medium.com/acuity-derivatives/the-volcker-metric-known-as-inventory-aging-and-thoughts-of-whisky-a6011bf720d4?source=tag_archive---------1-----------------------   \n",
       "71                                                                                                                                                                                                  https://towardsdatascience.com/prior-over-functions-gaussian-process-1c58e8c40272?source=tag_archive---------4-----------------------   \n",
       "72                                                                                                                                                                                         https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------1-----------------------   \n",
       "73                                                                                                                                                                                      https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c?source=tag_archive---------0-----------------------   \n",
       "74                                                                                                                                                                                                                         https://medium.com/swlh/ner-spacy-and-lasagne-51b56fdad57e?source=tag_archive---------6-----------------------   \n",
       "75                                                                                                                                                                                      https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0?source=tag_archive---------5-----------------------   \n",
       "76                                                                                                                                                                                                   https://medium.com/analytics-vidhya/a-short-introduction-of-stylegan-898fe781937?source=tag_archive---------5-----------------------   \n",
       "77                                                                                                                                                                                                             https://medium.com/@wyhzest/css-box-model-and-positioning-9f0263d60759?source=tag_archive---------9-----------------------   \n",
       "78                                                                                                                                                                                          https://towardsdatascience.com/text-summarization-using-deep-neural-networks-e7ee7521d804?source=tag_archive---------4-----------------------   \n",
       "79                                                                                                                                                                           https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1?source=tag_archive---------8-----------------------   \n",
       "80                                                                                                                                                                                                 https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875?source=tag_archive---------8-----------------------   \n",
       "81                                                                                                                                                                                                      https://towardsdatascience.com/using-resnet-for-time-series-data-4ced1f5395e3?source=tag_archive---------8-----------------------   \n",
       "82                                                                                                                                                                                                      https://medium.com/@bond-kirill-alexandrovich/understanding-unet-27de538e08d8?source=tag_archive---------3-----------------------   \n",
       "83                                                                                                                                                                                                                  https://tech.goibibo.com/presenting-goibibo-insights-6b2ea7b3abc4?source=tag_archive---------5-----------------------   \n",
       "84                                                                                                                                                                                                         https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714?source=tag_archive---------5-----------------------   \n",
       "85                                                                                                                                                                                   https://medium.com/@gurrampavan6/fast-and-faster-region-based-convolutional-network-6a391a5a247a?source=tag_archive---------3-----------------------   \n",
       "86                                                                                                                                                                                         https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf?source=tag_archive---------4-----------------------   \n",
       "87                                                                                                                                                                                               https://medium.com/analytics-vidhya/automated-feature-engineering-tools-44d00be56e3a?source=tag_archive---------4-----------------------   \n",
       "88                                                                                                                                                                                                       https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d?source=tag_archive---------3-----------------------   \n",
       "89                                                                                                                                                                      https://medium.com/@mohamedhajr/ophow-i-got-my-first-android-job-without-a-degree-and-experience-98c70b931a9d?source=tag_archive---------2-----------------------   \n",
       "90                                                                                                                                                                                                          https://towardsdatascience.com/machine-learning-basics-part-1-a36d38c7916?source=tag_archive---------8-----------------------   \n",
       "91                                                                                                                                                                                                   https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6?source=tag_archive---------9-----------------------   \n",
       "92                                                                                                                                                                                         https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff?source=tag_archive---------7-----------------------   \n",
       "93                                                                                                                                                                        https://medium.com/intel-student-ambassadors/diving-into-abstractive-text-summarization-part-1-e8570d370021?source=tag_archive---------5-----------------------   \n",
       "94                                                                                                                                                                                                                https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=tag_archive---------0-----------------------   \n",
       "95                                                                                                                                                                                                        https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3?source=tag_archive---------3-----------------------   \n",
       "96                                                                                                                                                  https://towardsdatascience.com/gaussian-mixture-model-clusterization-how-to-select-the-number-of-components-clusters-553bef45f6e4?source=tag_archive---------6-----------------------   \n",
       "97                                                                                                                                                                              https://towardsdatascience.com/understanding-optimization-algorithms-in-machine-learning-edfdb4df766b?source=tag_archive---------9-----------------------   \n",
       "98                                                                                                                                                        https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=tag_archive---------4-----------------------   \n",
       "99                                                                                                                                                                                                                         https://cvil.ly/no-home-for-ipad-on-apple-com-88074e5ad99f?source=tag_archive---------4-----------------------   \n",
       "100                                                                                                                                                                                                      https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263?source=tag_archive---------3-----------------------   \n",
       "101                                                                                                                                   https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------2-----------------------   \n",
       "102                                                                                                                                                                                     https://towardsdatascience.com/read-text-from-image-with-one-line-of-python-code-c22ede074cac?source=tag_archive---------4-----------------------   \n",
       "103                                                                                                                                                                    https://towardsdatascience.com/interpreting-recurrent-neural-networks-on-multivariate-time-series-ebec0edb8f5a?source=tag_archive---------4-----------------------   \n",
       "104                                                                                                                                                                      https://towardsdatascience.com/how-i-went-from-zero-coding-skills-to-data-scientist-in-6-months-c2207b65f2f3?source=tag_archive---------0-----------------------   \n",
       "105                                                                                                                                                                                                           https://uxdesign.cc/20-ideas-for-better-data-visualization-73f7e3c2782d?source=tag_archive---------3-----------------------   \n",
       "106                                                                                                                                                                                                       https://medium.com/@JoshDHolmes/blog-9-information-architecture-3bc96dabdc0?source=tag_archive---------2-----------------------   \n",
       "107                                                                                                                                                                                                                   https://medium.com/konvergen/understanding-dropout-ddb60c9f98aa?source=tag_archive---------2-----------------------   \n",
       "108                                                                                                                                                                    https://medium.com/@RU_TokenGo/tokengo-%D0%B7%D0%B0%D0%BF%D1%83%D1%81%D0%BA%D0%B0%D0%B5%D1%82-ico-15ed47e79fb7?source=tag_archive---------3-----------------------   \n",
       "109                                                                                                                                                                     https://medium.com/@hackintoshrao/tips-to-avoid-the-pitfall-of-over-fitting-in-linear-regression-468e590c4f92?source=tag_archive---------6-----------------------   \n",
       "110                                                                                                                                                             https://medium.com/@pallawi-ds/step-by-step-understand-the-architecture-of-region-proposal-network-r-cnn-695a14a060a7?source=tag_archive---------2-----------------------   \n",
       "111                                                                                                                                                                       https://medium.com/@unchainet/invest-in-unchainet-heterogeneous-cloud-computing-infrastructure-b61dd2ba36e0?source=tag_archive---------5-----------------------   \n",
       "112                                                                                                                                                                                                                    https://medium.com/teklit/coding-is-a-trap-get-out-14a6beb28c8?source=tag_archive---------7-----------------------   \n",
       "113                                                                                                                                                                           https://medium.com/emaasit/in-case-you-missed-it-my-webinar-on-model-based-machine-learning-1ca6bef79ae?source=tag_archive---------1-----------------------   \n",
       "114                                                                                                                                                                              https://medium.com/hackernoon/instance-segmentation-in-google-colab-with-custom-dataset-b3099ac23f35?source=tag_archive---------5-----------------------   \n",
       "115                                                                                                                                                           https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a?source=tag_archive---------0-----------------------   \n",
       "116                                                                                                                                                                               https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02?source=tag_archive---------9-----------------------   \n",
       "117                                                                                                                                                                   https://medium.com/the-official-unofficial-firefox-blog/the-first-inaugural-firefox-census-results-a1a05327ed7f?source=tag_archive---------2-----------------------   \n",
       "118                                                                                                                                                         https://towardsdatascience.com/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706?source=tag_archive---------8-----------------------   \n",
       "119                                                                                                                                        https://towardsdatascience.com/eagleview-super-high-resolution-image-segmentation-with-deeplabv3-mask-rcnn-using-keras-arcgis-9be08caac42c?source=tag_archive---------5-----------------------   \n",
       "120                                                                                                                                                                           https://medium.com/@udaybhaskarpaila/everything-you-need-to-know-about-logistic-regression-18e740be87a0?source=tag_archive---------8-----------------------   \n",
       "121                                                                                                                                                             https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be?source=tag_archive---------4-----------------------   \n",
       "122                                                                                                                                                                                                                   https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------3-----------------------   \n",
       "123                                                                                                                                                                                                          https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd?source=tag_archive---------1-----------------------   \n",
       "124                                                                                                                                                                          https://towardsdatascience.com/u-net-for-semantic-segmentation-on-unbalanced-aerial-imagery-3474fa1d3e56?source=tag_archive---------4-----------------------   \n",
       "125                                                                                                                                                                          https://medium.com/analytics-vidhya/dimensionality-reduction-by-stochastic-gradient-descent-f617ebde3c1b?source=tag_archive---------4-----------------------   \n",
       "126                                                                                                                                                                                        https://towardsdatascience.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647?source=tag_archive---------7-----------------------   \n",
       "127                                                                                                                                   https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------6-----------------------   \n",
       "128                                                                                                                                                                                                        https://medium.com/unpackai/sgd-mnist-putting-it-all-together-2b09d21c9e9a?source=tag_archive---------8-----------------------   \n",
       "129                                                                                                                                                                        https://towardsdatascience.com/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f?source=tag_archive---------9-----------------------   \n",
       "130                                                                                                                                             https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8?source=tag_archive---------2-----------------------   \n",
       "131                                                                                                                                                                           https://medium.com/nanonets/how-to-easily-detect-objects-with-deep-learning-on-raspberrypi-225f29635c74?source=tag_archive---------2-----------------------   \n",
       "132                                                                                                                                                                                               https://towardsdatascience.com/an-intuitive-explanation-of-beam-search-9b1d744e7a0f?source=tag_archive---------1-----------------------   \n",
       "133                                                                                                                                                                                                                 https://towardsdatascience.com/the-games-that-ai-won-ff8fd4a71efc?source=tag_archive---------6-----------------------   \n",
       "134                                                                                                                                                          https://medium.com/@bitsofinfo/clustering-liferay-globally-across-data-centers-gslb-with-jgroups-and-relay2-7786b8dbbb96?source=tag_archive---------3-----------------------   \n",
       "135                                                                                                                                                                                                           https://medium.com/@andreasyonathan/kuliah-itu-gak-penting-292defe6d476?source=tag_archive---------3-----------------------   \n",
       "136                                                                                                                                                                                     https://towardsdatascience.com/word-embeddings-in-2020-review-with-code-examples-11eb39a1ee6d?source=tag_archive---------1-----------------------   \n",
       "137                                                                                                                                                                                          https://towardsdatascience.com/autoencoders-introduction-and-implementation-3f40483b0a85?source=tag_archive---------1-----------------------   \n",
       "138                                                                                                                                                                                                     https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c?source=tag_archive---------8-----------------------   \n",
       "139                                                                                                                                                                                         https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1?source=tag_archive---------3-----------------------   \n",
       "140                                                                                                                                                                                                                  https://towardsdatascience.com/pixelcnns-blind-spot-84e19a3797b9?source=tag_archive---------6-----------------------   \n",
       "141                                                                                                                                                                                  https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac?source=tag_archive---------2-----------------------   \n",
       "142                                                                                                                                                                               https://towardsdatascience.com/practical-implementation-of-outlier-detection-in-python-90680453b3ce?source=tag_archive---------2-----------------------   \n",
       "143                                                                                                                                                                                                         https://medium.com/sap-design/explaining-system-intelligence-68f8fcc07a64?source=tag_archive---------2-----------------------   \n",
       "144                                                                                                                                                                              https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24?source=tag_archive---------0-----------------------   \n",
       "145                                                                                                                                                       https://medium.com/analytics-vidhya/step-by-step-implementation-of-conditional-generative-adversarial-networks-54e4b47497d6?source=tag_archive---------9-----------------------   \n",
       "146                                                                                                                                                                                  https://towardsdatascience.com/multiclass-text-classification-using-lstm-in-pytorch-eac56baed8df?source=tag_archive---------3-----------------------   \n",
       "147                                                                                                                                                                                                        https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2?source=tag_archive---------2-----------------------   \n",
       "148                                                                                                                                                                                          https://towardsdatascience.com/autoencoders-bits-and-bytes-of-deep-learning-eaba376f23ad?source=tag_archive---------0-----------------------   \n",
       "149                                                                                                                                                                                   https://medium.com/@dhruvp/how-to-write-a-neural-network-to-play-pong-from-scratch-956b57d4f6e0?source=tag_archive---------0-----------------------   \n",
       "150                                                                                                                                                                              https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db?source=tag_archive---------9-----------------------   \n",
       "151                                                                                                                                                 https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156?source=tag_archive---------0-----------------------   \n",
       "152                                                                                                                                                              https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089?source=tag_archive---------2-----------------------   \n",
       "153                                                                                                                                                                                 https://towardsdatascience.com/deep-latent-variable-models-unravel-hidden-structures-a5df0fd32ae2?source=tag_archive---------4-----------------------   \n",
       "154                                                                                                                                                                                 https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------6-----------------------   \n",
       "155                                                                                                                                                                                                                  https://medium.com/@elifmeseci/r-cnn-ailesi-part-ii-76cce9e4a9d6?source=tag_archive---------4-----------------------   \n",
       "156                                                                                                                                                                               https://towardsdatascience.com/clustering-techniques-hierarchical-and-non-hierarchical-b520b5d6a022?source=tag_archive---------7-----------------------   \n",
       "157                                                                                                                                                                         https://medium.com/analytics-vidhya/introduction-to-object-detection-with-rcnn-family-models-310558ce2033?source=tag_archive---------0-----------------------   \n",
       "158                                                                                                                                                                                                      https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537?source=tag_archive---------0-----------------------   \n",
       "159                                                                                                                                                                       https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=tag_archive---------8-----------------------   \n",
       "160                                                                                                                                                                                  https://medium.com/ipg-media-lab/amazon-adds-photographic-product-search-to-ios-app-3c023e5d71ed?source=tag_archive---------1-----------------------   \n",
       "161                                                                                                                                                                                      https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34?source=tag_archive---------8-----------------------   \n",
       "162                                                                                                                                                                   https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53?source=tag_archive---------2-----------------------   \n",
       "163                                                                                                                                                         https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438?source=tag_archive---------8-----------------------   \n",
       "164                                                                                                                                                                                   https://towardsdatascience.com/neural-networks-backpropagation-by-dr-lihi-gur-arie-27be67d8fdce?source=tag_archive---------5-----------------------   \n",
       "165                                                                                                                                                                 https://towardsdatascience.com/icml-2018-advances-in-transfer-multitask-and-semi-supervised-learning-2a15ef7208ec?source=tag_archive---------1-----------------------   \n",
       "166                                                                                                                                                                                  https://towardsdatascience.com/run-stylegan2-ada-on-an-aws-spot-instance-in-no-time-d2022fc1e119?source=tag_archive---------4-----------------------   \n",
       "167                                                                                                                                                          https://towardsdatascience.com/generating-text-with-recurrent-neural-networks-based-on-the-work-of-f-pessoa-1e804d88692d?source=tag_archive---------6-----------------------   \n",
       "168                                                                                                                                                                             https://medium.com/@adampickard_44261/advancements-in-machine-learning-assisted-ideation-5c42cdf69c37?source=tag_archive---------8-----------------------   \n",
       "169                                                                                                                                  https://medium.com/@jongdae.lim/%EA%B8%B0%EA%B3%84-%ED%95%99%EC%8A%B5-machine-learning-%EC%9D%80-%EC%A6%90%EA%B2%81%EB%8B%A4-part-5-83b7a44b797a?source=tag_archive---------8-----------------------   \n",
       "170                                                                                                                                                                         https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?source=tag_archive---------9-----------------------   \n",
       "171                                                                                                                                                                                              https://medium.com/hackernoon/rnn-or-recurrent-neural-network-for-noobs-a9afbb00e860?source=tag_archive---------6-----------------------   \n",
       "172                                                                                                                                                                                                          https://medium.com/@2809ayushic/optimizers-in-deep-learning-31db684c73cf?source=tag_archive---------0-----------------------   \n",
       "173                                                                                                                                                       https://towardsdatascience.com/isolation-forest-the-anomaly-detection-algorithm-any-data-scientist-should-know-1a99622eec2d?source=tag_archive---------1-----------------------   \n",
       "174                                                                                                                                                                                                                        https://medium.com/hackernoon/word2vec-part-1-fe2ec6514d70?source=tag_archive---------9-----------------------   \n",
       "175                                                                                                                                                                              https://towardsdatascience.com/keywords-to-know-before-you-start-reading-papers-on-gans-8a08a665b40c?source=tag_archive---------7-----------------------   \n",
       "176                                                                                                                                                                                                 https://medium.com/@robparkin_38642/bayesian-variational-autoencoder-4bb698c84644?source=tag_archive---------9-----------------------   \n",
       "177                                                                                                                                                                                     https://medium.com/cubo-ai/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540?source=tag_archive---------5-----------------------   \n",
       "178                                                                                                                                                                                                         https://medium.com/@robbietilton/emotional-computing-with-ai-3513884055fa?source=tag_archive---------2-----------------------   \n",
       "179                                                                                                                                                                  https://medium.com/@huangkaikai/computational-creativity-generative-creature-design-for-concept-art-c4a1180ae0e6?source=tag_archive---------1-----------------------   \n",
       "180                                                                                                                                                                                                   https://medium.com/nurture-ai/learning-artistic-styles-from-images-a07037fa46e3?source=tag_archive---------6-----------------------   \n",
       "181                                                                                                                                                                                            https://towardsdatascience.com/a-friendly-introduction-to-text-clustering-fa996bcefd04?source=tag_archive---------6-----------------------   \n",
       "182                                                                                                                                                                                https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf?source=tag_archive---------4-----------------------   \n",
       "183                                                                                                                                                                                           https://towardsdatascience.com/an-overview-for-text-representations-in-nlp-311253730af1?source=tag_archive---------6-----------------------   \n",
       "184                                                                                                                                                                        https://medium.com/@vivek-yadav/why-is-gradient-descent-robust-to-non-linearly-separable-data-a50c543e8f4a?source=tag_archive---------2-----------------------   \n",
       "185                                                                                                                                                                                                                        https://medium.com/edureka/k-means-clustering-1db7b018a0a2?source=tag_archive---------0-----------------------   \n",
       "186                                                                                                                                                                                                          https://towardsdatascience.com/meta-learning-ai-generalised-1007b9695fe1?source=tag_archive---------2-----------------------   \n",
       "187                                                                                                                                                                                      https://towardsdatascience.com/gamma-function-intuition-derivation-and-examples-5e5f72517dee?source=tag_archive---------7-----------------------   \n",
       "188                                                                                                                                                                               https://towardsdatascience.com/a-beginners-guide-to-convolutional-neural-networks-cnns-14649dbddce8?source=tag_archive---------4-----------------------   \n",
       "189                                                                                                                                                                   https://medium.com/@aneesha/using-affinity-propagation-to-find-the-number-of-clusters-in-a-dataset-52f5dd3b0760?source=tag_archive---------1-----------------------   \n",
       "190                                                                                                                                                                                   https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92?source=tag_archive---------6-----------------------   \n",
       "191                                                                                                                                                                                     https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29?source=tag_archive---------6-----------------------   \n",
       "192                                                                                                                                                                   https://blog.insightdatascience.com/data-visualization-in-python-advanced-functionality-in-seaborn-20d217f1a9a6?source=tag_archive---------6-----------------------   \n",
       "193                                                                                                                                                                                              https://medium.com/somx-labs/lets-talk-clustering-unsupervised-learning-1c89bc27e908?source=tag_archive---------3-----------------------   \n",
       "194                                                                                                                                                                                     https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------5-----------------------   \n",
       "195                                                                                                                                      https://medium.com/@ravipandey71998/image-classifier-using-vgg-19-deep-learning-model-in-google-colab-notebook-dishes-detection-34861168e055?source=tag_archive---------3-----------------------   \n",
       "196                                                                                                                                  https://medium.com/@aleksipietikinen/an-analysis-on-how-deepminds-starcraft-2-ai-s-superhuman-speed-could-be-a-band-aid-fix-for-the-1702fb8344d6?source=tag_archive---------2-----------------------   \n",
       "197                                                                                                                                                                                                 https://towardsdatascience.com/neural-style-transfer-using-vgg-model-ff0f9757aafc?source=tag_archive---------3-----------------------   \n",
       "198                                                                                                                                                              https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4?source=tag_archive---------2-----------------------   \n",
       "199                                                                                                                                                                                              https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129?source=tag_archive---------0-----------------------   \n",
       "200                                                                                                                                                                                                              https://medium.com/analytics-vidhya/ner-tensorflow-2-2-0-9f10dcf5a0a?source=tag_archive---------8-----------------------   \n",
       "201                                                                                                                                                                                 https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------3-----------------------   \n",
       "202                                                                                                                                                         https://medium.com/analytics-vidhya/implementation-of-principal-component-analysis-pca-in-k-means-clustering-b4bc0aa79cb6?source=tag_archive---------4-----------------------   \n",
       "203                                                                                                                                                                               https://medium.com/a-problem-like-maria/ai-class-com-a-classroom-with-160-000-students-9c16f6e31390?source=tag_archive---------4-----------------------   \n",
       "204                                                                                                                                                                                             https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17?source=tag_archive---------1-----------------------   \n",
       "205                                                                                                                                                                                   https://towardsdatascience.com/polynomial-regression-gradient-descent-from-scratch-279db2936fe9?source=tag_archive---------3-----------------------   \n",
       "206                                                                                                                                                                              https://medium.com/syncedreview/from-faces-to-kitties-to-apartments-gan-fakes-the-world-ae04e5cbddf6?source=tag_archive---------6-----------------------   \n",
       "207                                                                                                                                                                            https://medium.com/swlh/deep-learning-architectures-that-you-can-use-with-a-very-few-data-8e5b4fa1d5da?source=tag_archive---------8-----------------------   \n",
       "208                                                                                                                                                                                                            https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c?source=tag_archive---------1-----------------------   \n",
       "209                                                                                                                                                                                                https://becominghuman.ai/transfer-learning-part-4-0-vgg-16-and-vgg-19-d7f0045032de?source=tag_archive---------4-----------------------   \n",
       "210                                                                                                                                                       https://medium.com/syncedreview/google-deepmind-releases-structure-predictions-for-coronavirus-linked-proteins-7dfb2fad05b6?source=tag_archive---------8-----------------------   \n",
       "211                                                                                                                                                                                                https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94?source=tag_archive---------4-----------------------   \n",
       "212                                                                                                                                            https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------9-----------------------   \n",
       "213                                                                                                                                                                                   https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1?source=tag_archive---------7-----------------------   \n",
       "214                                                                                                                                                                                          https://medium.com/sa%C3%BAde-digital/rsna-2013-top-5-tend%C3%AAncias-em-ti-528f595225b7?source=tag_archive---------8-----------------------   \n",
       "215                                                                                                                                                                                                       https://netflixtechblog.com/extracting-image-metadata-at-scale-c89c60a2b9d2?source=tag_archive---------6-----------------------   \n",
       "216                                                                                                                                                                     https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9?source=tag_archive---------3-----------------------   \n",
       "217                                                                                                                                                                      https://medium.com/analytics-vidhya/using-maskrcnn-to-predict-tropical-fruits-in-custom-dataset-4f079d05fbe1?source=tag_archive---------4-----------------------   \n",
       "218                                                                                                                                                                        https://medium.com/@financial-engineering/tensorflow-2-0-variational-auto-encoder-vae-part-ii-df8adcd02f20?source=tag_archive---------9-----------------------   \n",
       "219                                                                                                                                                                                         https://medium.com/syncedreview/deepmind-et-al-paper-trumpets-graph-networks-9c74a271b903?source=tag_archive---------9-----------------------   \n",
       "220                                                                                                                                                                                                 https://towardsdatascience.com/data-science-for-newbies-including-me-d1c6bf3e390b?source=tag_archive---------0-----------------------   \n",
       "221                                                                                                                                                                           https://medium.com/@nnintruder/attacking-google-cloud-vision-api-with-adversarial-examples-d02af0174732?source=tag_archive---------3-----------------------   \n",
       "222                                                                                                                                                                        https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c?source=tag_archive---------2-----------------------   \n",
       "223                                                                                                                                                                          https://blog.agolo.com/knowledge-graphs-for-automatic-multi-longform-document-summarization-8f946e1e1877?source=tag_archive---------8-----------------------   \n",
       "224                                                                                                                                                                           https://medium.com/@gerardmaggiolino/creating-openai-gym-environments-with-pybullet-part-1-13895a622b24?source=tag_archive---------6-----------------------   \n",
       "225                                                                                                                                                                                https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31?source=tag_archive---------5-----------------------   \n",
       "226                                                                                                                                                                                       https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------2-----------------------   \n",
       "227                                                                                                                                                                                                     https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04?source=tag_archive---------0-----------------------   \n",
       "228                                                                                                                                     https://medium.com/syncedreview/quantum-chemistry-breakthrough-deepmind-uses-neural-networks-to-tackle-schr%C3%B6dinger-equation-a5ad4e3bfea0?source=tag_archive---------3-----------------------   \n",
       "229                                                                                                                                                                                                         https://towardsdatascience.com/explaining-k-means-clustering-5298dc47bad6?source=tag_archive---------5-----------------------   \n",
       "230                                                                                                                                                        https://medium.com/technology-invention-and-more/everything-you-need-to-know-about-artificial-neural-networks-57fac18245a1?source=tag_archive---------6-----------------------   \n",
       "231                                                                                                                                                                                             https://towardsdatascience.com/liquid-neural-networks-in-computer-vision-4a0f718b464e?source=tag_archive---------8-----------------------   \n",
       "232                                                                                                                                                                                                      https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b?source=tag_archive---------3-----------------------   \n",
       "233                                                                                                                                                                                  https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4?source=tag_archive---------0-----------------------   \n",
       "234                                                                                                                                                                                        https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96?source=tag_archive---------1-----------------------   \n",
       "235                                                                                                                                                     https://towardsdatascience.com/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca?source=tag_archive---------9-----------------------   \n",
       "236                                                                                                                                                                                     https://medium.com/@today.rafi/demystifying-object-detection-using-deep-learning-d3f83e2fb832?source=tag_archive---------2-----------------------   \n",
       "237                                                                                                                                                                                  https://towardsdatascience.com/paper-repro-deep-metalearning-using-maml-and-reptile-fd1df1cc81b0?source=tag_archive---------2-----------------------   \n",
       "238                                                                                    https://medium.com/@pedin024/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%84%AA%E5%8C%96%E5%99%A8ranger-a-synergistic-optimizer-using-radam-rectified-adam-gradient-centralization-and-f022d9dd4217?source=tag_archive---------3-----------------------   \n",
       "239                                                                                                                                                                                    https://towardsdatascience.com/machine-learning-polynomial-regression-with-python-5328e4e8a386?source=tag_archive---------1-----------------------   \n",
       "240                                                                                                                                                                      https://medium.com/@thirumalaivasudev/how-i-struggled-to-convert-mbr-to-gpt-and-installed-linux-7755b7946b93?source=tag_archive---------8-----------------------   \n",
       "241                                                                                                                                                                        https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568?source=tag_archive---------8-----------------------   \n",
       "242                                                                                                                                                      https://medium.com/ai%C2%B3-theory-practice-business/what-is-pre-training-in-nlp-introducing-5-key-technologies-455c54933054?source=tag_archive---------1-----------------------   \n",
       "243                                                                                                                                                                                                  https://towardsdatascience.com/vanishing-exploding-gradient-problem-b5b78c142bb7?source=tag_archive---------3-----------------------   \n",
       "244                                                                                                                                                 https://towardsdatascience.com/graph-neural-networks-through-the-lens-of-differential-geometry-and-algebraic-topology-3a7c3c22d5f?source=tag_archive---------1-----------------------   \n",
       "245                                                                                                                                                                                https://medium.com/@kerimov.nurlan/anomaly-detection-in-brightfield-microscopy-images-c92cdddafcc3?source=tag_archive---------8-----------------------   \n",
       "246                                                                                                                                                                                   https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7?source=tag_archive---------5-----------------------   \n",
       "247                                                                                                                                                                                           https://towardsdatascience.com/data-scientists-will-be-extinct-in-10-years-a6e5dd77162b?source=tag_archive---------2-----------------------   \n",
       "248                                                                                                                                                                                                           https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------3-----------------------   \n",
       "249                                                                                                                                                                             https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=tag_archive---------1-----------------------   \n",
       "250                                                                                                                                                                                                                 https://medium.com/@Dude_Next/the-dropout-tag-i-wear-9425f2cba27b?source=tag_archive---------8-----------------------   \n",
       "251                                                                                                                                                                                                     https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc?source=tag_archive---------5-----------------------   \n",
       "252                                                                                                                                                                                   https://medium.com/deep-systems/movix-ai-movie-recommendations-using-deep-learning-5903d6a31607?source=tag_archive---------9-----------------------   \n",
       "253                                                                                                                                                                   https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=tag_archive---------4-----------------------   \n",
       "254                                                                                                                                                                    https://towardsdatascience.com/generative-ai-visual-search-as-a-bridge-between-fiction-and-reality-46d2d78ee15?source=tag_archive---------3-----------------------   \n",
       "255                                                                                    https://medium.com/@akichan-f/efficientnet-b6-autoaug%E3%81%A8%E5%90%8C%E7%AD%89%E7%A8%8B%E5%BA%A6%E3%81%AE%E7%B2%BE%E5%BA%A6%E3%81%A75%E5%80%8D%E6%97%A9%E3%81%84assemble-resnet-c3b8b846e0a2?source=tag_archive---------9-----------------------   \n",
       "256                                                                                                                                                                 https://towardsdatascience.com/how-are-logistic-regression-ordinary-least-squares-regression-related-1deab32d79f5?source=tag_archive---------9-----------------------   \n",
       "257                                                                                                                                                                                                        https://medium.com/datathings/meta-learning-learning-to-learn-a55cadd32b17?source=tag_archive---------9-----------------------   \n",
       "258                                                                                                                                                                                       https://towardsdatascience.com/train-ner-with-custom-training-data-using-spacy-525ce748fab7?source=tag_archive---------1-----------------------   \n",
       "259                                                                                                                                                                                          https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81-gradient-descent-e97890236262?source=tag_archive---------7-----------------------   \n",
       "260                                                                                                                                                                                https://medium.com/@joaomariafernandes/why-i-dropped-out-of-college-but-you-shouldn-t-73a4b99f9cf9?source=tag_archive---------7-----------------------   \n",
       "261                                                                                                                                                                             https://medium.com/voice-tech-podcast/automatic-extractive-text-summarization-using-tfidf-3fc9a7b26f5?source=tag_archive---------4-----------------------   \n",
       "262                                                                                                                                                                               https://medium.com/javascript-scene/top-javascript-frameworks-and-tech-trends-for-2021-d8cb0f7bda69?source=tag_archive---------8-----------------------   \n",
       "263                                                                                                                                                     https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb?source=tag_archive---------2-----------------------   \n",
       "264                                                                                                                                                                                                                      https://medium.com/minds-on-media/finger-dasher-3332487b5f4e?source=tag_archive---------2-----------------------   \n",
       "265                                                                                                                                                                                  https://becominghuman.ai/a-news-analysis-neuralnet-learns-from-a-language-neuralnet-16646804fdeb?source=tag_archive---------9-----------------------   \n",
       "266                                                                                                                                                                                                        https://medium.com/kredo-ai-engineering/blog-series-on-ros-ai-ff28cc116560?source=tag_archive---------9-----------------------   \n",
       "267                                                                                                                                                                                                         https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3?source=tag_archive---------5-----------------------   \n",
       "268                                                                                                                                                              https://medium.com/@alexlenail/what-is-the-difference-between-ridge-regression-the-lasso-and-elasticnet-ec19c71c9028?source=tag_archive---------5-----------------------   \n",
       "269                                                                                                                                                                                                                  https://medium.com/@lipeng2/dropout-is-so-important-e517bbe3ffcc?source=tag_archive---------7-----------------------   \n",
       "270                                                                                                                                                                                      https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037?source=tag_archive---------5-----------------------   \n",
       "271                                                                                                                                                                     https://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49?source=tag_archive---------6-----------------------   \n",
       "272                                                                                                                                                                          https://medium.com/@ajiabs/socialdefender-social-reputation-management-platform-aji-abraham-593dafc771e2?source=tag_archive---------2-----------------------   \n",
       "273                                                                                                                                                                            https://towardsdatascience.com/the-hype-on-alphafold-keeps-growing-with-this-new-preprint-a8c1f21d15c8?source=tag_archive---------6-----------------------   \n",
       "274                                                                                                                                                                                                              https://medium.com/@eitan-kosman/neural-image-retrieval-72029a0dbd00?source=tag_archive---------6-----------------------   \n",
       "275                                                                                                                                                                              https://towardsdatascience.com/top-20-movies-about-machine-learning-ai-and-data-science-8382d408c8c3?source=tag_archive---------7-----------------------   \n",
       "276                                                                                                                                                                    https://medium.com/@luckylwk/transfer-learning-in-tensorflow-on-the-kaggle-rainforest-competition-4e978fadb571?source=tag_archive---------7-----------------------   \n",
       "277                                                                                                                                                                                         https://medium.com/analytics-vidhya/clustering-on-mixed-data-types-in-python-7c22b3898086?source=tag_archive---------7-----------------------   \n",
       "278                                                                                                                                                                                   https://medium.com/analytics-vidhya/insight-into-faster-r-cnn-for-object-detection-f1e64240eee1?source=tag_archive---------7-----------------------   \n",
       "279                                                                                                                                                                                        https://blog.mutsuda.com/intelligent-agent-based-wastewater-management-system-741b793f1c5c?source=tag_archive---------8-----------------------   \n",
       "280                                                                                                                                                                     https://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189?source=tag_archive---------2-----------------------   \n",
       "281                                                                                                                                                                                                   https://towardsdatascience.com/using-lstms-to-forecast-time-series-4ab688386b1f?source=tag_archive---------7-----------------------   \n",
       "282                                                                                                                                                     https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0?source=tag_archive---------8-----------------------   \n",
       "283                                                                                                                        https://medium.com/ai-academy-taiwan/%E5%B8%B6%E4%BD%A0%E8%AA%8D%E8%AD%98vector-quantized-variational-autoencoder-%E7%90%86%E8%AB%96%E7%AF%87-49a1829497bb?source=tag_archive---------6-----------------------   \n",
       "284                                                                                                                                                                          https://medium.com/stories-by-progress/true-democratization-of-analytics-with-meta-learning-cdefe3c7ddd5?source=tag_archive---------4-----------------------   \n",
       "285                                                                                                                                                                                           https://medium.com/@kawsar34/machine-learning-quiz-05-decision-tree-part-1-3ea71fa312e5?source=tag_archive---------5-----------------------   \n",
       "286                                                                                                                                                                                              https://towardsdatascience.com/speeding-up-bert-search-in-elasticsearch-750f1f34f455?source=tag_archive---------5-----------------------   \n",
       "287                                                                                                                                             https://medium.com/@interjc/%E5%86%99%E5%9C%A8%E7%9C%8B%E5%AE%8C%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9Aii%E4%B9%8B%E5%90%8E-ea5d294d2bd3?source=tag_archive---------0-----------------------   \n",
       "288                                                                                                                                                                                                                      https://medium.com/@ellehilly/classes-of-novels-c8207342dc0b?source=tag_archive---------7-----------------------   \n",
       "289                                                                                                                                                                                     https://medium.com/@akshikawijesundara/object-recognition-with-opencv-on-android-6435277ab285?source=tag_archive---------1-----------------------   \n",
       "290                                                                                                                                                         https://medium.com/@jonathan-hui/ssd-object-detection-single-shot-multibox-detector-for-real-time-processing-9bd8deac0e06?source=tag_archive---------7-----------------------   \n",
       "291                                                                                                                                                       https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec?source=tag_archive---------0-----------------------   \n",
       "292                                                                                                                                                                                                https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------1-----------------------   \n",
       "293                                                                                                                                                                                                        https://medium.com/swlh/transformer-based-sentence-embeddings-cd0935b3b1e0?source=tag_archive---------7-----------------------   \n",
       "294                                                                            https://medium.com/@botcho/stash-data-center-%E3%83%99%E3%83%BC%E3%82%BF%E7%89%88%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9-git-%E3%82%92%E5%A4%A7%E8%A6%8F%E6%A8%A1%E3%81%AB%E5%88%A9%E7%94%A8-2f0f46d5f2dd?source=tag_archive---------4-----------------------   \n",
       "295                                                                                                                                                             https://towardsdatascience.com/cnn-lstm-based-models-for-multiple-parallel-input-and-multi-step-forecast-6fe2172f7668?source=tag_archive---------2-----------------------   \n",
       "296                                                                                                                                                                                                    https://towardsdatascience.com/sentiment-analysis-using-rnns-lstm-60871fa6aeba?source=tag_archive---------9-----------------------   \n",
       "297                                                                                                                                                                                                             https://medium.com/@chinmaychetan04/activation-functions-78a99738a47c?source=tag_archive---------9-----------------------   \n",
       "298                                                                                                                                                                                 https://medium.com/@souravbit3366/sentence-correction-using-deep-learning-techniques-452eca50e1fd?source=tag_archive---------0-----------------------   \n",
       "299                                                                                                                                                                                                                          https://medium.com/project-agi/introduction-71d920ed051c?source=tag_archive---------0-----------------------   \n",
       "300                                                                                                                                                                                                   https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82?source=tag_archive---------8-----------------------   \n",
       "301                                                                                                                                                                                    https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29?source=tag_archive---------3-----------------------   \n",
       "302                                                                                                                                                                                                                        https://medium.com/@sachin-abeywardana/hi-tal-7212811eeb03?source=tag_archive---------4-----------------------   \n",
       "303                                                                                                                                                                     https://towardsdatascience.com/using-word-embeddings-to-identify-company-names-and-stock-tickers-f194e3648a66?source=tag_archive---------9-----------------------   \n",
       "304                                                                                                                                                                                           https://towardsdatascience.com/building-a-bayesian-deep-learning-classifier-ece1845bc09?source=tag_archive---------7-----------------------   \n",
       "305                                                                                                                                                        https://medium.com/free-code-camp/every-single-machine-learning-course-on-the-internet-ranked-by-your-reviews-3c4a7b8026c0?source=tag_archive---------2-----------------------   \n",
       "306                                                                                                                                                                                       https://medium.com/codait/art-ai-the-logic-behind-deep-learning-style-transfer-1f59f51441d1?source=tag_archive---------2-----------------------   \n",
       "307                                                                                                                                                                                 https://towardsdatascience.com/how-to-perform-abstractive-summarization-with-pegasus-3dd74e48bafb?source=tag_archive---------0-----------------------   \n",
       "308                                                                                                                                                                                                       https://medium.com/@wenchen-li/text-summarization-applications-ed319f0bb13c?source=tag_archive---------0-----------------------   \n",
       "309                                                                                                                                                              https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313?source=tag_archive---------5-----------------------   \n",
       "310                                                                                                                                                                               https://medium.com/cube-dev/time-series-prediction-using-recurrent-neural-networks-lstms-807fa6ca7f?source=tag_archive---------3-----------------------   \n",
       "311                                                                                                                                            https://medium.com/@RU_TokenGo/ico-tokengo-%D0%B7%D0%B0%D0%BA%D0%B0%D0%BD%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D1%82%D1%81%D1%8F-49baf882c955?source=tag_archive---------0-----------------------   \n",
       "312                                                                                                                                                                                                             https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add?source=tag_archive---------2-----------------------   \n",
       "313                                                                                                                                                                        https://towardsdatascience.com/semantic-image-segmentation-using-fully-convolutional-networks-bf0189fa3eb8?source=tag_archive---------1-----------------------   \n",
       "314                                                                                                                                                                                   https://medium.com/the-artificial-impostor/build-a-summarization-system-in-minutes-5f10c141bfe6?source=tag_archive---------7-----------------------   \n",
       "315                                                                                                                                                                                                  https://towardsdatascience.com/what-are-adversarial-examples-in-nlp-f928c574478e?source=tag_archive---------6-----------------------   \n",
       "316                                                                                                                                                                                   https://medium.com/@williamr/reducing-memory-usage-in-r-especially-for-regressions-8ed8070ae4d8?source=tag_archive---------4-----------------------   \n",
       "317                                                                                                                                                                      https://towardsdatascience.com/6-applications-of-auto-encoders-every-data-scientist-should-know-dc703cbc892b?source=tag_archive---------5-----------------------   \n",
       "318                                                                                                                                                                                                           https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f?source=tag_archive---------1-----------------------   \n",
       "319                                                                                                                                                                              https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610?source=tag_archive---------6-----------------------   \n",
       "320                                                                                                                                                                           https://medium.com/analytics-vidhya/when-neural-networks-saw-the-first-image-of-black-hole-3205e28b6578?source=tag_archive---------7-----------------------   \n",
       "321                                                                                                                                                                                   https://medium.com/starts-with-a-bang/weekend-diversion-the-ultimate-superhero-cake-129a990c35c?source=tag_archive---------0-----------------------   \n",
       "322                                                                                                                                                                                                                https://towardsdatascience.com/deep-generative-models-25ab2821afd3?source=tag_archive---------2-----------------------   \n",
       "323                                                                                                                                                                                               https://medium.com/responsibleml/adversarial-attacks-on-explainable-ai-f65d41e83c5f?source=tag_archive---------4-----------------------   \n",
       "324                                                                                                                                                                                                        https://medium.com/cltc-bulletin/adversarial-machine-learning-43b6de6aafdb?source=tag_archive---------3-----------------------   \n",
       "325                                                                                                                                                                                                                   https://medium.com/bisa-ai/intersection-over-union-a8d1532899b3?source=tag_archive---------4-----------------------   \n",
       "326                                                                                                                                                                                                    https://towardsdatascience.com/variational-autoencoder-in-finance-53ee5eb9ed98?source=tag_archive---------7-----------------------   \n",
       "327                                                                                                                                                                 https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463?source=tag_archive---------1-----------------------   \n",
       "328                                                                                                                                                                                                            https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af?source=tag_archive---------1-----------------------   \n",
       "329                                                                                                                                                                                                https://blog.fabric8.io/clustering-on-kubernetes-openshift3-using-dns-d786bfd681d9?source=tag_archive---------2-----------------------   \n",
       "330                                                                                                                                                                                   https://medium.com/@univprofblog1/support-vector-machine-matlab-r-and-python-codes-856a342fc35d?source=tag_archive---------4-----------------------   \n",
       "331                                                                                                                                                      https://towardsdatascience.com/intro-to-reinforcement-learning-temporal-difference-learning-sarsa-vs-q-learning-8b4184bb4978?source=tag_archive---------6-----------------------   \n",
       "332                                                                                                                                                                                              https://towardsdatascience.com/object-detection-and-tracking-in-pytorch-b3cf1a696a98?source=tag_archive---------7-----------------------   \n",
       "333                                                                                                                                                                                     https://onezero.medium.com/i-asked-gpt-3-about-covid-19-its-responses-shocked-me-589267ec41a6?source=tag_archive---------0-----------------------   \n",
       "334                                                                                                                                                                                         https://towardsdatascience.com/a-detailed-explanation-of-the-attention-u-net-b371a5590831?source=tag_archive---------4-----------------------   \n",
       "335                                                                                                                                                                                                      https://medium.com/ml2vec/overview-of-conditional-random-fields-68a2a20fa541?source=tag_archive---------9-----------------------   \n",
       "336                                                                                                                                                                                                         https://medium.com/bonsal-capital/the-charm-of-a-gritty-city-82bc645a4313?source=tag_archive---------0-----------------------   \n",
       "337                                                                                                                                                                                        https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d?source=tag_archive---------3-----------------------   \n",
       "338                                                                                                                                                                                                                       https://towardsdatascience.com/bitcoin-bonanza-2cb208026bbd?source=tag_archive---------5-----------------------   \n",
       "339                                                                                                                                                                                               https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca?source=tag_archive---------7-----------------------   \n",
       "340                                                                                                                                                                                      https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011?source=tag_archive---------9-----------------------   \n",
       "341                                                                                                                                                                               https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b?source=tag_archive---------5-----------------------   \n",
       "342                                                                                                                                                  https://medium.com/@mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289?source=tag_archive---------8-----------------------   \n",
       "343                                                                                                                                                                                          https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33?source=tag_archive---------9-----------------------   \n",
       "344                                                                                                                                                                                                   https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab?source=tag_archive---------2-----------------------   \n",
       "345                                                                                                                                                   https://medium.com/@nikhilparmar9/simple-sgd-implementation-in-python-for-linear-regression-on-boston-housing-data-f63fcaaecfb1?source=tag_archive---------0-----------------------   \n",
       "346                                                                                                                                                                                          https://towardsdatascience.com/implementing-binary-logistic-regression-in-r-7d802a9d98fe?source=tag_archive---------3-----------------------   \n",
       "347                                                                                                                                                               https://medium.com/@hemantranvir/spam-detection-using-rnn-simplernn-lstm-with-step-by-step-explanation-530367608071?source=tag_archive---------6-----------------------   \n",
       "348                                                                                                                                                                                                                              https://medium.com/@jonathan-hui/yolov4-c9901eaa8e61?source=tag_archive---------3-----------------------   \n",
       "349                                                                                                       https://medium.com/@geneonline/%E7%99%8C%E7%B4%B0%E8%83%9E%E7%94%9F%E9%95%B7%E7%9A%84%E9%96%8B%E9%97%9C-%E5%9F%BA%E5%9B%A0%E5%95%9F%E5%8B%95%E5%AD%90-promoter-ed16fab2e013?source=tag_archive---------0-----------------------   \n",
       "350                                                                                                                                                                                                               https://medium.com/analytics-vidhya/rnn-vs-gru-vs-lstm-863b0b7b1573?source=tag_archive---------4-----------------------   \n",
       "351                                                                                                                                                                 https://towardsdatascience.com/fancy-and-custom-neural-style-transfer-filters-for-video-conferencing-7eba2be1b6d5?source=tag_archive---------6-----------------------   \n",
       "352  https://medium.com/@bigdataschool/3-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%B0-%D0%B4%D0%B5%D1%82%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2-c-deep-learning-r-cnn-fast-r-cnn-%D0%B8-faster-r-cnn-acdf6380fd33?source=tag_archive---------4-----------------------   \n",
       "353                                                                                                                                                                                                https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922?source=tag_archive---------1-----------------------   \n",
       "354                                                                                                                                                                                                     https://medium.com/puneetsl/1-creating-a-q-a-system-introduction-81d404dfb3e4?source=tag_archive---------0-----------------------   \n",
       "355                                                                                                                                                                              https://medium.com/@saketdingliwal97/model-agnostic-meta-learning-maml-an-intuitive-way-f7539e043c0b?source=tag_archive---------9-----------------------   \n",
       "356                                                                                                                                                                                                 https://medium.com/@shivon/the-current-state-of-machine-intelligence-f76c20db2fe1?source=tag_archive---------0-----------------------   \n",
       "357                                                                                                                                                                                   https://medium.com/@shiva-verma/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e?source=tag_archive---------8-----------------------   \n",
       "358                                                                                                                                https://medium.com/analytics-vidhya/keras-embedding-layer-and-programetic-implementation-of-glove-pre-trained-embeddings-step-by-step-7a4b2fa71544?source=tag_archive---------2-----------------------   \n",
       "359                                                                                                                                                                    https://medium.com/@shashank7-iitd/understanding-vector-quantized-variational-autoencoders-vq-vae-323d710a888a?source=tag_archive---------9-----------------------   \n",
       "360                                                                                                                                                                                          https://medium.com/analytics-vidhya/what-does-it-mean-by-bidirectional-lstm-63d6838e34d9?source=tag_archive---------8-----------------------   \n",
       "361                                                                                                                                                                                                          https://towardsdatascience.com/k-means-vs-dbscan-clustering-49f8e627de27?source=tag_archive---------4-----------------------   \n",
       "362                                                                                                                                                                           https://towardsdatascience.com/drl-01-a-gentle-introduction-to-deep-reinforcement-learning-405b79866bf4?source=tag_archive---------4-----------------------   \n",
       "363                                                                                                                                                                                                  https://towardsdatascience.com/generative-adversarial-networks-gans-89ef35a60b69?source=tag_archive---------8-----------------------   \n",
       "364                                                                                                                                                          https://medium.datadriveninvestor.com/batch-vs-mini-batch-vs-stochastic-gradient-descent-with-code-examples-cd8232174e14?source=tag_archive---------7-----------------------   \n",
       "365                                                                                                                                                                                    https://towardsdatascience.com/lambda-functions-with-practical-examples-in-python-45934f3653a8?source=tag_archive---------5-----------------------   \n",
       "366                                                                                                                                                             https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b?source=tag_archive---------5-----------------------   \n",
       "367                                                                                                                                                                                                        https://towardsdatascience.com/few-shot-learning-with-fast-ai-81c66064e372?source=tag_archive---------6-----------------------   \n",
       "368                                                                                                                                          https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c?source=tag_archive---------4-----------------------   \n",
       "369                                                                                                                                                                                                     https://blog.goodaudience.com/solving-8-puzzle-using-a-algorithm-7b509c331288?source=tag_archive---------9-----------------------   \n",
       "370                                                                                                                                                                                                     https://medium.com/datapy-ai/nlp-building-text-summarizer-part-1-902fec337b81?source=tag_archive---------9-----------------------   \n",
       "371                                                                                                                                                                                                             https://medium.com/@helymarleena/from-metaphor-to-reality-15790952657?source=tag_archive---------4-----------------------   \n",
       "372                                                                                                                                                                                        https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f?source=tag_archive---------2-----------------------   \n",
       "373                                                                                                                                                                                              https://towardsdatascience.com/training-provably-robust-neural-networks-1e15f2d80be2?source=tag_archive---------2-----------------------   \n",
       "374                                                                                                                                                                            https://medium.com/@UdacityINDIA/tensorflow-or-pytorch-the-force-is-strong-with-which-one-68226bb7dab4?source=tag_archive---------4-----------------------   \n",
       "375                                                                                                                                                                                https://towardsdatascience.com/gaussian-mixture-models-vs-k-means-which-one-to-choose-62f2736025f0?source=tag_archive---------8-----------------------   \n",
       "376                                                                                                                                                           https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a?source=tag_archive---------2-----------------------   \n",
       "377                                                                                                                                         https://towardsdatascience.com/unsupervised-classification-project-building-a-movie-recommender-with-clustering-analysis-and-4bab0738efe6?source=tag_archive---------4-----------------------   \n",
       "378                                                                                                                                                                       https://medium.com/data-science-at-microsoft/causal-inference-part-2-of-3-selecting-algorithms-a966f8228a2d?source=tag_archive---------1-----------------------   \n",
       "379                                                                                                                                                                                               https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939?source=tag_archive---------4-----------------------   \n",
       "380                                                                                                                                                                                    https://towardsdatascience.com/adversarial-examples-to-break-deep-learning-models-e7f543833eae?source=tag_archive---------1-----------------------   \n",
       "381                                                                                                                                                                https://towardsdatascience.com/understanding-the-backbone-of-video-classification-the-i3d-architecture-d4011391692?source=tag_archive---------5-----------------------   \n",
       "382                                                                                                                                       https://medium.com/@univprofblog1/random-forests-classification-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-fb60ff088db4?source=tag_archive---------6-----------------------   \n",
       "383                                                                                                                                                                                                                      https://becominghuman.ai/transformers-in-vision-e2e87b739feb?source=tag_archive---------4-----------------------   \n",
       "384                                                                                                                                      https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225?source=tag_archive---------6-----------------------   \n",
       "385                                                                                                                                                                                 https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e?source=tag_archive---------1-----------------------   \n",
       "386                                                                                                                                                                                           https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac?source=tag_archive---------3-----------------------   \n",
       "387                                                                                                                                                          https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-3-9d686d0d85d9?source=tag_archive---------8-----------------------   \n",
       "388                                                                                                                                                                                                   https://medium.com/coders-camp/60-python-projects-with-source-code-919cd8a6e512?source=tag_archive---------5-----------------------   \n",
       "389                                                                                                                                                      https://towardsdatascience.com/the-softmax-function-neural-net-outputs-as-probabilities-and-ensemble-classifiers-9bd94d75932?source=tag_archive---------9-----------------------   \n",
       "390                                                                                                                                                                        https://medium.com/binaryandmore/beginners-guide-to-deriving-and-implementing-backpropagation-e3c1a5a1e536?source=tag_archive---------3-----------------------   \n",
       "391                                                                                                                                                                                          https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2?source=tag_archive---------1-----------------------   \n",
       "392                                                                                                                                                                                                  https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842?source=tag_archive---------0-----------------------   \n",
       "393                                                                                                                                                                                 https://medium.com/@peter.bulyaki/a-brief-introduction-to-artificial-neural-networks-9962114c3bad?source=tag_archive---------3-----------------------   \n",
       "394                                                                                                                                                                                     https://medium.com/syncedreview/biggan-a-new-state-of-the-art-in-image-synthesis-cf2ec5694024?source=tag_archive---------2-----------------------   \n",
       "395                                                                                                                                                                                                  https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86?source=tag_archive---------7-----------------------   \n",
       "396                                                                                                                                                                                                  https://medium.com/@nathancooperjones/these-bored-apes-do-not-exist-6bed2c73f02c?source=tag_archive---------1-----------------------   \n",
       "397                                                                                                                                                                                   https://medium.com/@ahmetxgenc/detecting-empty-car-parking-lot-with-mask-rcnn-model-4f6202794a6?source=tag_archive---------4-----------------------   \n",
       "398                                                                                                                                                                                                       https://medium.com/value-stream-design/online-machine-learning-515556ff72c5?source=tag_archive---------6-----------------------   \n",
       "399                                                                                                                                                                                                      https://pdnotebook.com/image-analysis-intro-using-python-opencv-18791f4edf22?source=tag_archive---------3-----------------------   \n",
       "400                                                                                                                                                                        https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35?source=tag_archive---------9-----------------------   \n",
       "401                                                                                                                                                                                                    https://medium.com/pandorabots-blog/using-oob-tags-in-aiml-part-i-21214b4d2fcd?source=tag_archive---------2-----------------------   \n",
       "402                                                                                                                                                         https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581?source=tag_archive---------1-----------------------   \n",
       "403                                                                                                                                                 https://towardsdatascience.com/should-ai-explain-itself-or-should-we-design-explainable-ai-so-that-it-doesnt-have-to-90e75bb6089e?source=tag_archive---------2-----------------------   \n",
       "404                                                                                                                                                                                               https://towardsdatascience.com/an-introduction-to-perceptron-algorithm-40f2ab4e2099?source=tag_archive---------2-----------------------   \n",
       "405                                                                                                                                                                                                                      https://gab41.lab41.org/taking-keras-to-the-zoo-9a76243152cb?source=tag_archive---------9-----------------------   \n",
       "406                                                                                                                                                                                                    https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2?source=tag_archive---------0-----------------------   \n",
       "407                                                                                                                            https://medium.com/@vlknlvnt/reinforcement-learning-peki%C5%9Ftirmeli-%C3%B6%C4%9Frenme-i%CC%87nsan-beyniyle-aradaki-fark-kapan%C4%B1rken-c0d0a6f7c2e8?source=tag_archive---------5-----------------------   \n",
       "408                                                                                                                                                                              https://medium.com/capire-info/sugerencias-para-definir-un-men%C3%BA-de-navegaci%C3%B3n-e6efe33bfe22?source=tag_archive---------0-----------------------   \n",
       "409                                                                                                                                                                                       https://towardsdatascience.com/how-to-implement-an-adam-optimizer-from-scratch-76e7b217f1cc?source=tag_archive---------0-----------------------   \n",
       "410                                                                                                                                                                     https://pub.towardsai.net/machine-learning-algorithms-for-beginners-with-python-code-examples-ml-19c6afd60daa?source=tag_archive---------4-----------------------   \n",
       "411                                                                                                                                                                                                 https://medium.com/hackernoon/gradient-descent-vs-coordinate-descent-9b5657f1c59f?source=tag_archive---------0-----------------------   \n",
       "412                                                                                                                                        https://medium.com/hackernoon/how-i-deployed-my-spark-document-classification-logistic-regression-model-s-as-a-standalone-app-64b05b44e102?source=tag_archive---------3-----------------------   \n",
       "413                                                                                                                                                             https://medium.com/mlearning-ai/demonstrating-customers-segmentation-with-dbscan-clustering-using-python-8a2ba0db2a2e?source=tag_archive---------7-----------------------   \n",
       "414                                                                                                                                                                               https://towardsdatascience.com/nlp-spam-detection-in-sms-text-data-using-deep-learning-b8632db85cc8?source=tag_archive---------7-----------------------   \n",
       "415                                                                                                                                                                                                                 https://towardsdatascience.com/pos-tagging-using-rnn-7f08a522f849?source=tag_archive---------4-----------------------   \n",
       "416                                                                                                                                                                       https://medium.com/geekculture/deep-convolutional-generative-adversarial-network-using-pytorch-ece1260acc47?source=tag_archive---------9-----------------------   \n",
       "417                                                                                                                                                                                        https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------5-----------------------   \n",
       "418                                                                                                                                                                                         https://medium.com/@jonathan-hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088?source=tag_archive---------2-----------------------   \n",
       "419                                                                                                                                                                                                              https://towardsdatascience.com/mercari-price-suggestion-97ff15840dbd?source=tag_archive---------6-----------------------   \n",
       "420                                                                                                                                                                                                                https://medium.com/swlh/embeddings-in-machine-learning-548eef7b2b5?source=tag_archive---------7-----------------------   \n",
       "421                                                                                                                                                                               https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=tag_archive---------3-----------------------   \n",
       "422                                                                                                                                                                                                 https://medium.com/@shashank7-iitd/understanding-attention-mechanism-35ff53fc328e?source=tag_archive---------8-----------------------   \n",
       "423                                                                                                                                                                                        https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205?source=tag_archive---------3-----------------------   \n",
       "424                                                                                                                                                                                                       https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba?source=tag_archive---------8-----------------------   \n",
       "425                                                                                                                                                                         https://medium.com/ai%C2%B3-theory-practice-business/object-detection-in-deep-learning-part2-855b78689f13?source=tag_archive---------8-----------------------   \n",
       "426                                                                                                                                                                                https://medium.com/mlearning-ai/a-brief-overview-of-r-cnn-fast-r-cnn-and-faster-r-cnn-9c6843c9ffc0?source=tag_archive---------1-----------------------   \n",
       "427                                                                                                                                                                           https://towardsdatascience.com/evasion-attacks-on-machine-learning-or-adversarial-examples-12f2283e06a1?source=tag_archive---------2-----------------------   \n",
       "428                                                                                                                                                                          https://medium.com/@andrewmarmon/fine-tuned-named-entity-recognition-with-hugging-face-bert-d51d4cb3d7b5?source=tag_archive---------5-----------------------   \n",
       "429                                                                                                                                                                                                             https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d?source=tag_archive---------7-----------------------   \n",
       "430                                                                                                                                                                                              https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56?source=tag_archive---------1-----------------------   \n",
       "431                                                                                                                                   https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------0-----------------------   \n",
       "432                                                                                                                                                                       https://medium.com/blog-rilut/neural-networks-without-backpropagation-direct-feedback-alignment-30d5d4848f5?source=tag_archive---------6-----------------------   \n",
       "433                                                                                                                                                                     https://medium.com/clustering-with-gaussian-mixture-model/clustering-with-gaussian-mixture-model-c695b6cd60da?source=tag_archive---------3-----------------------   \n",
       "434                                                                                                                                                                                       https://medium.com/analytics-vidhya/training-a-spacy-ner-pipeline-with-prodigy-ca58350cb868?source=tag_archive---------1-----------------------   \n",
       "435                                                                                                                                                                                                https://towardsdatascience.com/solving-the-multi-armed-bandit-problem-b72de40db97c?source=tag_archive---------8-----------------------   \n",
       "436                                                                                                                                                                                           https://towardsdatascience.com/single-stage-instance-segmentation-a-review-1eeb66e0cc49?source=tag_archive---------5-----------------------   \n",
       "437                                                                                                                                                                     https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2?source=tag_archive---------1-----------------------   \n",
       "438                                                                                                                                                                                                         https://towardsdatascience.com/predict-customer-churn-with-r-9e62357d47b4?source=tag_archive---------6-----------------------   \n",
       "439                                                                                                                                                               https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49?source=tag_archive---------4-----------------------   \n",
       "440                                                                                                                                                                                 https://towardsdatascience.com/important-topics-in-machine-learning-you-need-to-know-21ad02cc6be5?source=tag_archive---------9-----------------------   \n",
       "441                                                                                                                                                                                      https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9?source=tag_archive---------1-----------------------   \n",
       "442                                                                                                                                                                         https://towardsdatascience.com/wthe-ultimate-guide-to-clustering-algorithms-and-topic-modeling-4f7757c115?source=tag_archive---------4-----------------------   \n",
       "443                                                                                                                                                 https://towardsdatascience.com/text-summarization-from-scratch-using-encoder-decoder-network-with-attention-in-keras-5fa80d12710e?source=tag_archive---------6-----------------------   \n",
       "444                                                                                                                                         https://medium.com/@univprofblog1/linear-discriminant-analysis-matlab-r-and-python-codes-all-you-have-to-do-is-just-preparing-4acfffc4726?source=tag_archive---------5-----------------------   \n",
       "445                                                                                                                                                                                      https://medium.com/intuitionmachine/the-strange-loop-in-alphago-zeros-self-play-6e3274fcdd9f?source=tag_archive---------3-----------------------   \n",
       "446                                                                                                                                                                                             https://medium.com/@arifiany/segmentasi-semantik-untuk-klasifikasi-citra-a004b3906250?source=tag_archive---------8-----------------------   \n",
       "447                                                                                                                                                                                                    https://medium.com/@humble_bee/rnn-recurrent-neural-networks-lstm-842ba7205bbf?source=tag_archive---------7-----------------------   \n",
       "448                                                                                                                                                                                                              https://medium.com/@borisanthony/puppyslugs-r-us-part-1-88461c2104ba?source=tag_archive---------7-----------------------   \n",
       "449                                                                                                                                                               https://medium.com/ai-salon/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251?source=tag_archive---------5-----------------------   \n",
       "450                                                                                                                                                              https://towardsdatascience.com/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649?source=tag_archive---------2-----------------------   \n",
       "451                                                                                                                                                                            https://medium.com/analytics-vidhya/understanding-the-stylegan-and-stylegan2-architecture-add9e992747d?source=tag_archive---------2-----------------------   \n",
       "452                                                                                                                                                                                     https://medium.com/@jonathan-hui/map-mean-average-precision-for-object-detection-45c121a31173?source=tag_archive---------1-----------------------   \n",
       "453                                                                                                                                                                                                https://medium.com/@earnskins/guide-pop-slots-casino-level-27-13-easy-a387f127d9f3?source=tag_archive---------7-----------------------   \n",
       "454                                                                                                                                                                                               https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-2-cf81bf32c73d?source=tag_archive---------8-----------------------   \n",
       "455                                                                                                                                                                              https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d?source=tag_archive---------4-----------------------   \n",
       "456                                                                                                                                                                               https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c?source=tag_archive---------5-----------------------   \n",
       "457                                                                                                                                                                                        https://towardsdatascience.com/clustering-algorithm-for-customer-segmentation-e2d79e28cbc3?source=tag_archive---------0-----------------------   \n",
       "458                                                                                                                                                           https://towardsdatascience.com/train-neural-net-for-semantic-segmentation-with-pytorch-in-50-lines-of-code-830c71a6544f?source=tag_archive---------8-----------------------   \n",
       "459                                                                                                                                                                                https://towardsdatascience.com/multivariate-time-series-forecasting-with-transformers-384dc6ce989b?source=tag_archive---------2-----------------------   \n",
       "460                                                                                                                                                                                   https://towardsdatascience.com/blitz-a-bayesian-neural-network-library-for-pytorch-82f9998916c7?source=tag_archive---------4-----------------------   \n",
       "461                                                                                                                                                                   https://medium.com/gradientcrescent/neural-art-style-transfer-with-keras-theory-and-implementation-91b7fb08ee81?source=tag_archive---------9-----------------------   \n",
       "462                                                                                                                                                                                                                 https://techblog.ezra.com/different-embedding-models-7874197dc410?source=tag_archive---------6-----------------------   \n",
       "463                                                                                                                                                                                                                                       https://open.nytimes.com/equake-85b6566b7f2?source=tag_archive---------8-----------------------   \n",
       "464                                                                                                                                                                                                        https://towardsdatascience.com/gangogh-creating-art-with-gans-8d087d8f74a1?source=tag_archive---------1-----------------------   \n",
       "465                                                                                                                                                                                                                   https://ai.plainenglish.io/the-measure-of-a-measure-c8ceb734d5f?source=tag_archive---------1-----------------------   \n",
       "466                                                                                                                                                            https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-1-3d9fada3b80d?source=tag_archive---------0-----------------------   \n",
       "467                                                                                                                                                                                                 https://medium.com/dataweave/smartphones-vs-tablets-does-size-matter-963ab7dd6052?source=tag_archive---------3-----------------------   \n",
       "468                                                                                                                                                                    https://towardsdatascience.com/stochastic-gradient-descent-for-machine-learning-clearly-explained-cadcc17d3d11?source=tag_archive---------6-----------------------   \n",
       "469                                                                                                                                                                                                          https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea?source=tag_archive---------5-----------------------   \n",
       "470                                                                                                                                                                                        https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728?source=tag_archive---------0-----------------------   \n",
       "471                                                                                                                                                                                                  https://towardsdatascience.com/fooling-facial-detection-with-fashion-d668ed919eb?source=tag_archive---------4-----------------------   \n",
       "472                                                                                                                                                                                                                             https://towardsdatascience.com/stylegan2-ace6d3da405d?source=tag_archive---------2-----------------------   \n",
       "473                                                                                                                                                                                                  https://medium.com/pankajmathur/logistic-regression-with-tensorflow-a02c2bd2bd1e?source=tag_archive---------1-----------------------   \n",
       "474                                                                                                                                                                                                https://towardsdatascience.com/clustering-analysis-in-r-using-k-means-73eca4fb7967?source=tag_archive---------6-----------------------   \n",
       "475                                                                                                                                                                                                https://towardsdatascience.com/time-series-of-price-anomaly-detection-13586cd5ff46?source=tag_archive---------4-----------------------   \n",
       "476                                                                                                                                                                        https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92?source=tag_archive---------2-----------------------   \n",
       "477                                                                                                                                                                                                        https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484?source=tag_archive---------0-----------------------   \n",
       "478                                                                                                                                                                                                    https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a?source=tag_archive---------9-----------------------   \n",
       "479                                                                                                                                                           https://towardsdatascience.com/gmm-gaussian-mixture-models-how-to-successfully-use-it-to-cluster-your-data-891dc8ac058f?source=tag_archive---------7-----------------------   \n",
       "480                                                                                                                                                                               https://medium.com/hackernoon/speeding-up-your-code-2-vectorizing-the-loops-with-numpy-e380e939bed3?source=tag_archive---------6-----------------------   \n",
       "481                                                                                                                                                                                        https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211?source=tag_archive---------2-----------------------   \n",
       "482                                                                                                                                                                                                    https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada?source=tag_archive---------6-----------------------   \n",
       "483                                                                                                                                                                              https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b?source=tag_archive---------1-----------------------   \n",
       "484                                                                                                                                                                            https://onezero.medium.com/gpt-3-is-an-amazing-research-tool-openai-isnt-sharing-the-code-d048ba39bbfd?source=tag_archive---------4-----------------------   \n",
       "485                                                                                                                                                                                        https://towardsdatascience.com/introduction-to-machine-learning-for-beginners-eed6024fdb08?source=tag_archive---------3-----------------------   \n",
       "486                                                                                                                                                                                                    https://medium.com/on-docker/federated-clusters-with-docker-swarm-dce5516ecc8d?source=tag_archive---------6-----------------------   \n",
       "487                                                                                                                                                                                                https://towardsdatascience.com/clustering-based-unsupervised-learning-8d705298ae51?source=tag_archive---------7-----------------------   \n",
       "488                                                                                                                                                                                            https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610?source=tag_archive---------9-----------------------   \n",
       "489                                                                                                                                                                                        https://towardsdatascience.com/the-proper-way-to-use-machine-learning-metrics-4803247a2578?source=tag_archive---------8-----------------------   \n",
       "490                                                                                                                                                                                                  https://medium.com/moonvision/few-shot-object-detection-in-practice-4f8fa98cba57?source=tag_archive---------3-----------------------   \n",
       "491                                                                                                                                                                                     https://towardsdatascience.com/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=tag_archive---------6-----------------------   \n",
       "492                                                                                                                                                                       https://medium.com/analytics-vidhya/how-batch-normalization-and-relu-solve-vanishing-gradients-3f1a8ace1c88?source=tag_archive---------0-----------------------   \n",
       "493                                                                                                                                                                                             https://towardsdatascience.com/k-means-clustering-and-the-gap-statistics-4c5d414acd29?source=tag_archive---------5-----------------------   \n",
       "494                                                                                                                                                   https://medium.com/dark-matter-and-trojan-horses/of-brains-and-cities-neuroscience-and-cultures-of-decision-making-6bc6abb48d4b?source=tag_archive---------0-----------------------   \n",
       "495                                                                                                                                                                     https://medium.com/ensina-ai/redes-neurais-perceptron-multicamadas-e-o-algoritmo-backpropagation-eaf89778f5b8?source=tag_archive---------5-----------------------   \n",
       "496                                                                                                                                                                                                https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73?source=tag_archive---------7-----------------------   \n",
       "497                                                                                                                                                                                                            https://blog.insightdatascience.com/preparing-for-insight-ca7cc6087f91?source=tag_archive---------3-----------------------   \n",
       "498                                                                                                                                                                                                                         https://medium.com/altsoph/google-ai-contest-eed23cfdeb6f?source=tag_archive---------3-----------------------   \n",
       "499                                                                                                                                                                                                                            https://medium.com/huggingface/distilbert-8cf3380435b5?source=tag_archive---------5-----------------------   \n",
       "\n",
       "                                                                                                                                                                                   title  \\\n",
       "0                                                                                      Step-by-Step R-CNN Implementation From Scratch In Python | by Rohit Thakur | Towards Data Science   \n",
       "1                                                                             How Transformers Work. Transformers are a type of neural... | by Giuliano Giacaglia | Towards Data Science   \n",
       "2                                                                                                      Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science   \n",
       "3                                                                                                               Amazon’s Artificial Artificial Intelligence | by Sachin Palewar | Medium   \n",
       "4                                                                                                     This week in the #SDGs- February 17, 2017 | by SDGCounting | SDG Counting | Medium   \n",
       "5                                                                                                     Views From A College Dropout’s Unconventional Life — Year 2 | by Tam Pham | Medium   \n",
       "6                                                                              Introducción a Machine Learning. Machine Learning, Big Data, Deep... | by Virginia Peón | ECLaboratorio   \n",
       "7                                                                                                             When Exactly Did It Get Cool To Be A Geek? | by The Awl | The Awl | Medium   \n",
       "8                                                                                                  K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science   \n",
       "9                                                                                                           Lou Reed: Entre “Transformer” e “Berlin” o mito. | by Igor de Sousa | Medium   \n",
       "10                                                                                           Machine Learning is Fun!. The world’s easiest introduction to... | by Adam Geitgey | Medium   \n",
       "11                                                                               Master the COCO Dataset for Semantic Image Segmentation — Part 1 of 2 | by Viraf | Towards Data Science   \n",
       "12                                                      IT Support Ticket Classification and Deployment using Machine Learning and AWS Lambda | by Pankaj Kishore | Towards Data Science   \n",
       "13                                                                                                  Text Classification with BERT in PyTorch | by Ruben Winastwan | Towards Data Science   \n",
       "14                                                                                                              Anatomy of an Elasticsearch Cluster: Part I | by Ronak Nathani | Insight   \n",
       "15                                                                                      The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science   \n",
       "16                                                  IoT Learning Algorithms and Predictive Maintenance — Part III: Few-shot Learning | by Record Evolution | IoT & Data Science | Medium   \n",
       "17                                                                Machine Learning week 1: Cost Function, Gradient Descent and Univariate Linear Regression | by Lachlan Miller | Medium   \n",
       "18                                                                                              DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero   \n",
       "19                                            Computer Vision Tutorial: Implementing Mask R-CNN for Image Segmentation (with Python Code) | by Pulkit Sharma | Analytics Vidhya | Medium   \n",
       "20                                                                                                          Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science   \n",
       "21                                                                                              Credit Scoring with Machine Learning | by Hongri Jia | Passion for Data Science | Medium   \n",
       "22                                                        If you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works... | by Justin Davies | Medium   \n",
       "23                                 Creating and training a U-Net model with PyTorch for 2D & 3D semantic segmentation: Model building [2/4] | by Johannes Schmidt | Towards Data Science   \n",
       "24                                                              The best explanation of Convolutional Neural Networks on the Internet! | by Harsh Pokharna | TechnologyMadeEasy | Medium   \n",
       "25                                                                                           Key takeaways — O’reilly AI London Conference, Oct 9–11, 2018 | by Debmalya Biswas | Medium   \n",
       "26                                                                      Machine Learning — Word Embedding & Sentiment Classification using Keras | by Javaid Nabi | Towards Data Science   \n",
       "27                                                                                    Computer Vision: Instance Segmentation with Mask R-CNN | by Renu Khandelwal | Towards Data Science   \n",
       "28                                                                                       Traveling santa Problem — An incompetent algorist’s attempt | by Hrishikesh Huilgolkar | Medium   \n",
       "29                                                                                             Data without context is meaningless (and boring) | by Jan Schultink | SlideMagic | Medium   \n",
       "30                                                                                 K-Fold Cross Validation for Deep Learning Models using Keras | by Siladittya Manna | The Owl | Medium   \n",
       "31                                                                                                                        Gotta catch them all, but which one first? | by Knoyd | Medium   \n",
       "32                                                                                        GloVe, ELMo & BERT. A guide to state-of-the-art text... | by Ryan Burke | Towards Data Science   \n",
       "33                                                                                                       AI Safety and the Scaling Hypothesis | by Jeremie Harris | Towards Data Science   \n",
       "34                                                                                   Подводные камни UNet в Unity 5. или то, что не описано в документации | by Pavel Shestakov | Medium   \n",
       "35                                                     Real-time face recognition: training and deploying on Android using Tensorflow lite — transfer learning | by Saidakbar P | Medium   \n",
       "36                                                                                                            Decision Tree in Machine Learning | by Prince Yadav | Towards Data Science   \n",
       "37                                                                                              DeepMind’s Latest A.I. Health Breakthrough Has Some Problems | by Julia Powles | OneZero   \n",
       "38                                                                  DBSCAN clustering for data shapes k-means can’t handle well (in Python) | by Gabriel Pierobon | Towards Data Science   \n",
       "39                                                                               How Does Back-Propagation in Artificial Neural Networks Work? | by Anas Al-Masri | Towards Data Science   \n",
       "40                                                           Tesla’s Big Plans, DeepMind Pays For Itself, Internet Drones, and Moore’s Law | by Matt Kiser | Emergent // Future | Medium   \n",
       "41                                                                                                 Transfer learning from pre-trained models | by Pedro Marcelino | Towards Data Science   \n",
       "42                                                                                                     Serving PyTorch Models on AWS Lambda with Caffe2 & ONNX | by michaelulin | Medium   \n",
       "43                                                                                         [談理解] 電競賽評也能告訴我們如何設計智慧系統的解釋機制?. 「蟲苔已經撲到人家的臉上了!」... | by Chi-Lan Yang | 楊期蘭 | 人機共生你我它 | Medium   \n",
       "44                                                                      Artistic Style Transfer with Convolutional Neural Network | by Manjeet Singh | Data Science Group, IITR | Medium   \n",
       "45                                                                                         How to predict Quora Question Pairs using Siamese Manhattan LSTM | by Elior Cohen | ML Review   \n",
       "46                                                                           Use-cases of Google’s Universal Sentence Encoder in Production | by Sambit Mahapatra | Towards Data Science   \n",
       "47                                                                                                    Understanding Bidirectional RNN in PyTorch | by Ceshine Lee | Towards Data Science   \n",
       "48                                                                                                                    Appearance of The Principate [Pt. II] | by Daniel Voshart | Medium   \n",
       "49                                                            Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science   \n",
       "50                                                                                            Understanding Logistic Regression step by step | by Gustavo Chávez | Towards Data Science   \n",
       "51                                                                                                              Object Detection & Segmentation with Python | by Apdullah Yayik | Medium   \n",
       "52                                                                       Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science   \n",
       "53                                                                                             How to build a Recurrent Neural Network in TensorFlow (1/7) | by Erik Hallström | Medium   \n",
       "54                                                                 Text Classification in Spark NLP with Bert and Universal Sentence Encoders | by Veysel Kocaman | Towards Data Science   \n",
       "55                                                                                             DBScan on trajectories — Determining Eps and MinPts | by Marcio Geovani Jasinski | Medium   \n",
       "56                                                                                           TikTok’s new feature — anime filter got million posts in 3 days | by Vicente Luego | Medium   \n",
       "57                       AlphaFold-based databases and fully-fledged, easy-to-use, online AlphaFold interfaces poised to revolutionize biology | by LucianoSphere | Towards Data Science   \n",
       "58                                                                               Background Removal in Real-Time Video Chats using TensorflowJS, Part 1 | by Jean-Marc Beaujour | Medium   \n",
       "59                                                                                               Chatbots were the next big thing: what happened? | by Justin Lee | The Startup | Medium   \n",
       "60                                                                                  Reinforcement Learning w/ Keras + OpenAI: Actor-Critic Models | by Yash Patel | Towards Data Science   \n",
       "61                                                                     Machine Learning Project: Predicting Boston House Prices With Regression | by Victor Roman | Towards Data Science   \n",
       "62                                                                          AdaBelief Optimizer: fast as Adam, generalizes as well as SGD | by Kaustubh Mhaisekar | Towards Data Science   \n",
       "63                                                                                                                           Train New BERT Model on Any Language | Towards Data Science   \n",
       "64                                                                                  Credit Card Fraud Detection using Autoencoders in H2O | by Maneesha Rajaratne | Towards Data Science   \n",
       "65                                                                                                             Backpropagation: The Simple Proof | by Essam Wisam | Towards Data Science   \n",
       "66                                                                                                            Basics of Image Classification with PyTorch | by John Olafenwa | Heartbeat   \n",
       "67                                                                                                            Music Genre Classification Using CNN | by Arsh Chowdhry | Clairvoyant Blog   \n",
       "68                                                                       Multi-label Text Classification using BERT – The Mighty Transformer | by Kaushal Trivedi | HuggingFace | Medium   \n",
       "69                                                                                         Google DeepMind-style datacenter optimization AI model (on the cheap) | by commander | Medium   \n",
       "70                                                           The Volcker metric known as inventory aging... and thoughts of Whisky | by Acuity Derivatives | Acuity Derivatives | Medium   \n",
       "71                                                                                                      Prior over functions: Gaussian process | by Jehill Parikh | Towards Data Science   \n",
       "72                                                                                                            1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium   \n",
       "73                                                                                  Simple and multiple linear regression with Python | by Amanda Iglesias Moreno | Towards Data Science   \n",
       "74                                                                                NER, SpaCy and Lasagne. One of the great things about NER is... | by Paul Ellis | The Startup | Medium   \n",
       "75                                                                                    Word2vec with PyTorch: Implementing the Original Paper | by Olga Chernytska | Towards Data Science   \n",
       "76                                                            A short introduction to StyleGAN. Generative models(GAN) have always been... | by Praveenkumar | Analytics Vidhya | Medium   \n",
       "77                                                                                       CSS Box Model and Positioning. VGG Virtual Internship Assignment. | by Chijioke Nwagwu | Medium   \n",
       "78                                                                                               Text Summarization Using Deep Neural Networks | by Shivam Duseja | Towards Data Science   \n",
       "79                                                                       Probability concepts explained: Maximum likelihood estimation | by Jonny Brooks-Bartlett | Towards Data Science   \n",
       "80                                                                                                                       Build K-Means from scratch in Python | by Rishit Dagli | Medium   \n",
       "81                                                                                                     Using ResNet for ECG time-series data | by Sanne de Roever | Towards Data Science   \n",
       "82                                                                                            Understanding UNET. How to understand U-Net in the most... | by Kirill Bondarenko | Medium   \n",
       "83                                                                                        Presenting Goibibo Insights. Its now been quite some time for... | by Goibibo Tech | Backstage   \n",
       "84                                                                                                                          Understanding LSTM and its diagrams | by Shi Yan | ML Review   \n",
       "85                                                                                                         Fast and Faster Region-based Convolutional Network | by Pavan Gurram | Medium   \n",
       "86                                                                                                   GAN 2.0: NVIDIA’s Hyperrealistic Face Generator | by Synced | SyncedReview | Medium   \n",
       "87                                                                                                     Automated Feature Engineering Tools | by Rajneesh Jha | Analytics Vidhya | Medium   \n",
       "88                                                                Clustering documents with Python. A simple example with Wikipedia... | by Dimitris Panagopoulos | Towards Data Science   \n",
       "89                                                                                                   How I got my first android job without a degree or experience | by Mo Hajr | Medium   \n",
       "90                                                                       Machine Learning —Fundamentals. Basic theory underlying the field of... | by Javaid Nabi | Towards Data Science   \n",
       "91                                                                                                      Activation Functions in Neural Networks | by SAGAR SHARMA | Towards Data Science   \n",
       "92                                                                                             Train Object Detection AI with 6 lines of code | by Moses Olafenwa | DeepQuestAI | Medium   \n",
       "93                                                                    Diving into Abstractive Text Summarization — Part 1 | by Vincenzo Santopietro | Intel Student Ambassadors | Medium   \n",
       "94                                                                         Introduction to ResNets. This Article is Based on Deep Residual... | by Connor Shorten | Towards Data Science   \n",
       "95                                                                                       NLP — Text Summarization using NLTK: TF-IDF Algorithm | by Akash Panchal | Towards Data Science   \n",
       "96                                                    Gaussian Mixture Model clustering: how to select the number of components (clusters) | by Vincenzo Lavorini | Towards Data Science   \n",
       "97                                                                                Understanding Optimization Algorithms in Machine Learning | by Supriya Secherla | Towards Data Science   \n",
       "98                       HRNet Explained: Human Pose Estimation, Semantic Segmentation and Object Detection | by Hucker Marius | Oct, 2021 | Towards Data Science | Towards Data Science   \n",
       "99                                                                                                                           No home for iPad on Apple.com | by Craig Villamor | cvil.ly   \n",
       "100                                                                         Attention — Seq2Seq Models. Sequence-to-sequence (abrv. Seq2Seq)... | by Pranay Dugar | Towards Data Science   \n",
       "101                                   Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium   \n",
       "102                                                                                        Read Text from Image with One Line of Python Code | by Dario Radečić | Towards Data Science   \n",
       "103                                                                       Interpreting recurrent neural networks on multivariate time series | by André Ferreira | Towards Data Science   \n",
       "104                                                                        How I went from zero coding skills to data scientist in 6 months | by Kate Marie Lewis | Towards Data Science   \n",
       "105                                                                                                         20 ideas for better data visualization | by Taras Bakusevych | UX Collective   \n",
       "106                                                                                  Blog 9- Information Architecture. 1. What is the purpose of metadata... | by Joshua Holmes | Medium   \n",
       "107                                                                           Understanding Dropout. One particular layers that are useful... | by Roan Gylberth | Konvergen.AI | Medium   \n",
       "108                                                                                        TokenGo запускает ICO!. Приветствую вас, друзья! TokenGo... | by TokenGo Platform_RU | Medium   \n",
       "109                                                                                             Tips to avoid the pitfall of over fitting in Linear Regression | by karthic Rao | Medium   \n",
       "110                                                                                   Step by step -Understand the architecture of Region proposal network (R-CNN) | by Pallawi | Medium   \n",
       "111                                                                                            Invest in Unchainet |Heterogeneous Cloud Computing Infrastructure | by Unchainet | Medium   \n",
       "112                                                                                                                                                  Coding is a Trap. Get Out. | TekLit   \n",
       "113                                                                             In case you missed it: My Webinar on Model-Based Machine Learning | by Daniel Emaasit | emaasit | Medium   \n",
       "114                                                                                      Instance Segmentation in Google Colab with Custom Dataset | by RomRoc | HackerNoon.com | Medium   \n",
       "115                                                             Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK. | by Javed Shaikh | Towards Data Science   \n",
       "116                                                                                       Deep Reinforcement Learning for Automated Stock Trading | by Bruce Yang | Towards Data Science   \n",
       "117                                                                              The First Inaugural Firefox Census Results | by Firefox | The Official Unofficial Firefox Blog | Medium   \n",
       "118                                                            Audio Deep Learning Made Simple: Automatic Speech Recognition (ASR), How it Works | by Ketan Doshi | Towards Data Science   \n",
       "119                       EagleView high-resolution image semantic segmentation with Mask-RCNN/DeepLabV3+ using Keras and ArcGIS Pro | by Chunguang (Wayne) Zhang | Towards Data Science   \n",
       "120                                                                                                       Everything You Need to Know about Logistic Regression | by Uday Paila | Medium   \n",
       "121                                                                Gradient descent algorithms and adaptive learning rate adjustment methods | by Manish Chablani | Towards Data Science   \n",
       "122                                                      The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English   \n",
       "123                                                                                                                   DBSCAN Parameter Estimation Using Python | by Tara Mullin | Medium   \n",
       "124                                                                       U-Net for Semantic Segmentation on Unbalanced Aerial Imagery | by Amirhossein Heydarian | Towards Data Science   \n",
       "125                                                                              Dimensionality Reduction by Stochastic Gradient Descent | by Learner Subodh | Analytics Vidhya | Medium   \n",
       "126                                                                                              How to Fine-Tune BERT Transformer with spaCy 3 | by Walid Amamou | Towards Data Science   \n",
       "127                                   Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium   \n",
       "128                                                                                                              SGD: MNIST — Putting it all together | by Becky Zhu | unpackAI | Medium   \n",
       "129                                                                                                                                   What is Transformer Network | Towards Data Science   \n",
       "130                     Simple Image Classification using Convolutional Neural Network — Deep Learning in python. | by Venkatesh Tata | Becoming Human: Artificial Intelligence Magazine   \n",
       "131                                                                                How to easily Detect Objects with Deep Learning on Raspberry Pi | by Sarthak Jain | NanoNets | Medium   \n",
       "132                                                                                                  An intuitive explanation of Beam Search | by Renu Khandelwal | Towards Data Science   \n",
       "133                                                                                    The Games That AI Won. And The Progress They Represent | by Brandon Walker | Towards Data Science   \n",
       "134                                                                              Clustering Liferay globally across data centers (GSLB) with JGroups and RELAY2 | by bitsofinfo | Medium   \n",
       "135                                                                                    Kuliah Itu Gak Penting. “Buat apa kuliah kalo kalah sukses atau... | by Andreas Yonathan | Medium   \n",
       "136                                                                              Word embeddings in 2020. Review with code examples | by Rostyslav Neskorozhenyi  | Towards Data Science   \n",
       "137                                                                                    Autoencoders — Introduction and Implementation in TF. | by Manish Chablani | Towards Data Science   \n",
       "138                                                                                                            Getting Started With Google Colab | by Anne Bonner | Towards Data Science   \n",
       "139                                                                                          Your Guide to Natural Language Processing (NLP) | by Diego Lopez Yse | Towards Data Science   \n",
       "140                                                                         PixelCNN’s Blind Spot. Limitations of the PixelCNN and how to... | by Jessica Dafflon | Towards Data Science   \n",
       "141                                                                     Simple Introduction to Convolutional Neural Networks | by Matthew Stewart, PhD Researcher | Towards Data Science   \n",
       "142                                                                                 Practical implementation of outlier detection in python | by Md Sohel Mahmood | Towards Data Science   \n",
       "143                                                               Explaining system intelligence. Empower your users, but don’t overwhelm... | by Vladimir Shapiro | SAP Design | Medium   \n",
       "144                                                                                  Topic Modeling and Latent Dirichlet Allocation (LDA) in Python | by Susan Li | Towards Data Science   \n",
       "145                                                          Step by Step Implementation of Conditional Generative Adversarial Networks | by Neeraj Varshney | Analytics Vidhya | Medium   \n",
       "146                                                                                        Multiclass Text Classification using LSTM in Pytorch | by Aakanksha NS | Towards Data Science   \n",
       "147                                                                Linear Regression using Python. Linear Regression is usually the first... | by Animesh Agarwal | Towards Data Science   \n",
       "148                                                                                       Autoencoders — Bits and Bytes of Deep Learning | by Vindula Jayawardana | Towards Data Science   \n",
       "149                                                                                Write an AI to win at Pong from scratch with Reinforcement Learning | by Dhruv Parthasarathy | Medium   \n",
       "150                                                                               Basics of Using Pre-trained GloVe Vectors in Python | by Sebastian Theiler | Analytics Vidhya | Medium   \n",
       "151                                              Pipelines & Custom Transformers in scikit-learn: The step-by-step guide (with Python code) | by Himanshu Chandra | Towards Data Science   \n",
       "152                                                                                     TF-IDF from scratch in python on a real-world dataset. | by William Scott | Towards Data Science   \n",
       "153                                                                                       Deep Latent Variable Models: Unravel Hidden Structures | by Kevin Luxem | Towards Data Science   \n",
       "154                                                                                                        Sentence correction using Deep learning techniques | by Sourav kumar | Medium   \n",
       "155                                                                                                         R — CNN Ailesi Part II: Faster R-CNN & Mask R-CNN | by Elif Meşeci | Medium   \n",
       "156                                                                           Clustering Techniques. Clustering falls under the unsupervised... | by M Bharathwaj | Towards Data Science   \n",
       "157                                                                              Introduction to Object Detection with RCNN Family Models | by Sairaj Neelam | Analytics Vidhya | Medium   \n",
       "158                                                                    LSTM by Example using Tensorflow. In Deep Learning, Recurrent Neural... | by Rowel Atienza | Towards Data Science   \n",
       "159                                                                            Illustrated Guide to LSTM’s and GRU’s: A step by step explanation | by Michael Phi | Towards Data Science   \n",
       "160                                                                                       Amazon Adds Photographic Product Search To iOS App | by IPG Media Lab | IPG Media Lab | Medium   \n",
       "161                                                                                              How to cluster images based on visual similarity | by Gabe Flomo | Towards Data Science   \n",
       "162                                                                         A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way | by Sumit Saha | Towards Data Science   \n",
       "163                                                             Solving the FrozenLake environment from OpenAI gym using Value Iteration | by Diganta Kalita | Analytics Vidhya | Medium   \n",
       "164                                                                                             Neural Networks Backpropagation Made Easy | by Lihi Gur Arie, PhD | Towards Data Science   \n",
       "165                                                                  ICML 2018: Advances in transfer, multitask, and semi-supervised learning | by Isaac Godfried | Towards Data Science   \n",
       "166                                                                                        Run StyleGAN2 ADA on an AWS Spot Instance in No Time | by Oleg Polosin | Towards Data Science   \n",
       "167                                                                                 Generating text with Recurrent Neural Networks based on the work of F. Pessoa | Towards Data Science   \n",
       "168                                                                                                       Advancements in Machine Learning Assisted Ideation. | by Adam Pickard | Medium   \n",
       "169                                                                                             기계 학습(Machine Learning, 머신 러닝)은 즐겁다! Part 5 | by Jongdae Lim | Medium   \n",
       "170                                                                              Understanding PyTorch with an example: a step-by-step tutorial | by Daniel Godoy | Towards Data Science   \n",
       "171                                                                                                RNN or Recurrent Neural Network for Noobs | by Debarko De 🦁 | HackerNoon.com | Medium   \n",
       "172                                                                                                      Optimizers in Deep Learning. What is Optimizers? | by Ayushi choudhary | Medium   \n",
       "173                                                      “Isolation Forest”: The Anomaly Detection Algorithm Any Data Scientist Should Know | by Samuele Mazzanti | Towards Data Science   \n",
       "174                                                                                  Word2Vec (Part 1). Word2Vec; the Steroids for Natural... | by Mukul Malik | HackerNoon.com | Medium   \n",
       "175                                                                               Keywords to know before you start reading papers on GANs | by Dr. Varshita Sher | Towards Data Science   \n",
       "176                                                                                                                           Bayesian Variational Autoencoders | by Rob Parkin | Medium   \n",
       "177                                                                                       關於影像辨識,所有你應該知道的深度學習模型. Computer vision object detection... | by Steven Shen | Cubo AI | Medium   \n",
       "178                                                                                              Emotional Computing. Investigating the human to computer... | by Robbie Tilton | Medium   \n",
       "179                                                                                        Computational creativity: generative creature design for concept art | by Kyle Huang | Medium   \n",
       "180                                                                                                            Learning Artistic Styles from Images | by James Lee | Nurture.AI | Medium   \n",
       "181                                                                                                A Friendly Introduction to Text Clustering | by Korbinian Koch | Towards Data Science   \n",
       "182                                                                                     Normalization vs Standardization — Quantitative analysis | by Shay Geller | Towards Data Science   \n",
       "183                                                                                                    An Overview for Text Representations in NLP | by jiawei hu | Towards Data Science   \n",
       "184                                                                                             Why is gradient descent robust to non-linearly separable data? | by Vivek Yadav | Medium   \n",
       "185                                                                                                                                               K-means Clustering Algorithm | Edureka   \n",
       "186                                                            Meta Learning — AI Generalised.. AI learning to learn, to help with... | by Snehal Reddy Koukuntla | Towards Data Science   \n",
       "187                                                                                           Gamma Function — Intuition, Derivation, and Examples | by Aerin Kim | Towards Data Science   \n",
       "188                                                                                    A Beginner’s Guide to Convolutional Neural Networks (CNNs) | by Suhyun Kim | Towards Data Science   \n",
       "189                                                                                Using Affinity Propagation to Find the Number of Clusters in a Dataset | by Aneesha Bakharia | Medium   \n",
       "190                                                                                               10 Tips for Choosing the Optimal Number of Clusters | by Matt.0 | Towards Data Science   \n",
       "191                                                                                        Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca | Towards Data Science   \n",
       "192                                                                                               Data Visualization in Python: Advanced Functionality in Seaborn | by Insight | Insight   \n",
       "193                                                                                                   Let’s talk Clustering (Unsupervised Learning) | by Kaustubh N | SomX Labs | Medium   \n",
       "194                                                                                                  I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero   \n",
       "195                                                       Image Classifier using VGG-19 Deep learning model in Google Colab Notebook. Dishes Detection | by Ravi Prakash pandey | Medium   \n",
       "196               An Analysis On How Deepmind’s Starcraft 2 AI’s Superhuman Speed is Probably a Band-Aid Fix For The Limitations of Imitation Learning | by Aleksi Pietikäinen | Medium   \n",
       "197                                                                                                    Neural Style Transfer using VGG model | by Darshan Adakane | Towards Data Science   \n",
       "198                                                                 Generating Modern Art using\\nGenerative Adversarial Network(GAN) on Spell | by Anish Shrestha | Towards Data Science   \n",
       "199                                                                                                          A Brief Overview of Attention Mechanism | by Synced | SyncedReview | Medium   \n",
       "200                                                            Named Entity Recognition (NER) for CoNLL dataset with Tensorflow 2.2.0 | by Bhuvana Kundumani | Analytics Vidhya | Medium   \n",
       "201                                                                                                        Sentence correction using Deep learning techniques | by Sourav kumar | Medium   \n",
       "202                                                                Implementation of Principal Component Analysis(PCA) in K Means Clustering | by Wamika Jha | Analytics Vidhya | Medium   \n",
       "203                                                                                 AI-Class.com — A classroom with 160,000 students | by Maria Neumayer | A problem like Maria | Medium   \n",
       "204                                                                                                       Multi-Class Text Classification with LSTM | by Susan Li | Towards Data Science   \n",
       "205                                                                                        Polynomial Regression — Gradient Descent from Scratch | by Mark Garvey | Towards Data Science   \n",
       "206                                                                                         From Faces to Kitties to Apartments: GAN Fakes the World | by Synced | SyncedReview | Medium   \n",
       "207                                                                                Deep Learning Architectures That You Can Use with a Few Data | by Gorkem Polat | The Startup | Medium   \n",
       "208                                                                                                               10 rules for better dashboard design | by Taras Bakusevych | UX Planet   \n",
       "209                                                       Transfer Learning — Part — 4.0!! VGG-16 and VGG-19 | by RAVI SHEKHAR TIWARI | Becoming Human: Artificial Intelligence Magazine   \n",
       "210                                                                   Google DeepMind Releases Structure Predictions for Coronavirus Linked Proteins | by Synced | SyncedReview | Medium   \n",
       "211                                                                                                        Workflow of a Machine Learning project | by Ayush Pant | Towards Data Science   \n",
       "212                                                                               ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium   \n",
       "213                                                                                      Multi-Class Metrics Made Simple, Part II: the F1-score | by Boaz Shmueli | Towards Data Science   \n",
       "214                                                                                                  RSNA 2013 — Top 5 Tendências em TI | by Thiago Julio, MD | Saúde Digital | Medium   \n",
       "215                                                                                                   Extracting image metadata at scale | by Netflix Technology Blog | Netflix TechBlog   \n",
       "216                                                                           Machine Learning for Beginners: An Introduction to Neural Networks | by Victor Zhou | Towards Data Science   \n",
       "217                                                                         Using MaskRCNN to predict tropical fruits in custom dataset | by Bernardo Caldas | Analytics Vidhya | Medium   \n",
       "218                                                                                                       [TensorFlow 2.0] Variational Auto encoder (VAE) Part II | by A Ydobon | Medium   \n",
       "219                                                                                                     DeepMind et al Paper Trumpets Graph Networks | by Synced | SyncedReview | Medium   \n",
       "220                                                                                                 Data Science for Newbies (including me!) | by Helena Campbell | Towards Data Science   \n",
       "221                                                                                                Attacking Google Cloud Vision API with Adversarial Examples | by NN Intruder | Medium   \n",
       "222                                                                         An Intuitive Explanation of Connectionist Temporal Classification | by Harald Scheidl | Towards Data Science   \n",
       "223                                                                                                       Using Knowledge Graphs to Summarize Long Documents | by Abdarhman Taha | agolo   \n",
       "224                                                                                              Creating OpenAI Gym Environments with PyBullet (Part 1) | by Gerard Maggiolino | Medium   \n",
       "225                                                                                    Logistic Regression: A Simplified Approach Using Python | by Surya Remanan | Towards Data Science   \n",
       "226                                                                                  Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science   \n",
       "227                                                                        What is a Transformer?. An Introduction to Transformers and... | by Maxime | Inside Machine learning | Medium   \n",
       "228                                                    Quantum Chemistry Breakthrough: DeepMind Uses Neural Networks to Tackle Schrödinger Equation | by Synced | SyncedReview | Medium   \n",
       "229                                                                    Explaining K-Means Clustering. Comparing PCA and t-SNE dimensionality... | by Kamil Mysiak | Towards Data Science   \n",
       "230                                                               Everything You Need to Know About Artificial Neural Networks | by Josh | Technology, Invention, App, and More | Medium   \n",
       "231                                                                                                 Liquid Neural Networks in Computer Vision | by Jacob Solawetz | Towards Data Science   \n",
       "232                                                                                                                     Yes you should understand backprop | by Andrej Karpathy | Medium   \n",
       "233                                                                                                     New to Machine Learning? Avoid these three mistakes | by James Faghmous | Medium   \n",
       "234                                                                                    Difference between AlexNet, VGGNet, ResNet, and Inception | by Aqeel Anwar | Towards Data Science   \n",
       "235                                            A Hands-On Guide To Text Classification With Transformer Models (XLNet, BERT, XLM, RoBERTa) | by Thilina Rajapakse | Towards Data Science   \n",
       "236                                                                                                                 Demystifying Object Detection using Deep Learning | by Rafi | Medium   \n",
       "237                                                                           Paper repro: Deep Metalearning using “MAML” and “Reptile” | by Adrien Lucas Ecoffet | Towards Data Science   \n",
       "238                                                  深度學習優化器Ranger: a synergistic optimizer using RAdam (Rectified Adam), Gradient Centralization and LookAhead筆記 | by Patty Wu | Medium   \n",
       "239                                                                                            Machine Learning: Polynomial Regression with Python | by Nhan Tran | Towards Data Science   \n",
       "240                                                                                             How I struggled to Convert MBR to GPT and Installed Linux? | by thirumalaivasan | Medium   \n",
       "241                                                                                  Multi-Class Text Classification Model Comparison and Selection | by Susan Li | Towards Data Science   \n",
       "242                                                                 What Is Pre-Training in NLP? Introducing 5 Key Technologies | by dan lee | AI3 | Theory, Practice, Business | Medium   \n",
       "243                                                                                        Does your model train too slow? Alleviating Vanishing Gradient Problem | Towards Data Science   \n",
       "244                                                 Graph Neural Networks through the lens of Differential Geometry and Algebraic Topology | by Michael Bronstein | Towards Data Science   \n",
       "245                                                                                                      Anomaly detection in brightfield microscopy images | by Nurlan Kerimov | Medium   \n",
       "246                                                                                       Beam Search Decoding in CTC-trained Neural Networks | by Harald Scheidl | Towards Data Science   \n",
       "247                                                                                                  Data Scientists Will be Extinct in 10 Years | by Mikhail Mew | Towards Data Science   \n",
       "248                                                                       Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science   \n",
       "249                                                                      Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1 | by Renu Khandelwal | Towards Data Science   \n",
       "250                                                                                             The Dropout Tag I Wear. *On a personal note, before reading... | by Kerish Heik | Medium   \n",
       "251                                                                                                          Attention and its Different Forms | by Anusha Lihala | Towards Data Science   \n",
       "252                                                                                         Movix.ai — movie recommendations with Deep Learning | by Supervise.ly | Supervisely | Medium   \n",
       "253                                                              How to do Deep Learning on Graphs with Graph Convolutional Networks | by Tobias Skovgaard Jepsen | Towards Data Science   \n",
       "254                                                                          Generative AI: Visual Search as a Bridge between Fiction and Reality | by Merzmensch | Towards Data Science   \n",
       "255                                                                                                     EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNet | by Akihiro FUJII | Medium   \n",
       "256          How are Logistic Regression & Ordinary Least Squares Regression (Linear Regression) Related? Why the “Regression” in Logistic? | by Rakshith Vasudev | Towards Data Science   \n",
       "257                                                                 Meta-Learning: Learning to Learn. Although artificial intelligence and... | by Thomas HARTMANN | DataThings | Medium   \n",
       "258                                                                                  Training Custom NER. This blog explains, how to train and... | by Nishanth N | Towards Data Science   \n",
       "259                                                                                                                        ML入門(十)Gradient Descent. 簡單回顧 | by Chung-Yi | 程式設計之旅 | Medium   \n",
       "260                                                                                                        Why I dropped out of college, but you shouldn’t | by João Fernandes | Medium   \n",
       "261                                                                                   Automatic Extractive Text Summarization using TF-IDF | by ASHNA JAIN | Voice Tech Podcast | Medium   \n",
       "262                                                                                     Top JavaScript Frameworks and Tech Trends for 2021 | by Eric Elliott | JavaScript Scene | Medium   \n",
       "263                                                           Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting | by Huangwei Wieniawska | Level Up Coding   \n",
       "264                                                                                                                                  Finger Dasher | by R. E. Warner | Banapana | Medium   \n",
       "265                                                        A news-analysis NeuralNet learns from a language NeuralNet | by m.zaradzki | Becoming Human: Artificial Intelligence Magazine   \n",
       "266                                                                                        Building smart robots using AI + ROS: Part 1 | by karthic Rao | Kredo.ai Engineering | Medium   \n",
       "267                                                                                Clustering on mixed type data. A proposed approach using R | by Thomas Filaire | Towards Data Science   \n",
       "268                                                                                What is the difference between Ridge Regression, the LASSO, and ElasticNet? | by Alex Lenail | Medium   \n",
       "269                                                                             Improving neural networks by preventing co-adaptation of feature detectors | by Michael L. Peng | Medium   \n",
       "270                                                                                          Extreme Event Forecasting with LSTM Autoencoders | by Marco Cerliani | Towards Data Science   \n",
       "271                                                                               Natural Language Processing for Fuzzy String Matching with Python | by Susan Li | Towards Data Science   \n",
       "272                                                                                       SocialDefender — Social Reputation Management Platform — Aji Abraham | by Aji Abraham | Medium   \n",
       "273                                                                                 The hype on AlphaFold keeps growing with this new preprint | by LucianoSphere | Towards Data Science   \n",
       "274                                                                                        Neural Image Retrieval. Assume you have an image I and an image... | by Eitan Kosman | Medium   \n",
       "275                                                                                            Top 20 Must-Watch Artificial Intelligence movies | by Benedict Neo | Towards Data Science   \n",
       "276                                                                                      Transfer Learning in TensorFlow on the Kaggle Rainforest competition | by Luuk Derksen | Medium   \n",
       "277                                                                                                Clustering on Mixed Data Types in Python | by Ryan Kemmer | Analytics Vidhya | Medium   \n",
       "278                                                                                     Insight into Faster R-CNN for Object Detection. | by Haripriya Reddy | Analytics Vidhya | Medium   \n",
       "279                                                                                                   Intelligent Agent Based Wastewater Management System | by Masumi Mutsuda | mutsuda   \n",
       "280                                                                          Springer has released 65 Machine Learning and Data books for free | by Uri Eliabayev | Towards Data Science   \n",
       "281                                                                                                    Using LSTMs to forecast time-series | by Ravindra Kompella | Towards Data Science   \n",
       "282                                                         Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models | by Roland Hewage | Towards Data Science   \n",
       "283                                                                                             帶你認識Vector-Quantized Variational AutoEncoder - 理論篇 | by Tan | Taiwan AI Academy | Medium   \n",
       "284                                                                                    True Democratization of Analytics with Meta-Learning | by Progress | Stories by Progress | Medium   \n",
       "285                                                                                                 Machine Learning Quiz 05: Decision Tree (Part 1) | by Md Shahidullah Kawsar | Medium   \n",
       "286                                                                                                      Speeding up BERT Search in Elasticsearch | by Dmitry Kan | Towards Data Science   \n",
       "287                                                                                                                                               写在看完变形金刚II之后 | by Justin Chen | Medium   \n",
       "288                                                                                              Classes of Novels. According to Creative Writing Now, the... | by Jhen Hilario | Medium   \n",
       "289                                                                                                          Object Recognition with OpenCV on Android | by Akshika Wijesundara | Medium   \n",
       "290                                                                              SSD object detection: Single Shot MultiBox Detector for real-time processing | by Jonathan Hui | Medium   \n",
       "291                                                                               Blockchain is not only crappy technology but a bad vision for the future | by Kai Stinchcombe | Medium   \n",
       "292                                                                                                      Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science   \n",
       "293                                                                                                      Transformer-based Sentence Embeddings | by Haaya Naushan | The Startup | Medium   \n",
       "294                                                                                                                 Stash Data Center ベータ版リリース。Git を大規模に利用 | by Jerome Bouchon | Medium   \n",
       "295                                                                    CNN-LSTM-Based Models for Multiple Parallel Input and Multi-Step Forecast | by Halil Ertan | Towards Data Science   \n",
       "296                                                                                                      Sentiment analysis using RNNs(LSTM) | by Manish Chablani | Towards Data Science   \n",
       "297                                                                                                                                           Activation Functions | by Chinmay | Medium   \n",
       "298                                                                                                        Sentence correction using Deep learning techniques | by Sourav kumar | Medium   \n",
       "299                                                                                                                                  Introduction | by ProjectAGI | Project AGI | Medium   \n",
       "300                                                                              Implementing Grad-CAM in PyTorch. Recently I have come across a chapter... | by Stepan Ulyanin | Medium   \n",
       "301                                                                                                 Creating Bitcoin trading bots don’t lose money | by Adam King | Towards Data Science   \n",
       "302                                                                                                   Hi Tal,. Maybe I’m missing something here, but... | by Sachin Abeywardana | Medium   \n",
       "303                                                                             Using Word Embeddings to Identify Company Names and Stock Tickers | by Brian Ward | Towards Data Science   \n",
       "304                                                                                                 Building a Bayesian deep learning classifier | by Kyle Dorman | Towards Data Science   \n",
       "305                                      Every single Machine Learning course on the internet, ranked by your reviews | by David Venturi | We’ve moved to freeCodeCamp.org/news | Medium   \n",
       "306                                                Art & AI: The Logic Behind Deep Learning ‘Style Transfer’ | by Nick Kasten | Center for Open Source Data and AI Technologies | Medium   \n",
       "307                                                                                        How to Perform Abstractive Summarization with PEGASUS | by Jiahao Weng | Towards Data Science   \n",
       "308                                                                       text summarization: applications. this article is mainly a summarization... | by Wenchen's ai fantasy | Medium   \n",
       "309                                                                   🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning | by Thomas Wolf | HuggingFace | Medium   \n",
       "310                                                                     A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs) | by Neelabh Pant | Cube Dev | Medium   \n",
       "311                                                                               ICO TokenGo заканчивается!. Дорогие друзья! Подходит к концу май... | by TokenGo Platform_RU | Medium   \n",
       "312                                                           Basics of the Classic CNN. How a classic CNN (Convolutional Neural... | by Chandra Churh Chatterjee | Towards Data Science   \n",
       "313                                                                                Semantic Image Segmentation using Fully Convolutional Networks | by Arun Kumar | Towards Data Science   \n",
       "314                                                                                                     Building a Summarization System in Minutes | by Ceshine Lee | Veritable | Medium   \n",
       "315                                                                                                        What are adversarial examples in NLP? | by Jack Morris | Towards Data Science   \n",
       "316                                                                                                   Reducing Memory Usage in R (especially for regressions) | by William Ryan | Medium   \n",
       "317                                                                            7 Applications of Auto-Encoders every Data Scientist should know | by Satyam Kumar | Towards Data Science   \n",
       "318                                                                       Seq2Seq model in TensorFlow. In this project, I am going to build... | by Park Chansung | Towards Data Science   \n",
       "319                                                                                   Understanding 1D and 3D Convolution Neural Network | Keras | by Shiva Verma | Towards Data Science   \n",
       "320                                                                                  When Neural Networks saw the first image of Black Hole. | by Anuj shah (Exploring Neurons) | Medium   \n",
       "321                                                                                      Weekend Diversion: The Ultimate Superhero Cake | by Ethan Siegel | Starts With A Bang! | Medium   \n",
       "322                                                                                                                    Deep Generative Models | by Prakash Pandey | Towards Data Science   \n",
       "323                                                                                                           Adversarial attacks on Explainable AI | by Hubert Baniecki | ResponsibleML   \n",
       "324                                                                Adversarial Machine Learning. A Brief Introduction for Non-Technical... | by Charles Kapelke | CLTC Bulletin | Medium   \n",
       "325                                                                               Intersection Over Union. Pada masalah deteksi objek, output yang... | by Alfi Salim | BISA.AI | Medium   \n",
       "326                                                                                                      Variational Autoencoder In Finance | by Marie Imokoyende | Towards Data Science   \n",
       "327                           Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning & Big Data | by Stefan Kojouharov | Becoming Human: Artificial Intelligence Magazine   \n",
       "328                                                                           Region of Interest Pooling. A Technique which allowed a new... | by Sambasivarao. K | Towards Data Science   \n",
       "329                                                                                                        Clustering on Kubernetes & OpenShift3 using DNS | by Jimmi Dyson | fabric8 io   \n",
       "330         Support Vector Machine: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium   \n",
       "331                                                Intro to reinforcement learning: temporal difference learning, SARSA vs. Q-learning | by Viet Hoang Tran Duong | Towards Data Science   \n",
       "332                                                                                                   Object detection and tracking in PyTorch | by Chris Fotache | Towards Data Science   \n",
       "333                                                                                                  I Asked GPT-3 About Covid-19. Its Responses Shocked Me. | by Thomas Smith | OneZero   \n",
       "334                                                                                                A detailed explanation of the Attention U-Net | by Robin Vinod | Towards Data Science   \n",
       "335                                                                                                         Overview of Conditional Random Fields | by Ravish Chawla | ML 2 Vec | Medium   \n",
       "336                                                                        The Charm of a Gritty City. Baltimore as Entrepreneurship Hub | by Frank Bonsal III | Bonsal Capital | Medium   \n",
       "337                                                                                                  Understanding Latent Space in Machine Learning | by Ekin Tiu | Towards Data Science   \n",
       "338                                                                                      Bitcoin Bonanza!. Comparing the efficacy of GRU, LSTM... | by Ryan Burke | Towards Data Science   \n",
       "339                                                                                                     The Complete Beginner’s Guide To Chatbots | by Matt Schlicht | Chatbots Magazine   \n",
       "340                                                                                                   An Introduction To Conditional GANs (CGANs) | by Manish Nayak | DataDrivenInvestor   \n",
       "341                                                                                   Perturbation Theory in Deep Neural Network (DNN) Training | by Prem Prakash | Towards Data Science   \n",
       "342                                                                        A Step by Step approach to Solve DBSCAN Algorithms by tuning its hyper parameters | by Mohantysandip | Medium   \n",
       "343                                                                                        Deep Neural Networks for Regression Problems | by Mohammed AL-Ma'amari | Towards Data Science   \n",
       "344                                                                  Machine Learning for Humans, Part 2.1: Supervised Learning | by Vishal Maini | Machine Learning for Humans | Medium   \n",
       "345                                                                         Simple SGD implementation in Python for Linear Regression on Boston Housing Data | by Nikhil Parmar | Medium   \n",
       "346                                                                           Binary Logistic Regression. An overview and implementation in R | by Akanksha Rawat | Towards Data Science   \n",
       "347                                    Intuitive guide to word embedding, RNN (SimpleRNN, LSTM) with step by step implementation in keras for spam detection | by Hemant Ranvir | Medium   \n",
       "348                                                                                                          YOLOv4. While object detection matures in the... | by Jonathan Hui | Medium   \n",
       "349                                                                                                           癌細胞生長的開關:基因啟動子(Promoter)?. 啟動子 (Promoter)... | by Geneonline-基因線上 | Medium   \n",
       "350                                                                           RNN vs GRU vs LSTM. In this post, I will make you go... | by Hemanth Pedamallu | Analytics Vidhya | Medium   \n",
       "351                                                                  Fancy and custom Neural Style Transfer filters for video conferencing | by Maximus Mutschler | Towards Data Science   \n",
       "352                                                                   3 метода детектирования объектов c Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN | by Nick Komissarenko | Medium   \n",
       "353                                                                                                         Stepwise Regression Tutorial in Python | by Ryan Kwok | Towards Data Science   \n",
       "354                                                                                                         1. Creating a Q-A system (Introduction) | by Puneet Singh | techpsl | Medium   \n",
       "355                                                                                                  Model Agnostic Meta-Learning (MAML): An Intuitive Way | by Saket Dingliwal | Medium   \n",
       "356                                                                                                                 The Current State of Machine Intelligence | by Shivon Zilis | Medium   \n",
       "357                                                                                                      Understanding Input and Output shapes in LSTM | Keras | by Shiva Verma | Medium   \n",
       "358                                                     Keras Embedding layer and Programetic Implementation of GLOVE Pre-Trained Embeddings | by Akash Deep | Analytics Vidhya | Medium   \n",
       "359                                                                                        Understanding Vector Quantized Variational Autoencoders (VQ-VAE) | by Shashank Yadav | Medium   \n",
       "360                                                                                          What does it mean by Bidirectional LSTM? | by Jaimin Mungalpara | Analytics Vidhya | Medium   \n",
       "361                                                                                                K-Means vs. DBSCAN Clustering — For Beginners | by Ekta Sharma | Towards Data Science   \n",
       "362                                                                                     A gentle introduction to Deep Reinforcement Learning | by Jordi TORRES.AI | Towards Data Science   \n",
       "363                                                                         Learning to Build a Model for Sketch-to-Color Image Generation using Conditional GANs | Towards Data Science   \n",
       "364                                                                      Batch vs Mini-batch vs Stochastic Gradient Descent with Code Examples | by Matheus Jacques | DataDrivenInvestor   \n",
       "365                                                                                           Lambda Functions with Practical Examples in Python | by Susan Maina | Towards Data Science   \n",
       "366                                                                                   Performance Metrics for Classification problems in Machine Learning | by Mohammed Sunasra | Medium   \n",
       "367                                                                   Few-Shot Learning with fast.ai. In few-shot learning, we train a model... | by Igor Susmelj | Towards Data Science   \n",
       "368                       GAN — Introduction and Implementation — PART1: Implement a simple GAN in TF for MNIST handwritten digit generation | by Manish Chablani | Towards Data Science   \n",
       "369                                                                                                                                  Solving 8-Puzzle using A* Algorithm | Good Audience   \n",
       "370                                                                                                      NLP: Building Text Summarizer — Part 1 | by Ashish Singhal | DataPy.ai | Medium   \n",
       "371                                                                                      From metaphor to reality. When does artificial intelligence stop... | by Hely Marleena | Medium   \n",
       "372                                                                                                           1000x Faster Spelling Correction algorithm (2012) | by Wolf Garbe | Medium   \n",
       "373                                                                                                      Training Provably-Robust Neural Networks | by Klas Leino | Towards Data Science   \n",
       "374                                                                                              Tensorflow or PyTorch : The force is strong with which one? | by Udacity India | Medium   \n",
       "375                                                                                                             Gaussian Mixture Models vs K-Means. | by K.Kubara | Towards Data Science   \n",
       "376                                                         Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras | by Emil Lykke Jensen | Towards Data Science   \n",
       "377                                      Unsupervised Classification Project: Building a Movie Recommender with Clustering Analysis and K-Means | by Victor Roman | Towards Data Science   \n",
       "378                                                                            Causal inference (Part 2 of 3): Selecting algorithms | by Jane Huang | Data Science at Microsoft | Medium   \n",
       "379                                                                                                   Convolutional Neural Networks, Explained | by Mayank Mishra | Towards Data Science   \n",
       "380                                                                                      Adversarial Examples to Break Deep Learning Models | by Pau Labarta Bajo | Towards Data Science   \n",
       "381                                                               Understanding the Backbone of Video Classification: The I3D Architecture | by Madeline Schiappa | Towards Data Science   \n",
       "382  Random Forests Classification: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium   \n",
       "383                                          Why Transformers are Slowly Replacing CNNs in Computer Vision? | by Pranoy Radhakrishnan | Becoming Human: Artificial Intelligence Magazine   \n",
       "384                                                                                           어텐션 메커니즘과 transfomer(self-attention) | by platfarm tech team | mojitok | Medium   \n",
       "385                                                                                      Understanding the Mathematics behind Gradient Descent. | by Parul Pandey | Towards Data Science   \n",
       "386                                                                                                           Logistic Regression from scratch in Python | by Martín Pellarolo | Medium   \n",
       "387                                                                 Beginner Guide to Variational Autoencoders (VAE) with PyTorch Lightning (Part 3) | by Reo Neo | Towards Data Science   \n",
       "388                                                                                                         60 Python Projects with Source Code | by Aman Kharwal | Coders Camp | Medium   \n",
       "389                                                           The Softmax Function, Neural Net Outputs as Probabilities, and Ensemble Classifiers | by Haihan Lan | Towards Data Science   \n",
       "390                                                                        A beginner’s guide to deriving and implementing backpropagation | by Pranav Budhwant | binaryandmore | Medium   \n",
       "391                                                                                         mAP (mean Average Precision) might confuse you! | by Shivy Yohanandan | Towards Data Science   \n",
       "392                                                                                                                How to recognize fake AI-generated images | by Kyle McDonald | Medium   \n",
       "393                                                                                                       A brief introduction to artificial neural networks | by Peter Bulyaki | Medium   \n",
       "394                                                                                                BigGAN: A New State of the Art in Image Synthesis | by Synced | SyncedReview | Medium   \n",
       "395                                                                                                    A 2022-Ready Deep Learning Hardware Guide | by Nir Ben-Zvi | Towards Data Science   \n",
       "396                                                                                                                          These Bored Apes Do Not Exist: GAN to NFT Pipeline | Medium   \n",
       "397                                                                                                          Detecting Empty Parking Lots With Mask RCNN Model | by Ahmet Genç | Medium   \n",
       "398                                                                What is Online Machine Learning?. Making machines learn in real time | by Max Pagels | The Hands-on Advisors | Medium   \n",
       "399                                                                                       Image analysis intro using python & opencv | by Chris Loughnane | Product Development Notebook   \n",
       "400                                                                                  Multi Class Text Classification with LSTM using TensorFlow 2.0 | by Susan Li | Towards Data Science   \n",
       "401                                                              Using OOB Tags in AIML: Part I. Suppose you are building an Intelligent... | by Pandorabots | pandorabots-blog | Medium   \n",
       "402                                                                                                       Understanding Encoders-Decoders with Attention Based Mechanism | DataX Journal   \n",
       "403                                                  Should AI explain itself? or should we design Explainable AI so that it doesn’t have to | by Prajwal Paudyal | Towards Data Science   \n",
       "404                                                                                                           An Introduction to Perceptron Algorithm | by Yang S | Towards Data Science   \n",
       "405                                                                                              Taking Keras to the Zoo. If you follow any of the popular blogs... | by Karl N. | Gab41   \n",
       "406                                                                                         Introduction: Reinforcement Learning with OpenAI Gym | by ASHISH RANA | Towards Data Science   \n",
       "407                                                         Reinforcement Learning (Pekiştirmeli Öğrenme) — İnsan Beyniyle Aradaki Fark Kapanırken | by Volkan Levent Soylu | Medium   \n",
       "408                                                                                       Sugerencias para definir un menú de navegación | by editorCapire.info | Capire.info | Medium   \n",
       "409                                                                                                How to implement an Adam Optimizer from Scratch | by Enoch Kan | Towards Data Science   \n",
       "410                                                                   Machine Learning Algorithms For Beginners with Code Examples in Python | by Towards AI Editorial Team | Towards AI   \n",
       "411                                                                                             Gradient descent vs coordinate descent | by Francesco Gadaleta | HackerNoon.com | Medium   \n",
       "412          How I deployed my spark document classification(Logistic Regression) model/s as a standalone app for real-time prediction | by surendranath bobba | HackerNoon.com | Medium   \n",
       "413                                                                        Demonstrating Customers Segmentation with DBSCAN Clustering Using Python | by Hshan.T | MLearning.ai | Medium   \n",
       "414                                                                           NLP: Spam Detection in SMS (text) data using Deep Learning | by Sudip Shrestha, PhD | Towards Data Science   \n",
       "415                                                                           POS Tagging Using RNN. Learn how to use RNNs to tag words in... | by Tanya Dayanand | Towards Data Science   \n",
       "416                                                                         Deep Convolutional Generative Adversarial Network using PyTorch | by Renu Khandelwal | Geek Culture | Medium   \n",
       "417                                                                                             A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science   \n",
       "418                                                                                               Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3 | by Jonathan Hui | Medium   \n",
       "419                                                                             Price Prediction using Machine Learning Regression — a case study | by Arun Kumar | Towards Data Science   \n",
       "420                                                                 Embeddings in Machine Learning. Embeddings are a basic method to encode... | by Bayan Bennett | The Startup | Medium   \n",
       "421                                                                                     The 5 Clustering Algorithms Data Scientists Need to Know | by George Seif | Towards Data Science   \n",
       "422                                                                                                                       Understanding Attention Mechanism | by Shashank Yadav | Medium   \n",
       "423                                                                                            Ensemble methods: bagging, boosting and stacking | by Joseph Rocca | Towards Data Science   \n",
       "424                                                                       How to Improve Naive Bayes?. Section 3: Tuning the Model in Python | by Kopal Jain | Analytics Vidhya | Medium   \n",
       "425                                                                                   Object detection in Deep learning (Part2) | by Amin Ag | AI3 | Theory, Practice, Business | Medium   \n",
       "426                                                                                A brief overview of R-CNN, Fast R-CNN and Faster R-CNN | by Sema Zeynep Bulut | MLearning.ai | Medium   \n",
       "427                                                                                    Evasion attacks on Machine Learning (or “Adversarial Examples”) | by ilmoi | Towards Data Science   \n",
       "428                                                                                               Fine-Tuned Named Entity Recognition with Hugging Face BERT | by Andrew Marmon | Medium   \n",
       "429                                                                                       Gradient Boosting from scratch. Simplifying a complex algorithm | by Prince Grover | ML Review   \n",
       "430                                                                                                 Simple Reinforcement Learning: Q-learning | by Andre Violante | Towards Data Science   \n",
       "431                                   Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks | by Arthur Juliani | Emergent // Future | Medium   \n",
       "432                                                                       Neural Networks without Backpropagation: Direct Feedback Alignment | by Rizky Luthfianto | Blog rilut | Medium   \n",
       "433                                                                              Clustering with Gaussian Mixture Model | by Azad Soni | Clustering with Gaussian Mixture Model | Medium   \n",
       "434                                                                                             Training a spaCy NER Pipeline with Prodigy | by JP Zamanillo | Analytics Vidhya | Medium   \n",
       "435                                                                                                        Solving the Multi-Armed Bandit Problem | by Anson Wong | Towards Data Science   \n",
       "436                                                                                     Single Stage Instance Segmentation — A Review | by Patrick Langechuan Liu | Towards Data Science   \n",
       "437                                                                        Difference between AutoEncoder (AE) and Variational AutoEncoder (VAE) | by Aqeel Anwar | Towards Data Science   \n",
       "438                                                                       Predict Customer Churn with R. For any service company that bills on a... | by Susan Li | Towards Data Science   \n",
       "439                                                                    Anisotropic, Dynamic, Spectral and Multiscale Filters Defined on Graphs | by Boris Knyazev | Towards Data Science   \n",
       "440                                                                                     Important Topics in Machine Learning You Need to Know | by Sabina Pokhrel | Towards Data Science   \n",
       "441                                                                                             Deriving Backpropagation with Cross-Entropy Loss | by Essam Wisam | Towards Data Science   \n",
       "442                                                                                The Ultimate Guide to Clustering Algorithms and Topic Modeling | by Zijing Zhu | Towards Data Science   \n",
       "443                                                    Text Summarization from scratch using Encoder-Decoder network with Attention in Keras | by Varun Saravanan | Towards Data Science   \n",
       "444   Linear Discriminant Analysis: MATLAB, R and Python codes — All you have to do is just preparing data set (very simple, easy and practical) | by DataAnalysis For Beginner | Medium   \n",
       "445                                                                        Why AlphaGo Zero is a Quantum Leap Forward in Deep Learning | by Carlos E. Perez | Intuition Machine | Medium   \n",
       "446                                                                                                              Segmentasi Semantik untuk Klasifikasi Citra | by Ilma Arifiany | Medium   \n",
       "447                                                                                        Beginner’s Guide to RNN & LSTMs. Let’s understand how exactly RNN and... | by Dinesh | Medium   \n",
       "448                                                                                            Puppyslugs ‘R Us: Part 1. In “Puppyslugs ‘R Us: Part 0”, I... | by Boris Anthony | Medium   \n",
       "449                                                                       Understanding Deep Self-attention Mechanism in Convolution Neural Networks | by Shuchen Du | AI Salon | Medium   \n",
       "450                                                                  Transfer learning and Image classification using Keras on Kaggle kernels. | by Rising Odegua | Towards Data Science   \n",
       "451                                                                            Understanding the StyleGAN and StyleGAN2 Architecture | by Prem Chandra Singh | Analytics Vidhya | Medium   \n",
       "452                                                                                                         mAP (mean Average Precision) for Object Detection | by Jonathan Hui | Medium   \n",
       "453                                                                                                       GUIDE: POP! Slots Casino — Level 27 & 34 ($13+) [EASY] | by EarnSkins | Medium   \n",
       "454                                                                                                                Seq2seq pay Attention to Self Attention: Part 2 | by Gene Su | Medium   \n",
       "455                                                                                  Attention for time series forecasting and classification | by Isaac Godfried | Towards Data Science   \n",
       "456                                                                           Silhouette Coefficient. This is my first medium story, so... | by Ashutosh Bhardwaj | Towards Data Science   \n",
       "457                                                                                               Clustering Algorithm for Customer Segmentation | by Destin Gong | Towards Data Science   \n",
       "458                                                                Train a neural net for semantic segmentation in 50 lines of code, with Pytorch | by Sagi eppel | Towards Data Science   \n",
       "459                                                                                      Multivariate Time Series Forecasting with Transformers | by Jake Grigsby | Towards Data Science   \n",
       "460                                                                                     BLiTZ — A Bayesian Neural Network library for PyTorch | by Piero Esposito | Towards Data Science   \n",
       "461                                                                    Neural Art Style Transfer with Keras — Theory and Implementation | by Adrian Yijie Xu | GradientCrescent | Medium   \n",
       "462                                                                                                                            What are the common word embeddings? | The Ezra Tech Blog   \n",
       "463                                                                                                           EQuake. Riley Davis and David Souther... | by The NYT Open Team | NYT Open   \n",
       "464                                                                                               GANGogh: Creating Art with GANs. Introduction: | by Kenny Jones | Towards Data Science   \n",
       "465                                                      The Measure of a Measure. How to create innovative measurements... | by Charlie Kufs | Artificial Intelligence in Plain English   \n",
       "466                                                                                         Tutorial on Graph Neural Networks for Computer Vision and Beyond | by Boris Knyazev | Medium   \n",
       "467                                                                                           Smartphones vs Tablets: Does size matter? | by DataCrafts @ DataWeave | DataWeave | Medium   \n",
       "468                                                                     Stochastic Gradient Descent for machine learning clearly explained | by Baptiste Monpezat | Towards Data Science   \n",
       "469                                                                                                                                  Keyword Extraction with BERT | Towards Data Science   \n",
       "470                                                                                             A Basic Introduction to Separable Convolutions | by Chi-Feng Wang | Towards Data Science   \n",
       "471                                                                                                    Fooling Facial Detection with Fashion | by Bruce MacDonald | Towards Data Science   \n",
       "472                                                                                       StyleGAN2. This article explores changes made in... | by Connor Shorten | Towards Data Science   \n",
       "473                                                                                                Quick Logistic Regression with TensorFlow | by Pankaj Mathur | Pankaj Mathur | Medium   \n",
       "474                                                                                                      Clustering Analysis in R using K-means | by Luiz Fonseca | Towards Data Science   \n",
       "475                                                                                                          Time Series of Price Anomaly Detection | by Susan Li | Towards Data Science   \n",
       "476                                                                                   A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model | by Zhi Li | Towards Data Science   \n",
       "477                                                                            The Vanishing Gradient Problem. The Problem, Its Causes, Its... | by Chi-Feng Wang | Towards Data Science   \n",
       "478                                                                                                        Regularization in Machine Learning | by Prashant Gupta | Towards Data Science   \n",
       "479                                                             GMM: Gaussian Mixture Models — How to Successfully Use It to Cluster Your Data? | by Saul Dobilas | Towards Data Science   \n",
       "480                                                                         Speeding up your code (2): vectorizing the loops with Numpy | by Vincenzo Lavorini | HackerNoon.com | Medium   \n",
       "481                                                                                        Bayesian Linear Regression in Python via PyMC3 | by Dr. Robert Kübler | Towards Data Science   \n",
       "482                                                                                                       Introduction to recommender systems | by Baptiste Rocca | Towards Data Science   \n",
       "483                                                                                           A guide to transfer learning with Keras using ResNet50 | by Kenneth Cortés Aguas | Medium   \n",
       "484                                                                                  GPT-3 Is an Amazing Research Tool. But OpenAI Isn’t Sharing the Code. | by Dave Gershgorn | OneZero   \n",
       "485                                                                                                Introduction to Machine Learning for Beginners | by Ayush Pant | Towards Data Science   \n",
       "486                                                                                                        Federated Clusters with Docker Swarm | by Jeff Nickoloff | On Docker | Medium   \n",
       "487                                                                                                 Clustering Based Unsupervised Learning | by Syed Sadat Nazrul | Towards Data Science   \n",
       "488                                                                                                                Training a Conditional DC-GAN on CIFAR-10 | by Utkarsh Desai | Medium   \n",
       "489                                                                                             The proper way to use Machine Learning metrics | by Félix Revert | Towards Data Science   \n",
       "490                                                                                                    Few-shot Object Detection in Practice | by Alexander Hirner | Moonvision | Medium   \n",
       "491                                                                                      Object detection with Tensorflow model and OpenCV | by Gabriel Cassimiro | Towards Data Science   \n",
       "492                                                                          Batch Normalization and ReLU for solving Vanishing Gradients | by Lavanya Gupta | Analytics Vidhya | Medium   \n",
       "493                                                                                                      K-Means Clustering and the Gap-Statistics | by Tim Löhr | Towards Data Science   \n",
       "494                                                            Of brains and cities; neuroscience and cultures of decision-making | by Dan Hill | Dark Matter and Trojan Horses | Medium   \n",
       "495                                                                        Redes Neurais, Perceptron Multicamadas e o Algoritmo Backpropagation | by Tiago M. Leite | Ensina.AI | Medium   \n",
       "496                                                                                                     Spam Classifier in Python from scratch | by Tejan Karmali | Towards Data Science   \n",
       "497                                                                                                                                         Preparing for Insight | by Insight | Insight   \n",
       "498                                                                                                                    GOOGLE AI CONTEST | by Aleksey Tikhonov | Altsoph’s blog | Medium   \n",
       "499                                                     🏎 Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT | by Victor Sanh | HuggingFace | Medium   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                text  \\\n",
       "0    Towards Data Science\\nOct 18, 2019\\nClassification and object detection are the main parts of computer vision. Classification is finding what is in an image and object detection and localisation is finding where is that object in that image. Detection is a more complex problem to solve as we need to find the coordinates of the object in an image.\\nTo Solve this problem R-CNN was introduced by Ross Girshick, Jeff Donahue, Trevor Darrell and Jitendra Malik in 2014. R-CNN stands for Regions with CNN. In R-CNN instead of running classification on huge number of regions we pass the image through selective search and select first 2000 region proposal from the result and run classification on that. In this way instead of classifying huge number of regions we need to just classify first 2000 r...   \n",
       "1    Towards Data Science\\nMar 11, 2019\\nIf you liked this post and want to learn how machine learning algorithms work, how did they arise, and where are they going, I recommend the following:\\nwww.holloway.com\\nTransformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in their language models, and also used recently by DeepMind for AlphaStar — their program to defeat a top professional Starcraft player.\\nTransformers were developed to solve the problem of sequence transduction, or neural machine translation. That means any task that transforms an input sequence to an output sequence. This includes speech recognition, text-to-speech transformation, etc..\\nFor models to perform sequence transduction, it is necessary to...   \n",
       "2    Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...   \n",
       "3    Nov 21, 2005\\nToday, we build complex software applications based on the things computers do well, such as storing and retrieving large amounts of information or rapidly performing calculations. However, humans still significantly outperform the most powerful computers at completing such simple tasks as identifying objects in photographs — something children can do even before they learn to speak.When we think of interfaces between human beings and computers, we usually assume that the human being is the one requesting that a task be completed, and the computer is completing the task and providing the results. What if this process were reversed and a computer program could ask a human being to perform a task and return the results? What if it could coordinate many human beings to perfo...   \n",
       "4    SDG Counting\\nFeb 17, 2017\\n1 . IISD provided context to news that the report of the 48th Statistical Commission (coming up March 7th-10th in New York) intends to include a draft resolution on the global indicator framework for the UN Economic and Social Council (ECOSOC) and the UN General Assembly to adopt. Last year, through the 47th Statistical Commission, the global indicator framework was agreed upon as a starting point and “taken note of by ECOSOC” in June 2016. A formal adoption would mean that methodology standards for indicator review and revision would be followed, as well as coming closer to the acceptance of all 230 indicators by all member states.\\nsdg.iisd.org\\n2. The Global Festival of Ideas for Sustainable Development is less than two weeks away, and a detailed agenda o...   \n",
       "5    Jan 4, 2016\\nIf you asked me where I would be right now a year ago, my prediction wouldn’t even come close.\\nI had the opportunity to apprentice under radio show host and business coach, Margaret Jackson. On top of business skills, the biggest lesson she taught me was about legacy.\\nWhat legacy do I want to leave behind in the world?\\nMargaret told me to highlight my top 3 items on my bucket list. I wrote crazy goals like\\nMargaret looked at the rest of my (extensive) bucket list and started laughing to herself.\\n“Tam, you know there are people in organizations devoting their lives to ONE of these goals. How the hell in the world are you going to accomplish everything?”\\nMaintaining focus was the next crucial lesson. Mozart was known for music. Michael Jordan was known for basketball. ...   \n",
       "6                                                                                                                                                                                                                  ECLaboratorio\\nDec 5, 2016\\nMachine Learning, Big Data, Deep Learning, ... ¿por qué cada día se oyen mas estos términos? y de hecho ¿qué significan? Acompáñame a descubrirlo de forma sencilla y con muchos ejemplos en el siguiente vídeo:\\n... Y la presentación llena de enlaces que te pueden ayudar a profundizar más:\\n5 \\n5 \\nTrabajamos con equipos autónomos y autosuficientes enfocados a la creación de productos útiles, sencillos y que consigan mayor satisfacción del cliente\\n28 Followers\\nData scientist\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "7    The Awl\\nFeb 22, 2012\\nby Jane Hu\\nIn the final episode of “Freaks and Geeks,” the Freaks group leader Daniel Desario accepts an invitation to play Dungeons & Dragons with the notoriously geeky A/V club. Surprised by Daniel’s warm receptivity to the game, the Geeks wonders what this means for their future status. As Bill puts it: “Does him wanting to play with us again mean he’s turning into a geek or we’re turning into cool guys?” Sam answers, “I’m going to go for us becoming cool guys.” It’s a nice ambiguous note on which to end the show.\\nOutside the universe of “Freaks and Geeks,” a similar drift has occurred. Geekiness has accrued cachet, and geeks are becoming the cool guys. In an interview about the comedy web series “Geek Therapy,” actress America Young observed: “We started ta...   \n",
       "8    Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...   \n",
       "9    Nov 12, 2015\\nas mentiras e conturbações feitas a vida do “monstro” e “mito” Lou Reed atráves de biográfias e material descártavel são absurdamentes grandes, mas de certa forma provacadas pelo mesmo, uma figura icônica e contráditoria.\\nantes da fama Lou já era conturbado, mas a primeira aparição do Velvet em uma zine desmistifica algumas das alegações tardias do cantor e guitarrista. Lou Reed cita os beatles como criativos e absolutamente magníficos, assim como os Stones. ele cita Creedence como legais a primeira ouvida mas depois absolutamente tedioso e desgastante era 1972 e Lou estava no caminho de albúns como “Transformer” que absorvia toda a atmosfera Glam da época com uma pegada Rock and Roll, e ao mesmo tempo definia uma época, a ambiguidade sexual em sua capa ...   \n",
       "10   May 5, 2014\\nUpdate: This article is part of a series. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, Part 6, Part 7 and Part 8! You can also read this article in 日本語, Português, Português (alternate), Türkçe, Français, 한국어 , العَرَبِيَّة‎‎, Español (México), Español (España), Polski, Italiano, 普通话, Русский, 한국어 , Tiếng Việt or فارسی.\\nGiant update: I’ve written a new book based on these articles! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. Check it out now!\\nHave you heard people talking about machine learning but only have a fuzzy idea of what that means? Are you tired of nodding your way through conversations with co-workers? Let’s change that!\\nThis guide is f...   \n",
       "11   Towards Data Science\\nMay 3, 2020\\nCOCO (Common Objects in Context), being one of the most popular image datasets out there, with applications like object detection, segmentation, and captioning - it is quite surprising how few comprehensive but simple, end-to-end tutorials exist. When I first started out with this dataset, I was quite lost and intimidated. I had to plough my way through so many scattered, inadequate resources on the web, multiple vague tutorials, and some experimentation to finally see light at the end of this tunnel. When I was done, I knew I had to document this journey, from start to finish. And so I did. With the hope that someday, someone out there would find these of value and not have to go through all the trouble I faced.\\nHere’s presenting you a two part seri...   \n",
       "12   Towards Data Science\\nMar 15, 2019\\nProject Description and initial assumptions:\\nAs a part of our final project for Cognitive computing, we decided to address a real life business challenge for which we chose IT Service Management. Of all the business cases, we were interested with four user cases that might befitting for our project.\\n1. In Helpdesk, almost 30–40% of incident tickets are not routed to the right team and the tickets keep roaming around and around and by the time it reaches the right team, the issue might have widespread and reached the top management inviting a lot of trouble.\\n2. Let’s say that users are having some trouble with printers. User calls help desk, he creates a ticket with IT Support, and they realize that they need to update a configuration in user’s sys...   \n",
       "13   Towards Data Science\\nNov 10, 2021\\nBack in 2018, Google developed a powerful Transformer-based machine learning model for NLP applications that outperforms previous language models in different benchmark datasets. And this model is called BERT.\\nIn this post, we’re going to use a pre-trained BERT model from Hugging Face for a text classification task. As you might already know, the main goal of the model in a text classification task is to categorize a text into one of the predefined labels or tags.\\nSpecifically, soon we’re going to use the pre-trained BERT model to classify whether the text of a news article can be categorized as sport, politics, business, entertainment, or tech category.\\nBut before we dive into the implementation, let’s talk about the concept behind BERT briefly.\\...   \n",
       "14   Insight\\nJun 30, 2016\\nWant to learn Elasticsearch and other big data tools from top data engineers in Silicon Valley or New York? The Insight Data Engineering Fellows Program is a free 7-week professional training program where you can build cutting edge big data platforms and transition to a career in data engineering at top teams like Facebook, Uber, Slack and Squarespace.\\nLearn more about the program and apply today.\\nThis post is part of a series covering the underlying architecture and prototyping examples with a popular distributed search engine, Elasticsearch. In this post, we’ll be discussing the underlying storage model and how CRUD (create, read, update and delete) operations work in Elasticsearch.\\nElasticsearch is a very popular distributed search engine used at many comp...   \n",
       "15   Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...   \n",
       "16   IoT & Data Science\\nFeb 15, 2019\\nThe article tackles smart data processing of the Internet of Things (IoT) in a predictive maintenance context and relates this to recent developments in semi-supervised learning. While written with an eye towards a non-expert audience, the article references recent scientific publications. We leave it to the curious and technically oriented reader to expand their knowledge on the ideas we have sketched out (see References). We aim to be informative and open minds to stimulating discussions on IoT and data analytics.\\nWe cover the topic of IoT Learning Algorithms and Predictive Maintenance in a series of three articles. In PART I, we present a simple case study in detail and discuss some learning algorithms related to it. In PART II, we focus on IoT dat...   \n",
       "17   Jan 10, 2018\\nI have started doing Andrew Ng’s popular machine learning course on Coursera. The first week covers a lot, at least for someone who hasn’t touched much calculus for a few years\\nThese three topics were a lot to take in. I’ll talk about each in detail, and how they all fit together, with some python code to demonstrate.\\nEdit May 4th: I published a follow up focusing on how the Cost Function works here, including an intuition, how to calculate it by hand and two different Python implementations. I can do gradient descent and then bring them together for linear regression soon.\\nFirst, the goal of most machine learning algorithms is to construct a model: a hypothesis that can be used to estimate Y based on X. The hypothesis, or model, maps inputs to outputs. So, for example...   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law & Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "19   Analytics Vidhya\\nJul 22, 2019\\nI am fascinated by self-driving cars. The sheer complexity and mix of different computer vision techniques that go into building a self-driving car system is a dream for a data scientist like me.\\nSo, I set about trying to understand the computer vision technique behind how a self-driving car potentially detects objects. A simple object detection framework might not work because it simply detects an object and draws a fixed shape around it.\\nThat’s a risky proposition in a real-world scenario. Imagine if there’s a sharp turn in the road ahead and our system draws a rectangular box around the road. The car might not be able to understand whether to turn or go straight. That’s a potential disaster!\\nInstead, we need a technique that can detect the exact sh...   \n",
       "20   Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...   \n",
       "21   Passion for Data Science\\nApr 1, 2018\\nThe credit score is a numeric expression measuring people’s creditworthiness. The banking usually utilizes it as a method to support the decision-making about credit applications. In this blog, I will talk about how to develop a standard scorecard with Python (Pandas, Sklearn), which is the most popular and simplest form for credit scoring, to measure the creditworthiness of the customers.\\nNowadays, creditworthiness is very important for everyone since it is regarded as an indicator for how dependable an individual is. In various situations, service suppliers need to evaluate customers’ credit history first, and then decide whether they will provide the service or not. However, it is time-consuming to check the entire personal portfolios and gene...   \n",
       "22   Jun 6, 2016\\nIf you’re looking for a way to use Gensim to setup a doc2vec model, I found the following works rather well for my use case.\\nfrom gensim.models.doc2vec import LabeledSentence\\nfrom os import listdir\\nfrom os.path import isfile, join\\nimport gensim\\nimport DocIterator as DocIt\\ndocLabels = []\\ndocLabels = [f for f in listdir(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu”) if f.endswith(‘.txt’)]\\ndata = []\\nfor doc in docLabels:\\nwith open(“/Users/justin/DeepLearning/suck/GBP_USD/train/neu/” + doc, ‘r’) as f:\\ndata.append(f.read())\\nit = DocIt.DocIterator(data, docLabels)\\nmodel = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=3,alpha=0.04, min_alpha=0.005) # use fixed learning rate\\nmodel.build_vocab(it)\\nfor epoch in range(100):\\nprint(“Epoch “ + str...   \n",
       "23   Towards Data Science\\nDec 2, 2020\\nIn the previous chapter we built a dataloader that picks up our images and performs some transformations and augmentations so that they can be fed in batches to a neural network like the U-Net. In this part, we focus on building a U-Net from scratch with the PyTorch library. The goal is to implement the U-Net in such a way, that important model configurations such as the activation function or the depth can be passed as arguments when creating the model.\\nThe U-Net is a convolutional neural network architecture that is designed for fast and precise segmentation of images. It has performed extremely well in several challenges and to this day, it is one of the most popular end-to-end architectures in the field of semantic segmentation.\\nWe can split the...   \n",
       "24   TechnologyMadeEasy\\nJul 28, 2016\\nCNNs have wide applications in image and video recognition, recommender systems and natural language processing. In this article, the example that I will take is related to Computer Vision. However, the basic concept remains the same and can be applied to any other use-case!\\nFor a quick recap of Neural Networks, here’s a very clearly explained article series.\\nCNNs, like neural networks, are made up of neurons with learnable weights and biases. Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output. The whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs. Pretty straightforward, right?\\nSo, how are Convol...   \n",
       "25   Nov 18, 2018\\nKey takeaways — O’reilly AI London Conference, Oct 9–11, 2018\\nI had an opportunity to attend the O’reilly AI London Conference, Oct 9–11, 2018. Given our short attention span these days, let me try a more clickbait style approach for the takeaways :)\\nKey takeaways\\n1. AI Gurus are the new rock stars and there was never a better time to be in this field. There continues to be tremendous interest in Enterprise AI. This was the first...\\n1 \\n1 \\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Patents https://www.linkedinin/debmalya-biswas-397526\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n125 Followers\\nAI/ML, Privacy and Open Source | Principal Analytics Architect — CTS | x-Nokia, SAP, Oracle | 50+ Pat...   \n",
       "26   Towards Data Science\\nOct 4, 2018\\nIn the previous post, we discussed various steps of text processing involved in Nature Language Processing (NLP) and also implemented a basic Sentiment Analyzer using some of the classical ML techniques.\\nDeep learning has demonstrated superior performance on a wide variety of tasks including NLP, Computer Vision, and Games. To explore further, we will discuss and use some of the advanced NLP techniques, based on Deep Learning, to create an improved Sentiment Classifier.\\nSentiment classification is the task of looking at a piece of text and telling if someone likes or dislikes the thing they’re talking about.\\nThe input X is a piece of text and the output Y is the sentiment which we want to predict, such as the star rating of a movie review.\\nIf we c...   \n",
       "27   Towards Data Science\\nJul 31, 2019\\nThis is the fourth part in the series on Computer vision journey. In this article we will explore Mask R-CNN to understand how instance segmentation works with Mask R-CNN and then predict the segmentation for an image with Mask R-CNN using Keras\\nPart 1- CNN, R-CNN, Fast R-CNN, Faster R-CNN\\nPart 2 — Understanding YOLO, YOLOv2, YOLO v3\\nPart 3- Object Detection with YOLOv3 using Keras\\nWhat is instance segmentation and how is different from semantic segmentation?\\nSemantic Segmentation detects all the objects present in an image at the pixel level. Outputs regions with different classes or objects\\nSemantic segmentation groups pixels in a semantically meaningful way. Pixels belonging to a person, road, building, fence, bicycle, cars or trees are grou...   \n",
       "28   Jan 19, 2013\\nKaggle announced the Traveling santa problem in the christmas season. I joined in excitedly.. but soon realized this is not an easy problem. Solving this problem would require expertise on data structures and some good familiarity with TSP problems and its many heuristic algorithms. I had neither.. I had to find a way to deal with this problem. I compenseted my lack of algorithmic expertise with common sense, logic and intuition. I finished 65th out of 356 total competitors.\\nI did some research on packaged TSP solvers and top TSP algorithms. I found concorde but I could not get it to work on my ubuntu machine. So I settled with LKH which uses Lin-Kernighan heuristic for solving TSP and related problems. I wrote scripts for file conversions and for running LKH.\\nLKH easil...   \n",
       "29   SlideMagic\\nSep 1, 2011\\nThe quarter is done, and here comes the day-long sales results presentation. Excel is pasted into PowerPoint, creating huge decks through which senior management has to sit through. Sales organizes by channel: small restaurants sales, growth; large restaurants sales, growth, supermarkets sales, growth. Marketing presents by brands: brand 1 sales, growth, brand 2 sales, growth.If you are a marketing manager, looking at the Q3 sales and growth figures of a particular brand is really interesting. All the numbers of the previous quarters are more or less in your head. For the production manager though, going through these pages is mental torture, as she does not have the historical context readily available. (Read more about the Curse of Knowledge here)The solution...   \n",
       "30   The Owl\\nMar 20, 2020\\nwith a little help from sklearn\\nMachine Learning models often fails to generalize well on data it has not been trained on. Sometimes, it fails miserably, sometimes it gives somewhat better than miserable performance. To be sure that the model can perform well on unseen data, we use a re-sampling technique, called Cross-Validation.\\nWe often follow a simple approach of splitting the data into 3 parts, namely, Train, Validation and Test sets. But this technique does not generally work well for cases when we don’t have a large datasets. When we have limited data, dividing the dataset into Train and Validation sets may casue some data points with useful information to be excluded from the training procedure, and the model fails to learn the data distrubution properl...   \n",
       "31   Aug 8, 2016\\nFor this blog post, we decided to jump on the PokémonGO hype and add a bit of science into the craze. Our goal is to give you the optimal portfolio of Pokémon to train, so you can be as effective as possible against a wide variety of opponents. As each Pokémon has its strengths and weaknesses, we created clusters of Pokémon with similar characteristics and looked at the few selected ones allowing the player to compete against as many different enemies as possible.\\nWe used the Pokémon API fan service available on the internet to find all the information about the little creatures.\\nThe data we used consists of:\\nThe data is available for 811 Pokémon. Although we have done the analysis for all the Pokémon, in this post, we focus only on the first 150 Pokémon as thos...   \n",
       "32   Towards Data Science\\nMar 16, 2021\\nOne of the most challenging tasks for machine learning models is finding the best way to to generate numeric representations for words so the model can use that information in its calculations.\\nIn computer vision tasks, the red channel in a color (RGB) image will always refer to the red channel, and the green channel to the green channel. Text, however, is heavily based on context, such that the same word can take on multiple meanings depending on its use. Pandas, for example, can refer to cute and fuzzy bears or a Python data analysis library.\\nThis is further complicated when considering sentences and paragraphs. Consider the following:\\nPandas are cute and fuzzy. They don’t use Pandas data analysis library because they are bears.\\nNow I realize t...   \n",
       "33   Towards Data Science\\nJun 2, 2021\\nEditor’s note: This episode is part of our podcast series on emerging problems in data science and machine learning, hosted by Jeremie Harris. Apart from hosting the podcast, Jeremie helps run a data science mentorship startup called SharpestMinds.\\nWhen OpenAI announced the release of their GPT-3 API last year, the tech world was shocked. Here was a language model, trained only to perform a simple autocomplete task, which turned out to be capable of language translation, coding, essay writing, question answering and many other tasks that previously would each have required purpose-built systems.\\nWhat accounted for GPT-3’s ability to solve these problems? How did it beat state-of-the-art AIs that were purpose-built to solve tasks it was never explici...   \n",
       "34   Oct 17, 2016\\nИтак, вы решили подключить свой локальный пул геймобъектов, прочли документацию на сайте, нашли необходимые методы и решили , что сейчас все заработает. Возможно в вашем случае это действительно будет так, если вы до этого не регистрировали ни одного префаба для спаунинга по сети.\\nДело в том, что в Unity при спауне геймобъекта приватным методом ClientScene.OnObjectSpawn сначала проверяется наличие объекта в списке зарегистрированных (через инспектор компоненты NetworkManager или напрямую через добавление геймобъектов в словарь NetworkManager.spawnPrefabs), и только если необходимый геймобъект не найден, то идет в работу словарь хендлеров (делегатов SpawnDelegate) для спауна, в который и записывается ваш делегат с помощью методов ClientScene.RegisterSpawnHandl...   \n",
       "35   Feb 25, 2019\\nFor the last couple of weeks, I have been experimenting with mobilenet models for object detection on Android devices. Since I took a Deep learning course in the past semester, I knew that those mobilenet models could be trained for detecting other objects as well. Moreover, available guides such as this object detection tutorial and this Android deployment tutorial rely on the older version of the Tensorflow framework — Tensorflow Mobile, which is being deprecated as of February 2019. Instead, Tensorflow Lite will be the main framework for mobile devices in the future and Lite version has moved from the contribution stage to the core of Tensorflow.\\nAdditionally, there are recent articles that manually annotate images for training purposes. However, we will implement ope...   \n",
       "36   Towards Data Science\\nNov 13, 2018\\nA decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules. Below diagram illustrate the basic flow of decision tree for decision making with labels (Rain(Yes), No Rain(No)).\\nDecision tree is one of the predictive modelling approaches used in statistics, data mining and machine learning.\\nDecision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of ...   \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  OneZero\\nAug 6, 2019\\n1.1K \\n1.1K \\n12\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n1.2K Followers\\nAssociate Professor, Tech Law & Policy at the University of Western Australia. 2018 Poynter Fellow at Yale University.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "38   Towards Data Science\\nSep 30, 2018\\nIn this post I’d like to take some content from Introduction to Machine Learning with Python by Andreas C. Müller & Sarah Guido and briefly expand on one of the examples provided to showcase some of the strengths of DBSCAN clustering when k-means clustering doesn’t seem to handle the data shape well. I’m going to go right to the point, so I encourage you to read the full content of Chapter 3, starting on page 168 if you would like to expand on this topic. I’ll be quoting the book when describing the working of the algorithm.\\nThis is how k-means work in a visual representation:\\nOne issue with k-means clustering is that it assumes that all directions are equally important for each cluster. This is usually not a big problem, unless we come across wit...   \n",
       "39   Towards Data Science\\nJan 29, 2019\\nEver since the world of Machine Learning was introduced to non-linear functions that work recursively (i.e. Artificial Neural Networks), the applications of which boomed noticeably. In this context, proper training of a Neural Network is the most important aspect of making a reliable model. This training is usually associated with the term “Back-propagation”, which is highly vague to most people getting into Deep Learning. Heck, most people in the industry don’t even know how it works — they just know it does!\\nBack-propagation is the essence of neural net training. It is the practice of fine-tuning the weights of a neural net based on the error rate (i.e. loss) obtained in the previous epoch (i.e. iteration). Proper tuning of the weights ensures low...   \n",
       "40   Emergent // Future\\nJul 27, 2016\\nIssue 17 This week we review Elon Musk’s big plans for Tesla, how Google uses DeepMind to save millions of dollars, why Zuckerberg is building a fleet of internet drones, and check in on Moore’s Law death watch. Plus, projects to try at home, and our top reads from the past week.\\nNot a subscriber? Join the Emergent // Future newsletter here.\\nYou might have heard: Elon Musk outlined his masterplan for Tesla in blog post. For the past 10-years, Tesla’s vision had been to do:\\nNow, Musk is doubling-down on solar power, Tesla trucks, self-driving cars, and car-sharing — he wants your car to make you money when you aren’t using it. The company has already started developing electric and autonomous trucks and buses.\\ntl;dr “We’re not an electric car compan...   \n",
       "41   Towards Data Science\\nOct 23, 2018\\nThis article teaches you how to use transfer learning to solve image classification problems. A practical example using Keras and its pre-trained models is given for demonstration purposes.\\nDeep learning is fast becoming a key instrument in artificial intelligence applications (LeCun et al. 2015). For example, in areas such as computer vision, natural language processing, and speech recognition, deep learning has been producing remarkable results. Therefore, there is a growing interest in deep learning.\\nOne of the problems where deep learning excels is image classification (Rawat & Wang 2017). The goal in image classification is to classify a specific picture according to a set of possible categories. A classic example of image classification is th...   \n",
       "42   Oct 8, 2017\\nCode available here: https://github.com/michaelulin/pytorch-caffe2-aws-lambda\\nHaving worked with PyTorch, I love the flexibility and ease of development of the framework versus other platforms. As PyTorch is still early in its development, I was unable to find good resources on serving trained PyTorch models, so I’ve written up a method here that utilizes ONNX, Caffe2 and AWS Lambda to serve predictions from a trained PyTorch model. I hope that you find it to be useful.\\nHow to effectively deploy a trained PyTorch model\\nUsing ONNX, Facebook and Microsoft’s recently released platform for Neural Network interoperability, we can convert a model trained in PyTorch to Caffe2 and then serve predictions with that model from AWS Lambda.\\nONNX enables models trained in PyTorch to...   \n",
       "43   人機共生你我它\\nDec 20, 2018\\n「蟲苔已經撲到人家的臉上了!」 「快要滿人口啦!應該要開戰了喔,因為其實人口滿,你剛剛把人家斷炊,這邊是一個很好的時機點可以來壓制」\\n電競賽評每天在做的事就是分析許多專業玩家打game的過程,帶著觀眾理解這些專業玩家每一步背後的策略,仔細想想,這些賽評帶領觀眾理解專業玩家的方式,是不是也跟使用者透過一個解釋機制來理解黑盒子般的智慧系統類似?電競賽評是專家行為的詮釋者,從他們身上,能帶給我們什麼智慧代理系統設計的啟發?\\n來自美國Oregon State University的研究團隊發現了這個關聯,透過分析賽評們對於電競的即時評論,試圖了解:當解釋機制(賽評)在說明智慧系統運作(專業玩家動作)時,需要哪些線索來搞懂智慧系統的行為、對使用者說明時需要包含哪些資訊、以及要怎麼說出這些難懂的資訊才能幫助使用者搞懂智慧系統這個黑盒子。\\n在眾多線索中,哪些資訊才是賽評需要的呢?研究者分析賽評切換的畫面,發現遊戲賽評會不斷的蒐集玩家當下的表現、所處的環境、產能狀況或統計資料(例:擊殺比例)以及賽評不斷切換視角(例:畫面轉到不同地點、切換成不同玩家的視角)來幫助自己解釋這些玩家為什麼在此時此刻會做出特定的行為。透過分析賽評如何理解專業玩家,我們可以知道當設計解釋機制的時候,需要想辦法讓使用者需要知道系統已做、能做哪些事,就如同賽評會說出「蟲苔已經撲到人家的臉上了」或告訴觀眾「滿人口應該就可以開戰了」,藉由這些資訊來讓觀眾理解玩家做出特定行為的意圖。\\n除此之外,智慧系統的解釋機制也需要告訴使用者現在系統已經看到、聽到或取得哪些資訊,以自駕車來說,在操作面板上對駕駛顯示目前系統偵測到周圍環境哪些資訊、已經分別執行過哪些步驟,幫助駕駛理解系統做決策的過程;或是讓使用者知道智慧系統做了哪些事、能做哪些事,例如透過系統協助保安人員判斷某位...   \n",
       "44   Data Science Group, IITR\\nSep 4, 2017\\nWe all have used apps like Prisma and Lucid, but ever wondered how these things works? Like we give a photo from our camera roll and select a design to mix both the images and we get a new image which has the content of our input image and style of the design image. In the world of deep learning this is called style transfer.\\nStyle transfer is the technique of recomposing images in the style of other images. It all started when Gatys et al. published an awesome paper on how it was actually possible to transfer artistic style from one painting to another picture using convolutional neural networks..\\nHere are some examples :\\n“Neural networks are everywhere. I do not expect that they will take away the bread of artists and designers, but it took m...   \n",
       "45   ML Review\\nJun 7, 2017\\nThe article is about Manhattan LSTM (MaLSTM) — a Siamese deep network and its appliance to Kaggle’s Quora Pairs competition.I will do my best to explain the network and go through the Keras code (if you are only here for the code, scroll down :)Full code on Github\\nIn the past few years, deep learning is all the fuss in the tech industry.To keep up on things I like to get my hands dirty implementing interesting network architectures I come across in article readings.\\nFew months ago I came across a very nice article called Siamese Recurrent Architectures for Learning Sentence Similarity.It offers a pretty straightforward approach to the common problem of sentence similarity.Named MaLSTM (“Ma” for Manhattan distance), its architecture is depicted in figure 1 (dia...   \n",
       "46   Towards Data Science\\nJan 24, 2019\\nBefore building any Deep Learning model in Natural Language Processing (NLP), text embedding plays a major role. The text embedding converts text (words or sentences) into a numerical vector.\\nWhy do we convert texts into vectors?\\nA vector is an array of numbers of a particular dimension. A vector of size 5×1 contain 5 numbers and we can think of it as a point in 5D space. If there are two vectors each of dimension 5, they can be thought of two points in a 5D space. Thus we can calculate how close or distant those two vectors are, depending on the distance measure between them.\\nHence, lots of efforts in machine learning research are bring put to converting data into a vector as once data is converted into a vector, we can say two data points are si...   \n",
       "47   Towards Data Science\\nNov 13, 2017\\nBidirectional recurrent neural networks(RNN) are really just putting two independent RNNs together. The input sequence is fed in normal time order for one network, and in reverse time order for another. The outputs of the two networks are usually concatenated at each time step, though there are other options, e.g. summation.\\nThis structure allows the networks to have both backward and forward information about the sequence at every time step. The concept seems easy enough. But when it comes to actually implementing a neural network which utilizes bidirectional structure, confusion arises...\\nThe first confusion is about the way to forward the outputs of a bidirectional RNN to a dense neural network. For normal RNNs we could just forward the outputs ...   \n",
       "48   Jul 24, 2020\\nUsing the neural-net tool Artbreeder, Photoshop and historical references, I have created photoreal depictions of Roman Emperors. Scroll down to see each emperor.\\nON CREATIVE COMMONS & COPYRIGHT: Faces can be shared non-watermarked at 200 pixels max height OR 512 pixels with the digital mosaic watermark with Attribution-NonCommercial-ShareAlike. Please link back to this page. Continuation of this project depends on prints, licensing and commissions.\\n*CONCISE UPDATE (July 31st) replacing a July 27th CLARIFICATION: ‘TheApricity’, a tertiary source, has been removed entirely. I knew it to be unreliable prior to starting this project but kept here for posterity and debate. It is now clear to me they have distorted primary and secondary sources to push a pernicious white sup...   \n",
       "49   Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...   \n",
       "50   Towards Data Science\\nFeb 21, 2019\\nLogistic Regression is a popular statistical model used for binary classification, that is for predictions of the type this or that, yes or no, A or B, etc. Logistic regression can, however, be used for multiclass classification, but here we will focus on its simplest application.\\nAs an example, consider the task of predicting someone’s gender (Male/Female) based on their Weight and Height.\\nFor this, we will train a machine learning model from a data set of 10,000 samples of people’s weight and height. The data set is taken from the Conway & Myles Machine Learning for Hackers book, Chapter 2, and can it can be directly downloaded here.\\nThis is a preview of what the data looks like:\\nEach sample contains three columns: Height, Weight, and Male.\\nTh...   \n",
       "51   Aug 27, 2019\\nIt was announced by FAIR (facebook artificial intelligence research) last year that the Mask RCNN structure using the resnet50 infrastructure was successfully implemented on MS COCO and Balloon datasets and valuable resuts were obtained (see dedicated github page). In addition, the trained weights were also released for researchers and practitionars to make transfer learning to solve different problems with reasonable cost(see matterport github page).\\nIn my another article I have explaineed how to make transfer learning with such released MS COCO weights to deletect an locate weapons (see article here)\\nAt the end of this reading this article, you will see succesful object recognition and segmentation in video and images taken randomly from the outerside of the world.\\nI...   \n",
       "52   Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...   \n",
       "53   Nov 10, 2016\\nDear reader,\\nThis article has been republished at Educaora and has also been open sourced. Unfortunately TensorFlow 2.0 changed the API so it is broken for later versions. Any help to make the tutorials up to date are greatly appreciated. I also recommend you looking into PyTorch.\\nIn this tutorial I’ll explain how to build a simple working Recurrent Neural Network in TensorFlow. This is the first in a series of seven parts where various aspects and techniques of building Recurrent Neural Networks in TensorFlow are covered. A short introduction to TensorFlow is available here. For now, let’s get started with the RNN!\\nIt is short for “Recurrent Neural Network”, and is basically a neural network that can be used when your data is treated as a sequence, where the particula...   \n",
       "54   Towards Data Science\\nApr 12, 2020\\nNatural language processing (NLP) is a key component in many data science systems that must understand or reason about a text. Common use cases include text classification, question answering, paraphrasing or summarising, sentiment analysis, natural language BI, language modeling, and disambiguation.\\nNLP is essential in a growing number of AI applications. Extracting accurate information from free text is a must if you are building a chatbot, searching through a patent database, matching patients to clinical trials, grading customer service or sales calls, extracting facts from financial reports or solving for any of these 44 use cases across 17 industries.\\nText classification is one of the main tasks in modern NLP and it is the task of assigning a...   \n",
       "55   Jun 11, 2017\\nIn the last post I’ve applied DBScan to remove noises from a trajectory. However, to achieve an acceptable result from original trajectory I tried several parameters before end up witth:\\nUsually data analysis cannot afford such strategy since it would take too long to clean up big amount of data if every trajectory demands a human evaluation. The good news is that this process can be automated. Actually, the original DBScan paper from Ester et al. brings a section about determining the parameters Eps and MinPts using a heuristic approach.\\nThe basic idea is process data evaluating the k-th nearest neighbor of each point and sort them descending. Usually the result will point out a threshold value where clusters will appear on the right side of the chart while noises will...   \n",
       "56   Jun 28, 2020\\nTikTok is an application which has been used for talking materials between teens and startups for years now. Most of time we only see how it creates from a new emerging industry instead of investigating what makes the customer retention high as 39%.\\nTikTok’s Chinese version, Douyin, published a new filter in its app this week. Within 3 days, they gathered millions of posts which used this filter. The filter names as “Anime Change”. The main character is to change the video into animation.\\nIt’s not a new one to be honest, many applications have launched a similar filter before, such as B612. But the difference here is to change a video and to make the result acceptable.\\nThe technology used behind is one called Generative Adversarial Networks, AKA GAN. GAN is used for ge...   \n",
       "57   Towards Data Science\\nJul 26, 2021\\nNot only computational but also experimental biology. Thoughts on the future of data science niches in biology.\\nIn a recent story I covered the release of the academic paper describing AlphaFold’s version 2 and its source code, and I showed you how scientists around the world were starting to apply the program to their favorite proteins through Google Colab notebooks, for free and without any hardware needs. These notebooks are rapidly evolving to enable more features, allowing anybody to model not only isolated proteins but also complexes of multiple proteins, and including known structures of related proteins and multiple sequence alignments to improve the program’s results. Moreover, Deepmind and the European Bioinformatics Institute started to u...   \n",
       "58   Jun 27, 2018\\nAn app that removes and replaces in real-time the background in webcam video streams, and all from within the browser! No need for a green screen or a uniform background. This project was made during my 4 weeks at the AI Program of Insight Data Science (Palo Alto).\\nTry it here!\\nThere is a trend in AI to move from Centralized Cloud Computing to Edge Computing [1], in particular for real time services application for which Centralized Cloud Computing suffers from higher latency. Furthermore, Edge Computing AI might provide solutions for privacy conscientious consumers [2]. One tool that is likely to help this trend is TensorflowJS (TFJS), in brief Tensorflow in Javascript wrapper. TFJS enables to create AI apps, which training and prediction can be conducted on the client...   \n",
       "59   The Startup\\nJun 5, 2018\\nOh, how the headlines blared:\\n“...the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\\nAnd why wouldn’t they be? All the road signs pointed towards insane success.\\nMessaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!\\nPlus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.\\nAt the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptan...   \n",
       "60   Towards Data Science\\nJul 31, 2017\\nQuick Recap\\nLast time in our Keras/OpenAI tutorial, we discussed a very fundamental algorithm in reinforcement learning: the DQN. The Deep Q-Network is actually a fairly new advent that arrived on the seen only a couple years back, so it is quite incredible if you were able to understand and implement this algorithm having just gotten a start in the field. As with the original post, let’s take a quick moment to appreciate how incredible results we achieved are: in a continuous output space scenario and starting with absolutely no knowledge on what “winning” entails, we were able to explore our environment and “complete” the trials.\\nPut yourself in the situation of this simulation. This would essentially be like asking you to play a game, without a ...   \n",
       "61   Towards Data Science\\nJan 20, 2019\\nIn this project, we will develop and evaluate the performance and the predictive power of a model trained and tested on data collected from houses in Boston’s suburbs.\\nOnce we get a good fit, we will use this model to predict the monetary value of a house located at the Boston’s area.\\nA model like this would be very valuable for a real state agent who could make use of the information provided in a dayly basis.\\nYou can find the complete project, documentation and dataset on my GitHub page:\\nhttps://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/tree/master/projects/boston_housing\\nThe dataset used in this project comes from the UCI Machine Learning Repository. This data was collected in 1978 and each of the 506 entries represent...   \n",
       "62   Towards Data Science\\nDec 19, 2020\\nAll types of neural networks and many machine learning algorithms optimize their loss functions using gradient-based optimization algorithms. There are several such optimization algorithms, or optimizers, that exist and are used to train models - RMSprop, Stochastic Gradient Descent(SGD), Adaptive Moment Estimation(Adam) and so many more.\\nThere are two primary metrics to look at while determining the efficacy of an optimizer:\\nAdaptive algorithms like Adam have a good convergence speed, while algorithms like SGD generalize better.\\nBut recently researchers from Yale introduced a novel AdaBelief optimizer (AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients) that combines many benefits of existing optimization methods:\\nWe pro...   \n",
       "63   Towards Data Science\\nJul 6, 2021\\nMany of my articles have been focused on BERT — the model that came and dominated the world of natural language processing (NLP) and marked a new age for language models.\\nFor those of you that may not have used transformers models (eg what BERT is) before, the process looks a little like this:\\nNow, this is a great approach, but if we only ever do this, we lack the understanding behind creating our own transformers models.\\nAnd, if we cannot create our own transformer models — we must rely on there being a pre-trained model that fits our problem, this is not always the case:\\nSo in this article, we will explore the steps we must take to build our own transformer model — specifically a further developed version of BERT, called RoBERTa.\\nThere are a fe...   \n",
       "64   Towards Data Science\\nNov 17, 2018\\nFrauds in the finance field are very rare to be identified. Because of that, it can do a severe damage to the financial field. It is estimated that fraud costs at least $80 billion a year across all lines of insurance. If there is a small possibility of detecting fraudulent activities, that can do a major impact on annual losses. That is why financial companies invest in machine learning as a preemptive approach to tackling fraud.\\nThe benefits of using a machine learning approach are that,\\nThe best way to detect frauds is anomaly detection.\\nAnomaly detection is a technique to identify unusual patterns that do not conform to the expected behaviors, called outliers. It has many applications in business from fraud detection in credit card transaction...   \n",
       "65   Towards Data Science\\nSep 21, 2021\\nWhat sets artificial neural networks apart from other machine learning algorithms is how they can efficiently deal with big data and how they assume very little about your dataset.\\nYour neural network doesn’t care if your classification data isn’t linearly separable via a kernel or if the trend followed by your regression data is a roller coaster. As long that your dataset is some continuous mapping from one finite space (x) to another (y) then you can approximate that mapping to any degree of accuracy depending on your architecture. This follows from them being universal approximators as proven by the Universal Approximation Theory. The point is that back, when neural networks first showed up in the 40s, there was no fast way to make use of this as...   \n",
       "66   Heartbeat\\nMay 17, 2018\\nMany deep learning frameworks have been released over the past few years. Among them, PyTorch from Facebook AI Research is very unique and has gained widespread adoption because of its elegance, flexibility, speed, and simplicity. Most deep learning frameworks have either been too specific to application development without sufficient support for research, or too specific for research without sufficient support for application development.\\nHowever, PyTorch blurs the line between the two by providing an API that’s very friendly to application developers while at the same time providing functionalities to easily define custom layers and fully control the training process, including gradient propagation. This makes it a great fit for both developers and researche...   \n",
       "67   Clairvoyant Blog\\nMay 7, 2021\\n“If Music is a Place — then Jazz is the City, Folk is the Wilderness, Rock is the Road, Classical is a Temple.” — Vera Nazarin\\nWe’ve all used some music streaming app to listen to music. But what is the app's logic for creating a personalized playlist for us?\\nOne general example of logic is by having a Music Genre Classification System.\\nMusic genre classification forms a basic step for building a strong recommendation system.\\nThe idea behind this project is to see how to handle sound files in python, compute sound and audio features from them, run Machine Learning Algorithms on them, and see the results.\\nIn a more systematic way, the main aim is to create a machine learning model, which classifies music samples into different genres. It aims to predi...   \n",
       "68                                                                                                                                                                                                                                                      HuggingFace\\nJan 27, 2019\\nThe past year has ushered in an exciting age for Natural Language Processing using deep neural networks. Research in the field of using pre-trained models have resulted in massive leap in state-of-the-art results for many of the NLP tasks, such as text classification, natural language inference and question-answering.\\n3.3K \\n3.3K \\n30\\nStories @ Hugging Face\\n1K Followers\\nChief Architect & Technologist, AI & Machine Learning, Co-founder at utterworks\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "69   Aug 17, 2016\\nThere was news recently in bloomberg about how google was able to cut electricity usage in its datacenter by using an AI scheme made by DeepMind (of AlphaGo fame). Earlier this week, i decided to make a quick-and-dirty implemetation in python and share it here for anyone interested in a practical example of what exactly they did. First lets take a quick look at why one would want to make such a thing...\\nDatacenters (and indeed any other large scale structures that use a lot of energy) need to be carefully optimized for efficiency as even a 10% - 15% saving on the electricity bill can add up to millions of dollars a year. The biggest challenge here is that even though there are certain simple steps that anyone can take to reduce energy use (don’t use a very low server roo...   \n",
       "70   Acuity Derivatives\\nAug 1, 2014\\nInventory Aging is a rather innocuous looking member of the band of (now) seven metrics that, under the Volcker rule, banking entities with significant trading assets and liabilities are required to calculate daily and report monthly.\\nAs written, the metric description seems straightforward enough:\\nInventory Aging generally describes a schedule of the trading desk’s aggregate assets and liabilities and the amount of time that those assets and liabilities have been held. [It] should measure the age profile of the trading desk’s assets and liabilities and must include two schedules, an asset- aging schedule and a liability-aging schedule.\\nThe graphic below broadly outlines the processes of asset/liability tagging, matching, sorting and netting of trade...   \n",
       "71   Towards Data Science\\nSep 7, 2019\\nIn this post we discuss working of Gaussian process. Gaussian process fall under kernel methods, and are model free. Gaussian process are specially useful for low data regimen to “learn” complex functions. We shall review a very practical real world application (not related to deep learning or neural networks). The discussion follows from the talks of subject matter experts Prof Neil Lawrence and Prof Richard Tuner.\\nBackground reading:\\nMultivariate gaussian distribution: A Gaussian distribution can be specified using a mean (u), variance (σ2) and probability distribution function (PDF) as shown below\\nIf we have more than one independent gaussian distribution we can combine them. The combined PDF is also Gaussian i.e. a multivariate Gaussian. E.g. o...   \n",
       "72   Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is <=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...   \n",
       "73   Towards Data Science\\nJul 27, 2019\\nLinear regression is an approach to model the relationship between a single dependent variable (target variable) and one (simple regression) or more (multiple regression) independent variables. The linear regression model assumes a linear relationship between the input and output variables. If this relationship is present, we can estimate the coefficients required by the model to make predictions on new data.\\nIn this article, you will learn how to visualize and implement the linear regression algorithm from scratch in Python using multiple libraries such as Pandas, Numpy, Scikit-Learn, and Scipy. Additionally, we will measure the direction and strength of the linear relationship between two variables using the Pearson correlation coefficient as well...   \n",
       "74                  The Startup\\nFeb 2, 2021\\nOne of the great things about NER is trying to find those critters! I recently completed a project where one of the pre-requisites was to identify a location from large text fields containing randomly entered data.\\nOf course if there’s no control during the input of data then chaos reigns but we are where we are and if someone wants to put their homemade recipe for lasagne in an address field then hey it’s going to get messy but we’ll keep the lecture notes on data entry for another time and place.\\n34 \\n34 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n15 Followers\\nRandom ramblings from a sedate stroller.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "75   Towards Data Science\\nSep 29, 2021\\nWord Embeddings is the most fundamental concept in Deep Natural Language Processing. And word2vec is one of the earliest algorithms used to train word embeddings.\\nIn this post, I want to go deeper into the first paper on word2vec — Efficient Estimation of Word Representations in Vector Space (2013), which as of now has 24k citations, and this number is still growing.\\nOur plan is the following:\\nI am attaching my Github project with word2vec training. We will go through it in this post.\\nToday we are reviewing only the first paper on word2vec. However, there are several later papers, describing the evolution of word2vec:\\nI believe, if you understand the first paper, you’ll easily catch the ideas described in later papers. So let’s go!\\nDisclosure. ...   \n",
       "76            Analytics Vidhya\\nAug 1, 2021\\nGenerative models(GAN) have always been the niche and hard-to-master domain of the Deep learning space. Control over distinct features of output image has been a challenging research topic. StyleGAN is an approach that addresses this aspect. It distances itself from the conventional architectures of GAN and introduces a novel approach to generate high-resolution synthetic images along with a fair control over the distinct features...\\n5 \\n5 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n10 Followers\\nAI Enthusiast; M.Sc., University of Stuttgart, Mercedes-Benz AG\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "77   Jan 21, 2020\\nCSS Box Model and Positioning\\nVGG Virtual Internship Assignment.\\nThe CSS box model is crucial and fundamental to understand as far as layout and positioning are concerned in styling of a web page. This is so because every element in HTML generate a box around it and these boxes have properties that can be illustrated using what is popularly know as the CSS Box Model. You can view the box model from the developer tool by simply right clicking on an element on the web page then click on “inspect”.\\nOnce you are in the developer tools menu, ensure the “Elements” tab and “Styles” tab are selected (might be slightly different for other browsers). Then scroll down, you will see the box model for the element you are inspecting as shown below.\\nFrom the image above, we can see ...   \n",
       "78   Towards Data Science\\nAug 28, 2020\\nThe amount of textual data being produced every day is increasing rapidly both in terms of complexity as well as volume. Social Media, News articles, emails, text messages (the list goes on..), generate massive information and it becomes cumbersome to go through lengthy text materials (and boring too!). Thankfully with the advancements in Deep Learning, we can build models to shorten long pieces of text and produce a crisp and coherent summary to save time and understand the key points effectively.\\nWe can broadly classify text summarization into two types:\\n1. Extractive Summarization: This technique involves the extraction of important words/phrases from the input sentence. The underlying idea is to create a summary by selecting the most important ...   \n",
       "79   Towards Data Science\\nJan 3, 2018\\nIn this post I’ll explain what the maximum likelihood method for parameter estimation is and go through a simple example to demonstrate the method. Some of the content requires knowledge of fundamental probability concepts such as the definition of joint probability and independence of events. I’ve written a blog post with these prerequisites so feel free to read this if you think you need a refresher.\\nOften in machine learning we use a model to describe the process that results in the data that are observed. For example, we may use a random forest model to classify whether customers may cancel a subscription from a service (known as churn modelling) or we may use a linear model to predict the revenue that will be generated for a company depending on...   \n",
       "80   Oct 29, 2019\\nK-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity. The results of the K-means clustering algorithm are:\\nRather than defining groups before looking at the data, clustering allows you to find and analyze the groups that have formed organically. The “Choosing K” section below describes how the number of groups can be determined.\\nThis story covers:\\nThe algorithm can be used to confirm business ...   \n",
       "81   Towards Data Science\\nJun 29, 2020\\nRecurrent neural networks like plain RNN or more advanced models like LSTM and GRU used to be the goto models for deep-learning practitioners venturing into the time series domain. NLP, providing an abundance of sequence data, provided a willing subject. But transformer architectures like BERT and GPT have definitely taken over in the domain. Apart from these transformer architectures, CNN’s have also made a come-back or advance in the time-series domain. Are CNN’s good at modelling time-series?\\nHow good are CNN’s at modelling time-series?\\nTo answer this question tthis post replicates an article called “ECG Heartbeat Classification: A Deep Transferable Representation” [1] that applies ResNet, a CNN based architecture, to electrocardiogram (ECG) dat...   \n",
       "82   Jul 2, 2019\\nHow to understand U-Net in the most simple way.\\nHello everyone!\\nIn this article I want to explain in simple way the one of the most popular models structures to solve image segmentation task — UNET.\\nIf you haven’t heard about it and haven’t seen its architecture, it’s not a problem, because in this article I will start with a simple structure and at the end will be traditional UNET. Let’s start.\\nUNET model was created for medicine purpose to find tumors in lungs or brain, but nowadays it has got much wider usage field.\\nFor example your task is to find rectangles on images, no matter what color or shape they are.\\nWe have a red one and yellow one rectangles on a green background. This is an input for UNET model.\\nWe need to define positive regions on the image where we...   \n",
       "83   Backstage\\nDec 9, 2012\\nIts now been quite some time for Goibibo in business, which means that there is a huge amount of data that we have generated over this period. As a part of converting this data to information, we present to you our new initiative — Goibibo Insights.\\nAs the name suggests,Insights aims to give you interesting trends across the travel industry as seen by the large data we crunch at Goibibo. We believe this will further assist you in fine-tuning your travel plans. After all, this is your data — we have simply organised it and given it back.\\nRead on for the first series of insights with the info-graphics.\\nInsights are publicly shared on our Group portal (IbiboGroup) and also with the press.\\nOriginally published at goibibo.github.io on December 9, 2012.\\nBehind th...   \n",
       "84   ML Review\\nMar 13, 2016\\nI just want to reiterate what’s said here:\\ncolah.github.io\\nI’m not better at explaining LSTM, I want to write this down as a way to remember it myself. I think the above blog post written by Christopher Olah is the best LSTM material you would find. Please visit the original link if you want to learn LSTM. (But I did create some nice diagrams.)\\nAlthough we don’t know how brain functions yet, we have the feeling that it must have a logic unit and a memory unit. We make decisions by reasoning and by experience. So do computers, we have the logic units, CPUs and GPUs and we also have memories.\\nBut when you look at a neural network, it functions like a black box. You feed in some inputs from one side, you receive some outputs from the other side. The decision i...   \n",
       "85   Nov 27, 2019\\nObject detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.\\nThis post contains the details of Fast R-CNN and Faster R-CNN, which are the incremental improvements of R-CNN( aka “slow R-CNN”).\\nFast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks.\\nThe main contribution of Fast-R-CNN is the RoI pooling followed by a two-headed fully connected network.\\nAn input image is passed through CNN(set of convolutional and maxpooling layers)....   \n",
       "86                                                                                                                          SyncedReview\\nDec 14, 2018\\nLook at the two pictures below. Can you tell which is a photograph and which was generated by AI?\\nThe truth is... wait for for it... both images are AI-generated fakes, products of American GPU producer NVIDIA’s new...\\n632 \\n632 \\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology & Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "87   Analytics Vidhya\\nFeb 22, 2020\\nFeature Engineering is a technique to convert raw data columns to something meaningful which can help in predicting the outcomes in a machine learning task. Feature Engineering can be a very tedious and often the most time taking in machine learning life cycle.\\nBut to our rescue comes some of the cool tools which automates the whole feature engineering process and creates a large pool of features in a very short span for both classification and regression tasks.\\nWe have found following tools which automates the whole feature engineering process and creates large number of features for both relation and non-relational data. While some of them only performs feature engineering, we have some tools which also perform feature selection. Many a times these t...   \n",
       "88   Towards Data Science\\nAug 5, 2020\\nNatural Language Processing has made huge advancements in the last years. Currently, various implementations of neural networks are cutting edge and it seems that everybody talks about them. But, sometimes a simpler solution might be preferable. After all, one should try to walk before running. In this short article, I am going to demonstrate a simple method for clustering documents with Python. All code is available at GitHub (please note that it might be better to view the code in nbviewer).\\nWe are going to cluster Wikipedia articles using k-means algorithm. The steps for doing that are the following:\\n2. represent each article as a vector,\\n3. perform k-means clustering,\\n4. evaluate the result.\\nUsing the wikipedia package it is very easy to down...   \n",
       "89   Oct 7, 2016\\nIt’s a great time to work as an android developer, as Millions of android devices activated every day a huge demand for android developers is required.\\nBegging as an android developer can be extremely challenging too, so in this post, I will try to elaborate all the basic requirements and skills anyone needs to land a job as an android developer without the need of a degree or experience.\\nSo below is a list of all generalized requirements based on my little experience as an android developer and my researching for junior-level positions , the requirements will always vary from company to another and you will hardly find any two job descriptions exactly the same but these requirements will be good to start with.\\nYou might consider that this a lot of things but you can bu...   \n",
       "90   Towards Data Science\\nAug 15, 2018\\nThis article introduces the basics of machine learning theory, laying down the common concepts and techniques involved. This post is intended for the people starting with machine learning, making it easy to follow the core concepts and get comfortable with machine learning basics.\\nIn 1959, Arthur Samuel, a computer scientist who pioneered the study of artificial intelligence, described machine learning as “the study that gives computers the ability to learn without being explicitly programmed.”\\nAlan Turing’s seminal paper (Turing, 1950) introduced a benchmark standard for demonstrating machine intelligence, such that a machine has to be intelligent and responsive in a manner that cannot be differentiated from that of a human being.\\nMachine Learnin...   \n",
       "91   Towards Data Science\\nSep 6, 2017\\nIt’s just a thing function that you use to get the output of node. It is also known as Transfer Function.\\nIt is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\\nThe Activation Functions can be basically divided into 2 types-\\nFYI: The Cheat sheet is given below.\\nAs you can see the function is a line or linear. Therefore, the output of the functions will not be confined between any range.\\nEquation : f(x) = x\\nRange : (-infinity to infinity)\\nIt doesn’t help with the complexity or various parameters of usual data that is fed to the neural networks.\\nThe Nonlinear Activation Functions are the most used activation functions. Nonlinearity helps t...   \n",
       "92   DeepQuestAI\\nAug 1, 2019\\nStep-by-step tutorial on training object detection models on your custom dataset\\nObject detection is one of the most profound aspects of computer vision as it allows you to locate, identify, count and track any object-of-interest in images and videos. Object detection is used extensively in many interesting areas of work and study such as:\\nA number of pre-collected object detection datasets such as Pascal VOC, Microsoft’s COCO, Google’s Open Images are readily available along with their pre-trained models for detection and identifying only a fix set of items.\\nHowever, the challenge with using these public datasets and pre-trained models is that they do not provide a convenient way for you to easily train new object detection models to detect and identify yo...   \n",
       "93   Intel Student Ambassadors\\nFeb 14, 2019\\nText summarization is nowadays one of the most studied research topics in natural language processing (NLP) and has its applications in almost all domains of the internet, for example, e-shops, search engines and news websites that use summaries to give readers an overview of what a particular article might talk about.\\nText Summarization is a task to generate a shorter and concise version of a text while preserving the meaning of the original text.[1]\\nText summarization algorithms can be classified into two main categories:\\nExtractive text summarization algorithms are capable of extracting key sentences from a text without modifying any word [2][3]. Abstractive summarization, instead, involves a complex process understanding the language, the...   \n",
       "94   Towards Data Science\\nJan 24, 2019\\nThis Article is Based on Deep Residual Learning for Image Recognition from He et al. [2] (Microsoft Research): https://arxiv.org/pdf/1512.03385.pdf\\nIn 2012, Krizhevsky et al. [1] rolled out the red carpet for the Deep Convolutional Neural Network. This was the first time this architecture was more successful that traditional, hand-crafted feature learning on the ImageNet. Their DCNN, named AlexNet, contained 8 neural network layers, 5 convolutional and 3 fully-connected. This laid the foundational for the traditional CNN, a convolutional layer followed by an activation function followed by a max pooling operation, (sometimes the pooling operation is omitted to preserve the spatial resolution of the image).\\nMuch of the success of Deep Neural Network...   \n",
       "95   Towards Data Science\\nJun 10, 2019\\nIn the Article Text summarization in 5 steps using NLTK, we saw how we summarize the text using Word Frequency Algorithm.\\nBonus: See in Action with Streamlit App\\nNow, we’ll summarize the text using Tf-IDF Algorithm.\\nNote that, we’re implementing the actual algorithm here, not using any library to do the most of the tasks, we’re highly relying on the Math only.\\nIn a simple language, TF-IDF can be defined as follows:\\nA High weight in TF-IDF is reached by a high term frequency(in the given document) and a low document frequency of the term in the whole collection of documents.\\nTF-IDF algorithm is made of 2 algorithms multiplied together.\\nTerm frequency (TF) is how often a word appears in a document, divided by how many words there are.\\nTF(t) = (...   \n",
       "96   Towards Data Science\\nNov 21, 2018\\nIf you landed on this post, you probably already know what a Gaussian Mixture Model is, so I will avoid the general description of the this technique.\\nBut if you are not aware of the details, you can just see the GMM as a k-means which is able to form stretched clusters, like the ones you can see in Figure 2.\\nAll the code used for this post is in this notebook. In the same repository you can find the data to fully replicate the results you see plotted.\\nNow: suppose you are in the situation depicted in Figure 1, you want to discern how many clusters we have (or, if you prefer, how many gaussians components generated the data), and you don’t have information about the “ground truth”. A real case, where data do not have the nicety of behaving good as...   \n",
       "97   Towards Data Science\\nJun 18, 2021\\nMathematics behind two important optimization techniques in machine learning\\nOptimization is the process where we train the model iteratively that results in a maximum and minimum function evaluation. It is one of the most important phenomena in Machine Learning to get better results.\\nWhy do we optimize our machine learning models? We compare the results in every iteration by changing the hyperparameters in each step until we reach the optimum results. We create an accurate model with less error rate. There are different ways using which we can optimize a model. In this article, let’s discuss two important Optimization algorithms: Gradient Descent and Stochastic Gradient Descent Algorithms; how they are used in Machine Learning Models, and the math...   \n",
       "98   Towards Data Science\\nOct 6, 2021\\nOutline of HRNet explained:\\nIf you know already the basics (CNN + Areas of Application), skip down to section 3 or section 4.\\nHRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.\\nBut first, let’s understand what the fields mean and what kind of algorithm hides behind HRNet.\\nSemantic Segmentation is used to categorize structures of an image into certain classes. This is done by labeling each pixel with a certain class [3]. In the example below all pixels representing the cyclist are a class person and all pixels representing the bicycle are class ...   \n",
       "99                                                                    cvil.ly\\nFeb 24, 2010\\nHave you noticed that there’s no spot in the Apple.com navigation for the iPad? I tried navigating to iPhone, iPod+iTunes and Mac and could not find iPad in any of those locations. I wonder when they plan to address this?\\n[caption id=”” align=”aligncenter” width=”576\" caption=”No home for iPad in Apple.com IA”]\\n[/caption]\\nUpdate: Now there is a home for iPad! Note that they also separated iPod & iTunes.\\n[caption id=”” align=”aligncenter” width=”604\" caption=”Now there is a home for iPad on Aplle.com”]\\n[/caption]\\ndesign | technology | product\\n1.3K Followers\\nProduct leader, designer, tech and gadget nerd. Pragmatic optimist.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "100  Towards Data Science\\nJul 13, 2019\\nSequence-to-sequence (abrv. Seq2Seq) models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning. Google Translate started using such a model in production in late 2016. These models are explained in the two pioneering papers (Sutskever et al., 2014, Cho et al., 2014).\\nA Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.\\nIn the case of Neural Machine Translation, the input is a series of words, and the output is the translated series of words.\\nNow let's work on reducing the blackness of our black box. The model is composed of an encoder and a decoder. The encoder captures the context of ...   \n",
       "101  Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...   \n",
       "102  Towards Data Science\\nOct 28, 2019\\nDealing with images is not a trivial task. To you, as a human, it’s easy to look at something and immediately know what is it you’re looking at. But computers don’t work that way.\\nTasks that are too hard for you, like complex arithmetics, and math in general, is something that a computer chews without breaking a sweat. But here the exact opposite applies — tasks that are trivial to you, like recognizing is it cat or dog in an image are really hard for a computer. In a way, we are a perfect match. For now at least.\\nWhile image classification and tasks that involve some level of computer vision might require a good bit of code and a solid understanding, reading text from a somewhat well-formatted image turns out to be a one-liner in Python —and can b...   \n",
       "103  Towards Data Science\\nJul 31, 2019\\nIn this article, we’ll explore a state-of-the-art method of machine learning interpretability and adapt it to multivariate time series data, a use case which it wasn’t previously prepared to work on. You’ll find explanations to core concepts, on what they are and how they work, followed by examples. We’ll also address the main ideas behind the proposed solution, as well as a suggested visualization of instance importance.\\nIt’s not just hype anymore, machine learning is becoming an important part of our lives. Sure, there aren’t any sentient machines nor Scarlett Johansson ear lovers (shoutout to Her) out there, but the evolution of these algorithms is undeniable. They can ride cars, assist in medical prognosis, predict stock, play videogames at a pr...   \n",
       "104  Towards Data Science\\nJan 24, 2020\\nI had just walked away from 8 years of study and hard work with no plan. You might be wondering why someone would do that. My boss was crushing my spirit and knew that I needed to make a change.\\nMy boyfriend suggested becoming a data scientist. I said ‘you're crazy!’ I didn’t know the first thing about programming. Surely he was overestimating what I was capable of. Imposter syndrome strikes again.\\nAbout two weeks later my friend Anna suggested the exact same thing, I thought about it some more and began to entertain the idea. Why not? I decided to become a beginner again and reinvent myself as a data scientist.\\nI wanted to learn at my own pace so I decided to take online courses. I figured that with a PhD in Neuroscience I probably had enough for...   \n",
       "105  UX Collective\\nAug 17, 2021\\nApplications we design are becoming increasingly data-driven. The need for quality data visualization is high as ever. Confusing and misleading graphics are all around us, but we can change this by following these simple rules.\\nChoosing the wrong chart type, or defaulting to the most common type of data visualization could confuse users or lead to data misinterpretation. The same data set can be represented in many ways, depending on what users would like to see. Always start with a review of your data set and user interview.\\nYou can learn more on how to pick the right representation for your data, and how to design effective dashboards in my article about Dashboard design.\\nWhen using horizontal bars, plot negatives values on the left side and positive o...   \n",
       "106  Oct 18, 2015\\n1. What is the purpose of metadata? What are the categories of metadata?\\nMetadata provides definitions about the data they are attached to. It can include descriptive information about the context, quality, condition and characteristics.\\nMetadata is broken into three categories; structural (describes information about the document), descriptive (enables the document to be identified) and administrative (identifies the relationship of the document to the business context).\\n2. What is a controlled vocabulary? How is a controlled vocabulary beneficial to a web site and/or organisation?\\nA controlled vocabulary is a list of equivalent terms in the form of a synonym ring or a list of preferred terms in the form of an authority file.\\nThis is beneficial as it helps categoris...   \n",
       "107                                                                                                                        Konvergen.AI\\nJul 21, 2019\\nOne particular layer that is useful, yet mysterious when training neural networks is Dropout. Dropout is created as a regularization technique, that we can use to reduce the model capacity so that our model can achieve lower generalization error. The intuition is easy, we didn’t use all neurons but only turn on some neuron in each training iteration with probability p. But how does dropout works, and is it the same as the implementation?\\n105 \\n105 \\n2\\nThe sharing platform of Konvergen.ai. Visit our homepage at https://konvergen.ai\\n171 Followers\\nCofounder of Konvergen.AI\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "108  Feb 26, 2018\\nПриветствую вас, друзья! TokenGo запускает ICO!\\nМы долго шли к этому дню, к этому волнующему событию. До момента запуска ICO платформы TokenGo остались считанные часы.\\nВ первую очередь я хочу сказать спасибо всем тем, кто сегодня с нами! С кем-то мы знакомы уже несколько месяцев, успели пообщаться, обсудить будущее и подружиться, кто-то присоединяется только сейчас, изучает White Paper, читает темы на форумах, задает вопросы в Telegram-чате. И это очень здорово, что наше сообщество постоянно растет, укрепляется, и каждый участник вносит свой вклад в строительство экосистемы TokenGo. Отдельно хочу поздравить инвесторов, записавшихся в White List. Уверен, что полученный вами уникальный бонус вас обязательно порадует!\\nА в TokenGo все продолжает идти по плану. Совсем ...   \n",
       "109                                                                                                                                                                          Jan 10, 2016\\nTips to avoid the pitfall of over fitting in Linear Regression\\n8. The choice of the model has to be based on the observation from training error and test error . Also its tricky to make choice of right features to come to make build the model for your predictions.\\n1 \\n1 \\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n743 Followers\\nCo-founder at Stealth. Code with Love, Learn with Passion, Feel the music, Live like a hacker.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "110  Sep 5, 2020\\nThis blog is written to explain the evolution of object detection models in simple words and self-explanatory diagrams. This blog can be helpful to every individual who is entering into the field of computer vision and data science or has taken up a project which requires solving an object detection problem.\\nWe all must have heard about Faster R-CNN and there are high chances that you found this blog when you searched for the keyword “Faster R-CNN” as it has been among the state of arts used in many fields since January 2016.\\nA strong object detection architecture like Faster RCNN is built upon the successful research like R-CNN and Fast R-CNN. To honestly enjoy working, troubleshooting and pursuing the dream of creating your own model which can one day be called a state...   \n",
       "111  Aug 28, 2018\\nUnchainet is aiming to provide a decentralized cloud platform connecting providers with spare computing resources and clients who need them. Research shows 30% of servers in private data centers consume energy but are not being used. We are working to provide easy-to-install software for companies with private data centers, hosting companies and individuals so they can easily connect to the Unchainet network and start earning money on a transparent and efficient marketplace. Unchainet clients will include existing partners and all other cloud users. Our platform’s important differentiation from competing decentralized cloud platforms is familiar open source technology and bridging interfaces which completely removes friction associated with staff training and allows easy ...   \n",
       "112                                                                                        TekLit\\nJul 10, 2021\\nThe looming threat to the average programmer.\\nLet’s face it. Unless you are talented enough for Google to hire you, you are probably limited to developing APIs, websites, or customizing an ERP-like business system.\\nIf toiling day after day, adding mundane features to boring systems isn’t enough for you, you have the added task of keeping up with the frameworks and tools that will evolve with...\\n8.8K \\n8.8K \\n295\\nWe’re software developers, for better or for worse. Friendlier than your average StackOverflow moderator, but we probably won’t fix your code.\\n1.9K Followers\\nSoftware Developer | Writer for TekLit\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "113  emaasit\\nAug 3, 2016\\nIn case you missed my free webinar on “Model-Based Machine Learning”, here is the recording.\\nApologies for the poor quality of the video. Domino Data Lab’s webinar platform suffered a service degradation while recording the event. The webinar slides may be found below.\\n[slideshare id=64647075&doc=3rdpresentationpaperreview-160803065711]\\nIf you have any questions, please do not hesitate to contact me. Finally, I would like to thank Daniel Enthoven and Daniel Chalef from Domino Data Lab for setting up this webinar.\\nEmaasit’s personal blog about R, Bayesian Machine Learning, Big Data, Bayesian Nonparametrics, & Probabilistic Programming\\n252 Followers\\nFounder at @SparkIQ_Labs, PhD Student in Urban Mobility, Bayesian Machine Learning Research Scientist, Organizer...   \n",
       "114  HackerNoon.com\\nSep 18, 2018\\nThis article proposes an easy and free solution to train a Tensorflow model for instance segmentation in Google Colab notebook, with a custom dataset.\\nPrevious article was about Object Detection in Google Colab with Custom Dataset, where I trained a model to infer bounding box of my dog in pictures. The protagonist of my article is again my dog: in this case we take a step forward, we identify not only the bounding box, we make even pixel wise classification.\\nCompared to previous article, we hold the same characteristics:\\nThese features allow anybody following this tutorial to create an instance segmentation model, and test it in Google Colab or export the model to run in a local machine.\\nSource code of this article, including the sample dataset, is av...   \n",
       "115  Towards Data Science\\nJul 23, 2017\\nLatest Update:I have uploaded the complete code (Python and Jupyter notebook) on GitHub: https://github.com/javedsha/text-classification\\nDocument/Text classification is one of the important and typical task in supervised machine learning (ML). Assigning categories to documents, which can be a web page, library book, media articles, gallery etc. has many applications like e.g. spam filtering, email routing, sentiment analysis etc. In this article, I would like to demonstrate how we can do text classification using python, scikit-learn and little bit of NLTK.\\nDisclaimer: I am new to machine learning and also to blogging (First). So, if there are any mistakes, please do let me know. All feedback appreciated.\\nLet’s divide the classification problem in...   \n",
       "116  Towards Data Science\\nAug 25, 2020\\nNote from Towards Data Science’s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author’s contribution. You should not rely on an author’s works without seeking professional advice. See our Reader Terms for details.\\nThis blog is based on our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, presented at ICAIF 2020: ACM International Conference on AI in Finance.\\nOur codes are available on Github.\\ngithub.com\\nOur paper is available on SSRN.\\npapers.ssrn.com\\nIf you want to cite our paper, the reference format is as follows:\\nHongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated S...   \n",
       "117  The Official Unofficial Firefox Blog\\nNov 10, 2016\\nWe did a bit of informal censusing last month to get to know our users in the best way possible: anonymously and collectively. You might have seen the survey, which we shared through email, our about:home page, and social media. You might have also noticed it came from our Bureau of Censusing (not an official team here), Department of Whimsy (also not an official department, but you better believe we’re doing some introspection now as to why not). It was totally voluntary and, like everything we do, about openness and transparency.\\nSo in that spirit, let’s look at the results! You can find the full report here, if you’re into that sort of thing. There were 44 questions and a ton of interesting ways to slice the data, so for the sake ...   \n",
       "118  Towards Data Science\\nMar 25, 2021\\nOver the last few years, Voice Assistants have become ubiquitous with the popularity of Google Home, Amazon Echo, Siri, Cortana, and others. These are the most well-known examples of Automatic Speech Recognition (ASR). This class of applications starts with a clip of spoken audio in some language and extracts the words that were spoken, as text. For this reason, they are also known as Speech-to-Text algorithms.\\nOf course, applications like Siri and the others mentioned above, go further. Not only do they extract the text but they also interpret and understand the semantic meaning of what was spoken, so that they can respond with answers, or take actions based on the user's commands.\\nIn this article, I will focus on the core capability of Speech-to-...   \n",
       "119  Towards Data Science\\nDec 10, 2019\\nComputer vision in Machine Learning provides enormous opportunities for GIS. Its tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions.[1][2][3][4] In the last several years, computer vision is increasingly shifting from traditional statistical methods to the state-of-art deep learning neural network techniques.\\nIn this blog, I will share several empirical practices using Keras and ESRI ArcGIS Pro tools with deep learning and transfer learning techniques to build a building footprint image segmentation network model from a super-high-resolution 3-inch of EagleView (Pi...   \n",
       "120  Feb 6, 2020\\nIn this article, I will discuss all cases of Logistic Regression that are useful while applying.\\nLet’s take x as an input feature vector, and y is a class (-1 or +1), then the probability of class given input vector represented by the below formula.\\nand log loss is\\nLoss with regularization for optimization is\\nN is the number of data points we have, C is hyperparameter to control regularization. Above I added l2 regularization notation. x_i is the data points features and y_i(+1 or -1) is the label we have for x_i. This formulation works only for Binary classification.\\nAlso, we can represent the Loss function as below, and that works for multiclass formulation as well.\\nLet’s take we have K classes and N number of data points. Now the Log loss function is represented a...   \n",
       "121  Towards Data Science\\nJul 14, 2017\\nHere is a quick concise summary for reference. For more detailed explanation please read: http://ruder.io/optimizing-gradient-descent/\\nVanilla gradient descent, aka batch gradient descent, computes the gradient of the cost function w.r.t. to the parameters θ for the entire training dataset.\\nStochastic gradient descent (SGD) in contrast performs a parameter update for each training example x(i) and label y(i)\\nMini-batch gradient descent finally takes the best of both worlds and performs an update for every mini-batch of n training examples.\\nVanilla mini-batch gradient descent, however, does not guarantee good convergence, but offers a few challenges that need to be addressed:\\nSGD has trouble navigating ravines, i.e. areas where the surface curves...   \n",
       "122  Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...   \n",
       "123  Jul 10, 2020\\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is an unsupervised machine learning technique used to identify clusters of varying shape in a data set (Ester et al. 1996). Another post I wrote goes into what DBSCAN is and when to use it. You can find it here. This post will focus on estimating DBSCAN’s two parameters:\\nThere is no automatic way to determine the MinPts value for DBSCAN. Ultimately, the MinPts value should be set using domain knowledge and familiarity with the data set. From some research I’ve done, here are a few rules of thumb for selecting the MinPts value:\\nAfter you select your MinPts value, you can move on to determining ε. One technique to automatically determine the optimal ε value is described in this paper. This technique calc...   \n",
       "124  Towards Data Science\\nOct 3, 2021\\nIn this article, we review the problem of semantic segmentation on unbalanced binary masks. Focal loss and mIoU are introduced as loss functions to tune the network parameters. Finally, we train the U-Net implemented in PyTorch to perform semantic segmentation on aerial images. The training codes and PyTorch implementations are available through Github.\\nThe dataset used here is “Semantic segmentation of aerial imagery” which contains 72 satellite images of Dubai, the UAE, and is segmented into 6 classes. The classes include water, land, road, building, vegetation, and unlabeled.\\nU-Net is a convolutional neural network that originally was presented for biomedical image segmentation at the Computer Science Department of the University of Freiburg. It ...   \n",
       "125  Analytics Vidhya\\nAug 27, 2020\\nThis post demonstrates the use of Stochastic Gradient Descent for Dimensionality Reduction.\\nWhat is Dimensionality Reduction?\\nDimensionality reduction is the process of reducing a potentially large set of features F to a smaller set of features F’ to be considered in a given machine learning or statistics problem.\\nIn an unsupervised setting, dimensionality reduction is often used for exploratory data analysis, for example to visualize the distribution of high dimensional data in human-digestible two or three dimensions. In a supervised setting, the main use is to reduce the number of parameters a learning machine has to determine. In other words: The goal of dimensionality reduction is to overcome the curse of dimensionality.\\nA straightforward approa...   \n",
       "126  Towards Data Science\\nFeb 28, 2021\\nSince the seminal paper “Attention is all you need” of Vaswani et al, Transformer models have become by far the state of the art in NLP technology. With applications ranging from NER, Text Classification, Question Answering or text generation, the applications of this amazing technology are limitless.\\nMore specifically, BERT — which stands for Bidirectional Encoder Representations from Transformers— leverages the transformer architecture in a novel way. For example, BERT analyses both sides of the sentence with a randomly masked word to make a prediction. In addition to predicting the masked token, BERT predicts the sequence of the sentences by adding a classification token [CLS] at the beginning of the first sentence and tries to predict if the sec...   \n",
       "127  Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...   \n",
       "128  unpackAI\\nJun 6, 2021\\nThere are 7 steps to train/get a model in deep learning like this chart:\\nWe now put it with the SGD together and look at them step by step:\\nStep 1: Initialize\\nIn this step, we initialize our parameters with random values and tell PyTorch that we want to track their gradients:\\nWe will do the following things in this step:\\nStep 2: Predict\\nIn this step,we will calculate the predictions to see how close our predictions to our targets. The code will like this\\npreds = f(time, params)\\nStep 3: Calculate the Loss\\nIn this step, can change the weight by a little in the direction of the slope, calculate the loss and adjustment again, and repeat this a few times. We will get to the lowest point on the curve. We can use “mse”or “l1”to calculate.\\n“mse”stands for *mean...   \n",
       "129  Towards Data Science\\nApr 24, 2020\\nThe Transformer Neural Network is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease. It was proposed in the paper “Attention Is All You Need” 2017 [1]. It is the current state-of-the-art technique in the field of NLP.\\nBefore directly jumping to Transformer, I will take some time to explain the reason why we use it and from where it comes into the picture. (If you want to skip this part then directly go to the Transformer topic, but I suggest you read it sequentially for better understanding).\\nSo, the story starts with RNN (Recurrent Neural Networks).\\nWhat is RNN? How is it different from simple ANN? What is the major difference?\\nRNNs are the Feed Forward Neural Networks that are ro...   \n",
       "130  Becoming Human: Artificial Intelligence Magazine\\nDec 13, 2017\\nIn this article we will be solving an image classification problem, where our goal will be to tell which class the input image belongs to. The way we are going to achieve it is by training an artificial neural network on few thousand images of cats and dogs and make the NN(Neural Network) learn to predict which class the image belongs to, next time it sees an image having a cat or dog in it.\\nThe key thing to understand while following this article is that the model we are building now can be trained on any type of class you want, i am using cat and dog only as a simple example for making you understand how convolutional neural networks work. For example, if there are any doctors reading this, after completing this article...   \n",
       "131  NanoNets\\nMar 20, 2018\\nDisclaimer: I’m building nanonets.com to help build ML with less data and no hardware\\nIf you’re impatient scroll to the bottom of the post for the Github Repos\\nThe raspberry pi is a neat piece of hardware that has captured the hearts of a generation with ~15M devices sold, with hackers building even cooler projects on it. Given the popularity of Deep Learning and the Raspberry Pi Camera we thought it would be nice if we could detect any object using Deep Learning on the Pi.\\nNow you will be able to detect a photobomber in your selfie, someone entering Harambe’s cage, where someone kept the Sriracha or an Amazon delivery guy entering your house.\\n20M years of evolution have made human vision fairly evolved. The human brain has 30% of it’s Neurons work on proces...   \n",
       "132  Towards Data Science\\nFeb 2, 2020\\nIn this article, we will learn:\\nmedium.com\\ntowardsdatascience.com\\nIn this article, you will get a detailed explanation of how neural machine translation developed using sequence to sequence algorithm to find the most relevant words in sentences for a target language.\\nWhat is Beam search?\\nTo understand the Beam search, we will use the neural machine translation use case of sequence to sequence.\\nThe sequence to sequence model uses an encoder and decoder framework with Long Short Term Memory(LSTM) or Gated Recurrent Unit(GRU) as the basic blocks.\\nEncoder maps a source sequence encodes the source information and passes it to the decoder. The decoder takes the encoded data from the encoder as an input along with the start-of-string <START> token as ...   \n",
       "133  Towards Data Science\\nMar 15, 2020\\nSome tasks that AI does are actually not impressive. Think about your camera recognizing and auto-focusing on faces in pictures. That technology has been around since 2001, and it doesn’t tend to excite people. Why not? Well, because you can do that too, you can focus your eyes on someone’s face very easily. In fact, it’s so easy you don’t even know how you do it. If AI can do it too, then who cares how it works? Though we may not explicitly understand how this AI works, its underlying mechanisms don’t do anything we can’t. At least, this is what I think most people are thinking.\\nGames are just the opposite. Rather than games being an innate ability we have (like focusing your vision), you have an understanding of how and why you make decisions with...   \n",
       "134  May 21, 2014\\nRecently I’ve have been looking into options to solve the problem of GSLB’ing (global server load balancing) a Liferay Portal instance.\\nThis article is a work in progress... and a long one. Jan Eerdekens states it correctly in his article, “Configuring a Liferay cluster is part experience and part black magic” .... however doing it across data-centers however is like wielding black magic across N black holes....\\nFootnotes for this article are here: https://bitsofinfo.wordpress.com/2014/05/21/liferay-clustering-internals/\\nThe objective is a typical one.\\nHopefully this article will help others out there, point them in a new direction and give them some ideas on how to put something like this together.\\nI’d like to note that this is not necessarily the ideal way to do th...   \n",
       "135  May 2, 2017\\n“Buat apa kuliah kalo kalah sukses atau gaji aja kalah gede dari lulusan SMA/SMK?”\\nSerius, pasti banyak orang yang pernah terlintas pikiran brilian seperti diatas. Bahkan bisa jadi kamu yang membaca ini adalah satunya bukan? Tenang saja, kamu tidak sendirian karena saya juga pernah berpikir seperti itu kok hehehe :D\\nYa, tidak bisa dipungkiri karena kita sering melihat contoh orang-orang terkenal yang sukses padahal mereka OD (baca: Out Dewe, kalau DO kan Drop Out, jelek kesannya ditendang, sementara OD gak perlu nunggu ditendang udah keluar-keluar sendiri hehehe :p) atau bahkan sekolah pun gak tamat. Contohnya Brad Pitt, Oprah Winfrey, Lady Gaga, John Lennon, Eminem. Nama-nama itu pasti sudah tidak asing lagi kan?\\nMungkin ada yang berpikir orang yang OD maupun DO tidak ...   \n",
       "136  Towards Data Science\\nJul 24, 2020\\nIn this article we will study word embeddings — digital representation of words suitable for processing by machine learning algorithms.\\nOriginally I created this article as a general overview and compilation of current approaches to word embedding in 2020, which our AI Labs team could use from time to time as a quick refresher. I hope that my article will be useful to a wider circle of data scientists and developers. Each word embedding method in the article has a (very) short description, links for further study, and code examples in Python. All code is packed as Google Colab Notebook. So let’s begin.\\nAccording to Wikipedia, Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language pro...   \n",
       "137  Towards Data Science\\nJun 26, 2017\\nAutoencoders (AE) are a family of neural networks for which the input is the same as the output (they implement a identity function). They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.\\nA really popular use for autoencoders is to apply them to images. The trick is to replace fully connected layers by convolutional layers. These, along with pooling layers, convert the input from wide and thin (let’s say 100 x 100 px with 3 channels — RGB) to narrow and thick. This helps the network extract visual features from the images, and therefore obtain a much more accurate latent space representation. The reconstruction process uses upsampling and convolutions.\\nThe resulting netwo...   \n",
       "138  Towards Data Science\\nJan 1, 2019\\nYou know it’s out there. You know there’s free GPU somewhere, hanging like a fat, juicy, ripe blackberry on a branch just slightly out of reach.\\nBeautiful lightning-fast speed waiting just for you.\\nWondering how on earth to get it to work? You’re in the right place!\\nFor anyone who doesn’t already know, Google has done the coolest thing ever by providing a free cloud service based on Jupyter Notebooks that supports free GPU. Not only is this a great tool for improving your coding skills, but it also allows absolutely anyone to develop deep learning applications using popular libraries such as PyTorch, TensorFlow, Keras, and OpenCV.\\nColab provides GPU and it’s totally free. Seriously!\\nThere are, of course, limits. (Nitty gritty details are availabl...   \n",
       "139  Towards Data Science\\nJan 15, 2019\\nEverything we express (either verbally or in written) carries huge amounts of information. The topic we choose, our tone, our selection of words, everything adds some type of information that can be interpreted and value extracted from it. In theory, we can understand and even predict human behaviour using that information.\\nBut there is a problem: one person may generate hundreds or thousands of words in a declaration, each sentence with its corresponding complexity. If you want to scale and analyze several hundreds, thousands or millions of people or declarations in a given geography, then the situation is unmanageable.\\nData generated from conversations, declarations or even tweets are examples of unstructured data. Unstructured data doesn’t fit n...   \n",
       "140  Towards Data Science\\nSep 8, 2021\\nWritten by Walter Hugo Lopez Pinaya, Pedro F. da Costa, and Jessica Dafflon\\nHi everybody! Today, we will continue the series about autoregressive models and we will focus on one of the biggest limitations of PixelCNNs (i.e., blind spots) and how to improve to fix it.\\nSummary\\nFor each topic, the code is availiable in this repository.\\nIn the previous two posts, we introduced generative models, the concept behind PixelCNNs, and looked at how a coloured PixelCNN works. Recall that PixelCNNs are a type of generative models that learn the probability distribution of pixels, that means that the intensity of future pixels will be determined by previous pixels. In this blogpost series we implemented two PixelCNNs and noticed that the performance was not st...   \n",
       "141  Towards Data Science\\nFeb 26, 2019\\nIn this article, I will explain the concept of convolution neural networks (CNN’s) using many swan pictures and will make the case of using CNN’s over regular multilayer perceptron neural networks for processing images.\\nImage Analysis\\nLet us assume that we want to create a neural network model that is capable of recognizing swans in images. The swan has certain characteristics that can be used to help determine whether a swan is present or not, such as its long neck, its white color, etc.\\nFor some images, it may be more difficult to determine whether a swan is present, consider the following image.\\nThe features are still present in the above image, but it is more difficult for us to pick out these characteristic features. Let us consider some mor...   \n",
       "142  Towards Data Science\\nDec 26, 2020\\nOutliers, one of the buzzwords in the manufacturing industry, has driven engineers and scientists to develop newer algorithms as well as robust techniques for continuous quality improvement. If the data include even if one outlier, it has the potential to dramatically skew the calculated parameters. Therefore, it is of utmost importance to analyze the data without those deviant points. It is also important to understand which of the data points are considered as outliers. Extreme data points do not always necessarily mean those are outliers.\\nIn this article, I will discuss the algorithm and the python implementation for three different outlier detection techniques. Those are Interquartile (IQR) method, Hampel method and DBSCAN clustering method.\\nIn...   \n",
       "143  SAP Design\\nApr 11, 2018\\nThis blog belongs to the SAP Design series about intelligent system design. You might also be interested in our previous post, 5 Challenges to Your Machine Learning Project.\\nOne of the guiding design principles for intelligent systems is to empower end users. If we want people to trust machines, we must share information about the underlying models and the reasoning behind the results of algorithms. This is even more vital for business applications, when users are held accountable for every decision they make.\\nIt’s widely accepted that intelligent systems must come with a certain level of transparency. There’s even a new term for it: explainable AI. But, that’s just the beginning. As designers, we need to ask ourselves how explainable AI is tied to user inte...   \n",
       "144  Towards Data Science\\nMay 31, 2018\\nTopic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.\\nHere we are going to apply LDA to a set of documents and split them into topics. Let’s get started!\\nThe data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from Kaggle.\\nTake a peek of the data.\\n1048575\\nWe will perform the following steps:\\nLoading gensim and nltk libraries\\n[nltk_data] Downloading package wordnet to[nltk_data]...   \n",
       "145  Analytics Vidhya\\nJun 7, 2020\\nGenerative Adversarial Networks (GANs) have had a lot of success since they were introduced in 2014 by Ian Goodfellow. For somebody starting out in Machine Learning, the intricate Mathematics and the complex-looking architecture of GANs seems daunting. So, let’s demystify GANs/C-GANs and implement a simple application with PyTorch. This article is self-contained and is targeted for beginner to intermediate level Machine Learning enthusiasts.\\n159 \\n159 \\n2\\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n105 Followers\\nPh.D. student in Natural Language Processing (https://nrjvarshney.github.io)\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nT...   \n",
       "146  Towards Data Science\\nApr 7, 2020\\nHuman language is filled with ambiguity, many-a-times the same phrase can have multiple interpretations based on the context and can even appear confusing to humans. Such challenges make natural language processing an interesting but hard problem to solve. However, we’ve seen a lot of advancement in NLP in the past couple of years and it’s quite fascinating to explore the various techniques being used. This article aims to cover one such technique in deep learning using Pytorch: Long Short Term Memory (LSTM) models.\\nHere’s a link to the notebook consisting of all the code I’ve used for this article: https://jovian.ml/aakanksha-ns/lstm-multiclass-text-classification\\nIf you’re new to NLP or need an in-depth read on preprocessing and word embeddings, y...   \n",
       "147  Towards Data Science\\nOct 5, 2018\\nLinear Regression is usually the first machine learning algorithm that every data scientist comes across. It is a simple model but everyone needs to master it as it lays the foundation for other machine learning algorithms.\\nWhere can Linear Regression be used? It is a very powerful technique and can be used to understand the factors that influence profitability. It can be used to forecast sales in the coming months by analyzing the sales data for previous months. It can also be used to gain various insights about customer behaviour. By the end of the blog we will build a model which looks like the below picture i.e, determine a line which best fits the data.\\nThis is the first blog of the machine learning series that I am going to cover. One can get ...   \n",
       "148  Towards Data Science\\nAug 4, 2017\\nOne way to think of what deep learning does is as “A to B mappings,” says Andrew Ng, chief scientist at Baidu Research. “You can input an audio clip and output the transcript. That’s speech recognition.” As long as you have data to train the software, the possibilities are endless, he maintains. “You can input email, and the output could be: Is this spam or not?” Input loan applications, he says, and the output might be the likelihood a customer will repay it. Input usage patterns on a fleet of cars and the output could advise where to send a car next.\\nRather making the facts complicated by having complex definitions, think of deep learning as a subset of a subset. Artificial Intelligence encircles a wide range of technologies and techniques that ena...   \n",
       "149  Sep 25, 2016\\nThere’s a huge difference between reading about Reinforcement Learning and actually implementing it.\\nIn this post, you’ll implement a Neural Network for Reinforcement Learning and see it learn more and more as it finally becomes good enough to beat the computer in Pong! You can play around with other such Atari games at the OpenAI Gym.\\nBy the end of this post, you’ll be able to do the following:\\nThe code and the idea are all tightly based on Andrej Karpathy’s blog post. The code in me_pong.py is intended to be a simpler to follow version of pong.py which was written by Dr. Karpathy.\\nTo follow along, you’ll need to know the following:\\nIf you want a deeper dive into the material at hand, read the blog post on which all of this is based. This post is meant to be a simpl...   \n",
       "150  Analytics Vidhya\\nSep 7, 2019\\nThis article will cover: * Downloading and loading the pre-trained vectors * Finding similar vectors to a given vector * “Math with words” * Visualizing the vectors\\nFurther reading resources, including the original GloVe paper, are available at the end.\\nGlobal Vectors for Word Representation, or GloVe, is an “unsupervised learning algorithm for obtaining vector representations for words.” Simply put, GloVe allows us to take a corpus of text, and intuitively transform each word in that corpus into a position in a high-dimensional space. This means that similar words will be placed together.\\nIf you would like a detailed explanation of how GloVe works, linked articles are available at the end.\\nHead over to https://nlp.stanford.edu/projects/glove/.Then un...   \n",
       "151  Towards Data Science\\nMay 6, 2020\\nThis article will cover:\\nThere’s a video walkthrough of the code at the end for those who prefer the format. I personally like written tutorials, but I’ve had requests for video versions too in the past, so there it is.\\nSince you are here, there’s a very good chance you already know Pipelines make your life easy by pre-processing the data. I heard that too and tried to implement one in my code.\\nA shout-out to the few great tutorials I could find on the topic! I recommend you certainly browse through them, before or after the current article :\\ni. https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65ii. https://machinelearningmastery.com/how-to-transform-target-variables-for-regression-with-scikit-learniii...   \n",
       "152  Towards Data Science\\nFeb 15, 2019\\nTF-IDF stands for “Term Frequency — Inverse Document Frequency”. This is a technique to quantify words in a set of documents. We generally compute a score for each word to signify its importance in the document and corpus. This method is a widely used technique in Information Retrieval and Text Mining.\\nIf I give you a sentence for example “This building is so tall”. It's easy for us to understand the sentence as we know the semantics of the words and the sentence. But how can any program (eg: python) interpret this sentence? It is easier for any programming language to understand textual data in the form of numerical value. So, for this reason, we need to vectorize all of the text so that it is better represented.\\nBy vectorizing the documents we ca...   \n",
       "153  Towards Data Science\\nJul 31, 2019\\nUnderstanding the underlying structure of real-world data is one of the most compelling quests in machine learning. But with the advent of deep generative models researcher and practitioners have a powerful method to unravel it.\\nReal-world data is often complex and high-dimensional. Traditional approaches of data analysis are in most cases ineffective and can only model a very simple data distribution. Nowadays, we can use machine learning models to directly learn the structure of our data. The most common approach in machine learning is supervised learning, where we ask the model to learn a mapping from an input to an output variable, e.g. an image x to a label y. However, labelled data is expensive and prone to errors or biases by the human annota...   \n",
       "154  Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...   \n",
       "155  Aug 19, 2021\\nMerhaba, R-CNN Ailesi: Part I’ de CNN , R- CNN ve Fast R-CNN’den bahsetmiştim. Bu yazıda ise Faster R-CNN ile Mask R-CNN’in gelişimini, avantajlarını ve dezavantajlarını inceleyeceğiz.\\nBir önceki yazımda bahsettiğim R-CNN ve Fast R-CNN, bölge tekliflerini bulmak için seçici arama kullanır. Seçici arama, ağın performansını etkileyen yavaş ve zaman alıcı bir işlemdir. Bunun üzerine Shaoqing Ren ve ark. seçici arama algoritmasını ortadan kaldıran ve ağın bölge tekliflerini öğrenmesini sağlayan bir nesne algılama algoritması geliştirdi. Faster R-CNN’de bölge tekliflerini belirlemek için özellik haritası üzerinde Seçici Arama algoritması kullanmak yerine Bölge Teklif Ağı (RPN — Region Proposal Network) kullanılır.\\nFaster R-CNN’de izlenen adımlar:\\n...   \n",
       "156  Towards Data Science\\nSep 22, 2020\\nClustering falls under the unsupervised learning technique. In this technique, the data is not labelled and there is no defined dependant variable. This type of learning is usually done to identify patterns in the data and/or to group similar data.\\nIn this post, a detailed explanation on the type of clustering techniques and a code walk-through is provided.\\nClustering is a method of grouping of similar objects. The objective of clustering is to create homogeneous groups out of heterogeneous observations. The assumption is that the data comes from multiple population, for example, there could be people from different walks of life requesting loan from a bank for different purposes. If the person is a student, he/she could ask for an education loan, ...   \n",
       "157  Analytics Vidhya\\nAug 28, 2021\\nIn this post, you will discover a gentle introduction to the problem of object detection and state-of-the-art deep learning models designed to address it.\\nAfter reading this post, you will know:\\nLet’s get started.\\nThis article is divided into three parts; they are:\\n· Input: An image with a single object, such as a photograph.\\n· Output: A class label (e.g. one or more integers that are mapped to class labels).\\n2. Object Localization: Locate the objects in an image and output their location with a bounding box.\\n· Input: An image with one or more objects, such as a photograph.\\n· Output: One or more bounding boxes (e.g. defined by a point, width, and height).\\n3. Object Detection: Locate the objects with a bounding box and types or classes of the loc...   \n",
       "158  Towards Data Science\\nMar 17, 2017\\nIn Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class of RNN that has found practical applications is Long Short-Term Memory (LSTM) because it is robust against the problems of long-term dependency. There is no shortage of articles and references explaining LSTM. Two recommended references are:\\nChapter 10 of Deep Learning Book by Goodfellow et. al.\\nUnderstanding LSTM Networks by Chris Olah\\nThere is also no shortage of good libraries to build machine learning applications based on LSTM. In GitHub, Google’s Tensorflow has now over 50,000 stars at the time of this writing suggesting a strong popularity among machine learning practitioners.\\nWhat seems to be lacking is a...   \n",
       "159  Towards Data Science\\nSep 24, 2018\\nHi and welcome to an Illustrated Guide to Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU). I’m Michael, and I’m a Machine Learning Engineer in the AI voice assistant space.\\nIn this post, we’ll start with the intuition behind LSTM ’s and GRU’s. Then I’ll explain the internal mechanisms that allow LSTM’s and GRU’s to perform so well. If you want to understand what’s happening under the hood for these two networks, then this post is for you.\\nYou can also watch the video version of this post on youtube if you prefer.\\nRecurrent Neural Networks suffer from short-term memory. If a sequence is long enough, they’ll have a hard time carrying information from earlier time steps to later ones. So if you are trying to process a paragraph of text ...   \n",
       "160  IPG Media Lab\\nFeb 7, 2014\\nAmazon is raising the stakes of showrooming for retailers once again, folding its “Flow” technology, previously found in a standalone app released by its subsidiary, A9, into its main shopping app for iOS. “Flow” is visual product search, allowing users to photograph an object and see details about it on Amazon, which is even simpler than the previous norm of barcode recognition. Amazon’s competitive pricing is its main advantage in comparison to retailers, and by more effectively using other retailers as showrooms for the products it sells, it has the potential to further extend its dominance in more consumer categories.\\nThe media futures agency of IPG Mediabrands\\n1.99K Followers\\nKeeping brands ahead of the digital curve. An @IPGMediabrands company.\\nHel...   \n",
       "161  Towards Data Science\\nSep 29, 2020\\nIn this tutorial, I'm going to walk you through using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.\\nThe pre-trained model that will be used in this tutorial is the VGG16 convolutional neural network (CNN), which is considered to be state of the art for image recognition tasks. We are going to be using this model as a feature extractor only, meaning that we will remove the final (prediction) layer so that we can obtain a feature vector.\\nThis implementation will use the flowers dataset from Kaggle which you can download here. The dataset contains 210 images of 10 different species of flowers that will be downloaded as png files.\\nBefore we get started, we need...   \n",
       "162  Towards Data Science\\nDec 15, 2018\\nArtificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.\\nThe agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image & Video recognition, Image Analysis & Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutiona...   \n",
       "163  Analytics Vidhya\\nNov 28, 2019\\nSo I was trying to learn about Reinforcement Learning, and then I came across this thing called ‘Value Iteration’. I really couldn’t wrap my head around Value Iteration. It was very difficult for me to understand how it worked and how it could help an agent to find the optimal policy. Then I got an idea.\\nWhat better way to understand “Value Iteration” than to use it to solve some game or environment. Thus I began my journey to find some game easy enough problem to solve. And then I stumbled upon this fairy from OpenAI.\\nLet me explain the game/environment first.\\nThere are 64 states in the game. The agent starts from S (S for Start) and our goal is to get to G (G for Goal). So just go. Nope. Its a slippery surface. The F’s and the H’s in between are pre...   \n",
       "164  Towards Data Science\\nMay 8, 2021\\nUnderstanding the mathematic operands behind Neural Networks (NNs) is highly important for the data scientist capabilities, in designing an efficient deep model. In this article, the high-level calculus of a fully connected NN will be demonstrated, with focus on the backward propagation step. The article is oriented to people with basic knowledge of NNs, that seek to dive deeper into the NNs structure.\\nThe objective of the training process is to find the weights (W) and biases (b) that minimize the error. It is done by the gradient descent algorithm. To begin with, the weights are randomly initialized, and an iterative process of a subtle weights change is performed until convergence.\\nEach iteration begins with a forward pass, that outputs the curre...   \n",
       "165  Towards Data Science\\nAug 8, 2018\\nThe International Conference on Machine Learning took place last July in Stockholm. Altogether it showcased many interesting trends and directions in machine learning. Since, ICML was such a huge conference I will focus my attention on a few (of the many) interesting strands going on at the conference.\\nSpecifically, this year’s ICML split the oral talks into several different “tracks/sessions.” I was happy to see three of theses sessions focused on “transfer and multitask learning” as this has long been an area of interest of mine. Additionally, a large number of posters dealt with theses concepts as well as several orals from other tracks.\\nLack of large amounts of clean labeled data remains a barrier to the potential impact of deep learning. For ma...   \n",
       "166  Towards Data Science\\nNov 1, 2020\\nRecently NVIDIA published a paper called “Training Generative Adversarial Networks with Limited Data” and released the code. They proposed an adaptive discriminator augmentation (ADA) mechanism that stabilizes StyleGAN2 training and achieves significantly better results on small datasets.\\nIn this post, we’ll show how to quickly run this code on an AWS Spot instance.\\n“A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly.”\\n— Spot Instances, AWS Documentation\\nTo launch a Spot instance and run a Docker container with the environment, we will be using Spotty. Spotty is an open-...   \n",
       "167  Towards Data Science\\nApr 19, 2021\\nSequences of discrete tokens can be found in many applications, namely words in a text, notes in a musical composition, pixels in an image, actions in a reinforcement learning agent, etc [1]. These sequences often show a strong correlation between consecutive or nearby tokens. The correlations on words in a sentence or characters in words express the underlying semantics and language characteristics. The next token in the sequence x_n can be modeled as:\\nwhere x_i represents the ith token in the sequence. In Natural Language Processing (NLP), these are defined as language models. Usually, each token stands for a separate word or n-gram. The output generated is a probability distribution from which we can sample to generate the next token in the seque...   \n",
       "168                                                                                                                                                          Jun 23, 2020\\nThe most common debate around Artificial Intelligence and Machine Learning is “Will AI Take Your Job — or Make It Better?.” If most people had a choice, they would probably choose the latter. With any of these new technologies, it can be challenging to distinguish the hype from the headline. On one end, you have big tech companies and startups promising to fix problems ranging from detecting cancer to...\\n140 \\n140 \\n1\\nArt Director adampickard.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n13 Followers\\nArt Director adampickard.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "169  Feb 24, 2017\\n딥러닝(Deep Learning)과 시퀀스(Sequence)의 마법을 사용한 언어 번역(Language Translation)\\n우리는 모두 마법처럼 100 가지 다른 언어를 즉시 번역 할 수 있는 웹 사이트 인 구글 번역(Google Translate)을 알고 있고 사랑합니다. 심지어 휴대 전화나 스마트 워치에서도 사용할 수 있습니다:\\n구글 번역에 사용된 기술을 기계 번역(Machine Translation)이라고 합니다. 다른 방법으로는 절대 불가능했던 전세계 사람들의 의사 소통을 가능하게 함으로써 세상을 변화시켰습니다.\\n그런데, 사실 고등학생들이... 음... 지난 15 년간 스페인어 숙제를 하기위해 구글 번역의 도움을 받아 왔다는 것을 모두 알고 있습니다. 그렇다면 이건 오래된 뉴스가 아닌가요?\\n지난 2 년 동안, 딥러닝(deep learning)은 기계 번역에 대하...   \n",
       "170  Towards Data Science\\nMay 7, 2019\\nUpdate (May 18th, 2021): Today I’ve finished my book: Deep Learning with PyTorch Step-by-Step: A Beginner’s Guide.\\nUpdate (February 23rd, 2022): The paperback edition is available now (in three volumes). For more details, please check pytorchstepbystep.com.\\nPyTorch is the fastest growing Deep Learning framework and it is also used by Fast.ai in its MOOC, Deep Learning for Coders and its library.\\nPyTorch is also very pythonic, meaning, it feels more natural to use it if you already are a Python developer.\\nBesides, using PyTorch may even improve your health, according to Andrej Karpathy :-)\\nThere are many many PyTorch tutorials around and its documentation is quite complete and extensive. So, why should you keep reading this step-by-step tutorial?\\...   \n",
       "171  HackerNoon.com\\nJun 19, 2018\\nWhat is a Recurrent Neural Network or RNN, how it works, where it can be used? This article tries to answer the above questions. It also shows a demo implementation of a RNN used for a specific purpose, but you would be able to generalise it for your needs.\\nKnowhow. Python, CNN knowledge is required. CNN is required to compare why and where RNN performs better than CNN? No need to understand the math. If you want to check then go back to my earlier article to check what is a CNN.\\nWe will begin with the word use of the word “Recurrent”. Why is it called Recurrent? In english the word recurrent means:\\noccurring often or repeatedly\\nIn the case of this type of Neural Network it’s called Recurrent since it does the same operation over and over on sets of se...   \n",
       "172  Apr 5, 2021\\nWhat is Optimizers?\\nOptimizers are algorithms used to reduce the loss function and update the weights in backpropagation.\\nHere is the formula used by all the optimizers for updating the weights with a certain value of the learning rate.\\nThis is the most common optimizer used in neural networks. The weights are updated when the whole dataset gradient is calculated, If there is a huge amount of data weights updation takes more time and required huge amount of RAM size memory which will slow down the process and computationally expensive.\\nThere is also a saddle point problem. This is a point where the gradient is zero but is not an optimal point.\\nIn some cases, problems like Vanishing Gradient or Exploding Gradient may also occur due to incorrect parameter initialization...   \n",
       "173  Towards Data Science\\nJul 4, 2021\\n“Isolation Forest” is a brilliant algorithm for anomaly detection born in 2009 (here is the original paper). It has since become very popular: it is also implemented in Scikit-learn (see the documentation).\\nIn this article, we will appreciate the beauty in the intuition behind this algorithm and understand how exactly it works under the hood, with the aid of some examples.\\nAnomaly (or outlier) detection is the task of identifying data points that are “very strange” compared to the majority of observations.\\nThis is useful in a range of applications, from fault detection to discovery of financial frauds, from finding health issues to identifying unsatisfied customers. Moreover, it can also be beneficial for machine learning pipelines, since it has be...   \n",
       "174  HackerNoon.com\\nOct 15, 2016\\nWord2Vec; the Steroids for Natural Language Processing\\nLet’s start with the Basics.\\nQ) What are word vectors?\\nAns) Representation of words with numbers.\\nQ) Why Word Vectors?\\nAns) I’ll sum it up with three main reasons:\\n1. Computer cannot do computations on strings.\\n2. Strings don’t hold much explicit information themselves.\\n3. Words Vectors are usually dense vector representations.\\nQ) So what is Explicit information?\\nAns) Yes, the word itself doesn’t say much about what it represents in real life. Example:\\nThe string “cat” just tells us it has three alphabets “c”, ”a” and “t”.\\nIt has no information about the animal it represents or the count or the context in which it is being used.\\nQ) Dense Vector Representation?\\nAns) Short answer (for now),...   \n",
       "175  Towards Data Science\\nMar 22, 2021\\nThere is no denying the fact that GANs are awesome! If you don’t know what they are, check out this article where I explain GANs from scratch to a 5-year old and how to implement GANs in Pytorch! In a nutshell, GANs belong to a category of generative models that let us generate incredibly realistic synthetic data, with the same qualities as that of the underlying training data. That means if you feed the model images of a few bedroom decors, after few hours of training it can generate never-seen-before brand-new ideas for your interior design.\\nOver the past few weeks, I have probably read a dozen papers on GANs (and its variants) and tinkered around with their code on custom images (courtesy open-source Github repos). While most of these papers are ...   \n",
       "176                                                                                                                                                                                                                   Oct 5, 2017\\nThe main motivation for this post was that I wanted to get more experience with Bayesian types of Variational Autoencoders (VAEs) using Tensorflow.\\nAutoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we’ll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed...\\n248 \\n248 \\n1\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "177  Cubo AI\\nFeb 4, 2018\\nComputer vision object detection models: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, YOLO\\n這篇是簡介一些用來辨識影像中物體的 AI 模型。\\n在前面有提到,透過 CNN 模型,你可以輸入一張圖片,得到該圖片屬於哪種類別的結果,這過程我們把他稱作分類 (Classification)。\\n但在真實世界的應用情境通常要從一張圖片中辨識所有出現的物體, 並且標示出位置來 (標出位置稱之為 Object Localization)。你一定在網路上看過類似底下的影片,這段影片可以看出中國閉路攝影機(CCTV)發展的概況,不只是可以框出影像中每個物件,辨別物件種類,偵測出移動物體的動量,甚至是人臉辨識,實現楚門世界的惡夢。要做到這就需要靠深度學習中的 Object Detection 演算法,這也是最近幾年來深度學習最蓬勃發展的一塊領域。\\n基本的想法是,既然 CNN 對於物體的分類又快又好,那我們可不可以拿 CNN 來掃描並辨識圖片中的任何物體? 答案當然是 — 可以。\\n最簡單的作法就是用 Sliding Windows 的概念,也就是用一個固定大小的框框,逐一的掃過整張圖片,每次框出來的圖像丟到 CNN 中去判斷類別。由於物體的大小是不可預知的,所以還要用不同大小的框框去偵測。但是 Sliding Window 是非常暴力的作法,對單一影像我們需要掃描非常多次,每掃一次都需要算一次 CNN,這將會耗費大量的運算資源,而且速度慢,根本無法拿來應用!\\n所以後來就有人提出了 R-CNN (Regions with CNN)\\n與其用 Sliding Window 的方式掃過一輪,R-CNN 的作法是預先篩選出約 2000 個可能的區域,再將...   \n",
       "178  Apr 26, 2012\\nInvestigating the human to computer relationship through reverse engineering the Turing test\\nHumans are getting closer to creating a computer with the ability to feel and think. Although the processes of the human brain are at large unknown, computer scientists have been working to simulate the human capacity to feel and understand emotions. This paper explores what it means to live in an age where computers can have emotional depth and what this means for the future of human to computer interactions. In an experiment between a human and a human disguised as a computer, the Turing test is reverse engineered in order to understand the role computers will play as they become more adept to the processes of the human mind. Implications for this study are discussed and the di...   \n",
       "179  Oct 9, 2020\\nAbstract\\nWith the ever-powerful deep learning algorithm, computer graphics have been pushed to a new level. The generative adversarial network (GAN) can now generate almost any type of photo-realistic images with the proper size of datasets. However, most of the GAN use cases have been limited to the pursue of lifelike graphics. In this article, I prose a new framework “MonsterGAN,” combining machine learning, design, and psychology. MonsterGAN is a prototype of a generative design system (DRCI), which reduces the cognitive burden of creation and makes creativity scalable, for concept artists.\\nWhat happens if computer vision passes the Turing test? Where and how can we use it? As a designer, I’m fascinated by these questions because we designers are the graphic wizards w...   \n",
       "180  Nurture.AI\\nFeb 2, 2018\\nIt’s currently an arms race in the tech scene right now with Deep Learning and Artificial Intelligence already the next industry-grade buzzword. Everyone’s looking to make the next big commercial success with a successful and innovative application of Artificial Intelligence.\\nOne such breakthrough is the use of deep learning neural networks to mathematically separate the content and style of images. What naturally entails is the idea of taking the content of one image and the style of another, and merging them both into one image. This idea was successfully implemented in 2015 by Gatys. et al in their paper “A Neural Algorithm of Artistic Style”.\\nSince then, there have been many insights and improvements of the base idea. Modern iterations of the algorithm ar...   \n",
       "181  Towards Data Science\\nMar 26, 2020\\nThe topics covered in this article include k-means, brown clustering, tf-idf, topic models and latent Dirichlet allocation (also known as LDA).\\nClustering is one of the biggest topics in data science, so big that you will easily find tons of books discussing every last bit of it. The subtopic of text clustering is no exception. This article can therefore not deliver an exhaustive overview, but it covers the main aspects. This being said, let us start by getting on common ground what clustering is and what it isn’t.\\nYou just scrolled by clusters!\\nIn fact, clusters are nothing more than groups that contain similar objects. Clustering is the process used for separating the objects into these groups.\\nObjects inside of a cluster should be as similar a...   \n",
       "182  Towards Data Science\\nApr 4, 2019\\nEvery ML practitioner knows that feature scaling is an important issue (read more here).\\nThe two most discussed scaling methods are Normalization and Standardization. Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\\nIn this blog, I conducted a few experiments and hope to answer questions like:\\nI’ll analyze the empirical results of applying different scaling methods on features in multiple experiments settings.\\nFirst, I was trying to understand what is the difference between Normalization and Standardization.So, I encountered this excellent blog by Sebastian Raschka that supplies a mathematical background that sat...   \n",
       "183  Towards Data Science\\nMar 4, 2020\\nWriting is always a good choice when it comes to clarifying one’s understandings of a given topic. By putting thoughts on papers, ideas will be clarified and confusions exposed. Though it might not be the most comfortable thing to do it’s indeed an efficient way to learn and improve.\\nIf you ever find yourself having a hard time explaining something to a friend, something you’ve been studying for a while but somehow still didn’t manage to portray the subject clearly and intuitively, you should try writing it down.\\nIn this article, I attempt to summarize some of the ideas for text representations in NLP, aiming to build a foundation for future complex concepts to come and hoping to contribute my granito de arena to your learning as well.\\nThe above di...   \n",
       "184  Nov 8, 2016\\nClarification: Gradient descent by itself is NOT robust to non-linearly separable data. However, when used with appropriate nonlinear activation functions it is.\\nThe reason is due to the kernel trick. In kernel trick, we apply a nonlinear transform on the data, so the resulting data set is linearly separable. This is illustrated below. Consider task of classifying blue and red points, they are not linearly separable. But what if we transform this data by adding a third variable (z = x2+y2), wecan draw a plane between blue and red points, and separate the two set of points. This is precisely what neural networks also do.\\nNeural networks’ learning can be viewed as a 2 part process where they learn some nonlinear transform of the data, and how to separate data based on this...   \n",
       "185  Edureka\\nFeb 10, 2017\\nThe majority of retail business holders find it hard to recognize customer needs. The reason why Data-driven companies such as Netflix, Walmart, Target, etc. are doing so well is that they have an army of Certified Data Analysts that grow their business by using the right tools to create personalized marketing strategies. We do understand that not all customers are alike and have the same taste. So, this leads to the challenge of marketing the right product to the right customer. An offer or product which might entice a particular customer segment may not be very helpful to other segments. So, you can apply the k-means clustering algorithm to segment your entire customer audience into groups with similar traits and preferences based on various metrics (such as th...   \n",
       "186  Towards Data Science\\nJun 8, 2019\\nDeep Learning has shown immense success in various fields and is continuing to spread its wings. But one of the major issues with training any traditional neural network model is the requirement of colossal amounts of data, and using this data to perform many iterative updates across many labeled examples.\\nLet’s take a look at a classic example of cats vs dogs classification. Although over the last two decades, we have made our models better and better to increase the accuracy, but the fundamental problem mentioned above still persists. We still need loads of labelled dogs and cats to get a decent accuracy.\\nHow do humans classify them with much lesser examples. Lets say all of a sudden you are shown two new animals, which are as visually distinguish...   \n",
       "187  Towards Data Science\\nNov 23, 2019\\nWhy should I care?\\nMany probability distributions are defined by using the gamma function — such as Gamma distribution, Beta distribution, Dirichlet distribution, Chi-squared distribution, and Student’s t-distribution, etc.For data scientists, machine learning engineers, researchers, the Gamma function is probably one of the most widely used functions because it is employed in many distributions. These distributions are then used for Bayesian inference, stochastic processes (such as queueing models), generative statistical models (such as Latent Dirichlet Allocation), and variational inference. Therefore, if you understand the Gamma function well, you will have a better understanding of a lot of applications in which it appears!\\nBecause we want to ...   \n",
       "188  Towards Data Science\\nFeb 15, 2019\\nA convolution is how the input is modified by a filter. In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge. Each time a match is found, it is mapped out onto an output image.\\nFor example, there is a picture of Eileen Collins and the matrix above the red arrow is used as a convolution to detect dark edges. As a result, we see an image where only dark edges are emphasized.\\nNote that an image is 2 dimensional with width and height. If the image is colored, it is considered to have one more dimension for RGB color. Fo...   \n",
       "189  Jan 11, 2016\\nClustering and dimension reduction algorithms help you to explore a dataset. Clustering and dimension reduction are unsupervised learning algorithms i.e., they don’t need labelled data to build a model. k-means is a popular clustering algorithm — you specify the the number of clusters (k) and it then finds the best cluster for each data instance. Choosing a good initial value for the number of clusters (k) can be problematic as k can be anything between 1 and the number of data instances. Finding the number of clusters is an active research field and techniques do exist (such as the Silhouette coefficient) but have varying success as the dimensionality of the data increases. I’m not going to go into any of these other techniques to find k in this blog post. Instead I’m go...   \n",
       "190  Towards Data Science\\nJan 27, 2019\\nClustering is one of the most common unsupervised machine learning problems. Similarity between observations is defined using some inter-observation distance measures or correlation-based distance measures.\\nThere are 5 classes of clustering methods:\\n+ Hierarchical Clustering+ Partitioning Methods (k-means, PAM, CLARA)+ Density-Based Clustering+ Model-based Clustering+ Fuzzy Clustering\\nMy desire to write this post came mainly from reading about the clustree package, the dendextend documentation, and the Practical Guide to Cluster Analysis in R book written by Alboukadel Kassambara author of the factoextra package.\\nI will be using a lesser known data set from the cluster package: all.mammals.milk.1956, one which I haven’t looked at before.\\nThis sm...   \n",
       "191  Towards Data Science\\nJan 7, 2019\\nThis post was co-written with Baptiste Rocca.\\nYann LeCun described it as “the most interesting idea in the last 10 years in Machine Learning”. Of course, such a compliment coming from such a prominent researcher in the deep learning area is always a great advertisement for the subject we are talking about! And, indeed, Generative Adversarial Networks (GANs for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article Generative Adversarial Nets.\\nSo what are Generative Adversarial Networks ? What makes them so “interesting” ? In this post, we will see that adversarial training is an enlightening idea, beautiful by its simplicity, that represents a real conceptual progress for Machine Learning...   \n",
       "192  Insight\\nNov 13, 2015\\nSlater Stich is an Insight alum and was previously a Staff Data Scientist at Square. He is currently a Vice President at Valor Equity Partners.\\nSeaborn is a Python data visualization library with an emphasis on statistical plots. The library is an excellent resource for common regression and distribution plots, but where Seaborn really shines is in its ability to visualize many different features at once.\\nIn this post, we’ll cover three of Seaborn’s most useful functions: factorplot, pairplot, and jointgrid. Going a step further, we'll show how we can get even more mileage out of these functions by stepping up to their even-more-powerful forms: FacetGrid, PairGrid, and JointGrid.\\nTo showcase Seaborn, we’ll use the UCI “Auto MPG” data set. We did a bit of prepr...   \n",
       "193  SomX Labs\\nSep 2, 2016\\nSimple Definition:\\nA collection of similar objects to each other.\\nSlightly Complex Definition:\\nA connected component of a level set of the probability density function of underlying (and unknown) distribution from which our data samples are drawn.\\nYou are posed with a problem to solve, what you have is a large amount of data represented in lot of dimensions. The data can not be read or understood by looking at it raw by a human.\\nEven before you start defining your problem (hypothesis), you need to understand the data, perform an EDA on it. There are multiple ways to do it.\\nA. Perform Clustering\\nPerfect! Clustering is a good way of identifying interesting parts of data by grouping it.\\nClustering is a process of grouping a sample of data into smaller simil...   \n",
       "194                                                                                                                                                                                                      OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder & CEO of Gado Images. I write, speak & consult about tech, food, privacy, AI & photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "195  Aug 23, 2020\\nA simple Image classifier model to demonstrate the usage of VGG-19Deep Learning Model to predict input image. This model is developed in python programming and executed on a Colab notebook. At the end of this article you will learn how to develop a simple image classifier application that uses Pytorch Python based Deep Learning library to predict an image.\\nAt the end of this article you will learn:\\nVGG-19 is a variant of VGG model which in short consists of 19 layers (16 convolution layers, 3 Fully connected layer, 5 MaxPool layers and 1 SoftMax layer). There are other variants of VGG like VGG11, VGG16 and others.\\nAlexNet came out in 2012 and it improved on the traditional Convolutional neural networks, So we can understand VGG as a successor of the AlexNet.\\nVGG means...   \n",
       "196  Jan 27, 2019\\nAs all you have probably heard by now, an AI called AlphaStar developed by Google Deepmind has recently beaten human professionals in the real-time strategy game Starcraft 2. This is an unprecedented feat in the field of AI. However, I do have some constructive criticism about the way they did it.\\nI will try to make a convincing argument for the following:\\nFirst of all, I want to clarify that I am a layman. I’ve been following AI development and the Starcraft 2 scene for years but I do not claim to be an expert in either topic. If you notice any misconceptions in what I’m about to write please do point them out. I’m only a fanboy and all of this is incredibly fascinating to me. This essay will contain a lot of speculation and I admit that I can’t prove all of my core cl...   \n",
       "197  Towards Data Science\\nJan 16, 2020\\nIntroduction:\\nBefore we begin, let’s go to this website to get some inspiration. On the website, we choose a photo from the local computer (let’s assume the image named Joey.jpg). Let’s call this content image. Then we choose another image, say style image named style1.jpg from the local computer. What this website does is produces a mixed image that preserves the contours of the content image and adds the texture and color pattern from the style image to the content image. Following is the result.\\nDescription:\\nThis is called Neural Style Transfer (NST) and is done by using Deep Learning, Convolution Neural Network (CNN) to be specific. I assume you are familiar with CNN. If not, I would highly recommend Andrew Ng’s Course on CNN.\\nLet us understa...   \n",
       "198  Towards Data Science\\nNov 13, 2019\\nYou need to have a good understanding of:\\nAnd some basic knowledge of:\\nImage data used in this project has been collected from WikiArts.org.\\nIn this tutorial, we are going to look at the step by step process to create a Generative Adversarial Network to generate Modern Art and write a code for that using Python and Keras together.\\nAfter that, for training the model, we are going to use a powerful GPU Instance of Spell platform. Everything will be explained along the way and links will be provided for further readings.\\nLet’s get started!\\nBefore getting started, let’s look at our image dataset.\\nWikiArt has a huge collection of modern art with various different styles. For our particular project, we are going to use images of Cubism Style.\\nYou c...   \n",
       "199  SyncedReview\\nSep 25, 2017\\nAttention is simply a vector, often the outputs of dense layer using softmax function.\\nBefore Attention mechanism, translation relies on reading a complete sentence and compress all information into a fixed-length vector, as you can image, a sentence with hundreds of words represented by several words will surely lead to information loss, inadequate translation, etc.\\nHowever, attention partially fixes this problem. It allows machine translator to look over all the information the original sentence holds, then generate the proper word according to current word it works on and the context. It can even allow translator to zoom in or out (focus on local or global features).\\nAttention is not mysterious or complex. It is just an interface formulated by paramete...   \n",
       "200  Analytics Vidhya\\nAug 22, 2020\\nThis blog details the steps for Named Entity Recognition (NER) tagging of sentences (CoNLL-2003 dataset ) using Tensorflow2.2.0\\nCoNLL-2003 dataset includes 1,393 English and 909 German news articles. We will be looking at the English data. The CoNLL-2003 data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of t...   \n",
       "201  Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...   \n",
       "202  Analytics Vidhya\\nFeb 19, 2021\\nPrerequisites\\nThis article assumes that you are familiar with the basic theory behind PCA, K Means Algorithm and know Python programming language.\\nK Means clustering is one of the simplest yet efficient unsupervised algorithms. First let us have a brief description of what this algorithm does.\\nK Means Algorithm Suppose we have a dataset with two features x1 and x2. This is unlabelled data and our objective is to find K number of groups or “clusters” which are similar to each other. Suppose our training set looks like this :-\\nWe can clearly see there are two clusters, let us name them cluster 0 and cluster 1. Each cluster is associated with a centroid which is unique to each cluster. This algorithm iterates until the centroids do not change its positi...   \n",
       "203  A problem like Maria\\nOct 23, 2011\\nAI Class is a great experiment by two professors at the Stanford University: Sebastian Thrun and Peter Norvig. The course is being held as an actual course at Stanford University plus an online course for about 160,000 enrolled students. People in the advanced track have to do homework and write exams, people in the basic track just have to watch the lectures. Currently I’m in the advanced track, although I might switch to the basic track due to time problems (having a full time job + working on a private application + a University course is a bit too much). At the end of the course you’ll get a certificate, sadly not from Stanford but still. Pretty cool having done a course at Stanford... kind of.\\nI think it’s a great experience to attend a course ...   \n",
       "204  Towards Data Science\\nApr 10, 2019\\nAutomatic text classification or document classification can be done in many different ways in machine learning as we have seen before.\\nThis article aims to provide an example of how a Recurrent Neural Network (RNN) using the Long Short Term Memory (LSTM) architecture can be implemented using Keras. We will use the same data source as we did Multi-Class Text Classification with Scikit-Lean, the Consumer Complaints data set that originated from data.gov.\\nWe will use a smaller data set, you can also find the data on Kaggle. In the task, given a consumer complaint narrative, the model attempts to predict which product the complaint is about. This is a multi-class text classification problem. Let’s roll!\\nAfter first glance of the labels, we realized t...   \n",
       "205  Towards Data Science\\nJan 18, 2021\\nGradient descent is an important algorithm to understand, as it underpins many of the more advanced algorithms used in Machine Learning and Deep Learning. Getting to grips with the inner workings of gradient descent will therefore be of great benefit to anyone who plans on exploring ML algorithms further.\\nThe best way to learn is by doing, so in this article I will be walking through the steps of how the gradient descent process works, without using ML libraries such as scikit-learn for example. In day-to-day work, it is of course quicker and neater to make use of such libraries, but regarding the learning process I have found the exercise of implementing by hand to be invaluable for this particular algorithm.\\nThe goal of gradient descent is to min...   \n",
       "206  SyncedReview\\nFeb 27, 2019\\nWith just a mouse click, you can delight in mega-litters of adorable kitties, admire countless fresh anime characters, or stare into the twinkling eyes of all sorts of beautiful people. The only catch is that they’re all fake. As Synced previously reported, these hyperrealistic images now flooding the Internet come from US chip giant NVIDIA’s StyleGAN, a generative adversarial network based face generator that performs so well that most people can’t distinguish its creations from photos of real people.\\nSoon after StyleGAN was open-sourced earlier this month, Uber software engineer Philip Wang used the tool to create “This Person Does Not Exist,” a website which generates a new hyperrealistic fake human face every time it’s refreshed. The site quickly went v...   \n",
       "207                                                                                       The Startup\\nJun 26, 2020\\nConventional CNNs (AlexNet, VGG, GoogLeNet, ResNet, DenseNet ...) have good performances when there are many samples for each class in the dataset. Unfortunately, they generally do not work well when you have a small dataset. However, there are many real-life scenarios where it is challenging to gather data for your classes. For example, in face identification systems, there are...\\n373 \\n373 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n77 Followers\\nDeep learning researcher. PhD candidate at @METU. https://www.linkedin.com/in/gorkempolat/\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "208  UX Planet\\nJul 17, 2018\\nDashboard design is a frequent request these days. Businesses dream about a simple view that presents all information, shows trends and risky areas, updates users on what happened — a view that will guide them into a bright financial future.\\nFor me, a dashboard — is an at a glance preview of the most crucial information for the user at the moment he is looking at it, and an easy way to navigate directly to various areas of the application that require users attention. The term “dashboard” is a metaphor for a car dashboard, sometimes also called the cockpit area, usually near the front of an aircraft or spacecraft, from which a pilot controls the aircraft.\\nWorking on enterprise projects for years, I have designed countless dashboards. And every new one is the ...   \n",
       "209  Becoming Human: Artificial Intelligence Magazine\\nOct 1, 2021\\nIn Part 3 of the Transfer Learning series we have discussed the datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch. In this, article we will discuss theoretically about the VGG-16 and VGG-19 and in article 4.2 and 4.3 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:\\nbecominghuman.ai\\nFor the repository and document please follow below two mentioned links:\\nKeras:\\nkeras.io\\nPyTorch:\\npytorch.org\\nAlexNet came out in 2012 and it improved on the...   \n",
       "210  SyncedReview\\nMar 5, 2020\\nThis is an updated version.\\nIn a bid to help the global research community better understand the coronavirus, DeepMind today released the structure predictions for six proteins associated with SARS-CoV-2, the virus that causes COVID-19, using the most up-to-date version of their AlphaFold system.\\nAs the world struggles with the COVID-19 outbreak, one research team after another in the global scientific community has stepped up to offer expertise, tools and possible solutions. In the early stages of the outbreak front-line labs open-sourced genomes of the virus which enabled other researchers to rapidly develop tests around the pathogen. Other labs modelled the coronavirus infection peak or produced molecular structures to develop drug compounds and treatmen...   \n",
       "211  Towards Data Science\\nJan 11, 2019\\nIn this blog, we will discuss the workflow of a Machine learning project this includes all the steps required to build the proper machine learning project from scratch.\\nWe will also go over data pre-processing, data cleaning, feature exploration and feature engineering and show the impact that it has on Machine Learning Model Performance. We will also cover a couple of the pre-modelling steps that can help to improve the model performance.\\nPython Libraries that would be need to achieve the task: 1. Numpy 2. Pandas 3. Sci-kit Learn 4. Matplotlib\\nWe can define the machine learning workflow in 3 stages.\\nOkay but first let’s start from the basics\\nThe machine learning model is nothing but a piece of code; an engineer or data scientist makes it smart ...   \n",
       "212  May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...   \n",
       "213  Towards Data Science\\nJul 3, 2019\\nIn Part I of Multi-Class Metrics Made Simple, I explained precision and recall, and how to calculate them for a multi-class classifier. In this post I’ll explain another popular performance measure, the F1-score, or rather F1-scores, as there are at least 3 variants. I’ll explain why F1-scores are used, and how to calculate them in a multi-class setting.\\nBut first, a BIG FAT WARNING: F1-scores are widely used as a metric, but are often the wrong way to compare classifiers. You will often spot them in academic papers where researchers use a higher F1-score as “proof” that their model is better than a model with a lower score. However, a higher F1-score does not necessarily mean a better classifier. Use with care, and take F1 scores with a grain of sal...   \n",
       "214  Saúde Digital\\nJan 10, 2014\\nMuitas novidades foram apresentadas durante o congresso em Chicago. Muita inovação entre as aulas e sessões. Apresentações científicas com novas aplicações de conhecidas tecnologias e alguns novos protótipos. Diante de tanto conteúdo, seis dias passam rápido para quem gosta de tecnologia. Tentei elencar as cinco coisas mais bacanas que vi em termos de inovação e TI:\\n1. PACS 3.0\\nTermo repetido em inúmeras palestras. Ficou nítido que estamos diante de uma nova geração de PACS. Ferramentas de manipulação de imagens e workflow (manejo de worklists, aplicativos de laudo automatizados e reconhecimento de voz) já são considerados standart, e anualmente melhorados. As próximas versões de PACS, algumas já lançadas durante a feira, deverã...   \n",
       "215  Netflix TechBlog\\nMar 21, 2016\\nWe have a collection of nearly two million images that play very prominent roles in helping members pick what to watch. This blog describes how we use computer vision algorithms to address the challenges of focal point, text placement and image clustering at a large scale.\\nAll images have a region that is the most interesting (e.g. a character’s face, sharpest region, etc.) part of the image. In order to effectively render an image on a variety of canvases like a phone screen or TV, it is often required to display only the interesting region of the image and dynamically crop the rest of an image depending on the available real-estate and desired user experience. The goal of the focal point algorithm is to use a series of signals to identify the most int...   \n",
       "216  Towards Data Science\\nMar 5, 2019\\nHere’s something that might surprise you: neural networks aren’t that complicated! The term “neural network” gets used as a buzzword a lot, but in reality they’re often much simpler than people imagine.\\nThis post is intended for complete beginners and assumes ZERO prior knowledge of machine learning. We’ll understand how neural networks work while implementing one from scratch in Python.\\nLet’s get started!\\nNote: I recommend reading this post on victorzhou.com — much of the formatting in this post looks better there.\\nFirst, we have to talk about neurons, the basic unit of a neural network. A neuron takes inputs, does some math with them, and produces one output. Here’s what a 2-input neuron looks like:\\n3 things are happening here. First, each inpu...   \n",
       "217  Analytics Vidhya\\nJan 26, 2020\\nApplication to predict fruits using Mask_RCNN on custom dataset, this is a easy tutorial to how create a object detection application for a custom dataset, as a sample we are using a dataset of tropical fruits in this case only ( Oranges and Pineapple).\\nsource code in github : https://github.com/bernardcaldas/object-detection-custom-maskrcnn\\nin recent years we can see a lot applications in our life including, autonomous cars, facial detections app, education, military, finance etc.\\nInstance segmentation it's a task to identifying objects , detecting and delineating each distinct object of interest appearing in an image.\\nFollow the post created for Waleed Abdulla explaining how works Mask R-CNN one of the most used algorithm for image segmentation and...   \n",
       "218                                                                                                                                                                                                                                                                                                                                                                                                                                                   Nov 17, 2019\\nwww.tensorflow.org\\nLet’s get started!\\nIn the previous posting, we have finished two things, first, loading the dependent libraries to our workspace,\\n54 \\n54 \\n1\\nYdobon is nobody.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n85 Followers\\nYdobon is nobody.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "219  SyncedReview\\nJun 15, 2018\\nThe paper Relational inductive biases, deep learning, and graph networks, published last week on arXiv by researchers from DeepMind, Google Brain, MIT and University of Edinburgh, has stimulated discussion in the artificial intelligence community. The paper introduces a new machine learning framework called Graph Networks, which some believe promises huge potential for approaching the holy grail of artificial general intelligence.\\nDue to the development of big data and increasingly powerful computational resources over the past few years, modern AI technology — primarily deep learning — has show its prowess and even outsmarted humans in tasks such as image recognition and speech detection. However, AI remains challenged by tasks that involve complicated lea...   \n",
       "220  Towards Data Science\\nSep 15, 2015\\nData Science for Newbies (including me!)\\nI’ve studied math, I’ve studied computer science, and of course I’ve focused on machine learning algorithms. But I’m still new to the field of data science. I don’t know yet how or whether I can make an impact. But if I explain what it is, then people will know what I can do, what I could learn to do, and most importantly, what they can ask me to do. Here’s the primer.\\nThere are several types of machine learning algorithms, but my focus is on finding patterns in data. Those patterns could be entirely numerical, they could be graphical, or they could even be written out in words. Humans are very good at finding patterns, even going too far sometimes and making stereotypes. We’re at a point where many people j...   \n",
       "221  May 11, 2018\\nAdversarial attacks have been a concerning topic in the field of deep learning research in recent years. We’ve long since known that deep neural networks don’t generate perfect classification boundaries (this article in 2013. .. Yes, 2013 is a long time ago in fields related to deep learning.). Researchers have found numerous ways to generate adversarial examples to cause models to make mistakes (see e.g. this review paper and reference therein). This is obviously dangerous in commercial applications such as self-driving cars, automated robots, and other audio/visual recognition tasks. The vulnerability to adversarial examples is one of the major risks for applying deep neural networks in safety-critical scenarios.\\nBefore we go into our implementation, we need to categor...   \n",
       "222  Towards Data Science\\nJun 10, 2018\\nIf you want a computer to recognize text, neural networks (NN) are a good choice as they outperform all other approaches at the moment. The NN for such use-cases usually consists of convolutional layers (CNN) to extract a sequence of features and recurrent layers (RNN) to propagate information through this sequence. It outputs character-scores for each sequence-element, which simply is represented by a matrix. Now, there are two things we want to do with this matrix:\\nBoth tasks are achieved by the CTC operation. An overview of the handwriting recognition system is shown in Fig. 1.\\nLet’s have a closer look at the CTC operation and discuss how it works without hiding the clever ideas it is based on behind complicated formulas. At the end, I will poin...   \n",
       "223  agolo\\nApr 19, 2021\\nAutomatic text summarization is the task of automatically identifying the salient topics/key-phrases in a document(s) and then either generates or extracts a summary.\\nCurrently, most state-of-the-art summarizers are focused on single, short document summarization. Recent progress in summarization, mostly transformers-based, struggles with long inputs due to the architecture limitations, which have led many researchers to explore using new ideas like the longformer to overcome this issue. However, the final summaries are 5–10 sentences long that lacks coherence, and don’t give enough info about the original document. And of course, such methods can’t handle even tougher situations where the input is more than one long document. Similar observations could be found w...   \n",
       "224  Oct 22, 2019\\nThis guide assumes rudimentary knowledge of reinforcement learning and the structure of OpenAI Gym environments, along with proficiency in Python.\\nMany of the standard environments for evaluating continuous control reinforcement learning algorithms are built on the MuJoCo physics engine, a paid and licensed software. Bullet Physics provides a free and open source alternative to physics simulation with OpenAI Gym offering a set of environments built upon it. PyBullet is a library designed to provide Python bindings to the lower level C-API of Bullet. We will use PyBullet to design our own OpenAI Gym environments.\\nThis post will be the first of a two part series.\\nWe’ll go through building an environment step by step with enough explanations for you to learn how to indepe...   \n",
       "225  Towards Data Science\\nSep 17, 2018\\nIn Logistic Regression, we wish to model a dependent variable(Y) in terms of one or more independent variables(X). It is a method for classification. This algorithm is used for the dependent variable that is Categorical. Y is modeled using a function that gives output between 0 and 1 for all values of X. In Logistic Regression, the Sigmoid (aka Logistic) Function is used.\\nAfter we train a logistic regression model on some training data, we will evaluate the performance of the model on some test data. For this, we use the Confusion Matrix. A Confusion Matrix is a table that is often used to describe the performance of the classification model on a set of test data for which the true values are already known. Given below is a Confusion Matrix.\\nHere, ...   \n",
       "226  Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...   \n",
       "227  Inside Machine learning\\nJan 4, 2019\\nNew deep learning models are introduced at an increasing rate and sometimes it’s hard to keep track of all the novelties. That said, one particular neural network model has proven to be especially effective for common natural language processing tasks. The model is called a Transformer and it makes use of several methods and mechanisms that I’ll introduce here. The papers I refer to in the post offer a more detailed and quantitative description.\\nThe paper ‘Attention Is All You Need’ describes transformers and what is called a sequence-to-sequence architecture. Sequence-to-Sequence (or Seq2Seq) is a neural net that transforms a given sequence of elements, such as the sequence of words in a sentence, into another sequence. (Well, this might not surp...   \n",
       "228  SyncedReview\\nSep 18, 2019\\nWave function represents the quantum state of an atom, including the position and movement states of the nucleus and electrons. For decades researchers have struggled to determine the exact wave function when analyzing a normal chemical molecule system, which has its nuclear position fixed and electrons spinning. Fixing wave function has proven problematic even with help from the Schrödinger equation.\\nPrevious research in this field used a Slater-Jastrow Ansatz application of quantum Monte Carlo (QMC) methods, which takes a linear combination of Slater determinants and adds the Jastrow multiplicative term to capture the close-range correlations.\\nNow, a group of DeepMind researchers have brought QMC to a higher level with the Fermionic Neural Network — or ...   \n",
       "229  Towards Data Science\\nJul 13, 2020\\nToday’s data comes in all shapes and sizes. NLP data encompasses the written word, time-series data tracks sequential data movement over time (ie. stocks), structured data which allows computers to learn by example, and unclassified data allows the computer to apply structure. Whichever dataset you possess, you can be sure there is an algorithm ready to decipher its secrets. In this article, we want to cover a clustering algorithm named KMeans which attempts to uncover hidden subgroups hiding in your dataset. Furthermore, we will examine what effects dimension reduction has on the quality of the clusters obtained from KMeans.\\nIn our example, we will be examining a human resources dataset consisting of 15,000 individual employees. The dataset contain...   \n",
       "230  Technology, Invention, App, and More\\nDec 28, 2015\\nThe year 2015 was a monumental year in the field of artificial intelligence. Not only are computers learning more and learning faster, but we’re learning more about how to improve their systems. Everything is starting to align, and because of it we’re seeing strides we’ve never thought possible until now. We have programs that can tell stories about pictures. We have cars that are driving themselves. We even have programs that create art. If you want to read more about advancements in 2015, read this article. Here at Josh.ai, with AI technology becoming the core of just about everything we do, we think it’s important to understand some of the common terminology and to get a rough idea of how it all works.\\nA lot of the advances in art...   \n",
       "231  Towards Data Science\\nFeb 12, 2021\\nExcitement is building in the artificial intelligence community around MIT’s recent release of liquid neural networks. The breakthroughs that Hasani and team have made are incredible.\\nLet’s dive in.\\nArtificial intelligence research and applications involve the construction and training of deep neural networks. Until liquid neural networks, all deep learning systems have shared the same vulnerability — namely, that they learn a fixed mapping from input data to output prediction based on the training data that they are shown, making them brittle to the shifting environment around them. Furthermore, most deep learning models are context independent. For example, when applying an object detection model or a classification model to a video, the video wi...   \n",
       "232  Dec 19, 2016\\nWhen we offered CS231n (Deep Learning class) at Stanford, we intentionally designed the programming assignments to include explicit calculations involved in backpropagation on the lowest level. The students had to implement the forward and the backward pass of each layer in raw numpy. Inevitably, some students complained on the class message boards:\\n“Why do we have to write the backward pass when frameworks in the real world, such as TensorFlow, compute them for you automatically?”\\nThis is seemingly a perfectly sensible appeal - if you’re never going to write backward passes once the class is over, why practice writing them? Are we just torturing the students for our own amusement? Some easy answers could make arguments along the lines of “it’s worth knowing what’s unde...   \n",
       "233                                                      Nov 7, 2013\\nMachine learning (ML) is one of the hottest fields in data science. As soon as ML entered the mainstream through Amazon, Netflix, and Facebook people have been giddy about what they can learn from their data. However, modern machine learning (i.e. not the theoretical statistical learning that emerged in the...\\n275 \\n275 \\n2\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n548 Followers\\n@nomadic_mind. Sometimes the difference between success and failure is the same as between = and ==. Living is in the details.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "234  Towards Data Science\\nJun 7, 2019\\nIn this tutorial, I will quickly go through the details of four of the famous CNN architectures and how they differ from each other by explaining their W3H (When, Why, What, and How)\\nWhen?\\nWhy? AlexNet was born out of the need to improve the results of the ImageNet challenge. This was one of the first Deep convolutional networks to achieve considerable accuracy on the 2012 ImageNet LSVRC-2012 challenge with an accuracy of 84.7% as compared to the second-best with an accuracy of 73.8%. The idea of spatial correlation in an image frame was explored using convolutional layers and receptive fields.\\nWhat? The network consists of 5 Convolutional (CONV) layers and 3 Fully Connected (FC) layers. The activation used is the Rectified Linear Unit (ReLU). The ...   \n",
       "235  Towards Data Science\\nSep 3, 2019\\nPlease consider using the Simple Transformers library as it is easy to use, feature-packed, and regularly updated. The article still stands as a reference to BERT models and is likely to be helpful with understanding how BERT works. However, Simple Transformers offers a lot more features, much more straightforward tuning options, all the while being quick and easy to use! The links below should help you get started quickly.\\nThe Pytorch-Transformers (now Transformers) library has moved on quite a bit since this article was written. I recommend using SimpleTransformers as it is kept up to date with the Transformers library and is significantly more user-friendly. While the ideas and concepts in this article still stand, the code and the Github repo are...   \n",
       "236  Dec 28, 2019\\nObject detection has been quite a center of attraction nowadays because of its wide range of applications and advancements in Deep Learning technology. Object Detection is a subdomain of image processing and computer vision that deals with identifying and localizing objects in videos or digital images. The credit for the evolution of object detection goes to the breakthrough in deep learning classification algorithms called CNN- Convolutional Neural Network and Graphic Processing Units that have shown great leads in the development of real-world solutions for computer vision problems like autonomous driving car, face detection and recognition, people detection, and tracking, video surveillance, security system design, etc.\\nObject detection can be done either using machin...   \n",
       "237  Towards Data Science\\nApr 2, 2018\\nIn this post I reproduce two recent papers in the field of metalearning: MAML and the similar Reptile. The full notebook for this reproduction can be found here.\\nThe goal of both of these papers is to solve the K-shot learning problem. In K-shot learning, we need to train a neural network to generalize based on a very small number of examples (often on the order of 10 or so) instead of the often thousands of examples we see in datasets like ImageNet.\\nHowever, in preparation for K-shot learning, you are allowed to train on many similar K-shot problems to learn the best way to generalize based on only K examples.\\nThis is learning to learn or metalearning. We have already seen metalearning in my post on “Learning to Learn by Gradient Descent by Gradie...   \n",
       "238  Nov 20, 2020\\n今年人工智慧年會中,偶然聽到講師呼籲大家,都2020了,不要再用Adam了,請改用Ranger,因此著手來寫一篇Ranger的筆記。\\n今年有兩篇優化器相關的論文被提出,分別是LookAhead和RAdam,這兩種方法用不同角度對深度學習的優化做改進,後來研究員 Less Wright將兩個方法整合成一個新的優化器:Ranger,得到了更好的成果。\\n廢話不多說,先上PyTorch實現的GitHub:https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\\n要了解RAdam 和 LookAhead 是如何互補的,需要先分別討論他們的概念。\\n全名是Rectified Adam,白話地說,就是自動熱身(warmup)版的Adam。\\n概念\\nAdam是一種常用的自適應學習率 (adptive learning rate) 優化器,但類方法在訓練的初期,adptive learning rate的變異非常大,然後在少量的數據進行過度跳躍,下了錯誤決策,就容易收斂在local minimum。\\n為了解決這個問題,RAdam根據adaptive rate的變異程度去修正learning rate,讓Adam可以自動熱身,不需再手動調整,也避免模型收斂在local minimum。\\n概念是這樣:有個熱身用的開關,閥值為rho,這個rho代表adpative learning rate分配的自由度:\\n優點\\n如此的做法,讓RAdam在享有Adam快速收斂優勢的同時,又達到跟SGD差不多好的收斂結果。RAdam詳細概念可以參考我寫的另一篇文章:https://is.gd/2yxrE7。\\n2020由深度學習教父Geoffrey Hinton團隊發表的論文,LookAhead基於損失空...   \n",
       "239  Towards Data Science\\nMar 20, 2019\\nAbbreviations using in this post:\\nIn my previous post, we discussed about Linear Regression. Let’s take a look back. Linear Regression is applied for the data set that their values are linear as below example:\\nAnd real life is not that simple, especially when you observe from many different companies in different industries. Salary of 1 YE teacher is different from 1 YE engineer; even 1 YE civil engineer is different from mechanical engineer; and if you compare 2 mechanical engineers from 2 different companies, their salary mostly different as well. So how can we predict the salary of a candidate?\\nToday, we will use another data set to represent the Polynomial shape.\\nTo get an overview of the increment of salary, let’s visualize the data set into...   \n",
       "240  Apr 22, 2019\\nI was supposed to Install Linux in my PC which is having a storage of 500GB with Windows in it ,So as a regular Linux installation procedure I unallocated 60GB and started to install the linux OS during the installation I found something fishy ,The Unallocated space was not showing up as a free space to install the Operating System ,I was like What the heck is this as usual Searched this issue in the Internet and discussed it with my techie friends all they told is “YOU HAVE TO CONVERT GPT TO MBR” and they suggested me some tools too like MINITOOL PARTITION WIZARD,ES PARTITION MASTER but everything ended up in Popping up for PREMIUM ACCESS to perform the particular action .It again started to irritate me a lot , I restarted my Computer several times again and again and en...   \n",
       "241  Towards Data Science\\nSep 25, 2018\\nWhen working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier. The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\\nThis is what we are going to do today: use everything that we have presented about text classification in the previous articles (and more) and comparing between the tex...   \n",
       "242                                                                                                                                                                                                                                       AI3 | Theory, Practice, Business\\nFeb 24, 2020\\nWelcome back to my blog for engineers who want to learn AI!\\nStarting with this post, we’ll be launching into a new series of articles on pre-training in NLP. Today, we’ll begin by forming a big picture.\\n394 \\n394 \\nThe AI revolution is here! Navigate the ever changing industry with our thoughtfully written articles whether your a researcher, engineer, or entrepreneur\\n298 Followers\\nNLP Engineer, Google Developer Expert, AI Specialist in Yodo1\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "243  Towards Data Science\\nMar 11, 2021\\nYou must definitely have encountered the problem when training a model is getting slower for a very Deep Neural Network. This phenomenon happens prominently during the backpropagation training (using Gradient Descent) of the DNNs, wherein, each parameter’s gradient error is propagated along its way to the lower layers of the network. Why? This usually happens because gradients usually get smaller and smaller. As a result, the lower layers weights never change and training never converges to the good solution.\\nThis post categorically discuss about the ways to alleviate the Vanishing Gradient (or the Exploding Gradient) problem while training the DNNs\\nThere are various ways to overcome this challenge —\\nLet’s look into all these in detail...\\nWe know...   \n",
       "244  Towards Data Science\\nNov 18, 2021\\n“Symmetry, as wide or as narrow as you may define its meaning, is one idea by which man through the ages has tried to comprehend and create order, beauty, and perfection.”\\nThis somewhat poetic description by Hermann Weyl [1] underlines the cornerstone role of symmetry in science. Felix Klein’s 1872 “Erlangen Programme” [2] characterised geometries through symmetry groups. Not only was this a breakthrough in mathematics, unifying the “zoo of geometries,” but also led to the development of modern physical theories that can be entirely derived from the first principles of symmetry [3]. Similar principles have emerged in machine learning under the umbrella of Geometric Deep Learning, a general blueprint for deriving the majority of popular neural networ...   \n",
       "245  Jun 14, 2020\\nDisclaimer: This project was developed by Kaspar Hollo and Nurlan Kerimov for the Neural Networks course at the University of Tartu. The data and the code used in this project are not public and, in this blog-post only a few examples from the dataset will be shown. The data was provided by PerkinElmer.\\nNowadays, microscopy images are often used for doing medical diagnosis. For example, in this paper, a deep learning model was developed to count mitotic cells to help diagnose breast cancer. There is a problem though — the captured microscopy images may contain some so-called anomalies which can be considered as noise. It is found that the cell count and position predictions (cell segmentation) are performing badly in areas with anomalies. In our project, we tried to predi...   \n",
       "246  Towards Data Science\\nJul 10, 2018\\nNeural networks (NN) consisting of convolutional NN layers and recurrent NN layers combined with a final connectionist temporal classification (CTC) layer are a good choice for (handwritten) text recognition.\\nThe output of the NN is a matrix containing character-probabilities for each time-step (horizontal position), an example is shown in Fig 1. This matrix must be decoded to get the final text. One algorithm to achieve this is beam search decoding which can easily integrate a character-level language model.\\nWe will start our discussion with a recap of CTC and best path decoding. Then we will discuss the building blocks (basic algorithm, CTC scoring, language model) of the CTC beam search decoding algorithm. Finally, I will point you to a Python i...   \n",
       "247  Towards Data Science\\nMay 10, 2021\\nAs advances in AI continue to progress in leaps and bounds, accessibility to data science at a base level has become increasingly democratized. Traditional entry barriers to the field such as a lack of data and computing power have been swept aside with a continuous supply of new data startups popping up(some offering access for as little as a cup of coffee a day) and all powerful cloud computing removing the need for expensive onsite hardware. Rounding out the trinity of prerequisites, is the skill and know-how to implement, which has arguably become the most ubiquitous aspect of data science. One does not need to look far to find online tutorials touting taglines like “implement X model in seconds” , “apply Z method to your data in just a few lines...   \n",
       "248  Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...   \n",
       "249  Towards Data Science\\nJul 22, 2019\\nIn this article we will explore and understand the architecture and workings of different computer vision algorithm CNN, Region-based CNN(R-CNN), Fast R-CNN, Faster R-CNN. In the next article, we will explore Mask R-CNN and YOLO(You only look once)\\nWhat is the purpose of Computer Vision?\\nComputer vision is a subfield of AI. It is used to enable computers to understand, identify and generate intelligent understanding of the digital images the same way human vision does.\\nWhat does Computer Vision do?\\nUsing Computer vision we can identify\\nWhen we view an image, we scan the image. We may view an image from left to right or top to bottom to understand the different features of the image. Our brain combines different local features that we scanned to ...   \n",
       "250  Jan 8, 2016\\n*On a personal note, before reading this article take a deep breath and relax yourself. In this article, you will neither hear any neighbor’s aunties gossiping ills about you nor see your parents hesitations when you say something cause you are wearing a dropout tag that isn’t sugar coated. This is an article on the bright side of the moon about how I get the inspiration to ultimately drop out.\\nThis moment in my life about a year ago I got the ultimate boredom to drop out of my class to do something of my own that I am really passionate about. Everyone in the class was doing the same thing, solving Irodov’s problems where the task itself would be a terror for every country’s layman and more importantly, till now I don’t find any usefulness of that things beside teaching t...   \n",
       "251  Towards Data Science\\nMar 29, 2019\\nI assume you are already familiar with Recurrent Neural Networks (including the seq2seq encoder-decoder architecture).\\nIn the encoder-decoder architecture, the complete sequence of information must be captured by a single vector. This poses problems in holding on to information at the beginning of the sequence and encoding long-range dependencies.\\nThe core idea of attention is to focus on the most relevant parts of the input sequence for each output. By providing a direct path to the inputs, attention also helps to alleviate the vanishing gradient problem.\\nAssume you have a sequential decoder, but in addition to the previous cell’s output and hidden state, you also feed in a context vector c.\\nWhere c is a weighted sum of the encoder hidden states...   \n",
       "252  Supervisely\\nMay 2, 2017\\n“What movie should i watch this evening?” — have you ever had to answer this question at least once when you came home from work? As for us — yes, and more than once. Here we will say a few words about what we’ve been working on for the past six months: an interactive movie recommender system Movix.ai. The system is based on Deep Learning and it adapts to the user preferences in real time. As big movie fans we felt the need for such a service, and we believe that it will be useful for every movie lover.\\nAt Deep Systems we are engaged in creating solutions and products based on machine learning and Deep Learning. Among our projects: developing a “mind” for self-driving car prototype and automatic defects detection for roads and airport runways. The important p...   \n",
       "253  Towards Data Science\\nSep 18, 2018\\nMachine learning on graphs is a difficult task due to the highly complex, but also informative graph structure. This post is the first in a series on how to do deep learning on graphs with Graph Convolutional Networks (GCNs), a powerful type of neural network designed to work directly on graphs and leverage their structural information. The posts in the series are:\\nIn this post, I will give an introduction to GCNs and illustrate how information is propagated through the hidden layers of a GCN using coding examples. We’ll see how the GCN aggregates information from the previous layers and how this mechanism produces useful feature representations of nodes in graphs.\\nGCNs are a very powerful neural network architecture for machine learning on graphs....   \n",
       "254  Towards Data Science\\nFeb 8, 2021\\nFirst, tell me, please, what is fiction and what is reality — in the context of Generative Adversarial Networks?\\nWe’ve seen a lot of things, which hadn’t existed before its AI-driven creation. Sure, the GAN-generated images in This Person Does Not Exist or This Artwork Does Not Exist have no direct reference in the material world — they are products of knowledge and AI models training. But being transported into our world, they might get their own story, specific meaning, and particular use, leaving the Latent Space and become more real than fiction.\\nIndeed, you can use them for making movies; you also can generate fraud and fakes. AI is not to blame for misuse, but us, humans. You cannot fix society by breaking technology.\\nNevertheless, in Digital...   \n",
       "255  Feb 2, 2020\\nこの記事は、EfficientNet B6+AutoAugと同等程度の精度で5倍早いAssemble-ResNetを提案した2020/1/17投稿の論文””Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network [1]の解説記事です。\\nこの記事では以下のこと説明します。\\nこの論文のサマリは以下のような感じです。\\n既存のあらゆるテクニックを組み合わせて、EfficientNet B6+AutoAugと同等程度の精度で5倍早いネットワークを構築した研究。著者たちがいうにはAugMix等の最新のものはここでは使ってないので、まだ精度があがる可能性があるとのこと。\\nここでは、Assemble-ResNetのベースライン比較となっているEfficientNet+AutoAugmentの解説をします。EfficientNetは2019年に発表された既存のネットワークより大幅に軽くて高精度なネットワークです。AutoAugmentは2018年に発表された論文で、最適なデータ拡張を自動で探索する研究です。どちらも画像認識では頻繁にベースラインとして登場する強力な手法です。\\nEfficientNet[2]は2019/5/28に投稿された論文で、それまでの既存のネットワークより高速で高精度なネットワークです。論文の内容をまとめると下記のような感じです。今まで成されていなかった解像度・深さ・チャネル数を同時に最適化することによって、高速かつ高精度なネットワークを構築。式3におけるφ=1にしてMnasNetの探索空間でαβγを最適化(B0)、後にφを変...   \n",
       "256  Towards Data Science\\nJun 5, 2018\\nIf you are like me bothered by “regression” in “logistic regression” which realistically should be called “logistic classification”, considering it does classification, I have an answer for your botheration!\\nLogistic regression is useful for situations where there could be an ability to predict the presence or absence of a characteristic or outcome, based on values of a set of predictor variables. It is similar to a linear regression model but is suited to models where the dependent variable is dichotomous. It’s coefficients can be used to estimate odd ratios for each of the independent variables in the model. It is applicable to a broader range of research situations than discriminant analysis. Logistic Regression on the other hand is used to ascert...   \n",
       "257  DataThings\\nFeb 6, 2019\\nAlthough artificial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. Meta-learning aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning algorithm.\\nArtificial intelligence and machine learning are currently extremely fashionable. In recent years, this technology has left the ...   \n",
       "258  Towards Data Science\\nJul 24, 2020\\nThe article explains what is spacy, advantages of spacy, and how to get the named entity recognition using spacy. Now, all is to train your training data to identify the custom entity from the text.\\nSpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning lib...   \n",
       "259  程式設計之旅\\nSep 22, 2019\\n簡單回顧\\n在ML入門(五)Linear Regression有介紹什麼是Gradient Descent,就是對loss function做偏微分(切線斜率)就是找極大極小值的概念,找一組參數讓loss function越小越好。在ML入門(五)Linear Regression,我們要更新的是w, b,在這邊用一個theta表示。\\nGradient Descent如何運行\\n這邊可以搭配公式一起看,紅色箭頭就是loss function的gradient方向,當乘上learning rate後再乘上負號(改變方向)就會變成藍色箭頭,一直重複這樣的動作,這就是Gradient Descent的運行模式。\\nLearning Rate對 Loss Function的影響\\n調整learning rate的方法\\n既然learning rate有時候不是太大不然就是太小,是不是有什麼方法可以來讓機器自己調整。當一開始起始點離最低點還很遠的時候,learning rate可以大一點;當越來越接近最低點時,learning rate要小一點,這樣才能收斂在最低點附近。下面那張圖所示,假設定義learning rate是每次跟著更新次數做調整,也就是說你的更新次數越多,learning rate會跟次數的開根號成反比,learning rate會越小。那有人就覺得說可以根據不同參數調整不同的learning rate,以下會列出幾種方法:\\n現在對於每一個參數w都要給一個不同的η,就是每次更新的η就是等於前一次的η再除以σ^t,而 σ^t則代表的是第 t 次以前的所有梯度更新值之平方和開根號(root mean square),而ε只是為了不讓分母為0而加上去的值。\\n下面圖中的式子可以清楚看出,分子的部分(紅色框框)顯示,當g...   \n",
       "260  Oct 26, 2015\\nThis article’s title is even a surprise to me. This is not something that I expected to write and you’re probably wondering what happened to all that advice about “you grow your wings on your way down”. I know, but this is the kind of theme that creates a lot of fuss by itself and a lot of irresponsible advice is given.\\nHere I will clarify my position on pursuing an academic career and how is the life of a college drop out.\\nI’ve always been a decent student, I always knew that I could be one of the top students in the class, but I never felt like going after that status. Video games always seemed more interesting than boring themes with zero practical implication. So school never presented itself as a challenge when it came to studying. Even in college I pass at every s...   \n",
       "261  Voice Tech Podcast\\nApr 1, 2019\\nIn the recent years, information grows rapidly along with the development of social media. With the increasing amount of information, it takes more effort and time to review the entire text document and understand its contents. One possible solution to the above problem is to read the summary of the document. The summary will not only retain the essence of the document, but will also save a lot of time and effort. An effective summary of the document will concise and fluent while preserving key information and overall meaning.\\nThere are two major text summarization approaches, abstractive and extractive summarization. The approach of Abstractive summarization selects words on the basis of semantic understanding, and even includes those words which do n...   \n",
       "262  JavaScript Scene\\nDec 31, 2020\\nHappy New Year! It’s time to review the big trends in JavaScript and technology in 2020 and consider our momentum going into 2021.\\nOur aim is to highlight the learning topics and technologies with the highest potential job ROI. This is not about which ones are best, but which ones have the most potential to land you (or keep you in) a great job in 2021. We’ll also look at some larger tech trends towards the end.\\nJavaScript still reigns supreme on GitHub and Stack Overflow. Tip #1: Learn JavaScript, and in particular, learn functional programming in JavaScript. Most of JavaScript’s top frameworks, including React, Redux, Lodash, and Ramda, are grounded in functional programming concepts.\\nTypeScript jumped past PHP, and C# into 4th place, behind only Ja...   \n",
       "263  Level Up Coding\\nJun 25, 2020\\nDo you want to try some other methods to solve your forecasting problem rather than traditional regression? There are many neural network architectures, which are frequently applied in NLP field, can be used for time series as well. In this article, we are going to build two Seq2Seq Models in Keras, the simple Seq2Seq LSTM Model, and the Seq2Seq LSTM Model with Luong Attention, and compare their forecasting accuracy.\\nFirst of all, let’s create some time series data.\\nWe’ve just created two sequences, x1 and x2, by combining sin waves, trend, and random noise. Next we will preprocess x1 and x2.\\nSince the sequence length is n_ = 1000, the first 800 data points will be used as our train data, while the rest will be used as our test data.\\nIt is not a must ...   \n",
       "264                                                                                                                                                Banapana\\nJan 4, 2008\\nDasher is a novel piece of software that lets you point at what you want to write. Honestly, it’s kind of difficult to describe without [seeing the demonstration](http://www.youtube.com/watch?v=0d6yIquOKQ0). It’s very novel and makes novel use of some simple AI. I wonder if Apple would ever integrate this in to the iPhone? And it would seem to be of great use were it to be integrated into eye tracking software.\\nOur Minds on Media\\n86 Followers\\nWriter of story, poetry and code. Currently attempting to illustrate one Ism a day — https://ismisms.tumblr.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "265  Becoming Human: Artificial Intelligence Magazine\\nMar 28, 2017\\nPython notebook, using Keras library, available on this GitHub repo.\\nA common way to solve a complex computing task is to chain together specialized components. In data-science this is the pipeline approach. Each component mostly treats the other components as I/O black-boxes. As developers we potentially have the full picture but the system does not.\\nWith Neural Network what happens between I and O is often too interesting to be ignored. One Neural Network can leverage the way another Neural Network processes its inputs.\\nIn this post I discuss the following scenario :\\nTo “understand” english is necessary to analyse news. Thus during training a standalone ’N’ NeuralNet would learn about the semantics of english as a by...   \n",
       "266  Kredo.ai Engineering\\nDec 8, 2017\\nMotivation for writing blog series on AI + Robotic Operating Systems:\\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\\nROS is used to create application for a physical robot without depending on the actual machine, thus saving cost and time. These applications can be transferred onto the physical robot without modifications.\\nThe decision making capability of the robots can be aided with AI. The cases where the robot agent has to learn optimal strategies in high dimensional state space often means that it is impractical to generate sufficient...   \n",
       "267  Towards Data Science\\nJul 16, 2018\\nClustering unsupervised data is not an easy task. Indeed, data crunching and exploration is in such a context often driven by domain knowledge, if not pure intuition, and made difficult as there is no way to measure the accuracy of the resulting segmentation (as opposed to supervised learning).\\nIn addition, introductory courses to unsupervised learning quite often discuss ideal use cases, such as k-means tutorials, which only apply to numerical features.\\nHowever, real business situations often deviate from these ideal use cases, and need to analyze datasets made of mixed-type data, where numeric (the difference between two values is meaningful), nominal (categorical, not ordered) or ordinal (categorical, ordered) features coexist.\\nIn this post, I’...   \n",
       "268  Jul 31, 2017\\nThis article is about different ways of regularizing regressions. In the context of classification, we might use logistic regression but these ideas apply just as well to any kind of regression or GLM.\\nWith binary logistic regression, the goal is to find a way to separate your two classes. There are a number of ways of visualizing this.\\nNo matter which of these you choose to think of, we can agree logistic regression defines a decision rule\\nh(x|theta) = sigmoid(x dot theta + b)\\nand seeks a theta which minimizes some objective function, usually\\nloss(theta)= ∑ y*log(h(x|theta)) + (1−y)log(1−h(x|theta))\\nwhich is obfuscated by a couple clever tricks. It is derived from the intuitive objective function:\\nloss(theta)= ∑ (y - h(x|theta))\\ni.e. the number of misclassified x...   \n",
       "269  May 7, 2018\\nThis blog post aims to provide readers some insights on deep neural networks and intuition about dropout technique.\\nDeep neural networks are models composed of multiple layers of simple, non-linear neurons. With composition of enough neurons, the model can learn extremely complex functions that can accurately perform complicated tasks that are impossibly difficult to hard code, such as image classification, translation, speech recognition, etc. The key aspect of deep neural networks is that they are able to automatically learn data representation needed for features detection or classification without any a priori knowledge1.\\nFor example, VGG16 (shown below) is a convolutional neural network that is trained on ImageNet Large Scale Visual Recognition Competition (ILSVRC) ...   \n",
       "270  Towards Data Science\\nMay 22, 2019\\nDealing with extreme event prediction is a frequent nightmare for every Data Scientist. Looking around I found very interesting resources that deal with this problem. Personally, I literally fall in love with the approach released by Uber Researchers. In their papers (two versions are available here and here) they developed an ML solution for daily future prediction of traveler demand. Their methodology stole my attention for its geniality, good explanation, and easy implementation. So my purpose is to reproduce their discovery in pythonic language. I’m very satisfied with this challenge and in the end, I improved my knowledge of regression forecasting.\\nThe most important takeaways from this post can be summarized as:\\nBut Keep Kalm and let’s procee...   \n",
       "271  Towards Data Science\\nOct 12, 2018\\nIn computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\\nFuzzy string search can be used in various applications, such as:\\nSpeaking of dedupe, it may not as easy as it sounds, in particular if you have hundred thousands of records. Even Expedia does not make it 100% right:\\nThis post will explain what fuzzy string matching is together with its use cases and give examples using Python’s Fuzzywuzzy library.\\nEach hotel has its own nomenclature to name its rooms, the sam...   \n",
       "272  Jan 11, 2013\\nSocial media can be hard to control. From small and medium-sized businesses lacking additional manpower to large companies requiring a method for scheduling numerous team members, we decided to create a tool that will add additional value to social media efforts.\\nSocial Defender provides real-time social media monitoring, insights and gives the ability to accurately moderate social media efforts and understand customer sentiment.\\nBy using the tool, businesses can manage multiple social media networks including Facebook, Twitter, Tumblr, YouTube, G+, blogs and forums using just one login. This social media management tool gives businesses the ability to analyze what is being said online about a brand, service, industry, and competitors. Analytics provided by Social Defen...   \n",
       "273  Towards Data Science\\nAug 18, 2021\\nI am sure you read about AlphaFold in late 2020 when it “won” the CASP14 “contest” on modeling protein structures, and in July 2021 when the peer-reviewed paper and AI model were released. If not, or if you want to refresh what protein structures are, why biologists prayed for decades for programs to accurately predict them, and how AlphaFold works and performs, then check this story and this one, then come back here.\\nThis new story brings you the latest news, based on a just-published preprint.\\nTable of contents\\nThis story is based on a preprint just posted in the bioRxiv that formally describes a tool dubbed ColabFold under the moto Making protein folding accessible to all (which I would have rather phrased Making modern protein structure modeli...   \n",
       "274  Jul 4, 2020\\nAssume you have an image I and an image database X containing thousands of other images. You want to find a subset S⊆X containing images that are most similar to I. This is a task called image retrieval. However, before solving this, you may ask yourself, what is the meaning of similar images? Is it based on the colors in the images? Or maybe the content? In the second case, two images containing dogs could be considered similar regardless of their breed, which obviously may have different colors. In this post, I will describe a simple implementation of this. The implementation is based on neural networks and is done by comparing the similarity between the embeddings of the two images.\\nGiven a query image I, I extract the features using VGG-19 and use the output of the fi...   \n",
       "275  Towards Data Science\\nApr 9, 2020\\nMovies are more than just blockbusters hit with explosions and superpowers, it’s the main idea behind the movie that changes people and injects a notion in the viewer’s head.\\nTo illustrate, the movie Joker wasn’t a hero vs villain film, fighting with superpowers and wreaking havoc on New York City. It portrayed how there is a distinct chasm between the rich and the poor, the lucky and the unlucky, and how mental illness can distort a person’s morality and value system.\\nSo, movies are more than just an activity for enjoyment and amusement, it plays an imperative role in shaping our view on the world and communal consciousness.\\nIn short, movies educate people and spread ideas in ways a paperback book early does today.\\nOne reason for the effectivenes...   \n",
       "276  Jul 31, 2017\\nWhen I first noticed the Kaggle competition: “Planet: Understanding the Amazon from space” I was immediately thinking of trying out Transfer Learning using a pre-trained model. I had never really played with Transfer Learning before so I thought this would be a good one to try it out on. Transfer Learning is described by Wikipedia as:\\n“a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem”\\nwhere in this case the ‘relatedness’ of the problem is that both the Kaggle competition and the pre-trained model(s) are addressing computer vision problems. For more information on Transfer Learning there is a good resource from Stanfords CS class and a fun blog by Sebastian Ruder.\\...   \n",
       "277  Analytics Vidhya\\nJan 25, 2021\\nDuring my first ever data science internship, I was given a seemingly simple task to find clusters within a dataset. Given my basic knowledge of clustering algorithms like K-Means, DBSCAN, and GMM I thought that I could easily get this task done. However, as I took a closer look into the dataset, I realized the data contained a mixture of categorical and continuous data, and many common methods of clustering I knew would not easily work.\\nCategorical data consists of multiple discrete categories that commonly do not have any clear order or relationship to each-other. This data might look like “Android” or “iOS”.\\nContinuous data consists of real numbers that can take any value. This data might look like “3.14159” or “43\".\\nMany datasets contain a mixture...   \n",
       "278                                                                                                                       Analytics Vidhya\\nJan 23, 2020\\nFaster R-CNN is an object detection architecture presented by Ross Girshick, Shaoqing Ren, Kaiming He and Jian Sun in 2015, and is one of the famous object detection architectures that uses convolution neural networks.It detects and classifies objects in an image as shown below:\\nBefore diving into Faster R-CNN let’s learn about R-CNN, Fast R-CNN and RPN which are the building blocks...\\n303 \\n303 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n24 Followers\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "279  mutsuda\\nMar 22, 2012\\nFa dos anys, a l’assignatura d’AIA (Aplicacions de la Intel·ligència Artificial), ens van fer implementar un sistema intel·ligent que dominaria tot el procés de depuració d’aigua de Catalunya. Les diferents plantes havien de ser intel·ligents i tenir suficient coneixement del seu entorn com per decidir, entre elles, de quina manera actuar en cas de detecció d’un contaminant, pluja torrencial, etc. Elles soles decidien mitjançant diverses polítiques què fer en cadascuna de les situacions per tal de resoldre els problemes.\\nLes plantes entre si es comunicaven mitjançant missatges en format d’ontologia, que ve a ser una representació lògica del context en què s’està treballant. En aquest cas l’ontologia contenia informació sobre els tòxics, l’aigua, ai...   \n",
       "280  Towards Data Science\\nApr 26, 2020\\nHundreds of books are now free to download\\nSpringer has released hundreds of free books on a wide range of topics to the general public. The list, which includes 408 books in total, covers a wide range of scientific and technological topics. In order to save you some time, I have created one list of all the books (65 in number) that are relevant to the data and Machine Learning field.\\nAmong the books, you will find those dealing with the mathematical side of the domain (Algebra, Statistics, and more), along with more advanced books on Deep Learning and other advanced topics. You also could find some good books in various programming languages such as Python, R, and MATLAB, etc.\\nIf you are looking for more recommended books about Machine Learning a...   \n",
       "281  Towards Data Science\\nJan 17, 2018\\nThere are several time-series forecasting techniques like auto regression (AR) models, moving average (MA) models, Holt-winters, ARIMA etc., to name a few. So, what is the need for yet another model like LSTM-RNN to forecast time-series? This is quite a valid question to begin with and here are the reasons that I could come up with (respond below if you are aware of more, I will be curious to know)—\\nOn the other hand, there are the usual downsides that one needs to be careful about, while using LSTM’s (or any DNN architectures for that matter) — requirement of lots of data, multiple hyper-parameters to be tuned etc., I also came across few articles that mentioned that LSTM’s are not supposedly good at auto regression type of series. So take this wit...   \n",
       "282  Towards Data Science\\nMay 12, 2020\\nKeras provides a set of deep learning models that are made available alongside pre-trained weights on ImageNet dataset. These models can be used for prediction, feature extraction, and fine-tuning. Here I’m going to discuss how to extract features, visualize filters and feature maps for the pretrained models VGG16 and VGG19 for a given image.\\nHere we first import the VGG16 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG16 model. The numpy module is imported for array-processing. Then the VGG16 model is loaded with the pretrained weights for the imagenet dataset. VGG16 model is a series of convolutional layers followed ...   \n",
       "283  Taiwan AI Academy\\nApr 28, 2020\\n說到近年來最火紅以深度學習為主的生成模型,大家必定會想到生成對抗網路(Generative Adversarial Network, GAN),然而在GAN(2014)還沒被提出來之前,有另外一個同樣屬於生成模型的Variational AutoEnoder (VAE)常被大家所使用,很可惜的是當時GAN在許多任務上所產生的圖片清晰度較高,因此VAE類型的模型相對而言就勢弱了一些(當然GAN在訓練的特性上有一些難以克服的問題至今也尚未完全解決)。\\n故事總不會就這樣結束,2017年DeepMind在NIPS研討會上提出了Vector-Quantized Variational AutoEncoder模型,雖然在效果上仍然是先與VAE做比較,但VQ-VAE提出的概念讓它擁有比其它生成模型更獨特的地方,甚至在後續2019年6月提出的VQ-VAE2甚至宣稱在生成1024*1024的高解析度人臉時與當時效果最佳的BigGAN可作比擬。如果你開始對VQ-VAE感到好奇,就跟著我們一起看下去吧。\\n註1:如果你對Variational AutoEncoder甚至是AutoEncoder的概念還沒那麼熟的話,可以參考此篇AutoEncoder介紹、此篇VAE介紹、或是尋找其他資源唷。\\n我們可以這樣解讀AutoEncoder家族在做的事情,Encoder試圖找出輸入圖片x在潛在空間上的表徵(representation),在大多數的狀況中,大家使用連續型的分布去模擬z的樣貌(e.g. AE將輸入x投影至潛在空間的一個點;VAE則改為使用高斯分布模擬輸入x在潛在空間的樣貌),然而VQVAE的作者提到離散的潛在表徵在很多情境上也許才是比較適合的,例如語言概念,因此VQ-VAE主要的突破就是試圖讓Encoder產出離散的...   \n",
       "284  Stories by Progress\\nAug 14, 2017\\nThe democratization of analytics has become a popular term, and a quick Google search will generate results that explore the necessity of empowering more people with analytics and the rise of citizen data scientists. The ability to easily make better use of your (constantly growing) pool of data is a critical driver of business success, but many of the existing solutions that claim to democratize analytics only do so within severe limits. If you have a complex business scenario and are looking to get revolutionary insights using them, it’s easy to come away disappointed.\\nHowever, the democratization of analytics isn’t just a buzzword that refers to a narrow approach. It’s possible to do so much more. Let’s quickly review the current state of the mark...   \n",
       "285  Jun 1, 2021\\nLet’s check your basic knowledge of Decision Tree. Here are 10 multiple-choice questions for you and there’s no time limit. Have fun!\\nQuestion 1: Decision trees are also known as CART. What is CART?(A) Classification and Regression Trees(B) Customer Analysis and Research Tool(C) Communication Access Real-time Translation(D) Computerized Automatic Rating Technique\\nQuestion 2: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees implicitly perform variable screening or feature selection(B) Can handle both numerical and categorical data(C) Can handle multi-output problems.(D) All of the above\\nQuestion 3: What are the advantages of Classification and Regression Trees (CART)?(A) Decision trees require relatively less effort from users for ...   \n",
       "286  Towards Data Science\\nMar 15, 2021\\nIn two previous blog posts on my journey with BERT: Neural Search with BERT and Solr and Fun with Apache Lucene and BERT I’ve taken you through the practice of what it takes to enable semantic search powered by BERT in Solr (in fact, you can plug in any other dense embeddings method, other than BERT, as long as it outputs a float vector; a binary vector can also work). While it feels cool and modern to empower your search experience with a tech like BERT, making it performant is still important for productization. You want your search engine operations team to be happy in a real industrial setting. And you want your users to enjoy your search solution.\\nDevops cares about disk sizes, RAM and CPU consumption a lot. In some companies, they also care ab...   \n",
       "287  Jun 29, 2009\\n变形金刚II(Transformers:ROF)这样一部电影,从我从电影院看完他的第一部就开始期待了,昨天终于有幸去电影院看了。画面很,庞大,震撼说不上,可能在1的时候已经给我震完了吧。影院的效果就是好,所以看这个电影确实是一种享受的。当然就我个人看来他想超越1或者是原版动漫是没有多大可能了。我不是一个喜欢搞剧透的人,所以我非常不想说剧情。\\n只说一下对于剧情的感受:1. 剧情太商业化,变形金刚这么强大的战斗力和防御力,我不知道拿着枪的人类可以对他们造成什么样的威胁呢?美国大兵们与变形金刚们短兵相接,难道是为了方便狂派们刷数据么?2. 由于是美国电影,所以一定要展现美国军备的强大,所以战舰上的秘密武器可以KO看上去甚是强大的纸老虎 — — 狂派合体机器人;3. 主角一定得是人类,为了烘托人类主角的伟大性,不惜牺牲同样伟大但没有他伟大的各位领袖同志,主角由于起点比较低,所以随便摸一下某个能量体就可以吸收里面的精髓;4. 赶新潮,年轻人做网站办公司、经济危机,再在电影里融入一点青春元素,把学生宿舍比喻为霍格沃茨,可惜这方面的篇幅太短,如果开发一下说不定会为本集贫乏的剧情添加一点色彩;5. 冷兵器,变形金刚们之间的斗争,如果想要解决对方,就必须使用冷兵器或者蛮力,这方面是我所欣赏的,我可不希望擎天柱、威震天是被一把麦林爆头干掉的;6. HappyEnding,每一部想拍续集的电影都有那么一个HappyEnding,狂派还会回来的誓言也是必需的~\\n综上所述,这的确是一部好电影,看的时候请放松您的大脑,因为没什么可以让你去思考的。\\nBTW:搬到cosbeta的主机以后速度很快,很快,我非常欣慰。\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n8 Follower...   \n",
       "288  Oct 31, 2015\\nAccording to Creative Writing Now, the publishing world tends to classify Fiction as either Commercial (built to make money), or Literary (a work of art). There are no further explanations why art cannot also make money, but things just doesn’t work that way. Observe how Commercial Fiction and Literary Fiction are handled as separate categories. Commercial Fiction is divided into several genres. This kind of classification can help readers to determine what kind of novel do they like to read. Each genre also has its own rubric. Literary fiction has been generally chunked all together in bookstores as “General Fiction”. Because the precedence of literary authors is to produce works of art, while selling books is only a second thought. Literary authors are less likely to th...   \n",
       "289  Dec 20, 2016\\nThis article is for a person who has some knowledge on Android and OpenCV. We will look at how to use the OpenCV library to recognize objects on Android using feature extraction.\\nI am using Android Studio and you can follow this link to download and install Android studio and SDK tools but if you are a die hard eclipse fan you also can follow this tutorial( no hard feelings ;) )\\n2. Setting up OpenCV library inside Android Studio\\nYou have to download and import OpenCV library to android studio and there is a stackoverflow answer which you can follow to setup everything. If you are using Eclipse use this link.\\nNow you are ready to mingle with me ;). The algorithm we are going to use is ORB(Oriented FAST and Rotated BRIEF). As an OpenCV enthusiast, the most important thi...   \n",
       "290  Mar 14, 2018\\nSSD is designed for object detection in real-time. Faster R-CNN uses a region proposal network to create boundary boxes and utilizes those boxes to classify objects. While it is considered the start-of-the-art in accuracy, the whole process runs at 7 frames per second. Far below what real-time processing needs. SSD speeds up the process by eliminating the need for the region proposal network. To recover the drop in accuracy, SSD applies a few improvements including multi-scale features and default boxes. These improvements allow SSD to match the Faster R-CNN’s accuracy using lower resolution images, which further pushes the speed higher. According to the following comparison, it achieves the real-time processing speed and even beats the accuracy of the Faster R-CNN. (Accu...   \n",
       "291  Apr 5, 2018\\nBlockchain is not only crappy technology but a bad vision for the future. Its failure to achieve adoption to date is because systems built on trust, norms, and institutions inherently function better than the type of no-need-for-trusted-parties systems blockchain envisions. That’s permanent: no matter how much blockchain improves it is still headed in the wrong direction.\\nThis December I wrote a widely-circulated article on the inapplicability of blockchain to any actual problem. People objected mostly not to the technology argument, but rather hoped that decentralization could produce integrity.\\nLet’s start with this: Venmo is a free service to transfer dollars, and bitcoin transfers are not free. Yet after I wrote an article last December saying bitcoin had no use, som...   \n",
       "292  Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...   \n",
       "293                                                                                                                                                                                                                                                                                                                                                 The Startup\\nDec 22, 2020\\nNatural language processing (NLP) is a diverse field; the approaches and techniques are as varied...\\n172 \\n172 \\n1\\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n637 Followers\\nResearch Consultant and Data Scientist. Enthusiastic about machine learning, social justice, video games and philosophy.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "294  Sep 16, 2014\\nこれまで Stash は常に、最高のスピードと安全性を実現する Git リポジトリ管理ツール製品となってきました。そして今回、最高の拡張性も提供します。Stash Data Center のリリースの発表です (本日、ベータ版リリース)! このクラスタリング搭載の Stash Data Center デプロイメント オプションは、エンタープライズの大規模システムでのニーズを満たすことを目的としています。\\n今すぐベータ版トライアル\\nStash Data Center はアクティブ/アクティブ クラスタリングを提供し、ユーザーは途切れることなく確実に Git リポジトリにアクセスできます。 Data Center は負荷バランシング技術と冗長化技術を使い、ハードウェア障害による予期せぬシステムのダウンタイムのリスクを軽減します。データベースクラスタリングと共有ファイルシステムの業界標準技術を組み合わせ、Stash は単一障害点を排除します。Stash Data Center の初期設定プロセスの中で、クラスタリングは簡単に設定できますので、チームはすぐに立ち上げ稼働することができます。さらに、稼働規模を拡張するためのノードの追加や削除にダウンタイムは不要ですので、開発チームやビルドプロセスを妨害することはありません。\\n組織内で Git ベースのソリューションを利用するチームが増えるにつれ、開発者とビルドサーバーからのトラフィック量が急速に増加し、リソースを圧迫することがあります。Stash Data Center は、負荷継続時やピーク負荷時に、より高いアプリケーションスループットに対応でき、ユーザーやビルドの追加...   \n",
       "295  Towards Data Science\\nNov 17, 2021\\nTime series forecasting is a very popular field of machine learning. The reason behind this is the widespread usage of time series in daily life in almost every domain. Going into details for time series forecasting, we encounter lots of different kinds of sub-fields and approaches. In this writing, I will focus on a specific subdomain that is performing multi-step forecasts by receiving multiple parallel time series, and also mention basic key points that should be taken into consideration in time series forecasting. Note that forecasting models differ from predictive models at various points.\\nLet's think about lots of network devices spread over a large geography, and traffic flows through these devices continuously. Another example might be about...   \n",
       "296  Towards Data Science\\nJun 21, 2017\\nHere we use the example of reviews to predict sentiment (even though it can be applied more generically to other domains for example sentiment analysis for tweets, comments, customer feedback, etc). Whole idea here is that movie reviews are made of sequence of words and order of words encode lot of information that is useful to predict sentiment. Step 1 is to map words to word embeddings (see post 1 and 2 for more context on word embeddings). Step 2 is the RNN that receives a sequence of vectors as input and considers the order of the vectors to generate prediction.\\nThe architecture for this network is shown below.\\nHere, we’ll pass in words to an embedding layer. You can actually train up an embedding with word2vec and use it here. But it’s good en...   \n",
       "297  Aug 15, 2021\\nWhat are Activation Functions? Why are they used? why are there so many types? Does one works better than other?\\nFirstly, lets recap. A deep layer neural network as seen below receives the input and makes the decision based on its weights and biases which are learned during its backpropagation. As the Hidden layers increases , the decision making becomes more complex and sometimes leads to taking noise into consideration. When output is produced , mot all the neurons in the layers have equal say/contribution, and its because of the weights and bias updated during backpropagation. Done.\\nThen were is Activation function used? And Why?\\nSo basically, Activation functions decide whether the particular neuron or node to be fired /activated or not.\\nAs said, Activation functi...   \n",
       "298  Sep 11, 2021\\nMost of us use social media platforms to communicate with people or express ourselves in text. Generally, Most of the ML/DL models used this text to determine the sentiments or to predict any criminal activities and many more NLP-related tasks. The ML and DL models are trained in traditional language, mostly English for any NLP-related task.\\nBut in actual, we use informal English to communicate with friends especially short forms or abbreviations. So, this kind of text might not be very much helpful in doing NLP-based task.\\nSo, it will be better if we convert those short forms or informal words or text to standard English so that it helps most of NLP tasks in various areas like sentimental analysis, chat box. Etc. Therefore, we need to build a model to convert this corr...   \n",
       "299  Project AGI\\nApr 7, 2014\\nby David Rawlinson and Gideon Kowadlo\\nThis blog will be written by several people. Other contributors are welcome — send us an email to introduce yourself!\\nThe content will be a series of short articles about a set of common architectures for artificial general intelligence (AGI). Specifically, we will look at the commonalities in Deep Belief Networks and Numenta’s Memory Prediction Framework (MPF). MPF is these days better known by its concrete implementations CLA (Cortical Learning Algorithm) and HTM (Hierarchical Temporal Memory). For an introduction to Deep Belief Networks, read one of the papers by Hinton et al.\\nThis blog will typically use the term MPF to collectively describe all the current implementations — CLA, HTM, NUPIC etc. We see MPF as an int...   \n",
       "300  Feb 22, 2019\\nRecently I have come across a chapter in François Chollet’s “Deep Learning With Python” book, describing the implementation of Class Activation Mapping for the VGG16 network. He implemented the algorithm using Keras as he is the creator of the library. Hence, my instinct was to re-implement the CAM algorithm using PyTorch.\\nGrad-CAM\\nThe algorithm itself comes from this paper. It was a great addition to the computer vision analysis tools for a single primary reason. It provides us with a way to look into what particular parts of the image influenced the whole model’s decision for a specifically assigned label. It is particularly useful in analyzing wrongly classified samples. The Grad-CAM algorithm is very intuitive and reasonably simple to implement.\\nThe intuition behi...   \n",
       "301  Towards Data Science\\nApr 27, 2019\\nIn this article we are going to create deep reinforcement learning agents that learn to make money trading Bitcoin. In this tutorial we will be using OpenAI’s gym and the PPO agent from the stable-baselines library, a fork of OpenAI’s baselines library.\\nThe purpose of this series of articles is to experiment with state-of-the-art deep reinforcement learning technologies to see if we can create profitable Bitcoin trading bots. It seems to be the status quo to quickly shut down any attempts to create reinforcement learning algorithms, as it is “the wrong way to go about building a trading algorithm”. However, recent advances in the field have shown that RL agents are often capable of learning much more than supervised learning agents within the same p...   \n",
       "302  Dec 22, 2016\\nTal Perry\\nHi Tal,\\nMaybe I’m missing something here, but 1. I don’t think your first layer is a embedding layer but a dense layer. You are converting 4000 NUMBERS into 300 by multiplying by a matrix. Embedding layer is when you have categorical variables mapped to vectors, which doesn’t seem to be what’s happening. Unless you are using the name of the stock.\\n2. You mentioned that your output is 5 minute data, but your input is daily data. This is a bit confusing since the time intervals of the input and output have to be the same? If you are getting 5 minute stock data, where do you download them from (I haven’t been able to find anything of the sort).\\nCheers\\n11 \\n11 \\nPhD in Machine Learning | Founder of DeepSchool.io\\nLove podcasts or audiobooks? Learn on the go wit...   \n",
       "303  Towards Data Science\\nJul 13, 2021\\nProject Goal: Using word embeddings identify company names and stock tickers from natural text.\\nAssumption: Stock tickers and company names are used in similar context in natural text such as a Reddit post or a tweet.\\nUnder this assumption, word embeddings should be a good fit for identifying these target words as word embeddings are trained by the context in which words are found.\\nIn this post, I will skip describing what word embeddings are and how the Word2Vec algorithm works. I have written a much more detailed paper on the same project which can be found here. In this paper, I explain the details of what word embeddings are as well as how the Word2Vec Algorithm works. I also detail sentiment analysis via Naive Bayes. In this post, I will just...   \n",
       "304  Towards Data Science\\nJul 17, 2017\\nIn this blog post, I am going to teach you how to train a Bayesian deep learning classifier using Keras and tensorflow. Before diving into the specific training example, I will cover a few important high level concepts:\\nI will then cover two techniques for including uncertainty in a deep learning model and will go over a specific example using Keras to train fully connected layers over a frozen ResNet50 encoder on the cifar10 dataset. With this example, I will also discuss methods of exploring the uncertainty predictions of a Bayesian deep learning classifier and provide suggestions for improving the model in the future.\\nThis post is based on material from two blog posts (here and here) and a white paper on Bayesian deep learning from the Universit...   \n",
       "305  We’ve moved to freeCodeCamp.org/news\\nMay 3, 2017\\nA year and a half ago, I dropped out of one of the best computer science programs in Canada. I started creating my own data science master’s program using online resources. I realized that I could learn everything I needed through edX, Coursera, and Udacity instead. And I could learn it faster, more efficiently, and for a fraction of the cost.\\nI’m almost finished now. I’ve taken many data science-related courses and audited portions of many more. I know the options out there, and what skills are needed for learners preparing for a data analyst or data scientist role. So I started creating a review-driven guide that recommends the best courses for each subject within data science.\\nFor the first guide in the series, I recommended a few...   \n",
       "306  Center for Open Source Data and AI Technologies\\nFeb 21, 2019\\nWhen humans and machines collaborate, we can produce things neither would create on their own. The intersection of art and AI is an area that I find really exciting, but with all the business impact AI can have, I personally feel it doesn’t always get enough attention. In this spirit, I recently set out on a personal quest to learn more about PyTorch, the machine learning library that’s been creating a lot of buzz since its 1.0 release late last year, and I was pleasantly surprised by what I found.\\nFor me, PyTorch turned out to be more than just an interesting alternative to TensorFlow, with dynamic graphs and an imperative coding style. One of the examples from their official docs inspired me to track down some academic p...   \n",
       "307  Towards Data Science\\nFeb 4, 2021\\nNote: For those of you who prefer watching videos, please feel free to play above video on the same content.\\nGiven long documents to read, our natural preference is to not read, or at least, to scan just the main points. So having a summary would always be great to save us time ⏳ and brain processing power.\\nHowever, auto-summarization used to be an impossible task. Specifically, abstractive summarization is very challenging. Differing from extractive summarization (which extracts important sentences from a document and combines them to form a “summary”), abstractive summarization involves paraphrasing words and hence, is more difficult but can potentially give a more coherent and polished summary.\\nIt was not until the development of techniques like...   \n",
       "308                                                                                                        May 25, 2017\\nthis article is mainly a summarization of Yasemin Altun’s presentation in May 2014 on how google applies text summarization.\\ntext summarization is highly related to google knowledge graph project:\\nentities description within red circle use text summarization from wiki to give a one sentence description of the entity.\\n7 \\n7 \\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n83 Followers\\nnerd by train, leading purposeful life, trying to make a big impact. self-taught entrepreneur to be.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "309  HuggingFace\\nMay 9, 2019\\nA few years ago, creating a chatbot -as limited as they were back then- could take months 🗓, from designing the rules to actually writing thousands of answers to cover some of the conversation topics.\\nWith the recent progress in deep-learning for NLP, we can now get rid of this petty work and build much more powerful conversational AI 🌟 in just a matter of hours 🍃 as you will see in this tutorial.\\nWe’ve set up a demo running the pretrained model we’ll build together in this tutorial at convai.huggingface.co. Be sure to check it out! 🎮\\nHere is what we will learn and play with today:\\nTogether with this post, we released a clean and commented code base with a pretrained model! Check the Github repo here ✈️\\nThe story of this post began a few months ago in Mon...   \n",
       "310  Cube Dev\\nSep 7, 2017\\nThe Statsbot team has already published the article about using time series analysis for anomaly detection. Today, we’d like to discuss time series prediction with a long short-term memory model (LSTMs). We asked a data scientist, Neelabh Pant, to tell you about his experience of forecasting exchange rates using recurrent neural networks.\\nAs an Indian guy living in the US, I have a constant flow of money from home to me and vice versa. If the USD is stronger in the market, then the Indian rupee (INR) goes down, hence, a person from India buys a dollar for more rupees. If the dollar is weaker, you spend less rupees to buy the same dollar.\\nIf one can predict how much a dollar will cost tomorrow, then this can guide one’s decision making and can be very important ...   \n",
       "311  May 31, 2018\\nДорогие друзья! Подходит к концу май месяц, наступает долгожданное для многих лето. Сегодня я хочу подвести итоги и рассказать о планах на самое ближайшее будущее.\\nВо-первых, сегодня — 31 мая, очень важный для нас день, мы завершаем Баунти-кампанию TokenGo! Выполнен огромный объем задач, распределены все выделенные на баунти-кампанию токены! Руководство платформы TokenGo от всей души благодарит участников-баунтистов за неоценимый вклад в развитие и продвижение наших идей и поздравляет с окончанием большого и важного этапа! Мы надеемся, что все вы продолжите работу в данном направлении в баунти-кампаниях наших партнеров!\\nВо-вторых, хочу ответить на один из самых часто задаваемых вопросов! Можно ли теперь выводить токены? Да. Токены выводить можно! Причем, можно вы...   \n",
       "312  Towards Data Science\\nJul 31, 2019\\nConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but these networks have been some of the most influential innovations in the field of computer vision and image processing.\\nThe Convolutional neural networks are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.\\nLet’s say we have a color image in JPG form and its size is 480 x 480. The representative array will be 480 x 480 x 3. Each of these numbers is given a value from 0 to 255 which describes the pixel intensity at that point. RGB intensity values of the image are visualized by the computer for processing.\\nThe idea is that you give the computer ...   \n",
       "313  Towards Data Science\\nMay 10, 2020\\nHumans have the innate ability to identify the objects that they see in the world around them. The visual cortex present in our brain can distinguish between a cat and a dog effortlessly in almost no time. This is true not only with cats and dogs but with almost all the objects that we see. But a computer is not as smart as a human brain to be able to this on its own. Over the past few decades, Deep Learning researchers have tried to bridge this gap between human brain and computer through a special type of artificial neural networks called Convolutional Neural Networks(CNNs).\\nAfter a lot of research to study mammalian brains, researchers found that specific parts of the brain get activated to specific type of stimulus. For example, some parts in th...   \n",
       "314  Veritable\\nNov 1, 2018\\n(This is sort of a sequel or an update to “Building a Translation System in Minutes” published a year ago. This time we use a publicly available dataset, a different NLP task, and some task-specific evaluation metrics)\\nSummarization is the task of producing a shorter version of one or several documents that preserves most of the input’s meaning. [1]\\nThe text summarization task is mostly solved using variants of the seq2seq structure [2] these days. The seq2seq structure is much more complicated than the usual RNN models, and that makes implementing the model from scratch a rather daunting task. Luckily, OpenNMT project [3] provides ready-to-use implementations of seq2seq models that are close to state-of-the-art. We can use it as a starting point.\\nIn this pos...   \n",
       "315  Towards Data Science\\nAug 28, 2020\\nThis article talks about the concept of adversarial examples as applied to NLP (natural language processing). The terminology can be confusing at times, so we’ll begin with an overview of the language used to talk about adversarial examples and adversarial attacks. Then, we’ll talk about TextAttack, our open-source Python library for adversarial examples, data augmentation, and adversarial training in NLP that’s changing the way people research the robustness of NLP models. We’ll conclude with some thoughts on the future of this area of research.\\nAn adversarial example is an input designed to fool a machine learning model [1]. An adversarial example crafted as a change to a benign input is known as an adversarial perturbation. ‘Adversarial perturbat...   \n",
       "316  Jun 28, 2016\\nR uses a ton of memory. Here are ways to make it use a little less. Definitely not an expert, this is largely a resource/reference for myself, but thought it might be useful for others as well.\\nThe best introduction to how R uses memory is likely this guide, by Hadley Wickham.\\nGarbage collector: gc()\\nMy impression is that this function used to be more useful. R uses it to release memory it isn’t using, but will usually run it automatically. So you shouldn’t have to call it explicitly. However, if you want to see when this is happening, use gcinfo(TRUE) — you probably won’t want to leave this on all the time, it will get annoying. But, it can be very useful for finding the peak memory used by a function.\\nObject size: object.size()\\nTo find the size of a given R object,...   \n",
       "317  Towards Data Science\\nDec 20, 2021\\nAuto-Encoders are a popular type of unsupervised artificial neural network that takes un-labeled data and learns efficient codings about the structure of the data that can be used for another context. Auto-Encoders approximates the function that maps the data from full input space to lower dimension coordinates and further approximates to the same dimension of input space with minimum loss.\\nFor classification or regression tasks, auto-encoders can be used to extract features from the raw data to improve the robustness of the model. There are various other applications of an Auto-Encoder network, that can be used for some other context. We will 7 of such applications of auto-encoder in this article:\\nBefore diving into the applications of AutoEncoder...   \n",
       "318  Towards Data Science\\nMay 2, 2018\\nIn this project, I am going to build language translation model called seq2seq model or encoder-decoder model in TensorFlow. The objective of the model is translating English sentences to French sentences. I am going to show the detailed steps, and they will answer to the questions likehow to define encoder model, how to define decoder model, how to build the entire seq2seq model, how to calculate the loss and clip gradients.\\nPlease visit the Github repo for more detailed information and actual codes in Jupyter notebook. It will cover a bit more topics like how to preprocess the dataset, how to define inputs, and how to train and get prediction.\\nThis is a part of Udacity’s Deep Learning Nanodegree. Some codes/functions (save, load, measuring accurac...   \n",
       "319  Towards Data Science\\nSep 20, 2019\\nWhen we say Convolution Neural Network (CNN), generally we refer to a 2 dimensional CNN which is used for image classification. But there are two other types of Convolution Neural Networks used in the real world, which are 1 dimensional and 3-dimensional CNNs. In this guide, we are going to cover 1D and 3D CNNs and their applications in the real world. I am assuming you are already familiar with the concept of Convolutions Networks in general.\\nThis is the standard Convolution Neural Network which was first introduced in Lenet-5 architecture. Conv2D is generally used on Image data. It is called 2 dimensional CNN because the kernel slides along 2 dimensions on the data as shown in the following image.\\nThe whole advantage of using CNN is that it can e...   \n",
       "320  Apr 19, 2019\\nOn April 10th, scientists and engineers from Event Horizon Telescope team achieved a remarkable breakthrough in quest to understand the cosmos by unveiling the first image of black hole. This furthers strengthens Einstein theory of general relativity — “ massive objects cause a distortion in space-time, which is felt as gravity”.\\nWell I am not a physicist or astronomer to comprehend and explain in detail about this but like me there are millions and millions of people who despite being in different fields are fascinated by cosmos and specially black hole. The first image of black hole has send wave of excitement all over the world. I am a Deep learning engineer who mainly works with convolution neural network and I wanted to see what AI algorithms thinks about the black ...   \n",
       "321  Starts With A Bang!\\nAug 30, 2015\\nThanks to 3D printing, creativity and a lot of effort, this DIY Optimus Prime cake is unlike any other.\\n“When he came home, I could see a change. He was quieter and he was a man and a hero to me. I watched him and listened to him. I’d never had an opportunity to do a superhero, and when that came, [that voice] just came right out of me and I sounded like Optimus.” -Peter Cullen, on his brother\\nBeing a hero is something we all dream about in our own way. On our birthdays, everyone deserves to live out that fantasy, if only for a day. Have a listen to Tracy Chapman’s reflective and provocative song, Change,\\nwhile you consider the ultimate in “changing” superheros: Optimus Prime.\\nUnlike the flashy Decepticons, who transformed from robots into fighter...   \n",
       "322  Towards Data Science\\nJan 31, 2018\\nA Generative Model is a powerful way of learning any kind of data distribution using unsupervised learning and it has achieved tremendous success in just few years. All types of generative models aim at learning the true data distribution of the training set so as to generate new data points with some variations. But it is not always possible to learn the exact distribution of our data either implicitly or explicitly and so we try to model a distribution which is as similar as possible to the true data distribution. For this, we can leverage the power of neural networks to learn a function which can approximate the model distribution to the true distribution.\\nTwo of the most commonly used and efficient approaches are Variational Autoencoders (VAE) a...   \n",
       "323  ResponsibleML\\nJan 23, 2021\\nAre explainability methods black-box themselves?\\nThere are various adversarial attacks on machine learning models; hence, ways of defending, e.g. by using Explainable AI methods. Nowadays, attacks on model explanations come to light, so does the defense to such adversary. Here, we introduce fundamental concepts related to the domain. A further reference list is available at https://github.com/hbaniecki/adversarial-explainable-ai.\\nWhen considering an explanation as a function of model and data, there is a possibility to change one of these variables to achieve a different result.\\nThe first concept is to manipulate model explanations via data change. Dombrowski et al. [2019] showcase that perturbed images produce arbitrarily made visual explanations (e.g. ...   \n",
       "324  CLTC Bulletin\\nDec 3, 2019\\nA Brief Introduction for Non-Technical Audiences\\nRecent years have seen a rapid increase in the use of machine learning, through which computers can be programmed to identify patterns in information and make increasingly accurate predictions over time. Machine learning is a key enabling technology behind artificial intelligence (AI), and is used for such valuable applications as email spam filters and malware detection, as well as more complex technologies like speech recognition, facial recognition, robotics, and self-driving cars.\\nWhile machine learning models have many potential benefits, they may be vulnerable to manipulation. Cybersecurity researchers refer to this risk as “adversarial machine learning,” as AI systems can be deceived (by attackers or ...   \n",
       "325  BISA.AI\\nMar 25, 2020\\nPada masalah deteksi objek, output yang dihasilkan berupa bounding box (kotak pembatas) hasil prediksi sistem terhadap objek yang telah ditentukan. Bounding box ini merepresentasikan posisi objek dalam sebuah gambar. Untuk mengevaluasi model deteksi objek yang telah kita latih terdapat beberapa cara, salah satu caranya adalah dengan menggunakan metode Intersection Over Union (IOU). IOU memanfaatkan bounding box yang terdapat pada gambar.\\nIntersection Over Union (IOU) adalah nilai berdasarkan statistik kesamaan dan keragaman set sampel yang tujuannya untuk mengevaluasi area tumpang tindih (area yang beririsan) antara dua bounding box, yaitu bounding box hasil prediksi dan bounding box ground truth (kebenaran). Jadi, syarat untuk menerapkan IOU adalah mempunyai ke...   \n",
       "326  Towards Data Science\\nApr 15, 2019\\nThis article explores the use of a variational autoencoder to reduce the dimensions of financial time series with Keras and Python. We will further detect similarities between financial instruments in different markets and will use the results obtained to construct a custom index.\\nDisclaimer: The research presented in this article comes from our Winter 2019 Term Project for the Deep Learning course at the University of Toronto School of Continuing Studies. It was done in collaboration with Humberto Ribeiro de Souza. The concepts and ideas are our own. We are in no way representing our current or previous employers.\\nIn this section, we will discuss:\\nCreating The Geometric Moving Average Dataset\\nIn order to compare time series of various price rang...   \n",
       "327  Becoming Human: Artificial Intelligence Magazine\\nJul 9, 2017\\nOver the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.\\nThis is the most complete list and the Big-O is at the very end, enjoy...\\n>>> Update: We have recently redesigned these cheat sheets into a Super High Definition PDF. Check them out below:\\nbecominghuman.ai\\nchatbotslife.com\\naijobsboard.com\\nThis machine learning cheat sheet will help you find the right estimator for the job which is the most difficult part. The flowchart will help you che...   \n",
       "328  Towards Data Science\\nApr 22, 2019\\nThe major hurdle for going from image classification to object detection is fixed size input requirement to the network because of existing fully connected layers. In object detection, each proposal will be of a different shape. So there is a need for converting all the proposals to fixed shape as required by fully connected layers. ROI Pooling is exactly doing this.\\nRegion of Interest (ROI) pooling is used for utilising single feature map for all the proposals generated by RPN in a single pass. ROI pooling solves the problem of fixed image size requirement for object detection network.\\nROI pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of...   \n",
       "329  fabric8 io\\nApr 17, 2015\\nOne of the big promises of Kubernetes & OpenShift is really easy management of your containerised applications. For standalone or load-balanced stateless applications, Kubernetes works brilliantly, but one thing that I had a bit of trouble figuring out was how do perform cluster discovery for my applications? Say one of my applications needs to know about at least one other node (seed node) that it should join a cluster with.\\nThere is an example in the Kubernetes repo for Cassandra that requests existing service endpoints from the Kubernetes API server & use those as the seed servers. You can see the code for it here. That works great for a cluster that allows unauthenticated/unauthorized access to the API server, but hopefully most people are going to lock d...   \n",
       "330  Aug 17, 2016\\nI release MATLAB, R and Python codes of Support Vector Machine (SVM). They are very easy to use. You prepare data set, and just run the code! Then, SVM and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/XdZSo Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/OyXVZ Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/AtOvT Please download the supplemental zip file (this is free) from the URL below to run the SVM code. http://univprofb...   \n",
       "331  Towards Data Science\\nFeb 23, 2021\\nReinforcement learning (RL) is surely a rising field, with the huge influence from the performance of AlphaZero (the best chess engine as of now). RL is a subfield of machine learning that teaches agents to perform in an environment to maximize rewards overtime.\\nAmong RL’s model-free methods is temporal difference (TD) learning, with SARSA and Q-learning (QL) being two of the most used algorithms. I chose to explore SARSA and QL to highlight a subtle difference between on-policy learning and off-learning, which we will discuss later in the post.\\nThis post assumes you have basic knowledge of the agent, environment, action, and rewards within RL's scope. A brief introduction can be found here.\\nThe outline of this post include:\\nWe will compare these...   \n",
       "332  Towards Data Science\\nDec 10, 2018\\nIn my previous story, I went over how to train an image classifier in PyTorch, with your own images, and then use it for image recognition. Now I’ll show you how to use a pre-trained classifier to detect multiple objects in an image, and later track them across a video.\\nWhat’s the difference between image classification (recognition) and object detection? In classification, you identify what’s the main object in the image and the entire image is classified by a single class. In detection, multiple objects are identified in the image, classified, and a location is also determined (as a bounding box).\\nThere are several algorithms for object detection, with YOLO and SSD among the most popular. For this story, I’ll use YOLOv3. I won’t get into the tech...   \n",
       "333                                                                                                                                                                                                      OneZero\\nSep 1, 2021\\nOpenAI’s GPT-3 is the most powerful AI system I’ve ever used. Trained on billions of web pages and tens of thousands of books, the system can generate nearly any kind of text, from news articles to computer code to sea shanties.\\n1.2K \\n1.2K \\n25\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n30K Followers\\nCo-Founder & CEO of Gado Images. I write, speak & consult about tech, food, privacy, AI & photography. http://www.bayareatelegraph.com or tom@gadoimages.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "334  Towards Data Science\\nMay 1, 2020\\nIn this story, I explain the Attention U-Net from Attention U-Net:Learning Where to Look for the Pancreas written by Oktay et. al. The paper was written in 2018 and proposed a novel attention gate (AG) mechanism that allows the U-Net to focus on target structures of varying size and shape.\\nAttention, in the context of image segmentation, is a way to highlight only the relevant activations during training. This reduces the computational resources wasted on irrelevant activations, providing the network with better generalisation power. Essentially, the network can pay “attention” to certain parts of the image.\\na. Hard Attention\\nAttention comes in two forms, hard and soft. Hard attention works on the basis of highlighting relevant regions by cropping ...   \n",
       "335  ML 2 Vec\\nAug 7, 2017\\nConditional Random Fields are a discriminative model, used for predicting sequences. They use contextual information from previous labels, thus increasing the amount of information the model has to make a good prediction. In this post, I will go over some topics that will introduce CRFs. I will go over:\\nMachine Learning models have two common categorizations, Generative and Discriminative. Conditional Random Fields are a type of Discriminative classifier, and as such, they model the decision boundary between the different classes. Generative models, on the other hand, model how the data was generated, which after having learnt, can be used to make classifications. As a simple example, Naive Bayes, a very simple and popular probabilistic classifier, is a Generati...   \n",
       "336  Bonsal Capital\\nJan 25, 2014\\nSome people ask me Why Baltimore? Couldn’t you do what you do from anywhere in the U.S.? Isn’t this the place where the acclaimed HBO series The Wire was filmed? Has Baltimore ever been on a tech entrepreneur-friendly list? Aren’t there more voluminous entrepreneurial hubs? While the concise response is pegged to an authentic and ever-congealing entrepreneurial ecosystem more focused on the act of doing (the scoreboard) than a Top Ten List, the more interesting answer is found in an array of professional and personal attributes. Let me paint a picture as to why Baltimore is a great city to build a business, a career, a life.\\nBaltimore has a nearly three hundred year history of resilience and determination. What many do not grasp is that Baltimore is a top...   \n",
       "337  Towards Data Science\\nFeb 4, 2020\\nIf I have to describe latent space in one sentence, it simply means a representation of compressed data.\\nImagine a large dataset of handwritten digits (0–9) like the one shown above. Handwritten images of the same number (i.e. images that are 3’s) are the most similar to each other compared to other images of different numbers (i.e. 3s vs. 7s). But can we train an algorithm to recognize these similarities? How?\\nIf you have trained a model to classify digits, then you have also trained the model to learn the ‘structural similarities’ between images. In fact, this is how the model is able to classify digits in the first place- by learning the features of each digit.\\nIf it seems that this process is ‘hidden’ from you, it’s because it is. Latent, by de...   \n",
       "338  Towards Data Science\\nJan 25, 2021\\nI have been following crypto prices for several years now. I am fascinated with the evolution of the blockchain and its implications. I’ve chuckled more than once at the idea of digital currency. Not that it’s new, but I was born in the 80’s when we had to fill out a paper and speak with a human if we wanted to withdraw actual paper money...Remember paper money?\\nIn any case, today I want to share one of my recent projects with you. I will be comparing three models to determine their efficacy at predicting the price of Bitcoin, the King of Crypto. For this project, I used gated recurrent units (GRU), long short term memory units (LSTM), and bidirectional LSTM units (BiLSTM). First, let’s take a quick dive into the workings of these mysterious predict...   \n",
       "339  Chatbots Magazine\\nApr 20, 2016\\nWhat are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?\\nThese are the questions we’re going to answer for you right now.\\nReady? Let’s do this.\\n(Do you work in ecommerce? Stop reading and click here, we made something for you.)\\n(p.s. here is where I believe the future of bots is headed, you will probably disagree with me at first.)\\n(p.p.s. My newest guide about conversational commerce is up, I think you’ll find it super interesting.)\\n“~90% of our time on mobile is spent on email and messaging platforms. I would love to back teams that build stuff for places where the consumers hang out!” — Niko Bonatsos, Managing Director at General Catalyst\\nA chatbot is a s...   \n",
       "340  DataDrivenInvestor\\nMay 9, 2019\\nConditional GANs (CGANs) are an extension of the GANs model. You can read about a variant of GANs called DCGANs in my previous post here. CGANs are allowed to generate images that have certain conditions or attributes.\\nLike DCGANs, Conditional GANs also has two components.\\nwww.datadriveninvestor.com\\nConditional GANs (CGANs): The Generator and Discriminator both receive some additional conditioning input information. This could be the class of the current image or some other property.\\nFor example, if we train a DCGANs to generate new MNIST images, There is no control over which specific digits will be produced by the Generator. There is no mechanism for how to request a particular digit from the Generator. This problem can be addressed by a variation...   \n",
       "341  Towards Data Science\\nMar 23, 2020\\nVanishing Gradient, Saddle Point, Adversarial Training\\nPrerequisite- this post assumes the reader has an introductory-level understanding of neural network architectures, and have trained some form of deep networks, during which might have faced some issues related to training or robustness of a model.\\nA small perturbation or nudge in various parameters/components associated with training such as gradients, weights, inputs etc. can affect DNN training in overcoming some of the issues one might bump into, for example, vanishing gradient problem, saddle point trap, or creating a robust model to avoid malicious attacks through adversarial training etc.\\nTypically, perturbation theory is the study of a small change in a system which can be as a result ...   \n",
       "342  Mar 12, 2020\\nDBSCAN is a clustering method that is used in machine learning to separate clusters of high density from clusters of low density region. Its a very efficient clustering algorithm as it used to segregate the data points with high density observations vs data points of low density observations in form of various clusters.It can sort the data into various shapes of clusters as well. Major challenge of using DBSCAN algorithm is to find right set hyper parameters(eps and min_samples values) to fit in to the algorithm for getting accurate result.\\nLet’s look at a Spatial data of two dimensional coordinates (x,y) using we need to find out various possible star coagulation or dense clusters from this data.\\nRead the input data using Pandas dataframe.\\nAn initial plotting of the d...   \n",
       "343  Towards Data Science\\nSep 29, 2018\\nNeural networks are well known for classification problems, for example, they are used in handwritten digits classification, but the question is will it be fruitful if we used them for regression problems?\\nIn this article I will use a deep neural network to predict house pricing using a dataset from Kaggle .\\nYou can download the dataset from Here\\nI highly recommend you to try running the code using my notebook on Google colab [Here]\\n1- Process the dataset2- Make the deep neural network3- Train the DNN4- Test the DNN5- Compare the result from the DNN to another ML algorithm\\nFirst of all, we will import the needed dependencies :\\nWe will not go deep in processing the dataset, all we want to do is getting the dataset ready to be fed into our models...   \n",
       "344  Machine Learning for Humans\\nAug 19, 2017\\nHow much money will we make by spending more dollars on digital advertising? Will this loan applicant pay back the loan or not? What’s going to happen to the stock market tomorrow?\\nIn supervised learning problems, we start with a data set containing training examples with associated correct labels. For example, when learning to classify handwritten digits, a supervised learning algorithm takes thousands of pictures of handwritten digits along with labels containing the correct number each image represents. The algorithm will then learn the relationship between the images and their associated numbers, and apply that learned relationship to classify completely new images (without labels) that the machine hasn’t seen before. This is how you’re a...   \n",
       "345  Dec 11, 2019\\nHello Folks, in this article we will build our own Stochastic Gradient Descent (SGD) from scratch in Python and then we will use it for Linear Regression on Boston Housing Dataset. Just after a short recap of SGD, we will start building our own custom SGD.\\nTo keep the concept simple and easy to understand, we will touch the math calculations in an extremely simple step by step manner with its Python Code.\\nThen in the end we will combine all the code to solve the Linear Regression on Boston Housing Dataset.\\nWikipedia says: “ Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties. ”\\nLet’s begin, the Linear Regression optimization problem is to optimize or MINimize the SQUARED ERROR as shown below.\\nBut...   \n",
       "346  Towards Data Science\\nOct 31, 2017\\nHave you ever come across a situation where you want to predict a binary outcome like:\\nA very simple Machine Learning algorithm which will come to your rescue is Logistic Regression.\\nLogistic Regression is a classification algorithm which is used when we want to predict a categorical variable (Yes/No, Pass/Fail) based on a set of independent variable(s).\\nIn the Logistic Regression model, the log of odds of the dependent variable is modeled as a linear combination of the independent variables.\\nLet’s get more clarity on Binary Logistic Regression using a practical example in R.\\nConsider a situation where you are interested in classifying an individual as diabetic or non-diabetic based on features like glucose concentration, blood pressure, age etc...   \n",
       "347                                                                                                                                                                                                                                                                                       Jun 20, 2019\\nThis tutorial will guide you through the implementation and intuitive grasp on what is actually happening underneath the RNN networks.\\nThere has been extensive writing on this subject but I could not find a single source where the complete walk through of word...\\n68 \\n68 \\n2\\nSoftware Design and Product Management\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n14 Followers\\nSoftware Design and Product Management\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "348  May 4, 2020\\nEven object detection starts maturing in the last few years, the competition remains fierce. As shown below, YOLOv4 claims to have state-of-the-art accuracy while maintains a high processing frame rate. It achieves an accuracy of 43.5% AP (65.7% AP50) for the MS COCO with an approximately 65 FPS inference speed on Tesla V100. In object detection, high accuracy is not the only holy grail anymore. We want the model to run smoothly in the edge devices. How to process input video in real-time with low-cost hardware becomes important also.\\nThe fun part of reading the YOLOv4 development is what new technologies have been evaluated, modified, and integrated into YOLOv4. And it also makes changes to make the detector more suitable for training on a single GPU.\\nImprovements can b...   \n",
       "349  May 19, 2016\\n啟動子 (Promoter) 在人體遺傳基因扮演著重要角色,宛如人體一個開關,可以決定基因的活動,並控制細胞開始生產人體所需的蛋白質。當啟動子發生突變時,將可能導致基因表現的調節障礙。近期國際學者在癌細胞基因組的研究中發現,基因啟動子中的 DNA 突變數量增加,是因結合 DNA 控制基因表現的某些蛋白質,阻止人體的一個細胞修復系統去修復損傷的 DNA。啟動子突變的多寡與 DNA 修復系統相互作用,引發癌細胞生長有了重要的發現。\\n皮膚癌啟動子的突變密度特別高\\n2016 年 4 月發表在《Nature》的研究指出,科學家們分析來自 14 種癌症類型、1,161 個腫瘤的 2000 多萬 DNA 突變。他們發現在許多癌症類型,尤其是皮膚癌中,基因啟動子的基因組區域內突變數量特別高。研究進一步探究發現,人體控制基因表達的一些蛋白質,降低人體細胞修復系統的功能發揮,導致無法正常修復受損的 DNA,這個系統被稱為核苷酸切除修復 (NER, Nucleotide Excision-Repair)。NER 是唯一能修復紫外線造成的 DNA 損傷的系統,不僅如此,它還能處理抽煙誘導的遺傳損傷。\\n(上圖為DNA修復示意圖)\\n延伸閱讀:腫瘤的轉移與「偽轉移」 基因定序分析癌細胞親緣\\nDNA 修復如何參與癌細胞生長\\n西班牙研究團隊人員利用來自人類黑色素瘤樣本的全基因組序列分析調控區域的突變,並進一步分析核苷酸切除修復 (NER) 活性位點。結果發現,NER 功能的下降可導致一些轉錄因子位點的突變率增高。除此,在肺癌樣本中,他們也證實一些轉錄因子結合位點的突變率增高,尤其是與抽煙相關的突變。另一研究中,研究人員則分析多個癌症類型調控元件的突變。結果發現預測轉錄因子將結合的位置,即調控區域的核心,比側翼序列的突變率高達 5 倍。\\n總結,這項研究提示,在...   \n",
       "350  Analytics Vidhya\\nNov 14, 2020\\nIn this post, I will make you go through the theory of RNN, GRU and LSTM first and then I will show you how to implement and use them with code.\\nThere are already many posts on these topics out there. But in this post, I wanted to provide a much better understanding and comparison with help of code.\\nLet’s start with RNN!\\nRecurrent Neural Networks (RNN) are designed to work with sequential data. Sequential data(can be time-series) can be in form of text, audio, video etc.\\nRNN uses the previous information in the sequence to produce the current output. To understand this better I’m taking an example sentence.\\n“My class is the best class.”\\nAt the time(T0 ), the first step is to feed the word “My” into the network. the RNN produces an output.\\nAt the t...   \n",
       "351  Towards Data Science\\nJun 27, 2021\\nMy open-source GitHub script provides AI-based filters which apply a rather new technology called Artistic Neural Style Transfer to the input stream of your physical webcam device. In contrast to traditional filters, these AI-based filters are feature-aware. Depending on what kind of features are apparent in the video, the AI adapts the output. In addition, these kinds of filters can be learned from any real-world image. Since the provided filters are directly applied on the webcam video stream, they can be used in all types of video conferencing tools, such as Zoom, Skype, Discord, MS-Teams....\\nIn detail, my script sets up a virtual webcam device that applies Artistic Neural Style Transfer to the input stream of the physical webcam device. This new...   \n",
       "352  Jul 24, 2020\\nПроблема классификации объекта на изображении уже решена — сверточные нейронные сети (Convolutional Neural Networks, CNN) уже неплохо справляются с определением кошек или собак. Но если на изображении много объектов, которые нужно найти, задача сразу усложняется. На смену обычным сверточным нейросетям пришли более сложные модели. В этой статье рассмотрим 3 популярных способа детектирования изображений методами Deep Learning: R-CNN, Fast R-CNN и Faster R-CNN.\\nРаспознавание образов — это общий термин, описывающий круг задач компьютерного зрения, которые решают проблему обнаружения объектов на изображении или видеокадрах. К ним относятся классификация изображения, локализация объектов, детектирование объектов и сегментация. Проведем между ними грань:\\nКлассификация и...   \n",
       "353  Towards Data Science\\nMar 9, 2021\\nHow do you find meaning in data? In our mini project, my friend @ErikaSM and I seek to predict Singapore’s minimum wage if we had one, and documented that process in an article over here. If you have not read it, do take a look.\\nSince then, we have had comments on our process and suggestions to develop deeper insight into our information. As such, this follow-up article outlines two main objectives, finding meaning in data, and learning how to do stepwise regression.\\nIn the previous article, we discussed how the talk about a minimum wage in Singapore has frequently been a hot topic for debates. This is because Singapore uses a progressive wage model and hence does not have a minimum wage.\\nThe official stance of the Singapore Government is that a co...   \n",
       "354  techpsl\\nNov 11, 2013\\nWikipedia says, “Question Answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.”As I have taken the course of “Information Retrieval” this fall at UB, my final project is decided to be a Q-A system. Well we (me and my 3 group partners) have not decided much on features, which can make our project stand out, but for now we would like to start with a small goal. Somehow index the infobox of Wikipedia, and try to query it using natural language. My initial research suggests that IBM has already created something similar but on a very large scale, and they call it Watson.As we d...   \n",
       "355  Jan 22, 2020\\nThere has been a great advancement in the research in the area of meta-learning in recent years. And so has been an expansion in the available literature and blog posts.\\nModel Agnostic Meta-Learning (MAML) lies at the heart of the developments in the area. There have been many excellent blog-posts explaining meta-learning in general (here and here) and MAML in particular (here and here). The heavy terms and complex equations make the algorithm to look like a big shot rocket science. However, through this blog, I want to provide intuitive reasoning behind the algorithm that can be easy to understand for a person who has no idea about meta-learning. All one needs to know is the basic idea all machine learning researchers have been following from its inception: “Throw all y...   \n",
       "356  Dec 10, 2014\\n(The 2016 Machine Intelligence landscape and post can be found here)\\nI spent the last three months learning about every artificial intelligence, machine learning, or data related startup I could find — my current list has 2,529 of them to be exact. Yes, I should find better things to do with my evenings and weekends but until then...\\nWhy do this?\\nA few years ago, investors and startups were chasing “big data” (I helped put together a landscape on that industry). Now we’re seeing a similar explosion of companies calling themselves artificial intelligence, machine learning, or somesuch — collectively I call these “machine intelligence” (I’ll get into the definitions in a second). Our fund, Bloomberg Beta, which is focused on the future of work, has been investing in thes...   \n",
       "357                                                                                                                                 Jan 14, 2019\\nEven if we understand LSTMs theoretically, still many of us are confused about its input and output shapes while fitting the data to the network. This guide will help you understand the Input and Output shapes of the LSTM.\\nLet’s first understand the Input and its shape in LSTM Keras. The input data to LSTM looks like the following diagram.\\n1.95K \\n1.95K \\n17\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n918 Followers\\nCreating out of the box machine learning projects | shivajbd@gmail.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "358                                                                                                                  Analytics Vidhya\\nAug 23, 2020\\nKeras Embedding layer is first of Input layer for the neural networks. After the conversion of our raw input data in the token and padded sequence, now its time to feed the prepared input to the neural networks. In our previous two post we had covered step by step conversion of words into token and padded sequence, so i highly recommend to just...\\n53 \\n53 \\nAnalytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com\\n28 Followers\\nData scientist, (NLP, CV,ML,DL) Expert 007011\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "359  Sep 1, 2019\\nFrom my most recent escapade into the deep learning literature I present to you this paper by Oord et. al. which presents the idea of using discrete latent embeddings for variational auto encoders. The proposed model is called Vector Quantized Variational Autoencoders (VQ-VAE). I really liked the idea and the results that came with it but found surprisingly few resources to develop an understanding. Here’s an attempt to help other who might venture into this domain after me.\\nLike numerous other people Variational Autoencoders (VAEs) are my choice of generative models. Unlike GANs they are easier to train and reason about (No offence intended dear GANs). Going forward I assume you have some understanding of VAEs. If you don’t I suggest going through this post, I found it t...   \n",
       "360  Analytics Vidhya\\nFeb 9, 2021\\nThis has turn the old approach by giving an input from both the direction and by this it can remember the long sequences.\\nIn my previous article we discussed about RNN, LSTM and GRU. Now, there are certain limitations are still persist with LSTM because it is not able to remember the context for a longer period of time.\\nYou can see in this LSTM architecture that information is still have to pass from longer path. LSTM and GRU are introduced to overcome the problem of vanishing gradient and sequential data memory but the architecture of both are having multiple sequential path. Thus, vanishing gradient problem is still persist. Also, LSTM and GRU can remember sequences of 10s and 100s but not 1000s or more.\\nBidirectional Network\\nNow, when we are dealin...   \n",
       "361  Towards Data Science\\nMay 27, 2020\\nClustering is grouping of unlabeled data points in such a way that: The data points within the same group are similar to each other, and the data points in different groups are dissimilar to each other.The goal is to create clusters that have high intra-cluster similarity and low inter-cluster similarity.\\nK-Means cluster is one of the most commonly used unsupervised machine learning clustering techniques. It is a centroid based clustering technique that needs you decide the number of clusters (centroids) and randomly places the cluster centroids to begin the clustering process. The goal is to divide N observations into K clusters repeatedly until no more groups can be formed.\\n1. Decide the number of clusters. This number is called K and number of c...   \n",
       "362  Towards Data Science\\nMay 15, 2020\\nThis is the first post of the series “Deep Reinforcement Learning Explained”; an introductory series that gradually and with a practical approach introduces the reader to the basic concepts and methods used in modern Deep Reinforcement Learning.\\nSpanish version of this publication:\\nmedium.com\\nDeep Reinforcement Learning (DRL), a very fast-moving field, is the combination of Reinforcement Learning and Deep Learning. It is also the most trending type of Machine Learning because it can solve a wide range of complex decision-making tasks that were previously out of reach for a machine to solve real-world problems with human-like intelligence.\\nToday I’m starting a series about Deep Reinforcement Learning that will bring the topic closer to the reader....   \n",
       "363  Towards Data Science\\nJun 23, 2020\\nThis article is a part of the Gans-Series published by me on TowardsDataScience Publication on Medium. If you do not know what GANs are or if you have an idea about it but wish to quickly go over it again, I highly recommend you read the previous article which is just a 7 minutes long read and provides a simple understanding of GANs for people who are new to this amazing domain of Deep Learning.\\nAs you can tell from the gif shown above, this article is going to be all about learning how to create a Conditional GAN to predict colorful images from the given black and white sketch inputs without knowing the actual ground truth.\\nSketch to Color Image generation is an image-to-image translation model using Conditional Generative Adversarial Networks as ...   \n",
       "364  DataDrivenInvestor\\nMay 5, 2020\\nOne of the main questions that arise when studying Machine Learning and Deep Learning is the several types of Gradient Descent. Should I use Batch Gradient Descent? Mini-batch Gradient Descent or Stochastic Gradient Descent? In this post, we are going to understand the difference between those concepts and take a look at code implementations from Gradient Descent, to clarify these methods.\\nEdit: Updated version here.\\nAt this point, we know that our matrix of weights W and our vector of bias b are the core values of our Neural Networks (NN) (Check the Deep Learning Basics post). We can make an analogy with these concepts with the memory in which a NN stores patterns, and it is through tuning these parameters that we teach a NN. The acting of tuning is ...   \n",
       "365  Towards Data Science\\nJun 17, 2021\\nWhen I first came across lambda functions in python, I was very much intimidated and thought they were for advanced Pythonistas. Beginner python tutorials applaud the language for its readable syntax, but lambdas sure didn’t seem user-friendly.\\nHowever, once I understood the general syntax and examined some simple use cases, using them was less scary.\\nSimply put, a lambda function is just like any normal python function, except that it has no name when defining it, and it is contained in one line of code.\\nA lambda function evaluates an expression for a given argument. You give the function a value (argument) and then provide the operation (expression). The keyword lambda must come first. A full colon (:) separates the argument and the expression.\\...   \n",
       "366  Nov 11, 2017\\n“Numbers have an important story to tell. They rely on you to give them a voice.” — Stephen Few\\nAfter doing the usual Feature Engineering, Selection, and of course, implementing a model and getting some output in forms of a probability or a class, the next step is to find out how effective is the model based on some metric using test datasets. Different performance metrics are used to evaluate different Machine Learning Algorithms. For now, we will be focusing on the ones used for Classification problems. We can use classification performance metrics such as Log-Loss, Accuracy, AUC(Area under Curve) etc. Another example of metric for evaluation of machine learning algorithms is precision, recall, which can be used for sorting algorithms primarily used by search engines.\\...   \n",
       "367  Towards Data Science\\nAug 27, 2020\\nLately, posts and tutorials about new deep learning architectures and training strategies have dominated the community. However, one very interesting research area, namely few-shot learning, is not getting the attention it deserves. If we want widespread adoption of ML we need to find ways to train them efficiently, with little data and code. In this tutorial, we will go through a Google Colab Notebook to train an image classification model using only 5 labeled samples per class. Using only 5 exemplary samples is also called 5-shot learning.\\nDon’t forget to check out our Google Colab Notebook for the full code of this tutorial!\\nJupyter Notebook (Google Colab)The full code of this tutorial will be provided as a notebook. Jupyter Notebooks are python...   \n",
       "368  Towards Data Science\\nJun 27, 2017\\nThe idea behind GANs is that you have two networks, a generator GG and a discriminator DD, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it’s received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistinguishable from real data to the discriminator.\\nThis is equilibrium state and expectation is discriminator is emitting a probability of 0.5 for both real and fake data.\\nThe general structure of a ...   \n",
       "369  Good Audience\\nSep 15, 2018\\nSolving the sliding puzzle using a basic AI algorithm.\\nN-Puzzle or sliding puzzle is a popular puzzle that consists of N tiles where N can be 8, 15, 24, and so on. In our example N = 8. The puzzle is divided into sqrt(N+1) rows and sqrt(N+1) columns. Eg. 15-Puzzle will have 4 rows and 4 columns and an 8-Puzzle will have 3 rows and 3 columns. The puzzle consists of N tiles and one empty space where the tiles can be moved. Start and Goal configurations (also called state) of the puzzle are provided. The puzzle can be solved by moving the tiles one by one in the single empty space and thus achieving the Goal configuration.\\nThe tiles in the initial(start) state can be moved in the empty space in a particular order and thus achieve the goal state.\\nNote: There...   \n",
       "370                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            DataPy.ai\\nNov 18, 2019\\n105 \\n105 \\n3\\nSchool for Data Science\\n98 Followers\\nTrying to become ( .* ?) | MSc @ University of Twente | ML-NLP-Big Data-DL | tencsor.github.io | theguywithblacktie.github.io\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "371  Jul 19, 2014\\n“A mind is like a computer program that is executed in our brain” says the computer metaphor of the mind. It was developed in the 1950s. It basically compares the human mind to a computer program, suggesting that computers and our brain function on the same principles.\\nIn the philosophy of artificial intelligence (AI), the brain is perceived as a similar information processing machine as a digital computer.\\nThere is no doubt that some of our thinking processes, such as mental calculation and logical reasoning, are algorithmic. The digital computer functions with binary computer language where the symbols ‘1’ and ‘0’ represent the state of circuit’s gate. This means that an electrical impulse either goes through (state ‘1’) or does not (state ‘0’). It is similar to the f...   \n",
       "372  Jun 7, 2012\\nUpdate1: An improved SymSpell implementation is now 1,000,000x faster.Update2: SymSpellCompound with Compound aware spelling correction. Update3: Benchmark of SymSpell, BK-Tree und Norvig’s spell-correct.\\nRecently I answered a question on Quora about spelling correction for search engines. When I described our SymSpell algorithm I was pointed to Peter Norvig’s page where he outlined his approach.\\nBoth algorithms are based on Edit distance (Damerau-Levenshtein distance). Both try to find the dictionary entries with smallest edit distance from the query term.\\nIf the edit distance is 0 the term is spelled correctly, if the edit distance is <=2 the dictionary term is used as spelling suggestion. But SymSpell uses a different way to search the dictionary, resulting in a sign...   \n",
       "373  Towards Data Science\\nNov 13, 2021\\nOver the last several years, deep networks have extensively been shown to be vulnerable to attackers that can cause the network to make perplexing mistakes, simply by feeding maliciously-perturbed inputs to the network. Clearly, this raises concrete safety concerns for neural networks deployed in the wild, especially in safety-critical settings, e.g., in autonomous vehicles. In turn, this has motivated a volume of work on practical defenses, ranging from attack detection strategies to modified training routines that aim to produce networks that are difficult — or impossible — to attack. In this article, we’ll take a look at an elegant and effective defense I designed with my colleagues at CMU (appearing in ICML 2021) that modifies the architecture of...   \n",
       "374  Apr 24, 2018\\nBy — Yashwardhan Jain\\nSo, since you’re reading this article, I’m going to assume you have started your deep learning journey and have been playing around for a while with artificial neural nets. Or maybe, you’re just thinking of starting. Whichever case it be, you find yourself in a bit of a dilemma. You have read about various deep learning frameworks and libraries and maybe two really stand out. The two most popular deep learning libraries: Tensorflow and PyTorch. And you can’t quite figure out what exactly is the difference. Fret not! I’m here to add one more article to the unending repository of the Internet. And maybe, help you get some clarity. Also, I’m going to make it easier and quicker for you, and give you just five points. Five points of comparison, no more. ...   \n",
       "375  Towards Data Science\\nOct 8, 2020\\nK-Means and Gaussian Mixtures (GMs) are both clustering models. Many data scientist, however, tend to choose a more popular K-Means algorithm. Even if GMs can prove superior in certain clustering problems.\\nIn this article, we will see that both models offer a different performance in terms of speed and robustness. We will also see that it is possible to use K-Means as an initializer for GMs which tends to boost the performance of the clustering model.\\nFirst, let’s review the theoretical part of these algorithms. It will help us to understand their behaviour later in the article.\\nK-Means is a popular non-probabilistic clustering algorithm. The goal of the algorithm is to minimize the distortion measure J. We achieve that by the following iterative p...   \n",
       "376  Towards Data Science\\nAug 25, 2020\\nThe internet is full of text classification articles, most of which are BoW-models combined with some kind of ML-model typically solving a binary text classification problem. With the rise of NLP, and in particular BERT (take a look here, if you are not familiar with BERT) and other multilingual transformer based models, more and more text classification problems can now be solved.\\nHowever, when it comes to solving a multi-label, multi-class text classification problem using Huggingface Transformers, BERT, and Tensorflow Keras, the number of articles are indeed very limited and I for one, haven’t found any... Yet!\\nTherefore, with the help and inspiration of a great deal of blog posts, tutorials and GitHub code snippets all relating to either BERT, ...   \n",
       "377  Towards Data Science\\nMar 19, 2019\\nThe goal of this project is to find out similarities within groups of people in order to build a movie recommending system for users. We are going to analyze a dataset from Netflix database to explore the characteristics that people share in movies’ taste, based on how they rate them.\\nData will come from the MovieLens user rating dataset.\\nThis dataset has two files, we will import both and work with both of them.\\nWe will want to find out how the structure of the dataset works and how many records do we have in each of these tables.\\nWe will start by considering a subset of users and discovering what are their favourite genre. We will do this by defining a function that will calculate each user’s average rating for all science fiction and romance m...   \n",
       "378  Data Science at Microsoft\\nNov 5, 2020\\nBy Jane Huang, Daniel Yehdego, and Siddharth Kumar\\nThis is the second article of a series focusing on causal inference methods and applications. In Part 1, we discussed when and why causal models can help with different business problems. We also provided fundamentals for causal inference analysis and compared a few popular Python packages for causal analysis. In this article, we dive into details of various causal inference estimation methods and discuss algorithm selection for your own problem settings. Causal inference can be used on top of A/B tests in multiple ways to extract insights, but this article focuses mainly on estimation methods under unconfoundedness or on quasi-experimental bases when a randomized control trial (RCT) is not feas...   \n",
       "379  Towards Data Science\\nAug 26, 2020\\nA Convolutional Neural Network, also known as CNN or ConvNet, is a class of neural networks that specializes in processing data that has a grid-like topology, such as an image. A digital image is a binary representation of visual data. It contains a series of pixels arranged in a grid-like fashion that contains pixel values to denote how bright and what color each pixel should be.\\nThe human brain processes a huge amount of information the second we see an image. Each neuron works in its own receptive field and is connected to other neurons in a way that they cover the entire visual field. Just as each neuron responds to stimuli only in the restricted region of the visual field called the receptive field in the biological vision system, each neuron i...   \n",
       "380  Towards Data Science\\nNov 16, 2021\\nDo you think it is impossible to fool the vision system of a self-driving Tesla car?\\nOr that machine learning models used in malware detection software are too good to be evaded by hackers?\\nOr that face recognition systems in airports are bulletproof?\\nLike any of us machine learning enthusiasts, you might fall into the trap of thinking that deep models used out there are perfect.\\nWell, you are WRONG.\\nThere are easy ways to build adversarial examples that can fool any deep learning model and create security issues. In this post, we will cover the following:\\nLet’s start!\\nIn the last 10 years, deep learning models have left the academic kindergarten, become big boys, and transformed many industries. This is especially true for computer vision mod...   \n",
       "381  Towards Data Science\\nJun 7, 2020\\nOne of the distinctive differences between information in a single image and information in a video is the temporal element. This has led to improvements of deep learning model architectures to incorporate 3D processing in order to additionally process temporal information. This article summarizes the architectural changes from images to video through the I3D model.\\nThe I3D model was presented by researchers from DeepMind and the University of Oxford in a paper called “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” [1]. The paper compares previous approaches to the problem of action detection in videos while additionally presenting a new architecture, the focus here. Their approach starts with a 2D architecture and inflates all ...   \n",
       "382  Aug 23, 2016\\nI release MATLAB, R and Python codes of Random Forests Classification (RFC). They are very easy to use. You prepare data set, and just run the code! Then, RFC and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/RciDk Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/gdJgy Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/nDrmZ Please download the supplemental zip file (this is free) from the URL below to run the RFC code. http://un...   \n",
       "383  Becoming Human: Artificial Intelligence Magazine\\nAug 31, 2021\\nBefore getting into Transformers, let’s understand why researchers were interested in building something like Transformers inspite of having MLPs , CNNs and RNNs.\\nEveryone wants a universal model to solve different tasks with accuracy and speed. Just like MLPs which are universal function approximators, Transformer models are universal approximators of sequence-to-sequence functions.\\nTransformers use the concept of Attention mechanism. Let’s look what is attention and briefly go through self attention mechanisms.\\nAttention mechanism enhances the important parts of the input data and fades out the rest. Take the example of you captioning an image. You will have to focus on the relevant part of the image to generate meani...   \n",
       "384  mojitok\\nMar 10, 2019\\n어텐션 메커니즘은 자연어 기계 번역을 위한 Seq2Seq 모델에 처음 도입되었습니다. 어텐션 메커니즘은 NLP 태스크 뿐만 아니라, 도메인에 관계 없이 다양하게 쓰이고 있습니다. 현재의 SOTA NLP모델들은 대부분 어텐션 메커니즘을 적용하고 있으니 최근 논문을 이해함에 있어 이해하고 넘어가야 하는 부분입니다.\\n코드는 이곳(https://github.com/graykode/nlp-tutorial)을 참고해주세요 .\\n1. Seq2Seq (링크)2. Seq2Seq with Attention (링크)3. Bi-LSTM with Attention (링크)4. Transformer (링크)\\nSeq2Seq 모델은 대중적이므로 가볍게 짚고만 넘어가겠습니다. Seq2Seq 모델에 대한 자세한 설명들은 ratsgo님의 블로그를 참조하면 볼 수 있습니다. 더불어 자세한 내용은 원작 논문인 Neural Machine Translation by Jointly Learn...   \n",
       "385  Towards Data Science\\nMar 18, 2019\\n“Premature optimization is the root of all evil.” ― Donald Ervin Knuth\\nAgile is a pretty well-known term in the software development process. The basic idea behind it is simple: build something quickly, ➡️ get it out there, ➡️ get some feedback ➡️ make changes depending upon the feedback ➡️ repeat the process. The goal is to get the product near the user and guide you with feedback to obtain the best possible product with the least error. Also, the steps taken for improvement need to be small and should constantly involve the user. In a way, an Agile software development process involves rapid iterations. The idea of — start with a solution as soon as possible, measure and iterate as frequently as possible, is Gradient descent under the hood.\\nGradi...   \n",
       "386  Feb 23, 2018\\nWhile Python’s scikit-learn library provides the easy-to-use and efficient LogisticRegression class, the objective of this post is to create an own implementation using NumPy. Implementing basic models is a great idea to improve your comprehension about how they work.\\nWe will use the well known Iris data set. It contains 3 classes of 50 instances each, where each class refers to a type of iris plant. To simplify things, we take just the first two feature columns. Also, the two non-linearly separable classes are labeled with the same category, ending up with a binary classification problem.\\nGiven a set of inputs X, we want to assign them to one of two possible categories (0 or 1). Logistic regression models the probability that each input belongs to a particular category...   \n",
       "387  Towards Data Science\\nJun 10, 2021\\nThis blog post is part of a mini-series that talks about the different aspects of building a PyTorch Deep Learning project using Variational Autoencoders.\\nPart 1: Mathematical Foundations and ImplementationPart 2: Supercharge with PyTorch LightningPart 3: Convolutional VAE, Inheritance and Unit TestingPart 4: Streamlit Web App and Deployment\\nIn this section, we will look at how we can use the code we wrote in the previous section and use it to build a convolutional VAE. This VAE would be better at identifying important features in the images and thus generate even better images.\\nThe best part is that this new model can be built with minimal additional code thanks to PyTorch modules and class inheritance.\\nConvolution is an operation commonly used ...   \n",
       "388  Coders Camp\\nJan 14, 2021\\nPython has been in the top 10 popular programming languages for a long time, as the community of Python programmers has grown a lot due to its easy syntax and library support. In this article, I will introduce you to 60 amazing Python projects with source code solved and explained for free.\\nIf you’re a newbie to Python where you’ve just learned lists, tuples, dictionaries, and some basic Python modules like the random module, here are some Python projects with source code for beginners for you:\\nIf you have learned the fundamental Python libraries and some of the external libraries, you should now know how to install external libraries and work with them. So if you are at that level now, you can work on all the advanced Python projects with source code menti...   \n",
       "389  Towards Data Science\\nNov 13, 2017\\nIn this article, we’ll look at:\\nLinks to my other articles:\\nIn many cases when using neural network models such as regular deep feedforward nets and convolutional nets for classification tasks over some set of class labels, one wonders whether it is possible to interpret the output, for example y = [0.02, 0, 0.005, 0.975], as the probability of some input being in a class equal to the respective component values yi in the output vector. Skipping straight to the long answer: no, unless you have a softmax layer as your output layer and train the net with the cross-entropy loss function. This point is important because it is sometimes omitted in online sources and even in some textbooks regarding classification with neural networks. We’ll take a look ...   \n",
       "390  binaryandmore\\nJul 16, 2018\\nThis article is divided into two sections:1. Derivation — In this section, we will be deriving all the required formulae for performing backpropagation. I strongly recommend that you derive the equations on paper as you read through the article.2. Implementation — In this part, we will use the derived formulae to implement backpropagation from scratch. We will be solving a binary classification problem in python using numpy.\\nDisclaimerThis article assumes a basic understanding of neural networks and how they work. If you are not familiar with neural networks, or think your concepts are a little rusty, you may want to review chapter 1 of the amazing book, Neural Networks and Deep Learning, by Michael Nielsen, or if you prefer video lectures, you might want ...   \n",
       "391  Towards Data Science\\nJun 9, 2020\\nOne can be forgiven for taking mAP (mean average precision) to literally mean the average of precisions. Nevertheless, you couldn’t be further from the truth!\\nLet me explain.\\nIn computer vision, mAP is a popular evaluation metric used for object detection (i.e. localisation and classification). Localization determines the location of an instance (e.g. bounding box coordinates) and classification tells you what it is (e.g. a dog or cat).\\nMany object detection algorithms, such as Faster R-CNN, MobileNet SSD, and YOLO, use mAP to evaluate their models for publishing their research.\\nYou might ask, if it’s such a popular metric, why is it still confusing?\\nFair enough!\\nmAP stands for Mean Average Precision (as you might already have guessed looking at...   \n",
       "392  Dec 5, 2018\\nIn 2014 machine learning researcher Ian Goodfellow introduced the idea of generative adversarial networks or GANs. “Generative” because they output things like images rather than predictions about input (like “hotdog or not”); “adversarial networks” because they use two neural networks competing with each other in a “cat-and-mouse game”, like a cashier and a counterfeiter: one trying to fool the other into thinking it can generate real examples, the other trying to distinguish real from fake.\\nThe first GAN images were easy for humans to identify. Consider these faces from 2014.\\nBut the latest examples of GAN-generated faces, published in October 2017, are more difficult to identify.\\nHere are some things you can look for when trying to recognize an image produced by a GA...   \n",
       "393  Nov 2, 2012\\nThis post will try to give you a brief introduction to artificial neural networks or at least to some types of them. I will skip the introduction to biological neural networks as I am neither a biologist nor a doctor, I prefer not to write about what I do not fully understand.\\nOverview of artificial neural networks and supervised learning\\nI think it is very important to note that artificial neural networks are neither magical AI circuits nor oracles with the ability of predicting stock market movements. You can save one as a file on the disk and you can name it skynet if you like but it will not get more intelligent from that. In reality they are simply mathematical tools that can come very handy in solving certain problems (and can prove to be completely useless for oth...   \n",
       "394  SyncedReview\\nOct 2, 2018\\n“Best GAN samples ever yet? Very impressive ICLR submission! BigGAN improves Inception Scores by >100.”\\nThe above Tweet is from renowned Google DeepMind research scientist Oriol Vinyals. It was retweeted last week by Google Brain researcher and “Father of Generative Adversarial Networks” Ian Goodfellow, and picked up momentum and praise from AI researchers on social media.\\n402 \\n402 \\n5\\nWe produce professional, authoritative, and thought-provoking content relating to artificial intelligence, machine intelligence, emerging technologies and industrial insights.\\n23K Followers\\nAI Technology & Industry Review — syncedreview.com | Newsletter: http://bit.ly/2IYL6Y2 | Share My Research http://bit.ly/2TrUPMI | Twitter: @Synced_Global\\nHelp\\nStatus\\nWriters\\nBlog\\...   \n",
       "395  Towards Data Science\\nNov 15, 2020\\nThis is as up to date as: 3/1/2022\\nThis is a vastly revised version of the older version you all know and love.Almost every part of this guide has been thoroughly rewritten. The original guide has been getting updated over the course of 6 years, so I decided it’s time to basically (almost) write it from scratch.This time I tried to make this a bit more thorough and general. I’ll keep updating this, but I also want to make sure my readers can understand the topic even if I stop doing so one day.\\nSo, you’ve decided you want to purchase a machine dedicated to training machine learning models. Or, rather, you work in an organization where the buzzwords of this guide are constantly thrown around and you simply want to know a bit more about what they mea...   \n",
       "396  Dec 6, 2021\\nTL;DR — I complain about NFTs, then attempt to train both a GAN and super-resolution model to generate Bored Apes that do not exist. You can check out all the generated images on thisboredapedoesnotexist.nathancooperjones.com.\\nFriday, November 12th, 2021 started out as a normal day for me. Before starting my day at work, I decided to open Twitter to see if I missed anything since the night before.\\nThen, it happened. I saw this Tweet:\\nSay what you will about how Jimmy Fallon tells and reacts to jokes, but if this was a joke, I did not understand it. An animated monkey dressed in a sailor cap? I soon learned that this wasn’t just any animated ape, but one of exactly 10,000 unique images produced in a collection called Bored Ape Yacht Club. After ten minutes down a Twitter...   \n",
       "397                                                                                                                                                                                                                                               Dec 20, 2019\\nNowadays, there are big problems about parking areas. The large number of vehicles in the cities and the scarcity of parking spaces lead to parking problems in the cities. The biggest solution that can be brought to this problem is to provide people with the information whether the parking spaces are automatically empty or full. Using a mask...\\n17 \\n17 \\n1\\nSoftware Engineer\\nLove podcasts or audiobooks? Learn on the go with our new app.\\n49 Followers\\nSoftware Engineer\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "398  The Hands-on Advisors\\nApr 20, 2018\\nDuring the start of my career, I was fortunate enough to work on a subfield of machine learning known as online learning (also known as incremental or out-of-core learning). Compared to “traditional” ML solutions, online learning is a fundamentally different approach, one that embraces the fact that learning environments can (and do) change from second to second. It’s tricky to get right, but when applied correctly, the results you can achieve with online learning are nothing short of remarkable. In this post, I’ll give a quick introduction to the technique.\\nUpdate 27/09/2019: lots of people have asked if there exist any purpose-built incremental learning libraries. Yes! Vowpal Wabbit is extremely powerful, and has been around for quite a while. Fo...   \n",
       "399  Product Development Notebook\\nOct 26, 2015\\nIt’s been a while since I first wrote about how useful computer vision can be in product development, and I recently put together a quick demo for other engineers at my new gig (@ Continuum) that is cleaner and more thorough than previous versions (plus it uses the cv2 library instead of the deprecated cv library I used before).\\n(and of course it’s written in python)\\n...\\n...\\n...\\nImage analysis is hugely powerful, particularly in the context of product development. Most of the challenges in computer vision (and AI in general) comes from trying to process unstructured and/or uncontrolled information.\\nFortunately, we product development engineers spend a bunch of time setting up experiments in the lab. In those cases we have much more cont...   \n",
       "400  Towards Data Science\\nDec 8, 2019\\nA lot of innovations on NLP have been how to add context into word vectors. One of the common ways of doing it is using Recurrent Neural Networks. The following are the concepts of Recurrent Neural Networks:\\nThe above is the architecture of Recurrent Neural Networks.\\nAssuming we are solving document classification problem for a news article data set.\\nTherefore, we generally do not use vanilla RNNs, and we use Long Short Term Memory instead. LSTM is a type of RNNs that can solve this long term dependency problem.\\nIn our document classification for news article example, we have this many-to- one relationship. The input are sequences of words, output is one single class or label.\\nNow we are going to solve a BBC news document classification problem w...   \n",
       "401  pandorabots-blog\\nOct 9, 2014\\nSuppose you are building an Intelligent Virtual Agent or Virtual Personal Assistant (VPA) that uses a Pandorabot as the natural language processing engine. You might want this VPA to be able to perform tasks such as sending a text message, adding an event to a calendar, or even just initiating a phone call. OOB tags allow you to do just that!\\nOOB stands for “out of band,” which is an engineering term used to refer to activity performed on a separate, hidden channel. For a Pandorabot VPA, this translates to activities which fall outside of the scope of an ordinary conversation, such as placing a phone call, checking dynamic information like the weather, or searching wikipedia for the answer to some question. The task is executed, but does not necessarily ...   \n",
       "402  DataX Journal\\nFeb 1, 2021\\nHow attention-based mechanism completely transformed the working of neural machine translations while exploring contextual relations in sequences!\\nWhen it comes to applying deep learning principles to natural language processing, contextual information weighs in a lot! In the past few years, it has been shown that various improvement in existing neural network architectures concerned with NLP has shown an amazing performance in extracting featured information from textual data and performing various operations for a day to day life. One of the models which we will be discussing in this article is encoder-decoder architecture along with the attention model.\\nThe encoder-decoder architecture for recurrent neural networks is actually proving to be powerful for...   \n",
       "403  Towards Data Science\\nMar 4, 2019\\nIn this article, I’ll go over:\\nThis article got longer that what I originally intended, so for the busy souls, here is a synopsis.\\nExplanations for AI behavior that are generated Ad-hoc or post-hoc are more like justifications and may not be capture the truth of the decision process. If trust and accountability is needed, that has to be taken into account early on in the design process. Explainable AI (XAI )is NOT an AI that can explain itself, it is a design decision by developers. It is AI that is transparent enough so that the explanations that are needed are part of the design process.\\nNow, the full story.\\nA self driving car knocked down and killed a pedestrian in Tempe, AZ in 2018. Issues like who is to blame (accountability), who to prevent ...   \n",
       "404  Towards Data Science\\nJun 19, 2019\\nThis blog will cover following questions and topics\\n1. What is Perceptron?\\n2. Stochastic Gradient Descent for Perceptron\\n3. Implementation in Python\\n1. What is Perceptron?\\nPerceptron set the foundations for Neural Network models in 1980s. The algorithm was developed by Frank Rosenblatt and was encapsulated in the paper “Principles of Neuro-dynamics: Perceptrons and the Theory of Brain Mechanisms” published in 1962. At that time, Rosenblatt’s work was criticized by Marvin Minksy and Seymour Papert, arguing that neural networks were flawed and could only solve linear separation problem. However, such limitation only occurs in the single layer neural network.\\nPerceptron can be used to solve two-class classification problem. The generalized form of...   \n",
       "405  Gab41\\nDec 13, 2015\\nIf you follow any of the popular blogs like Google’s research, FastML, Smola’s Adventures in Data Land, or one of the indie-pop ones like Edwin Chen’s blog, you’ve probably also used ModelZoo. Actually, if you’re like our boss, you affectionately call it “The Zoo”. (Actually x 2, if you have interesting blogs that you read, feel free to let us know!)\\nUnfortunately, ModelZoo is only supported in Caffe. Fortunately, we’ve taken a look at the difference between the kernels in Keras, Theano, and Caffe for you, and after reading this blog, you’ll be able to load models from ModelZoo into any of your favorite Python tools.\\nWhy this post? Why not just download our Github code?\\nIn short, it’s better you figure out how these things work before you use them. That way, you...   \n",
       "406  Towards Data Science\\nSep 21, 2018\\nUnderstand the basic goto concepts to get a quick start on reinforcement learning and learn to test your algorithms with OpenAI gym to achieve research centric reproducible results.\\nThis article first walks you through the basics of reinforcement learning, its current advancements and a somewhat detailed practical use-case of autonomous driving. After that we get dirty with code and learn about OpenAI Gym, a tool often used by researchers for standardization and benchmarking results. When the coding section comes please open your terminal and get ready for some hands on.A time saver tip: You can directly skip to ‘Conceptual Understanding’ section if you want to skip basics and only want try out Open AI gym directly.\\nMainly three categories of learn...   \n",
       "407  Nov 23, 2017\\nHatırlarsınız, önce 1997’de DeepMind’ın bilgisayarı Deep Blue Kasparov’u satrançta yenmişti. Bir sonraki adımdaysa AlphaGo önce dünya Go şampiyonu Ke Jie’yi, sonrasında da bir üst model AlphaGo Zero en iyi Go oyuncularından biri sayılan Lee Sedol’u 2016’da 3 kez yendi. Şimdi yeni adımın StarCraft olacağı söyleniyor; ki bilen bilir StarCraft koordinasyon, hızlı karar alma, dikkat olarak epey zorlayıcı bir oyundur. AlphaGo bütün bunları Reinforcement Learning (Pekiştirmeli Öğrenme) ile yaptı.\\nPekiştirmeli Öğrenme, Makine Öğrenmesi’nin alt kollarından biri. Makine Öğrenmesi’nde genellikle Markov Karar Süreci adı verilen bir model kullanılıyor. Bu model yapay zekânın önceden bilgilendirilmesine ve yönlendirilmesine dayalı. Kesin bir neden sonuç ili...   \n",
       "408  Capire.info\\nJun 18, 2008\\nEscribe Jorge Garrido G.\\nAlgunas sugerencias sobre cómo construir un menú que entregue orientación y control al usuario, sin perder claridad en su forma de presentarse.¿Qué es un menú? ¿Qué representa? ¿Qué comunica? ¿Para qué sirve? ¿Todo sitio web o aplicación debe tener un menú?\\nLas respuestas no son tan sencillas ni están tan claras; mucho menos se puede considerar este como un tema superado. No lo creo por lo que percibo cuando navego, periódicamente. Veo menús poco cuidados, incomprendidos, mal diseñados, desenfocados.\\nHay muchos otros recursos, fuera de los menús de navegación, para destacar los contenidos más importantes: Accesos directos con características gráficas sobresalientes, listados de hotlinks, nubes de tags y un largo ...   \n",
       "409  Towards Data Science\\nNov 6, 2020\\nIt’s not as hard as you think!\\nTl;dr if you want to skip the tutorial. Here is the notebook I created.\\nAdam is algorithm the optimizes stochastic objective functions based on adaptive estimates of moments. The update rule of Adam is a combination of momentum and the RMSProp optimizer.\\nThe rules are simple. Code Adam from scratch without the help of any external ML libraries such as PyTorch, Keras, Chainer or Tensorflow. Only libraries we are allowed to use arenumpy and math .\\n(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ(っ^‿^)っ\\nThe easiest way to learn how Adam’s works is to watch Andrew Ng’s video. Alternatively, you can read Adam’s original paper to get a better understanding of the motivation and intuition behind it.\\nTwo values that Adam depend on are ...   \n",
       "410  Towards AI\\nJun 3, 2020\\nAuthor(s): Pratik Shukla, Roberto Iriondo, Sherwin Chen\\nLast updated April 14, 2021\\nmembers.towardsai.net\\nMachine learning (ML) is rapidly changing the world, from diverse types of applications and research pursued in industry and academia. Machine learning is affecting every part of our daily lives. From voice assistants using NLP and machine learning to make appointments, check our calendar, and play music, to programmatic advertisements — that are so accurate that they can predict what we will need before we even think of it.\\nMore often than not, the complexity of the scientific field of machine learning can be overwhelming, making keeping up with “what is important” a very challenging task. However, to make sure that we provide a learning path to those ...   \n",
       "411  HackerNoon.com\\nMay 31, 2014\\nWhen it comes to function minimization, it’s time to open a book of optimization and linear algebra. I am currently working on variable selection and lasso-based solutions in genetics. What lasso does is basically minimizing the loss function and an penalty in order to set to zero some regression coefficients and select only those covariates that are really associated with the response. Pheew, the shortest summary of lasso ever!\\nWe all know that, provided the function to be minimized is convex, a good direction to follow, in order to find a local minimum, is towards the negative gradient of the function. Now, my question is how good or bad is following the negative gradient with respect to a coordinate descent approach that loops across all dimensions and...   \n",
       "412  HackerNoon.com\\nOct 4, 2016\\nTLDR — Use pipelines to save TF-IDF model generated from the training set, and SVM model for prediction. So essentially save two models, one for feature extraction and transformation of input, the other for prediction.\\nOne of the big challenges when you develop a text classification model, the trained model which you get is not enough for prediction if your plan was to train offline and deploy only the model for prediction in some cases. Especially in the case where we are extracting features from the training set using `Hashing Trick` and to normalise the importance of a feature/term to the document using `Inverse Document Frequency`, the most frequent terms in documents actually have lesser importance to the whole corpus. This is all commonly labelled ac...   \n",
       "413                                                                                                                                                                                                                                                                                                                                                                                                                                   MLearning.ai\\nMar 4, 2021\\n4 \\n4 \\nData Scientists must think like an artist when finding a solution when creating a piece of code. ⚪️ Artists enjoy working on interesting problems, even if there is no obvious answer ⚪️ linktr.ee/mlearning 🔵 Follow to join our 18K+ Unique DAILY Readers 🟠\\n36 Followers\\nData.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "414  Towards Data Science\\nJul 27, 2020\\nToday, internet and social media have become the fastest and easiest ways to get information. In this age, reviews, opinions, feedbacks, messages and recommendations have become significant source of information. Thanks to advancement in technologies, we are now able to extract meaningful information from such data using various Natural Language Processing (NLP) techniques. NLP , a branch of Artificial Intelligence (AI), makes use of computers and human natural language to output valuable information. NLP is commonly used in text classification task such as spam detection and sentiment analysis, text generation, language translations and document classification.\\nThe purpose of this article is to understand how we can use TensorFlow2 to build SMS spa...   \n",
       "415  Towards Data Science\\nSep 3, 2020\\nThe classical way of doing POS tagging is using some variant of Hidden Markov Model. Here we'll see how we could do that using Recurrent neural networks. The original RNN architecture has some variants too. It has a novel RNN architecture — the Bidirectional RNN which is capable of reading sequences in the ‘reverse order’ as well and has proven to boost performance significantly.\\nThen two important cutting-edge variants of the RNN which have made it possible to train large networks on real datasets. Although RNNs are capable of solving a variety of sequence problems, their architecture itself is their biggest enemy due to the problems of exploding and vanishing gradients that occur during the training of RNNs. This problem is solved by two popular ga...   \n",
       "416                                                                                                                                                                                                                                            Geek Culture\\nMay 6, 2021\\nThis post will learn to create a DCGAN using PyTorch on the MNIST dataset.\\nA basic understanding of CNN\\nA sample implementation using CNN\\nUnderstanding Deep Convolutional GAN\\nGANs were invented by Ian Goodfellow in 2014 and first described in the paper Generative...\\n3 \\n3 \\n1\\nA new tech publication by Start it up (https://medium.com/swlh).\\n3.7K Followers\\nLoves learning, sharing, and discovering myself. Passionate about Machine Learning and Deep Learning\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "417  Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...   \n",
       "418  Mar 18, 2018\\nYou only look once (YOLO) is an object detection system targeted for real-time processing. We will introduce YOLO, YOLOv2 and YOLO9000 in this article. For those only interested in YOLOv3, please forward to the bottom of the article. Here is the accuracy and speed comparison provided by the YOLO web site.\\nA demonstration from the YOLOv2.\\nLet’s start with our own testing image below.\\nThe objects detected by YOLO:\\nGrid cell\\nFor our discussion, we crop our original photo. YOLO divides the input image into an S×S grid. Each grid cell predicts only one object. For example, the yellow grid cell below tries to predict the “person” object whose center (the blue dot) falls inside the grid cell.\\nEach grid cell predicts a fixed number of boundary boxes. In this example, the ye...   \n",
       "419  Towards Data Science\\nMar 30, 2020\\nThis article is a detailed account of my approach to solving a regression problem, which is also a popular Kaggle competition. Hope you find it useful and enjoy reading it :)\\nArtificial Intelligence is an integral part of all major e-commerce companies today. With the evolution of the information industry and extensive research in the field of AI in the past two decades, businesses have started to explore the ways to automate various activities using state of the art Machine Learning algorithms and Deep Neural Networks. Many IT giants and start-ups have already taken a big leap in this field and have dedicated teams and resources for research and development of cutting edge AI applications. Online retail platforms today are extensively driven by AI-...   \n",
       "420                                                                                                  The Startup\\nAug 13, 2020\\nI first came across the concept of embeddings while developing the RNN typing practice app.\\nEven though I am just beginning to understand the range of uses for embeddings, I thought it would be useful to write down some of the basics.\\nFirst, let’s look at what I knew before embeddings, one-hot vectors.\\n52 \\n52 \\nGet smarter at building your thing. Follow to join The Startup’s +8 million monthly readers & +754K followers.\\n13 Followers\\nMy goal is to serve humanity and to bring happiness to others. I want to understand the problems around us and help find solutions. https://www.bayanbennett.com\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "421  Towards Data Science\\nFeb 5, 2018\\nWant to be inspired? Come join my Super Quotes newsletter. 😎\\nClustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. Clustering is a method of unsupervised learning and is a common technique for statistical data analysis used in many fields.\\nIn Data Science, we can use clustering analysis to gain some valuable insights from our data by seeing what groups the data points fall into when we apply a clustering algorithm. T...   \n",
       "422  Feb 5, 2019\\nAttention mechanism for sequence modelling was first introduced in the paper: Neural Machine Translation by jointly learning to align and translate, Bengio et. al. ICLR 2015. Even though the paper itself mentions the word “attention” scarcely (3 times total in 2 consecutive lines!!) the term has caught on. A lot of prominent work that came later on uses the same naming convention (Well, I for one think it’s more of a “soft memory” rather than “attention”).\\nThis post focuses on Bengio et. al. 2015 and tries to give a step by step explanation of the (attention) model explained in their paper. Probably it’s just me but the explanation given in the paper and the diagrams that came with it left a lot to the imagination. This post tries to make understanding their great work a ...   \n",
       "423  Towards Data Science\\nApr 23, 2019\\nThis post was co-written with Baptiste Rocca.\\n“Unity is strength”. This old saying expresses pretty well the underlying idea that rules the very powerful “ensemble methods” in machine learning. Roughly, ensemble learning methods, that often trust the top rankings of many machine learning competitions (including Kaggle’s competitions), are based on the hypothesis that combining multiple models together can often produce a much more powerful model.\\nThe purpose of this post is to introduce various notions of ensemble learning. We will give the reader some necessary keys to well understand and use related methods and be able to design adapted solutions when needed. We will discuss some well known notions such as boostrapping, bagging, random forest, bo...   \n",
       "424  Analytics Vidhya\\nApr 2, 2021\\nReference How to Implement Naive Bayes? Section 2: Building the Model in Python, prior to continuing...\\n[10] Define Grid Search Parameters\\nWhy this step: To set the selected parameters used to find the optimal combination. By referencing the sklearn.naive_bayes.GaussianNB documentation, you can find a completed list of parameters with descriptions that can be used in grid search functionalities.\\n[11] Hyperparameter Tune using Training Data\\nNote: Total number of fits is 1000 since the cv is defined as 10 and there are 100 candidates (var_smoothing has 100 defined parameters). Therefore, the calculation for a total number of fits → 10 x [100] = 1000.\\nWhy this step: To find an optimal combination of hyperparameters that minimizes a predefined loss funct...   \n",
       "425  AI3 | Theory, Practice, Business\\nSep 22, 2019\\nR-CNN & Fast R-CNN\\nFollowing part1, an object-detection-algorithm has to draw up to several bounding boxes representing different objects of interest within the image and you would not know how many beforehand.\\nA direct approach (brut force) to solve this issue would be to take different regions of interest from the image and use a CNN to classify the presence of the object within that region. The problem here, the objects of interest might have different spatial locations within the image and different aspect ratios. Hence, you would have to select a huge number of regions and this could computationally hard (increasingly hard). Therefore, algorithms like R-CNN, YOLO, etc have been developed to find these occurrences and find them fast...   \n",
       "426  MLearning.ai\\nMay 6, 2021\\nR-CNN architecture is used to detect the classes of objects in the images and the bounding boxes of these objects. RCNN architecture has been developed since classification cannot be made for more than one object with CNN in visuals containing more than one object.\\nThe general working principle of R-CNN takes place in two steps. First, the features where the object can be found in the visual are determined with selective search, then after the regions are determined, each region is given as an input to a CNN model and the prediction process is performed for classes and bounding boxes.\\nSelective Search:\\nIt is used to determine the regions on the image that should be captured. Small areas are determined first. Then, similar regions are combined to create lar...   \n",
       "427  Towards Data Science\\nJul 14, 2019\\nMachine learning is exciting. However, just like any new technology or invention, not only does ML enable new amazing capabilities — but also, unfortunately, new vulnerabilities.\\nPreviously I’ve discussed how to think about these vulnerabilities in a structured way (or how to develop a “threat model” for your ML). This time I’d like to dive deep into how your ML system can be exploited during inference time through what is known as an evasion attack.\\nWith no time to waste, let’s get started.\\nAn evasion attack happens when the network is fed an “adversarial example” — a carefully perturbed input that looks and feels exactly the same as its untampered copy to a human — but that completely throws off the classifier.\\nDespite all the hype around adver...   \n",
       "428  Aug 5, 2021\\nIn many organizations, there is a unique vocabulary that maps names to known entities within that domain. At the United Nations, for instance, we have many specific entities which it is useful to identify in documents, including specific named committees and assemblies, important topics like the Sustainable Development Goals (SGDs), and many different countries and cultural groups that must be identified correctly. Exhaustively naming each and every important topic that may appear in a document, however, is not reasonable considering the shear number that may be important, especially considering the context of a document or sentence in which this entity is present. Instead, we want to be able to automatically identify and predict named entities using Named Entity Recogniti...   \n",
       "429  ML Review\\nDec 9, 2017\\nSimplifying a complex algorithm\\nAlthough most of the Kaggle competition winners use stack/ensemble of various models, one particular model that is part of most of the ensembles is some variant of Gradient Boosting (GBM) algorithm. Take for an example the winner of latest Kaggle competition: Michael Jahrer’s solution with representation learning in Safe Driver Prediction. His solution was a blend of 6 models. 1 LightGBM (a variant of GBM) and 5 Neural Nets. Although his success is attributed to the semi-supervised learning that he used for the structured data, but gradient boosting model has done the useful part too.\\nEven though GBM is being used widely, many practitioners still treat it as complex black-box algorithm and just run the models using pre-built lib...   \n",
       "430  Towards Data Science\\nMar 18, 2019\\nOne of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it seemed to make sense. In this quick post I’ll discuss q-learning and provide the basic background to understanding the algorithm.\\nQ-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It’s considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn’t needed. More specifically, q-learning seeks to learn a policy that maximizes the total reward.\\nThe ‘q’ in q-learning stands for quali...   \n",
       "431  Emergent // Future\\nAug 25, 2016\\nFor this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1–3). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q...   \n",
       "432  Blog rilut\\nJan 3, 2017\\nHere’s a quick summary on Arild Nøkland’s 2016 paper “Direct Feedback Alignment” which is not only written clearly but also interesting. Both Lillicrap et al. (2016) and Nøkland (2016) were able to train a Neural Network (NN) without Backpropagation.\\nFirst, create a simple NN like this:\\nwith cross-entropy as its loss function.\\nSo here is our implementation so far:\\nTo train a NN, we have to get the loss function derivative w.r.t to softmax function. Let’s take a look at Equation 5 from Nøkland’s paper.\\nwhich simply corresponds to:\\nI am sorry as I am not going to explain the Calculus behind this. Should you refer to Sadowski’s Notes on Backpropagation if you want the explanation.\\nThis is our implementation of Backpropagation:\\nWhere d1, d2, and ewill be us...   \n",
       "433  Clustering with Gaussian Mixture Model\\nDec 5, 2017\\nOne of the popular problems in unsupervised learning is clustering. Clustering is the assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense.\\nAs in above diagram the result of clustering is colouring of the squares into three clusters.\\nOne of the basic approach to solve cluster analysis problem is K-means. K-means algorithm partitioned the data into K clusters .\\nK means:\\nIn general, suppose we have n data points, that have to be partitioned in K clusters. The goal is to assign a cluster to each data point. K-means is a clustering method that aims to find the K positions of the clusters that minimize the distance(for example Euclidian distance) from the...   \n",
       "434  Analytics Vidhya\\nApr 26, 2021\\nThe success of a custom Named Entity Recognition (NER) model is dependent on the quality of data passed to it. However, supplying a model with sufficient examples of training data is typically a time-consuming and exhaustive process. Using Prodigy, the task of labeling your data for building a custom NER pipeline to a spaCy model is much quicker and simpler.\\nAccording to the official Prodigy site:\\nProdigy is a modern annotation tool for creating training and evaluation data for machine learning models. You can also use Prodigy to help you inspect and clean your data, do error analysis and develop rule-based systems to use in combination with your statistical models.\\nProdigy makes it easy to label your data to use in model training. For this overview, ...   \n",
       "435  Towards Data Science\\nSep 25, 2017\\nThe multi-armed bandit problem is a classic reinforcement learning example where we are given a slot machine with n arms (bandits) with each arm having its own rigged probability distribution of success. Pulling any one of the arms gives you a stochastic reward of either R=+1 for success, or R=0 for failure. Our objective is to pull the arms one-by-one in sequence such that we maximize our total reward collected in the long run.\\nThe non-triviality of the multi-armed bandit problem lies in the fact that we (the agent) cannot access the true bandit probability distributions — all learning is carried out via the means of trial-and-error and value estimation. So the question is:\\nHow can we design a systematic strategy that adapts to these stochastic re...   \n",
       "436  Towards Data Science\\nApr 28, 2020\\nUpdate:\\nInstance segmentation is a challenging computer vision task that requires the prediction of object instances and their per-pixel segmentation mask. This makes it a hybrid of semantic segmentation and object detection.\\nEver since Mask R-CNN was invented, the state-of-the-art method for instance segmentation has largely been Mask RCNN and its variants (PANet, Mask Score RCNN, etc). It adopts the detect-then-segment approach, first perform object detection to extract bounding boxes around each object instances, and then perform binary segmentation inside each bounding box to separate the foreground (object) and the background.\\nThere are some other instance segmentation methods other than the top-down approach of detect-then-segment (or segmen...   \n",
       "437  Towards Data Science\\nNov 3, 2021\\nThe ability to simplify means to eliminate the unnecessary so that the necessary may speak — Hans Hofmann\\nData compression is an essential phase in training a network. The idea is to compress the data so that the same amount of information can be represented by fewer bits. This also helps with the problem of the curse of dimensionality. A dataset with many attributes is different to train with because it tends to overfit the model. Hence dimensionality reduction techniques need to be applied before the dataset can be used for training.\\nThis is where the Autoencoder (AE) and Variational Autoencoder (VAE) come into play. They are end-to-end networks that are used to compress the input data. Both Autoencoder and Variational Autoencoder are used to tran...   \n",
       "438  Towards Data Science\\nNov 16, 2017\\nFor any service company that bills on a recurring basis, a key variable is the rate of churn. Harvard Business Review, March 2016\\nFor just about any growing company in this “as-a-service” world, two of the most important metrics are customer churn and lifetime value. Entrepreneur, February 2016\\nCustomer churn occurs when customers or subscribers stop doing business with a company or service, also known as customer attrition. It is also referred as loss of clients or customers. One industry in which churn rates are particularly useful is the telecommunications industry, because most customers have multiple options from which to choose within a geographic location.\\nSimilar concept with predicting employee turnover, we are going to predict customer c...   \n",
       "439  Towards Data Science\\nAug 12, 2019\\nI’m presenting an overview of important Graph Neural Network works, by distilling key ideas and explaining simple intuition behind milestone methods using Python and PyTorch. This post continues the first part of my tutorial.\\nIn the “Graph of Graph Neural Network (GNN) and related works” above, I added papers on graphs that I have come across in the last year. In this graph, a directed edge between two works denotes that one paper is based on the other (while not necessary citing it) and a color of the work denotes:\\nNote, that some other important works and edges are not shown to avoid further clutter, and only a tiny fraction of works, highlighted in bold boxes, will be covered in this post. Disclaimer: I still found room to squeeze our own recent...   \n",
       "440  Towards Data Science\\nSep 4, 2019\\nMachine learning is a hot topic right now and everyone is trying to get their hands on any information they can get about the topic. With the amount of information that is out there about machine learning, one can get overwhelmed. In this post, I have listed some of the most important topics in machine learning that you need to know, along with some resources which can help you in further reading about the topics which you are interested to know in-depth.\\nAI is a branch of computer science that aims to create intelligent machines that mimic human behaviour such as knowledge, reasoning, problem-solving, perception, learning, planning, ability to manipulate and move objects\\nAI is an area of computer science that emphasizes the creation of intelligent ...   \n",
       "441  Towards Data Science\\nOct 2, 2021\\nThere is a myriad of loss functions that you can choose for your neural network. The choice of loss function is imperative for the network’s performance because eventually the parameters in the network are going to be set such that the loss is minimized.\\nCross-Entropy loss is a popular choice if the problem at hand is a classification problem, and in and of itself it can be classified into either categorical cross-entropy or multi-class cross-entropy (with binary cross-entropy being a special case of the former.) In case you’re scratching your head about how different are these, I’ll try to introduce each before delving into the derivation.\\nLet’s start with categorical cross-entropy. For this loss function our y’s are one-hot encoded to denote the c...   \n",
       "442  Towards Data Science\\nJul 23, 2021\\nClustering is one of the most used unsupervised machine learning algorithms. You can think of clustering as putting unorganized data points into different categories so that you can learn more about the structures of your data. Clustering has a variety of applications in extracting information from data without labels. For example, companies cluster customers based on their characteristics, like purchasing behaviors, to make better market campaigns, to set pricing strategies to make more profit, etc. Clustering algorithms are also widely used in natural language processing (NLP) to extract information from unstructured textual data, and topic modeling is one example.\\nThe series of articles aims to provide readers with a thorough view of two common b...   \n",
       "443  Towards Data Science\\nJun 14, 2020\\nDuring our school days, most of us would have encountered the reading comprehension section of our English paper. We would be given a paragraph or Essay based on which we need to answer several questions.\\nHow do we as humans approach this task at hand? We go through the entire text, make sense of the context in which the question is asked and then we write answers. Is there a way we can use AI and deep learning techniques to mimic this behavior of us?\\nAutomatic text summarization is a common problem in machine learning and natural language processing (NLP). There are two approaches to this problem.\\n2. Abstractive Summarization-Abstractive text summarization, on the other hand, is a technique in which the summary is generated by generating novel se...   \n",
       "444  Aug 26, 2016\\nI release MATLAB, R and Python codes of Linear Discriminant Analysis (LDA). They are very easy to use. You prepare data set, and just run the code! Then, LDA and prediction results for new samples can be obtained. Very simple and easy!\\nYou can buy each code from the URLs below.\\nhttps://gum.co/uVtRo Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/MATLAB_scripts_functions.zip\\nhttps://gum.co/bZPL Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univprofblog.html.xdomain.jp/code/R_scripts_functions.zip\\nhttps://gum.co/JHFt Please download the supplemental zip file (this is free) from the URL below to run the LDA code. http://univp...   \n",
       "445  Intuition Machine\\nOct 22, 2017\\nSelf-play is Automated Knowledge Creation\\nThe 1983 movie “War Games” has a memorable climax where the supercomputer known as WOPR (War Operation Plan Response) is asked to train on itself to discover the concept of an un-winnable game. The character played by Mathew Broderick asks “Is there any way that it can play itself?”\\n34 years later, DeepMind has shown how this is exactly done in real life! The solution is the same, set the number of players to zero (i.e. zero humans).\\nThere is plenty to digest about this latest breakthrough in Deep Learning technology. DeepMind authors use the term “self-play reinforcement learning”. As I remarked in the piece about “Tribes of AI”, DeepMind is particularly fond of their Reinforcement Learning (RL) approach. De...   \n",
       "446  Sep 3, 2018\\nSegmentasi citra merupakan bagian dari proses pengolahan citra. Segmentasi citra (image segmentation) mempunyai arti membagi suatu citra menjadi wilayah-wilayah yang homogen berdasarkan kriteria keserupaan tertentu antara suatu piksel dengan piksel — piksel tetangganya, kemudian hasil dari proses segmentasi ini akan digunakan untuk proses tingkat tinggi lebih lanjut yang dapat dilakukan terhadap suatu citra, misalnya proses klasifikasi citra dan proses identifikasi objek.\\nSegmentasi semantik adalah proses klasifikasi setiap piksel dari sebuah citra sebagai sebuah label kelas untuk memahami citra dalam tingkat per piksel. Label kelas yang yang dimaksud adalah kelas objek, seperti rumah, buku, manusia, dan lain-lain.\\nSelain mengenali dan membedakan pengendara dan motor, se...   \n",
       "447  Dec 5, 2019\\nWhat is RNN?\\nRecurrent Neural Network is basically a generalization of feed-forward neural network that has an internal memory. RNNs are a special kind of neural networks that are designed to effectively deal with sequential data. This kind of data includes time series (a list of values of some parameters over a certain period of time) text documents, which can be seen as a sequence of words, or audio, which can be seen as a sequence of sound frequencies over time.RNN is recurrent in nature as it performs the same function for every input of data while the output of the current input depends on the past one computation. For making a decision, it considers the current input and the output that it has learned from the previous input.\\nCells that are a function of inputs fro...   \n",
       "448  Aug 5, 2015\\nIn “Puppyslugs ‘R Us: Part 0”, I started out quite cheekily on a topic I hope to explore here in a bit more serious detail.\\nI am going to start with the recent Google “DeepDream” release and the so-called Puppyslug images you’ve likely encountered, explaining roughly what those are and how they come to be. I will connect that to AI and algorithms in general and then move specifically to how they already appear in your everyday mobile experience. From there we can paint a picture of what’s in store for us, and why I say... the Puppyslugs are Us. I’ll conclude by setting up Part 2, and how all of this lands squarely in the lap of Design to deal with.\\nPuppyslugs. Quick background:\\nAbout two months ago (early June 2015), Google Researchers start showing off some algorithmic...   \n",
       "449                                                                                                                                                                                                                                                                                                                                                                                                   AI Salon\\nJan 8, 2020\\nConvolution neural networks (CNN) are broadly used in deep learning and computer vision algorithms. Even though many CNN-based algorithms meet industry standards and can be embedded in commercial products...\\n422 \\n422 \\n1\\nA tea drinking place to talk about AI\\n198 Followers\\nMachine learning engineer based in Tokyo\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "450  Towards Data Science\\nNov 2, 2018\\nIn my last post, we trained a convnet to differentiate dogs from cats. We trained the convnet from scratch and got an accuracy of about 80%. Not bad for a model trained on very little dataset (4000 images).\\nBut in real world/production scenarios, our model is actually under-performing.\\nAlthough we suggested tuning some hyperparameters — epochs, learning rates, input size, network depth, backpropagation algorithms e.t.c — to see if we could increase our accuracy.\\nWell, I did try...\\nAnd truth is, after tuning, re-tuning, not-tuning , my accuracy wouldn’t go above 90% and at a point It was useless.\\nOf course having more data would have helped our model; But remember we’re working with a small dataset, a common problem in the field of deep learning.\\...   \n",
       "451  Analytics Vidhya\\nFeb 12, 2021\\nThe article contains the introduction of StyleGAN and StyleGAN2 architecture which will give you an idea. It may help you to start with StyleGAN. You will find some metric or the operations name which you don’t know, to gain a deep understanding of StyleGAN and StyleGAN2 you can go through the paper whose link is provided in the resources section.\\nLet’s start with the StyleGAN and then we move towards StyleGAN 2.\\nThe major changes they have done in the Generator part of the “Progressive Growing of GANs” architecture. Below you can see both the traditional and the style-based generator (new one or StyleGAN network) network.\\nIn the traditional network, latent vectors directly pass into the block just after the normalization whereas in the StyleGAN netwo...   \n",
       "452  Mar 7, 2018\\nAP (Average precision) is a popular metric in measuring the accuracy of object detectors like Faster R-CNN, SSD, etc. Average precision computes the average precision value for recall value over 0 to 1. It sounds complicated but actually pretty simple as we illustrate it with an example. But before that, we will do a quick recap on precision, recall, and IoU first.\\nPrecision & recall\\nPrecision measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\\nRecall measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions.\\nHere are their mathematical definitions:\\nFor example, in the testing for cancer:\\nIoU (Intersection over union)\\nIoU measures the overlap between ...   \n",
       "453  Jul 8, 2020\\nGuide made for EarnSkins users, by JaxStart the offer now at www.earnskins.gg to earn some side money!Use referral code ‘wolf’ to get yourself a free 50 points to start with.\\nUPDATE: The offer is currently to finish Level 34, this strategy still works, tested and confirmed, however it takes a bit longer now.\\nVideo Guide: https://youtu.be/AIEBGMRPe7I\\nThe POP! Slots offer is a casino/slots based app offer that exists for both iOS and Android phones. The offer required me to reach level 27 in the app, which was easily obtainable and you can automate it really easy making the time spent actually doing anything is extremely low.\\nThere’s three different types of this offer that I’m aware of. One requires you to reach level 27, one level 26 while the last one requires you to ...   \n",
       "454  Oct 3, 2018\\nPart 1 https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-1-d332e85e9aad\\nChinese Version https://medium.com/%40bgg/seq2seq-pay-attention-to-self-attention-part-2-%E4%B8%AD%E6%96%87%E7%89%88-ef2ddf8597a4\\nWe have talked about Seq2seq and Attention model in the first part. In this part, I will be focusing on Self attention, proposed by Google in the paper “Attention is all you need”. Self attention is the concept of “The transformer”model, which outperforms the attention model in various tasks. Two main concepts of the “transformer” model are “self attention” and “multi-head”.\\nThe biggest advantage comes from how The Transformer lends itself to parallelization and self attention.\\nHope you enjoy it.\\nI will use the figure in part 1 as a quick overview. We...   \n",
       "455  Towards Data Science\\nApr 10, 2019\\nTransformers (specifically self-attention) have powered significant recent progress in NLP. They have enabled models like BERT, GPT-2, and XLNet to form powerful language models that can be used to generate text, translate text, answer questions, classify documents, summarize text, and much more. With their recent success in NLP one would expect widespread adaptation to problems like time series forecasting and classification. After all, both involve processing sequential data. However, to this point research on their adaptation to time series problems has remained limited. Moreover, while some results are promising, others remain more mixed. In this article, I will review current literature on applying transformers as well as attention more broadly ...   \n",
       "456  Towards Data Science\\nMay 26, 2020\\nAfter learning and applying several supervised ML algorithms like least square regression, logistic regression, SVM, decision tree etc. most of us try to have some hands-on unsupervised learning by implementing some clustering techniques like K-Means, DBSCAN or HDBSCAN.\\nWe usually start with K-Means clustering. After going through several tutorials and Medium stories you will be able to implement k-means clustering easily. But as you implement it, a question starts to bug your mind: how can we measure its goodness of fit? Supervised algorithms have lots of metrics to check their goodness of fit like accuracy, r-square value, sensitivity, specificity etc. but what can we calculate to measure the accuracy or goodness of our clustering technique? The a...   \n",
       "457  Towards Data Science\\nJul 4, 2021\\nIn a business context: Clustering algorithm is a technique that assists customer segmentation which is a process of classifying similar customers into the same segment. Clustering algorithm helps to better understand customers, in terms of both static demographics and dynamic behaviors. Customer with comparable characteristics often interact with the business similarly, thus business can benefit from this technique by creating tailored marketing strategy for each segment.\\nIn a data science context: Clustering algorithm is an unsupervised machine learning algorithm that discovers groups of data points that are closely related. The fundamental difference between supervised and unsupervised algorithm is that:\\nAfter giving an overview of what is cluster...   \n",
       "458  Towards Data Science\\nDec 3, 2021\\nHow to train a neural net for semantic segmentation in less than 50 lines of code (40 if you exclude imports). The goal here is to give the fastest simplest overview of how to train semantic segmentation neural net in PyTorch using the built-in Torchvision neural nets (DeepLabV3).\\nCode is available: https://github.com/sagieppel/Train-Semantic-Segmentation-Net-with-Pytorch-In-50-Lines-Of-Code\\nThe goal is semantic segmentation is to take images and identify regions belonging to specific classes. This is done by processing the image through a convolution neural network that outputs a map with a class per pixel. The classes are given as a set of numbers. For example, in this case, we will use the LabPics V1 dataset with three classes (shown in the figur...   \n",
       "459  Towards Data Science\\nOct 28, 2021\\nMany real-world applications of Machine Learning involve making predictions about the outcomes of a group of related variables based on historical context. We might want to forecast the traffic conditions on connected roads, the weather at nearby locations, or the demand for similar products. By modeling multiple time series together, we hope that changes in one variable may reveal key information about the behavior of related variables. Multivariate Time Series Forecasting (TSF) datasets have two axes of difficulty: we need to learn temporal relationships to understand how values change over time and spatial relationships to know how variables impact one another.\\nPopular statistical approaches to TSF can struggle to interpret long context sequences...   \n",
       "460  Towards Data Science\\nApr 4, 2020\\nThis is a post on the usage of a library for Deep Bayesian Learning. If you are new to the theme, you may want to seek one of the many posts on medium about it or just the documentation section on Bayesian DL of our lib repo.\\nAs there is a rising need for gathering uncertainty over neural network predictions, using Bayesian Neural Network layers became one of the most intuitive approaches — and that can be confirmed by the trend of Bayesian Networks as a study field on Deep Learning.\\nIt occurs that, despite the trend of PyTorch as a main Deep Learning framework (for research, at least), no library lets the user introduce Bayesian Neural Network layers intro their models with as ease as they can do it with nn.Linear and nn.Conv2d, for example.\\nLogic...   \n",
       "461  GradientCrescent\\nFeb 4, 2019\\nIntroduction\\nOver the past five years, neural networks have received attention through AI-generated art pieces, whether these be paintings, poetry, or music. During October of last year, an AI-generated art piece sold for over $400,000 at an auction at Christie’s, sparking debate and discussion over the intrinsic value and nature of art generated by machines.\\nWhile most of these mentioned art pieces were original pieces generated through Generative Adversarial Networks (GAN’s, which we will discuss in a future tutorial), apps such as PRISMA have been receiving attention for being able to apply the styles of famous paintings to one’s own photos. The concept, known as neural style transfer (henceforth NST), was first introduced in a paper by Leon Gatys et...   \n",
       "462  The Ezra Tech Blog\\nMar 4, 2021\\nEmbeddings are an important component of natural language processing pipelines. They refer to the vector representation of textual data. You can think of embeddings as a transformation from human-readable text to computer-readable numbers or vectors as seen in Fig. 1. These embeddings can be used in any machine learning task that takes text as the input, e.g. question answering, classification, text generation.\\nDifferent embedding techniques vary in their complexity and capabilities. For instance, the most simple form of word embeddings can be represented with one-hot encodings where each word in the corpus of size V is mapped to a unique index in a vector of the same size. This gives us a vector of all zeros except for one element that indicates the w...   \n",
       "463  NYT Open\\nSep 30, 2013\\nBy RILEY DAVIS and DAVID SOUTHER\\nRiley Davis and David Souther collaborated on EQuake, a 3D earthquake visualizer they developed in about a day. They discuss their motivations and approach in this piece.\\nWe were inspired by this xkcd comic imagining a situation in which tweets about an earthquake spread faster than the earthquake’s seismic waves.\\nWe both like to make complex scientific information more accessible by tying it to scales that people already understand. We thought it would be interesting to plot waves from real earthquakes onto a globe to show how fast the waves actually travel through the crust. This tool could easily be used to map out tweets (or any other geographic data) when other earthquakes occurred. To implement this, we were able to use ...   \n",
       "464  Towards Data Science\\nJun 18, 2017\\nIntroduction:\\nThe work here presented is the result of a semester long independent research performed by Kenny Jones and Derrick Bonafilia (both Williams College 2017) under the guidance of Professor Andrea Danyluk. The code associated with this project can be found at https://github.com/rkjones4/GANGogh. Kenny and Derrick are both heading to Facebook next year as Software Engineers and hope to continue studying GANs in whatever capacity is available to them.\\nBackground:\\nGenerative Adversarial Networks (GANS) were introduced by Ian Goodfellow et. al. in a 2014 paper. GANs address the lack of relative success of deep generative models compared to deep discriminative models. The authors cite the intractable nature of the maximum likelihood estimatio...   \n",
       "465  Artificial Intelligence in Plain English\\nSep 12, 2010\\nIf you can measure a phenomenon, you can analyze the phenomenon. But if you don’t measure the phenomenon accurately and precisely, you won’t be able to analyze the phenomenon accurately and precisely. So in planning a statistical analysis, once you have specific concepts you want to explore you’ll need to identify ways the concepts could be measured.\\nStart with conventional measures, the ones everyone would recognize and know what you did to determine. Then, consider whether there are any other ways to measure the concept directly. From there, establish whether there are any indirect measures or surrogates that could be used in lieu of a direct measurement. Finally, if there are no other options, explore whether it would be feasi...   \n",
       "466  Aug 4, 2019\\nI’m answering questions that AI/ML/CV people not familiar with graphs or graph neural networks typically ask. I provide PyTorch examples to clarify the idea behind this relatively new and exciting kind of model.\\nThe questions addressed in this part of my tutorial are:\\nTo answer them, I’ll provide motivating examples, papers and Python code making it a tutorial on Graph Neural Networks (GNNs). Some basic knowledge of machine learning and computer vision is expected, however, I’ll provide some background and intuitive explanation as we go.\\nFirst of all, let’s briefly recall what is a graph? A graph G is a set of nodes (vertices) connected by directed/undirected edges. Nodes and edges typically come from some expert knowledge or intuition about the problem. So, it can be a...   \n",
       "467  DataWeave\\nAug 4, 2015\\nWe have seen a steady increase in the number of smartphones and tablets since the last five years. Looking at the number of smartphones, tablets and now wearables ( smart watches and fitbits ) that are being launched in the mobiles market, we can truly call this ‘The Mobile Age’.\\nWe, at DataWeave, deal with millions of data points related to products which vary from electronics to apparel. One of the main challenges we encounter while dealing with this data is the amount of noise and variation present for the same products across different stores.\\nOne particular problem we have been facing recently is detecting whether a particular product is a mobile phone (smartphone) or a tablet. If it is mentioned explicitly somewhere in the product information or metadata...   \n",
       "468  Towards Data Science\\nJun 1, 2020\\nAs you may know, supervised machine learning consists in finding a function, called a decision function, that best models the relation between input/output pairs of data. In order to find this function, we have to formulate this learning problem into an optimization problem.\\nLet’s consider the following task: finding the best linear function that maps the input space, the variable X to the output space, the variable Y.\\nAs we try to model the relation between X and Y by a linear function, the set of functions that the learning algorithm is allowed to select is the following :\\nThe term b is the intercept, also called bias in machine learning. This set of functions is our hypothesis space.But how do we choose the values for the parameters a,b and how ...   \n",
       "469  Towards Data Science\\nOct 29, 2020\\nWhen we want to understand key information from specific documents, we typically turn towards keyword extraction. Keyword extraction is the automated process of extracting the words and phrases that are most relevant to an input text.\\nWith methods such as Rake and YAKE! we already have easy-to-use packages that can be used to extract keywords and keyphrases. However, these models typically work based on the statistical properties of a text and not so much on semantic similarity.\\nIn comes BERT. BERT is a bi-directional transformer model that allows us to transform phrases and documents to vectors that capture their meaning.\\nWhat if we were to use BERT instead of statistical models?\\nAlthough there are many great papers and solutions out there that ...   \n",
       "470  Towards Data Science\\nAug 14, 2018\\nAnyone who takes a look at the architecture of MobileNet will undoubtedly come across the concept of separable convolutions. But what is that, and how is it different from a normal convolution?\\nThere are two main types of separable convolutions: spatial separable convolutions, and depthwise separable convolutions.\\nConceptually, this is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so I’ll start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning.\\nThe spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The ot...   \n",
       "471  Towards Data Science\\nJun 4, 2019\\nUsage of facial recognition is on the rise. With the recent debates over the ethics of facial recognition potential adversarial attacks against facial detection have been on my mind. Facial recognition is being used everywhere from airports to social media. It seems to be near impossible to opt-out of having your face scanned.\\nAn ideal attack on facial detection would be an article of clothing that looks inconspicuous to the uninformed. With inspiration from the Hyperface project I decided to research and implement a wearable adversarial example. In this article I’ll detail the process of creating an adversarial image to fool a selected type of facial detection and how I implemented a practical example on a face mask.\\nThe first thing it’s important ...   \n",
       "472  Towards Data Science\\nDec 17, 2019\\nThe first version of the StyleGAN architecture yielded incredibly impressive results on the facial image dataset known as Flicker-Faces-HQ (FFHQ). The most impressive characteristic of these results, compared to early iterations of GANs such as Conditional GANs or DCGANs, is the high resolution (10242) of the generated images. In addition to resolution, GANs are compared along dimensions such as the diversity of images generated (avoiding mode collapse) and a suite of quantitative metrics comparing real and generated images such as FID, Inception Score, and Precision and Recall.\\nFrechet Inception Distance (FID) is one of the most common automated metrics used to evaluate images sampled from generative models. This metric is based on comparing activa...   \n",
       "473  Pankaj Mathur\\nApr 1, 2016\\nHere is a simple logistic regression model built with TensorFlow. We are using MNIST Image example data set which is provided by default with Tensorflow package.\\nHere are the hyperparameters we choose to run initial model:\\nWe achieved impressive 90.8% accuracy in 20 epochs with a learning rate of 0.01 by running simple logistic regression model build with Tensorflow on MNIST dataset.\\nI am using Conda to install TensorFlow. You might already have a TensorFlow environment, but please check below to make sure you have all the necessary packages. If you have never used Conda environments before, please go through my other tutorial What is Anaconda and Why should I bother about it?\\nAssuming you have conda install on your machine, please run the following comm...   \n",
       "474  Towards Data Science\\nAug 15, 2019\\nThe purpose of clustering analysis is to identify patterns in your data and create groups according to those patterns. Therefore, if two points have similar characteristics, that means they have the same pattern and consequently, they belong to the same group. By doing clustering analysis we should be able to check what features usually appear together and see what characterizes a group.\\nIn this post, we are going to perform a clustering analysis with multiple variables using the algorithm K-means. The intention is to find groups of mammals based on the composition of the species’ milk. The main points covered here are:\\nThe dataset used is part of the package cluster.datasets and contains 25 observations on the following 6 variables:\\nname — a char...   \n",
       "475  Towards Data Science\\nJan 23, 2019\\nAlso known as outlier detection, anomaly detection is a data mining process used to determine types of anomalies found in a data set and to determine details about their occurrences. Automatic anomaly detection is critical in today’s world where the sheer volume of data makes it impossible to tag outliers manually. Auto anomaly detection has a wide range of applications such as fraud detection, system health monitoring, fault detection, and event detection systems in sensor networks, and so on.\\nBut I would like to apply anomaly detection to hotel room prices. The reason is somewhat selfish.\\nHave you had experience that, lets say, you travel to a certain destination for business regularly and you always stay at the same hotel. While most of the time...   \n",
       "476  Towards Data Science\\nMay 30, 2019\\nWord embedding is one of the most important techniques in natural language processing(NLP), where words are mapped to vectors of real numbers. Word embedding is capable of capturing the meaning of a word in a document, semantic and syntactic similarity, relation with other words. It also has been widely used for recommender systems and text classification. This tutorial will show a brief introduction of genism word2vec model with an example of generating word embedding for the vehicle make model.\\nWord2vec is one of the most popular technique to learn word embeddings using a two-layer neural network. Its input is a text corpus and its output is a set of vectors. Word embedding via word2vec can make natural language computer-readable, then further imp...   \n",
       "477  Towards Data Science\\nJan 8, 2019\\nAs more layers using certain activation functions are added to neural networks, the gradients of the loss function approaches zero, making the network hard to train.\\nCertain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid function will cause a small change in the output. Hence, the derivative becomes small.\\nAs an example, Image 1 is the sigmoid function and its derivative. Note how when the inputs of the sigmoid function becomes larger or smaller (when |x| becomes bigger), the derivative becomes close to zero.\\nFor shallow network with only a few layers that use these activations, this isn’t a big problem. However, when more ...   \n",
       "478  Towards Data Science\\nNov 15, 2017\\nOne of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don’t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.\\nThe concept of balancing bias and variance, is helpful in understanding the phenomenon of overfitting.\\nmedium.com\\nOne of the ways of avoiding overfitting is using cross validation, that helps in estimating the error over test set, and in deciding what parameters work best for your model.\\nmedium.com\\nThis arti...   \n",
       "479  Towards Data Science\\nMay 23, 2021\\nThis article is part of the series that explains how different Machine Learning algorithms work and provides you a range of Python examples to help you get started with your own Data Science project.\\nWhile it is not always possible to categorize every algorithm perfectly, it is still beneficial to try and do so. The below interactive chart is my attempt to help you see the broader universe of Machine Learning.\\nMake sure to click👇 on different categories to enlarge and reveal more.\\nNote, in many cases, the same algorithm can be used to solve multiple types of problems. E.g., one can use Neural Networks for classification, regression, and as part of the reinforcement learning.\\nIf you enjoy Data Science and Machine Learning, please subscribe to get ...   \n",
       "480  HackerNoon.com\\nAug 18, 2017\\nFrom this series:\\nIn the previous post I described the working environment and the basic code for clusterize points in the Poincaré ball space. Here I will improve that code transforming two loops to matrix operations.\\nI ended that post with a very promising plot about the speed improvement on a element-wise product of two vectors. So let’s detail it.\\nSuppose we have two arrays:\\nand we want to obtain as result an array where the elements are the element-wise multiplication of them:\\nWe can do it in two ways: with a loop over the elements, or with a vectorized operation. Now: what happens in terms of execution time? I did this calculations with arrays of different dimensions, ranging from 100.000 to 10.000.000.\\nIn the right plot you see the execution ...   \n",
       "481  Towards Data Science\\nDec 30, 2020\\nIn this article, we will see how to conduct Bayesian linear regression with PyMC3. If you got here without knowing what Bayes or PyMC3 is, don’t worry! You can use my articles as a primer\\nYou can view Bayesian linear regression as a more verbose version of standard linear regression. Linear regression gives you single values, for the model parameters as well as the predictions. Bayesian linear regression, in turn, gives you distributions.\\nWe will see what this exactly means in a second. Let us quickly introduce a simple dataset to be able to compare both linear regression approaches.\\nWe have done it all several times: Grabbing a dataset containing features and continuous labels, then shoving a line through the data, and call it a day. As a running...   \n",
       "482  Towards Data Science\\nJun 2, 2019\\nThis post was co-written with Joseph Rocca.\\nDuring the last few decades, with the rise of Youtube, Amazon, Netflix and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\\nIn a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy or anything else depending on industries).\\nRecommender systems are really critical in some industries as they can generate a huge amount of income wh...   \n",
       "483  Jul 4, 2020\\nIn this blog post we will provide a guide through for transfer learning with the main aspects to take into account in the process, some tips and an example implementation in Keras using ResNet50 as the trained model. The task is to transfer the learning of a ResNet50 trained with Imagenet to a model that identify images from CIFAR-10 dataset. Several methods were tested to achieve a greater accuracy which we provide to show the variety of options for a training. However with the final model of this blog we get an accuracy of 94% on test set.\\nLearning something new takes time and practice but we find it easy to do similar tasks. This is thanks to human association involved in learning. We have the capability to identify patterns from previous knowledge an apply it into new...   \n",
       "484                                                                                                                                                                                                                                                     OneZero\\nAug 20, 2020\\nFor years, A.I. research lab OpenAI has been chasing the dream of an algorithm that can write like a human.\\nIts latest iteration on that concept, a language-generation algorithm called GPT-3...\\n532 \\n532 \\n4\\nThe undercurrents of the future. A publication from Medium about technology and people.\\n19.1K Followers\\nSenior Writer at OneZero covering surveillance, facial recognition, DIY tech, and artificial intelligence. Previously: Qz, PopSci, and NYTimes.\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "485  Towards Data Science\\nJan 7, 2019\\nWe have seen Machine Learning as a buzzword for the past few years, the reason for this might be the high amount of data production by applications, the increase of computation power in the past few years and the development of better algorithms.\\nMachine Learning is used anywhere from automating mundane tasks to offering intelligent insights, industries in every sector try to benefit from it. You may already be using a device that utilizes it. For example, a wearable fitness tracker like Fitbit, or an intelligent home assistant like Google Home. But there are much more examples of ML in use.\\nIt was in the 1940s when the first manually operated computer system, ENIAC (Electronic Numerical Integrator and Computer), was invented. At that time the word ...   \n",
       "486  On Docker\\nMar 30, 2016\\nTL;DR Federated clustering overview with a focus on Swarm. Includes architecture diagrams and tools for building an experiment in AWS. Swarm’s API is a great building block that helps you create much more sophisticated deployment architectures or scale/diversify underlying infrastructure. Whale-Mullet is a Swarm fork I built to make the whole thing work.\\nDocker Swarm provides an abstraction that allows a user to treat a cluster like a single node. That is the case as long as the Swarm API is mostly compatible with the Docker API. This begs the question, “If I can treat a Swarm like a single machine can I create a Swarm of Swarm clusters?” This is called cluster federation. This article describes what how I tried to build a federated Swarm cluster, what problem...   \n",
       "487  Towards Data Science\\nApr 3, 2018\\nUnsupervised machine learning is the machine learning task of inferring a function to describe hidden structure from “unlabeled” data (a classification or categorization is not included in the observations). Common scenarios for using unsupervised learning algorithms include:- Data Exploration- Outlier Detection- Pattern Recognition\\nWhile there is an exhaustive list of clustering algorithms available (whether you use R or Python’s Scikit-Learn), I will attempt to cover the basic concepts.\\nThe most common and simplest clustering algorithm out there is the K-Means clustering. This algorithms involve you telling the algorithms how many possible cluster (or K) there are in the dataset. The algorithm then iteratively moves the k-centers and selects the d...   \n",
       "488  Jun 8, 2018\\nAfter some promising results and tons of learning (summarized in my previous post) with a basic DC-GAN on CIFAR-10 data, I wanted to play some more with GANs. One issue with a traditional DC-GAN was that the data is expected to have similar properties in order for the training to converge properly. For instance, in case of CIFAR-10, training the DC-GAN on images of a single class was much easier and more likely to produce sharp images than training on all 10 classes. In that post on GAN learnings, I had casually mentioned Conditional GANs as an improvement over traditional GANs when the training data might come from different classes. This post describes how to setup a Conditional DC-GAN to generate images from all the classes of CIFAR-10 data.\\nGenerative Adversarial Netw...   \n",
       "489  Towards Data Science\\nSep 10, 2019\\nNote I focus on binary classification problems in this article, but the approach would be similar with multi classification and regression problems.\\nTry to convince someone that your ML model is accurate and should be trusted because it has a LogLoss of 0.34. Non data scientists will surely gawk at you while data scientists will ask for a lot more information.\\nAs a data scientist, you know it’s hard to make it clear (particularly to non data scientists) why your model should be trusted because you cannot easily translate complex measures of accuracy into tangible elements. And that’s 100% legitimate, models should be understood by everyone, at least their accuracy.\\nOn top of it, if your approach is scientifically correct, your model should have at...   \n",
       "490  Moonvision\\nApr 12, 2019\\nObject detection is vital to automate manual tasks, such as checking the completeness of objects and the exact types of its parts. In contrast to segmentation, objects are located and classified as discrete instances. This is achieved by decoding regression and activation maps after a cascade of convolutions. You can read more about state-of-the art in object detection in this survey.\\nHowever, contemporary issues in object detection are often studied in isolation. In production use cases though, multiple constraints must be solved at once. In this post, we describe the combination of techniques that we’ve developed over time that meet many of these constraints.\\nAs with any machine learning task, the amount of training data is limited. As we will review below...   \n",
       "491  Towards Data Science\\nJul 15, 2021\\nIn this article, I’m going to demonstrate how to use a trained model to detect objects in images and videos using two of the best libraries for this kind of problem. For the detection, we need a model capable of predicting multiple classes in an image and returning the location of those objects so that we can place boxes on the image.\\nWe are going to use a model from the Tensorflow Hub library, which has multiple ready to deploy models trained in all kinds of datasets and to solve all kinds of problems. For our use, I filtered models trained for object detection tasks and models in the TFLite format. This format is usually used for IoT applications, for its small size and faster performance than bigger models. I choose this format because I intend t...   \n",
       "492  Analytics Vidhya\\nApr 26, 2021\\nA logical and sequential roadmap to understanding the advanced concepts in training deep neural networks.\\nWe will break our discussion into 4 logical parts that build upon each other. For the best reading experience, please go through them sequentially:\\n1. What is Vanishing Gradient? Why is it a problem? Why does it happen?2. What is Batch Normalization? How does it help in Vanishing Gradient?3. How does ReLU help in Vanishing Gradient?4. Batch Normalization for Internal Covariate Shift\\nFirst, let’s understand what vanishing means:\\nVanishing means that it goes towards 0 but will never really be 0.\\nVanishing gradient refers to the fact that in deep neural networks, the backpropagated error signal (gradient) typically decreases exponentially as a func...   \n",
       "493  Towards Data Science\\nOct 22, 2020\\nThere is a lot of code going on under the hood. That’s why I provide my Github repository at the end of this post and I show just a little code of the K-Means.\\nClustering is an important technique in Pattern Analysis to identify distinct groups in data. Due to data being mostly more than three-dimensional, we perform dimensionality reduction methods like PCA or Laplacian Eigenmaps before applying a clustering technique. The data is then available in 2D or 3D and this allows us to visualize the found clusters very nicely to humans. Even though this is a basic workflow, it is not always the case.\\nData is also often unlabeled. This means you have no clear definition of what you want to find within this data. That’s why clustering is a good data explor...   \n",
       "494                                                                                                                                                                                                                                                                                     Dark Matter and Trojan Horses\\nDec 21, 2011\\nA chilly December night in 2011. I had been invited to take part in an evening event called the North House Salon, one of a series of salons...\\nArticles, cases and considerations regarding strategic design practice and thinking.\\n21K Followers\\nDesigner, urbanist, etc. Director of Strategic Design at Vinnova, Swedish govt. Prof. AHO Oslo, Visiting Prof. UCL Bartlett IIPP, Design Academy Eindhoven, RMIT\\nHelp\\nStatus\\nWriters\\nBlog\\nCareers\\nPrivacy\\nTerms\\nAbout\\nKnowable\\n   \n",
       "495  Ensina.AI\\nMay 10, 2018\\nVocê já se perguntou como funcionam os sistemas de reconhecimento de imagem? Como um aplicativo do seu celular faz para detectar rostos, ou um teclado inteligente sugere a próxima palavra? As chamadas Redes Neurais tem sido amplamente usadas para tarefas como essas, mas mostraram-se úteis também em outras áreas, como aproximação de funções, previsão de séries temporais e processamento de linguagem natural.\\nNeste artigo, explico como funciona um tipo básico de Rede Neural, o Perceptron Multicamadas, e um fascinante algoritmo responsável pelo aprendizado da rede, o backpropagation. Tal modelo de rede serviu de base para os modelos mais complexos hoje existentes, como as Redes Convolucionais, que são o estado da arte para classificação de imagens...   \n",
       "496  Towards Data Science\\nAug 2, 2017\\nWe all face the problem of spams in our inboxes. Let’s build a spam classifier program in python which can tell whether a given message is spam or not! We can do this by using a simple, yet powerful theorem from probability theory called Baye’s Theorem. It is mathematically expressed as\\nWe have a message m = (w1, w2, . . . . , wn), where (w1, w2, . . . . , wn) is a set of unique words contained in the message. We need to find\\nIf we assume that occurrence of a word are independent of all other words, we can simplify the above expression to\\nIn order to classify we have to determine which is greater\\nWe are going to make use of NLTK for processing the messages, WordCloud and matplotlib for visualization and pandas for loading data, NumPy for generatin...   \n",
       "497  Insight\\nApr 16, 2014\\nJohn Joo is an Insight alumnus from the August 2013 session with a PhD in applied physics from Harvard. He recently joined Insight as a Program Director in January, leading the most recent cohort of Fellows in their transition from academia to industry.\\nWhen I was first considering making the transition from applied physics to data science, I had a lot of questions. What skills did I need to develop to get started in data science? What courses should I take? Did I need to know how to program and code? What languages? How much statistics did I need to know? The list goes on. Now that I’ve spent a few months as a Program Director here at Insight, I think it’s time I shared with you the tools and tips that got me, and nearly 100 other Insight Fellows, started on ou...   \n",
       "498  Altsoph’s blog\\nSep 16, 2010\\nВчера узнал, что сейчас идет Google AI Contest.\\nВ двух словах, задача состоит в написании логики бота, играющего в некоторый аналог игры Galcon — космической стратегии, основанной на разделении ресурсов. Прием ботов на конкурс идет до 27 ноября, а потом их будут стравливать и выявлять победителя. Языки доступны из списка C++, C#, Java, Python.\\nБыло бы времени побольше, я бы, наверное, поучавствовал.\\nВспоминаются стародавние времена, когда мы еще в школе рубились в RobotBattle, а потом на первом курсе с группой сотоварищей писали интерпретатор RedCode на придуманной нами модели тороидальной памяти (ToroWars).\\nRandom notes on people and machines\\n274 Followers\\nhttp://altsoph.com, Senior Data Analyst, Researcher.\\nHelp\\nStatus\\nWriters\\nBlog\\nCar...   \n",
       "499  HuggingFace\\nAug 28, 2019\\n2019, October 3rd — Update: We are releasing our NeurIPS 2019 workshop paper describing our approach on DistilBERT with improved results: 97% of BERT’s performance on GLUE (the results in the paper superseed the results presented here). The approach is slightly different from the one explained in this present blog post so this blog post should be a good entry point to the paper! We applied the same method to GPT2 and are releasing DistilGPT2! Training code and pre-trained weights for DistilBERT and DistilGPT2 are available here. 🤗\\nIn the last 18 months, transfer learning from large-scale language models has significantly improved upon the state-of-the-art on pretty much every Natural Language Processing task.\\nUsually based on the Transformer architecture of...   \n",
       "\n",
       "     claps  \n",
       "0       29  \n",
       "1     3952  \n",
       "2       27  \n",
       "3       27  \n",
       "4       27  \n",
       "5       27  \n",
       "6       27  \n",
       "7      180  \n",
       "8       27  \n",
       "9       27  \n",
       "10   80816  \n",
       "11     328  \n",
       "12     191  \n",
       "13      27  \n",
       "14      61  \n",
       "15   38267  \n",
       "16     222  \n",
       "17    5277  \n",
       "18      29  \n",
       "19      27  \n",
       "20      38  \n",
       "21      27  \n",
       "22      27  \n",
       "23      27  \n",
       "24      27  \n",
       "25      29  \n",
       "26    1661  \n",
       "27      27  \n",
       "28      27  \n",
       "29      27  \n",
       "30      27  \n",
       "31      27  \n",
       "32      27  \n",
       "33      27  \n",
       "34      27  \n",
       "35     137  \n",
       "36      38  \n",
       "37      29  \n",
       "38    1452  \n",
       "39      27  \n",
       "40      27  \n",
       "41    1566  \n",
       "42      47  \n",
       "43      27  \n",
       "44      72  \n",
       "45      38  \n",
       "46     999  \n",
       "47      27  \n",
       "48      27  \n",
       "49      29  \n",
       "50      27  \n",
       "51      27  \n",
       "52      27  \n",
       "53    7023  \n",
       "54      61  \n",
       "55      27  \n",
       "56      27  \n",
       "57     359  \n",
       "58      27  \n",
       "59      61  \n",
       "60      27  \n",
       "61      27  \n",
       "62      27  \n",
       "63      27  \n",
       "64      29  \n",
       "65      47  \n",
       "66     259  \n",
       "67      27  \n",
       "68    2239  \n",
       "69      27  \n",
       "70      27  \n",
       "71      27  \n",
       "72      27  \n",
       "73      61  \n",
       "74      29  \n",
       "75      99  \n",
       "76      27  \n",
       "77      27  \n",
       "78      27  \n",
       "79   28380  \n",
       "80      27  \n",
       "81      27  \n",
       "82      27  \n",
       "83      27  \n",
       "84    9765  \n",
       "85      27  \n",
       "86      27  \n",
       "87      27  \n",
       "88      27  \n",
       "89      27  \n",
       "90     428  \n",
       "91   24186  \n",
       "92    2170  \n",
       "93      27  \n",
       "94      27  \n",
       "95      27  \n",
       "96      84  \n",
       "97      27  \n",
       "98      27  \n",
       "99      27  \n",
       "100     27  \n",
       "101  16886  \n",
       "102     27  \n",
       "103     27  \n",
       "104     29  \n",
       "105  12005  \n",
       "106     27  \n",
       "107     27  \n",
       "108     27  \n",
       "109     27  \n",
       "110     35  \n",
       "111     27  \n",
       "112     27  \n",
       "113     27  \n",
       "114     27  \n",
       "115   8677  \n",
       "116   2217  \n",
       "117     27  \n",
       "118     27  \n",
       "119     27  \n",
       "120     27  \n",
       "121     56  \n",
       "122     27  \n",
       "123     27  \n",
       "124     27  \n",
       "125     27  \n",
       "126     27  \n",
       "127  16886  \n",
       "128     27  \n",
       "129    760  \n",
       "130    606  \n",
       "131   5908  \n",
       "132    385  \n",
       "133     27  \n",
       "134     27  \n",
       "135     27  \n",
       "136     99  \n",
       "137     47  \n",
       "138   4477  \n",
       "139   2369  \n",
       "140     38  \n",
       "141    594  \n",
       "142     27  \n",
       "143     27  \n",
       "144   5151  \n",
       "145     27  \n",
       "146     27  \n",
       "147     27  \n",
       "148     27  \n",
       "149    267  \n",
       "150     27  \n",
       "151     27  \n",
       "152    246  \n",
       "153     47  \n",
       "154     81  \n",
       "155     80  \n",
       "156     61  \n",
       "157     27  \n",
       "158   1220  \n",
       "159  18245  \n",
       "160     27  \n",
       "161     27  \n",
       "162   7418  \n",
       "163     27  \n",
       "164     27  \n",
       "165     29  \n",
       "166     27  \n",
       "167     61  \n",
       "168     27  \n",
       "169    439  \n",
       "170   9056  \n",
       "171     81  \n",
       "172     27  \n",
       "173    290  \n",
       "174     27  \n",
       "175     81  \n",
       "176     27  \n",
       "177    938  \n",
       "178    137  \n",
       "179     27  \n",
       "180     27  \n",
       "181    137  \n",
       "182     99  \n",
       "183    191  \n",
       "184     27  \n",
       "185     81  \n",
       "186     27  \n",
       "187    353  \n",
       "188     27  \n",
       "189   3493  \n",
       "190     27  \n",
       "191   7664  \n",
       "192     27  \n",
       "193     27  \n",
       "194     27  \n",
       "195     27  \n",
       "196   2664  \n",
       "197     27  \n",
       "198    191  \n",
       "199     27  \n",
       "200     27  \n",
       "201     81  \n",
       "202     27  \n",
       "203     27  \n",
       "204   1325  \n",
       "205     27  \n",
       "206     27  \n",
       "207     27  \n",
       "208  22790  \n",
       "209     38  \n",
       "210     27  \n",
       "211     27  \n",
       "212     27  \n",
       "213   3445  \n",
       "214     27  \n",
       "215     27  \n",
       "216     38  \n",
       "217     27  \n",
       "218     27  \n",
       "219     27  \n",
       "220     27  \n",
       "221    137  \n",
       "222    892  \n",
       "223     27  \n",
       "224     38  \n",
       "225     27  \n",
       "226     27  \n",
       "227   5341  \n",
       "228     27  \n",
       "229     27  \n",
       "230     27  \n",
       "231     27  \n",
       "232  17643  \n",
       "233     27  \n",
       "234     27  \n",
       "235   1154  \n",
       "236     27  \n",
       "237   1374  \n",
       "238     27  \n",
       "239     27  \n",
       "240     27  \n",
       "241   3168  \n",
       "242     82  \n",
       "243     27  \n",
       "244     27  \n",
       "245     99  \n",
       "246   1055  \n",
       "247   4564  \n",
       "248     27  \n",
       "249     27  \n",
       "250     27  \n",
       "251     27  \n",
       "252     61  \n",
       "253     38  \n",
       "254    313  \n",
       "255     27  \n",
       "256     27  \n",
       "257     27  \n",
       "258     27  \n",
       "259     27  \n",
       "260     27  \n",
       "261     47  \n",
       "262    102  \n",
       "263     27  \n",
       "264     27  \n",
       "265     27  \n",
       "266     27  \n",
       "267    460  \n",
       "268     27  \n",
       "269     27  \n",
       "270     27  \n",
       "271    278  \n",
       "272     27  \n",
       "273     38  \n",
       "274     27  \n",
       "275    118  \n",
       "276    780  \n",
       "277     27  \n",
       "278     27  \n",
       "279     27  \n",
       "280  15553  \n",
       "281     27  \n",
       "282     61  \n",
       "283     47  \n",
       "284     27  \n",
       "285     27  \n",
       "286     99  \n",
       "287     27  \n",
       "288     27  \n",
       "289     27  \n",
       "290   2033  \n",
       "291     61  \n",
       "292     29  \n",
       "293     29  \n",
       "294     27  \n",
       "295    253  \n",
       "296     47  \n",
       "297     27  \n",
       "298     81  \n",
       "299     27  \n",
       "300     27  \n",
       "301    118  \n",
       "302     27  \n",
       "303     29  \n",
       "304    253  \n",
       "305   6719  \n",
       "306     27  \n",
       "307     27  \n",
       "308     27  \n",
       "309   2566  \n",
       "310    802  \n",
       "311     27  \n",
       "312     29  \n",
       "313     27  \n",
       "314     27  \n",
       "315    258  \n",
       "316     27  \n",
       "317     27  \n",
       "318     27  \n",
       "319     27  \n",
       "320     27  \n",
       "321     27  \n",
       "322     27  \n",
       "323     27  \n",
       "324     47  \n",
       "325     27  \n",
       "326     27  \n",
       "327  84087  \n",
       "328     27  \n",
       "329     27  \n",
       "330     27  \n",
       "331     38  \n",
       "332     27  \n",
       "333     27  \n",
       "334     27  \n",
       "335     27  \n",
       "336     29  \n",
       "337   1139  \n",
       "338     27  \n",
       "339   8763  \n",
       "340     27  \n",
       "341     27  \n",
       "342     27  \n",
       "343    811  \n",
       "344   8782  \n",
       "345     27  \n",
       "346     27  \n",
       "347     38  \n",
       "348   2196  \n",
       "349     27  \n",
       "350     27  \n",
       "351     27  \n",
       "352     27  \n",
       "353     38  \n",
       "354     27  \n",
       "355     27  \n",
       "356    869  \n",
       "357    354  \n",
       "358     27  \n",
       "359    893  \n",
       "360     27  \n",
       "361     27  \n",
       "362    183  \n",
       "363     61  \n",
       "364     27  \n",
       "365     27  \n",
       "366   2433  \n",
       "367     27  \n",
       "368     56  \n",
       "369     27  \n",
       "370     27  \n",
       "371     47  \n",
       "372     27  \n",
       "373     27  \n",
       "374   1412  \n",
       "375     27  \n",
       "376     27  \n",
       "377     27  \n",
       "378     27  \n",
       "379     38  \n",
       "380     47  \n",
       "381     27  \n",
       "382     27  \n",
       "383    494  \n",
       "384    118  \n",
       "385   1522  \n",
       "386    845  \n",
       "387     27  \n",
       "388   1161  \n",
       "389     27  \n",
       "390   2511  \n",
       "391     27  \n",
       "392     27  \n",
       "393     27  \n",
       "394     27  \n",
       "395    359  \n",
       "396     81  \n",
       "397     27  \n",
       "398     27  \n",
       "399     27  \n",
       "400    615  \n",
       "401     27  \n",
       "402     38  \n",
       "403     27  \n",
       "404     27  \n",
       "405     27  \n",
       "406    870  \n",
       "407     27  \n",
       "408     27  \n",
       "409    235  \n",
       "410   1190  \n",
       "411     27  \n",
       "412     27  \n",
       "413     27  \n",
       "414    191  \n",
       "415     27  \n",
       "416     27  \n",
       "417   4430  \n",
       "418   8487  \n",
       "419     46  \n",
       "420     27  \n",
       "421  38267  \n",
       "422     75  \n",
       "423   8908  \n",
       "424     27  \n",
       "425     27  \n",
       "426     27  \n",
       "427     81  \n",
       "428     27  \n",
       "429     29  \n",
       "430     27  \n",
       "431  16886  \n",
       "432     27  \n",
       "433     27  \n",
       "434     27  \n",
       "435     27  \n",
       "436     27  \n",
       "437     27  \n",
       "438    681  \n",
       "439    188  \n",
       "440     27  \n",
       "441     27  \n",
       "442     27  \n",
       "443    137  \n",
       "444     27  \n",
       "445   3355  \n",
       "446     27  \n",
       "447     99  \n",
       "448     27  \n",
       "449     27  \n",
       "450     27  \n",
       "451     27  \n",
       "452   6205  \n",
       "453     27  \n",
       "454     27  \n",
       "455    118  \n",
       "456     27  \n",
       "457     27  \n",
       "458     38  \n",
       "459     29  \n",
       "460     27  \n",
       "461     29  \n",
       "462     81  \n",
       "463     27  \n",
       "464    811  \n",
       "465     27  \n",
       "466    898  \n",
       "467     27  \n",
       "468     27  \n",
       "469    942  \n",
       "470   4430  \n",
       "471     27  \n",
       "472     27  \n",
       "473     27  \n",
       "474     29  \n",
       "475   1512  \n",
       "476    196  \n",
       "477   1780  \n",
       "478   4912  \n",
       "479     27  \n",
       "480     73  \n",
       "481     27  \n",
       "482   5286  \n",
       "483     61  \n",
       "484     27  \n",
       "485   1574  \n",
       "486     29  \n",
       "487    934  \n",
       "488    558  \n",
       "489     29  \n",
       "490     27  \n",
       "491     27  \n",
       "492     27  \n",
       "493     47  \n",
       "494     27  \n",
       "495     38  \n",
       "496     27  \n",
       "497     27  \n",
       "498     27  \n",
       "499   5102  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JB99Gw7F9EDe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
